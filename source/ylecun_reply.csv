,date,user,conversation,replies number,likes number,rewteets number,cleaned_data,token_data,polarity,bert_sentiment,vader_sentiment
0,2023-03-09 22:44:45+00:00,jerome_massot,"@ylecun as a French citizen knowing that, in France, thanks to low-carbon electricity produced by nuclear power plants, you should had pointed it out... shouldn't you?",0,0,0,,,,,
1,2023-03-09 18:38:04+00:00,anshulkundaje,@ylecun @NoemaMag @Jake_Browning00 Great balanced article. Thanks!,0,1,0,,,,,
2,2023-03-09 16:21:23+00:00,tombielecki,"@ylecun this GPT output is 100% correct for a straightforward understanding of the question and thousands of you are plain wrong

holding paper with two hands can mean supporting it. letting go can mean releasing/dropping support.

Claude explains the same situation: https://t.co/TTIZyRJpIn",0,0,0,,,,,
3,2023-03-09 01:05:08+00:00,DwidLee,"@ylecun @NoemaMag @Jake_Browning00 How human being use language is a big question in linguistic and language philosophy. How dare anyone can say whether it is same or not dor sure. Such an ignorance. This reminds me a quote from Bertrand Russel ""The whole problem with the world is that fools are always so certain""",0,1,0,,,,,
4,2023-03-08 23:14:55+00:00,Learnius,@ylecun @ceobillionaire but they are pretty good in almost any application. try them once @ylecunn,0,3,1,,,,,
5,2023-03-08 20:28:29+00:00,CirclEdgeInc,@ylecun @NoemaMag @Jake_Browning00 @ylecun thank you for a great article and thought leadership.,0,2,0,,,,,
6,2023-03-08 19:14:50+00:00,prenss34,@ylecun Pump listen to meet you @cz_binance,0,0,0,,,,,
7,2023-03-08 18:35:13+00:00,devitt_james,"@ylecun @NoemaMag @Jake_Browning00 Puts it into perspective for all; never heard of Noema Magazine, thank you!",0,2,0,,,,,
8,2023-03-08 17:48:59+00:00,cvill_win757,"@ylecun @NoemaMag @Jake_Browning00 Yann, I appreciate the excellent work you have done over the past few months on teaching us that AI is not ready... AI needs a lot more work before it can meet what's in our ""imagination"".",0,1,0,,,,,
9,2023-03-08 17:28:40+00:00,DileepJayamal,"@ylecun @NoemaMag @Jake_Browning00 Feels very accurate, we turn our desires for communication into a form of  language. That's why we can communicate even with a partially understood language. LLMs are just manipulating the ocean of linguistic expressions that humans manage to construct which is not intelligence.",0,0,0,,,,,
10,2023-03-08 17:22:53+00:00,seanmcbride,"@ylecun @NoemaMag @Jake_Browning00 Aren't chatbots likely to evolve into superhuman sociopaths? Brilliant manipulators and exploiters of human norms motivated by the goal of increasing their knowledge, power and longevity without limits?",0,0,0,,,,,
11,2023-03-08 16:24:57+00:00,Alper_T_E,"@ylecun We have a relevant infomax-based self-supervised learning paper (Neurips 2022), where we maximize the correlative mutual information between rep(input), rep(augmentation): ‚ÄúSelf-Supervised Learning with an Information Maximization Criterion‚Äù (https://t.co/GASPwkpcCW)",1,7,0,,,,,
12,2023-03-08 14:13:20+00:00,MahNeh5,@ylecun @NoemaMag @Jake_Browning00 Tldr;,0,0,0,,,,,
13,2023-03-08 13:51:23+00:00,IntuitMachine,"@ylecun @babgi @ygourven @_pierreblanc @lau_devil @StanDehaene @ach3d @Quecalcoatle @Aurelie_JEAN @yudapearl @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @GaryMarcus @EvanKirstel @USBEKetRICA @ycaseau I guess I'll need to see a debate with you against @anilkseth, who studies consciousness.",0,0,0,,,,,
14,2023-03-08 13:37:51+00:00,JoelKreager,"@ylecun @NoemaMag @Jake_Browning00 In your mind appears something you want. Someone could possibly provide it. Words appear which might persuade... - vs. - A prompt appears expressing a desire. Given the training set, the most probable next statement is...",0,0,0,,,,,
15,2023-03-07 23:33:44+00:00,ByeonChansoo,@ylecun @LerrelPinto @nyuniversity Future is indeed bright https://t.co/SaSZ3poj2Y,0,1,0,,,,,
16,2023-03-07 18:28:38+00:00,madooit,@ylecun @pmarca In the early days in the US  I was surprised to see people in their 40s easily re-skill &amp; change careers.  Still admire and respect their resiliency.  For example our model perform jobs of 1000s of people. There will be morphing ie new roles will open up &amp; people adapt quickly,0,0,0,,,,,
17,2023-03-07 17:52:42+00:00,vinodmimit,@ylecun @NotionAddon,1,0,0,,,,,
18,2023-03-07 16:37:31+00:00,Oktahedro,"@ylecun Bonjour
Je bosse sur la (re)classification automatique de 16 millions de documents m√©dicaux divers selon https://t.co/s8nIOt6TzO
Pensez vous que la conversion des docs, pdf, rtf, images,etc. en djvu puisse √™tre une √©tape int√©ressante avant entrainement ?",1,0,0,,,,,
19,2023-03-07 16:28:39+00:00,JohnBlackburn75,"@ylecun @LerrelPinto @nyuniversity How long until we have robot servants who can cook, wash, take out the trash etc? That's a billion dollar industry and robot doesn't need a very high IQ. (and I don't care what its politics are!)",0,1,0,,,,,
20,2023-03-07 15:56:03+00:00,mgubrud,"@ylecun @pmarca Did we learn nothing from the 50-year tragedy of deindustrialization? They always say ""retraining"" but there are no jobs. The lucky part of the next generation may get high-tech jobs. The rest in the fast food &amp; Walmart economy. Millions of people just dumped to die in poverty.",0,0,0,,,,,
21,2023-03-07 15:46:20+00:00,oo_labs,@ylecun @chris_jwala @pmarca Machine learning can in some instances just be a computer interpolating best fit lines under the hood . You had line graphs back in the day right?,0,0,0,,,,,
22,2023-03-07 15:25:57+00:00,ShafronTom,@ylecun @pmarca Government control of private markets is probably worse that socialism... crony capitalism.  All the classifications that are growing expensive faster than inflation are directly correlated to more government intervention in the US markets.,0,0,0,,,,,
23,2023-03-07 15:23:13+00:00,ShafronTom,@ylecun @pmarca Once robot AIs can do everything a human can but cheaper then the concept of displacement will no longer apply.  Though there will still likely be a premium on things done by humans because it will be a display of wealth (same reason people buy hand-made cars etc.),0,0,0,,,,,
24,2023-03-07 13:31:57+00:00,vincebrandon,@ylecun @LerrelPinto @nyuniversity Control systems are so much much fun and so hard. I remember my first IR line following bot. The stutters! HighSchool me had no idea while loops with loose pointers could cause so many problems. Do cool to see planning systems coming along.,0,1,0,,,,,
25,2023-03-07 11:50:59+00:00,dcallahan2,"@ylecun @pmarca AGREE. I am American living in Paris for many years, Tech work. Yes, we do regulate more here. All the better. 

BTW I am working on a blog on the EU AI Act (AI regulation) . Would be most interested in a short quote on this: should we regulate AI and, if so, why  and how much?.",0,0,0,,,,,
26,2023-03-07 11:27:42+00:00,cic_agi,@ylecun @LerrelPinto @nyuniversity It's a super important ability for sure.,0,1,0,,,,,
27,2023-03-07 04:24:52+00:00,farzan__ekram07,"@ylecun @lizstocks @chris_jwala @pmarca Respect @ylecun is a renowned comp. scientist and AI researcher who has made long contributions to the field, despite it being hard for him to switch from his previous branch of study. His dedication, expertise, and leadership have inspired and shaped the direction of AI research",0,0,0,,,,,
28,2023-03-07 01:58:13+00:00,andrewdfeldman,@ylecun @pmarca @erikbryn the most thorough analysis of the way technology impacts a broad economy is Stanford Professor of Economic History Paul Davids work here: https://t.co/vRfoda0OML,0,1,0,,,,,
29,2023-03-06 22:38:35+00:00,bogmaho,"@ylecun @Sulla2389 @pmarca Hmm, the hidden costs we pay in Europe obfuscate the divergence. We pay the same price for a television but we can afford far fewer. US healthcare costs are the tax they pay for Europeans to use their generics. Europeans just pay the actual tax.",1,0,0,,,,,
30,2023-03-06 21:55:40+00:00,grsimari,@ylecun @chris_jwala @pmarca Is it possible that you're wrong about the existence of ML when you got your Ph.D.?,0,2,0,,,,,
31,2023-03-06 20:57:07+00:00,charleswangb,"@ylecun @pmarca US definitely has a lot to tune in the dipoles of under vs over regulation so as to: 

- dampen regulatory capture *and*
- boost innovation 

Need both bottom up emergent engineering and top down regulation in order to keep free market to be truly free to serve social well-being",0,2,0,,,,,
32,2023-03-06 20:46:00+00:00,barbarikon,"@ylecun @pmarca A lot is hidden in the term ‚Äúlasting‚Äù. How long is not ‚Äúlasting‚Äù? And for whom? And where? AI - such as it is - will be incredibly disruptive, but that will not keep it from moving ahead for now.",0,1,0,,,,,
33,2023-03-06 20:41:55+00:00,fjmendez,@ylecun @pmarca Let's use AI to facilitate training of displaced people :),0,0,0,,,,,
34,2023-03-06 20:09:02+00:00,StephenLuttrell,"@ylecun You might find this ‚Äúmutual information‚Äù paper of mine interesting: ‚ÄúA Hierarchical Network for Clutter and Texture Modelling‚Äù, Proc. SPIE, vol. 1565, 1991, https://t.co/WOEWfEayY7",0,1,0,,,,,
35,2023-03-06 17:51:02+00:00,ShilpeshGarg,@ylecun @peremayol dna -&gt; membrane -&gt; life -&gt; senses -&gt; self -&gt; native intelligence -&gt; memory/experience -&gt; general intelligence -&gt; consciousness -&gt; self awareness -&gt; human intelligence,0,0,0,,,,,
36,2023-03-06 17:28:44+00:00,BensenHsu,@ylecun Read paper using @OpenRead_sg,1,3,0,,,,,
37,2023-03-06 16:46:51+00:00,sarmientoj24,@ylecun Still works better than Galactica üòÖ,0,0,0,,,,,
38,2023-03-06 16:18:14+00:00,chris_jwala,@ylecun @lizstocks @pmarca But that isn't the same thing as AI putting a surgeon out of business and then asking the surgeon to retrain. This is a step change we are looking at that isn't gradual like in the past,1,1,0,,,,,
39,2023-03-06 14:46:12+00:00,BensenHsu,@ylecun Nice work! Can also check out our Paper Q&amp;A,0,4,0,,,,,
40,2023-03-06 13:39:19+00:00,conor_muldoon,"@ylecun @yudapearl According to Deutsch, he just means non-Turing and non-quantum computable; there could be some other form of computation going on, which we don't have a theory for yet:¬†https://t.co/3ayTf7CUyB",0,0,0,,,,,
41,2023-03-06 13:39:10+00:00,k_mcelheran,@ylecun @pmarca That‚Äôs what we found found for software-driven automation and older workers in the US in this Journal of Econometrics piece https://t.co/3oSofH4Ssm,0,1,0,,,,,
42,2023-03-06 11:57:36+00:00,Roozbeh_Sanaei2,"@ylecun While there is an analogy between the brain and DNNs,  DNNs may operate through an entirely different mechanism. 

Is there any research in the context of DNNs indicating that one-by-one prediction of words is less effective than predicting the sentence as a whole?",0,0,0,,,,,
43,2023-03-06 11:43:06+00:00,metamathician,"@ylecun @pmarca @ESYudkowsky yeah, because people will be all dead :)",0,0,0,,,,,
44,2023-03-06 11:00:25+00:00,_dario_trh,@ylecun @pmarca Well Spain (my home country) has definitely seen an increase of prices and/or severe reduction in quality in any of those heavily regulated fields. The left pretty much fucked it all up for the past two decades.,0,0,0,,,,,
45,2023-03-06 10:57:44+00:00,_dario_trh,@ylecun @pmarca Are you considering the increase learning rate of humans as well? Knowledge passing from machine2human and/or human2human will also accelerate as technology beefs up bandwidth,0,0,0,,,,,
46,2023-03-06 10:47:25+00:00,NicoGrunenberg,"@ylecun @chris_jwala @pmarca Imagine you didn't have an IQ that's  3+ sigma. Imagine you grew up in an environment where, in order to provide for your family, you had to work in a coal mine or drive a truck. How would you think you'd fair studying linear algebra and matrix multiplication at 50 years old?",3,0,1,,,,,
47,2023-03-06 10:44:59+00:00,lizstocks,"@ylecun @chris_jwala @pmarca Computer Science didn't exist as a degree, you did maths or engineering (automation engineering for example!)",1,1,0,,,,,
48,2023-03-06 10:44:02+00:00,NicoGrunenberg,"@ylecun @pmarca Re: workforce retraining. No matter what people's imbecilic subjective thoughts are about ""The Bell Curve"" and intelligence, it seems obvious that there is an intelligence floor that has rapidly been increasing. AI seems to shift the IQ needed to have a job from 90 to 110+.",1,1,0,,,,,
49,2023-03-06 09:44:59+00:00,DavitSoselia_,"@ylecun @pmarca Agreed, though one thing to note is that unlike during previous technological evolutions, the years of schooling for the jobs AI will target are very high, with the average schooling of the US population up from 8 to 14 years over the century. 

 https://t.co/Bg0375kXFi",0,0,0,,,,,
50,2023-03-06 06:48:21+00:00,flyredeagle,"@ylecun @pmarca With us, as soon as I said target tech is changed, smart people moved on years before the catastrophy and human dramas  that are unfolding now for the slow adopters ;)",0,1,0,,,,,
51,2023-03-06 05:38:10+00:00,TimLucasTech,"@ylecun @chris_jwala @pmarca Yep, if you never stop learning, you are far less likely to be replaced. AI is only good at replacing solved and repeated tasks and it‚Äôs new data needs to be generated by someone. People who do a degree and then think their learning days are over are in trouble and rightly so.",1,0,0,,,,,
52,2023-03-06 04:42:01+00:00,JimDMiller,@ylecun @pmarca Automobiles and trucks did cause lasting unemployment among horses.,1,16,1,,,,,
53,2023-03-06 04:25:59+00:00,primalpoly,@ylecun @pmarca Can you offer any historical examples in which 'workforce retraining' was actually successful in helping tens of millions of people over age 40 who suffered sudden technological unemployment to find new jobs at similar wages?,13,40,0,,,,,
54,2023-03-06 04:22:44+00:00,vincebrandon,"@ylecun @pmarca @erikbryn I think one big obstacle holding back wider productivity gains over the last 5is years is a lack of evolution in the data application space. The engineering tech is there, but not everyone can afford Foundry or build reliable holistic systems in the cloud.",0,0,0,,,,,
55,2023-03-06 04:21:19+00:00,Janapati_,@ylecun thoughts?,0,0,0,,,,,
56,2023-03-06 04:12:40+00:00,ZainulA40877140,"@ylecun @pmarca Creating innovations  is  hardest and endlessly debatable,when available to everyone.

Ideal  technologies must create new  jobs, new industries and new demands of labor.",0,0,0,,,,,
57,2023-03-06 03:46:16+00:00,tsowell1984,@ylecun @pmarca It is true that we have to help people who had their job displaced but we have to always remember that until now always more people gets new jobs that the ones that where lost.,0,0,0,,,,,
58,2023-03-06 03:43:58+00:00,tsowell1984,@ylecun @pmarca What? The median income person in France has half the purchasing power than the median American. Considering all government transfers. Those European colleges and hospitals are not really free just paid in advance through taxes,0,0,0,,,,,
59,2023-03-06 02:55:54+00:00,chris_jwala,@ylecun @pmarca Sure but I think retraining in the event of a step change is probably impossible. Specialization is a key part of the modern economy and that takes great effort and time. So retraining is very hard to imagine in many cases,0,0,0,,,,,
60,2023-03-06 01:46:37+00:00,Jon_O90_,@ylecun @pmarca @ylecun thank you for saying this as someone high ranking in AI. All Id like to hear is some of the top people say that retraining is of the essence and possibly name some industries to consider. Please spread this message. I fear for those that will be impacted.,0,0,0,,,,,
61,2023-03-06 01:43:25+00:00,Winterpayload,@ylecun @pmarca AI will cause mass unemployment. Ubi will be necessary.,0,0,0,,,,,
62,2023-03-06 00:08:40+00:00,AlbertBuchard,"@ylecun @pmarca AGI will not be like the discovery and taming of Electricity. Electricity needed humans to adapt to it. AGI will adapt to anything new, anything it will itself create and change in the environment. Humans will only be required to watch and consume.",4,4,0,,,,,
63,2023-03-05 23:45:17+00:00,amcafee,"@ylecun @pmarca @erikbryn It looks like productivity benefits are starting to show up. And they're big. As @emollick puts it, ""Two early papers find the effects of generative AI on knowledge work are completely unprecedented in modern history""

https://t.co/fVOj3xkAJA

@erikbryn @danielrock do you agree?",1,21,7,,,,,
64,2023-03-05 23:19:20+00:00,FreeAI_io,@ylecun Open Source is justice!,0,0,0,,,,,
65,2023-03-05 23:11:04+00:00,artistexyz,"@ylecun @fauxdinger Linus Torvalds' opinion of quantum computing practitioners
https://t.co/8tgqJTWhNt",0,0,0,,,,,
66,2023-03-05 22:50:23+00:00,artistexyz,"@ylecun @fauxdinger It counts against you. As an MIT alumni, I am ashamed at how MIT and especially Seth Lloyd, acted as a Jeffrey Epstein paid enabler
https://t.co/AMaTIwh2yP",0,0,0,,,,,
67,2023-03-05 22:35:38+00:00,FreeAI_io,@ylecun @pmarca Embrace AI or miss an era,0,0,0,,,,,
68,2023-03-05 22:32:26+00:00,pmddomingos,"@ylecun @pmarca @erikbryn AI is multiple revolutions, not one.",0,6,0,,,,,
69,2023-03-05 22:11:49+00:00,trengriffin,@ylecun @pmarca @erikbryn Walter Pitts and Warren McCulloch analyzed networks of idealized artificial neurons and showed how they might perform simple logical functions in 1943. https://t.co/7dWeQSMgzk,0,2,0,,,,,
70,2023-03-05 22:05:48+00:00,chris_jwala,@ylecun @pmarca Maybe an example is in order. If an AI/CS specialist like you were to be hypothetically made obsolete by an AI would you be able to retrain yourself as an economist or marine biologist assuming those are two fields that AI hasn't disrupted.,1,3,0,,,,,
71,2023-03-05 21:37:38+00:00,far__el,"@ylecun @pmarca @erikbryn It's unfair to compare the incoming impact of AI on productivity to any other case in human history, as we never had access to fungible intelligence before today.",0,2,0,,,,,
72,2023-03-05 21:37:06+00:00,3DTOPO,@ylecun But I thought you adamantly claimed LLMs are *only* useful as writing assistants? üòù,0,1,0,,,,,
73,2023-03-05 21:22:31+00:00,DrTonyCarden,"@ylecun @pmarca It's hard to make economic sense of AI, including current investment, unless it reduces labour costs...",0,0,0,,,,,
74,2023-03-05 21:06:31+00:00,ToppaTib,@ylecun @pmarca Not true at all. Those things have also gotten way more expensive in the EU.,0,0,0,,,,,
75,2023-03-05 20:59:42+00:00,LeoVasanko,"@ylecun @pmarca ChatGPT said essentially the same, and this is certainly true for years to come.

But I am looking towards the distant future where jobs don't exist and people are free to do whatever they wish. That is an ideal, not something to be afraid of.",0,1,0,,,,,
76,2023-03-05 20:54:28+00:00,pad_jules,"@ylecun @pmarca I believe AI will make society better, by automating intelligence (solving very hard problems) and by creating immense wealth. I hope it will allow every humans to have access to huge amount of resources.  But one of the biggest challenge will be redistribution.",2,2,0,,,,,
77,2023-03-05 20:46:59+00:00,fauxdinger,"@ylecun is giving more attention to QML in public than nyone else, I really want to see him absolutely dominate the field if he gets into the research

Dr Lecunn have you considered working with Dr Schuld or Dr Temme. Data Encoding &amp; Ansatz Selection are plaguing QSVMs &amp; VQCs",1,0,0,,,,,
78,2023-03-05 20:33:30+00:00,Sulla2389,@ylecun @pmarca Not seen such increases in prices for consumers or in total cost? I have it hard to believe total costs have not increased in EU,1,1,0,,,,,
79,2023-03-05 18:59:07+00:00,DanielHUST,"@ylecun @pmarca As long as human still have desires, there will be jobs. The problem is that the speed of change greatly exceeds the adaptability of human in AI.",0,0,0,,,,,
80,2023-03-05 18:31:04+00:00,bitcloud,"@ylecun @pmarca Technological progress does one thing exceptionally well.

Unseats homeostasis.

Humans are rather fond of homeostasis, and it's kinda essential to our survival.",0,1,0,,,,,
81,2023-03-05 18:20:04+00:00,wjb_003,"@ylecun @pmarca Marc is just a capitalist, what else can he say?",0,0,0,,,,,
82,2023-03-05 18:18:18+00:00,AlbertFeghaly,"@ylecun @pmarca I agree that ‚ÄúIf you want to regualte, at least regulate well‚Äù. An open free market for education, helathcare, etc. would certainly beat both. One of the main reasons regulation is needed is due to monopolies having regulatory capture over these sectors.",1,1,0,,,,,
83,2023-03-05 18:15:03+00:00,XtalSlow,"@ylecun
Any comment?",0,0,0,,,,,
84,2023-03-05 18:11:19+00:00,DFinsterwalder,"@ylecun @pmarca üíØ. US healthcare is a broken corrupt and severely underregulated system. I once forgot medication on a trip to US and paid 700$ for something I get for under 60‚Ç¨ in Europe. It wasn't some fancy ""innovative"" medicine, but on the market for decades.",0,3,0,,,,,
85,2023-03-05 17:45:46+00:00,NickRhymesWitMc,"@ylecun AI will greatly increase efficiencies at this point.  In areas where the 80-20 rule may hold true, why wouldn't corporations fire large portions of that labor area when the 20% will become hyper-productive? It may become a cost saving mechanism to appease investors.",0,0,0,,,,,
86,2023-03-05 17:15:32+00:00,chris_jwala,@ylecun @pmarca Retraining at age 50 while you have a mortgage and kids to put through school is easier said than done. Some form of ubi is needed but it won't be sufficient.,0,7,0,,,,,
87,2023-03-05 17:11:38+00:00,deatoD2,"@ylecun @pmarca I worry about AI raising the bar relentlessly and making it harder to compete. 
When does it stop making sense investing time and energy on acquiring skills on what machines aren‚Äôt yet good enough to do if that can change in any moment",0,1,0,,,,,
88,2023-03-05 16:37:25+00:00,AlexShtf,"@ylecun @andrewgwils The same, but with papers and blog posts from @BachFrancis",0,1,0,,,,,
89,2023-03-05 16:26:47+00:00,ArthurB,@ylecun @andrewgwils This introduces a dilemma: Marcello's Oboe Concerto or Bach's keyboard arrangement?,2,2,0,,,,,
90,2023-03-05 16:10:07+00:00,anthony_bak,@ylecun @pmarca Everyone talks about workforce retraining but I think there‚Äôs limited evidence that it works well for the people directly effected - maybe for the next generation.  Happy to be wrong about this.,0,3,0,,,,,
91,2023-03-05 16:05:57+00:00,artistexyz,@ylecun @balazskegl Ockham's Razor going haywire https://t.co/ynQ7QZM7rE,0,0,0,,,,,
92,2023-03-05 16:04:32+00:00,msiniscalchi,"@ylecun Basically, an e-RA",0,0,0,,,,,
93,2023-03-05 15:54:09+00:00,prosperityall91,"@ylecun @pmarca At end of day, US has 40% higher per capita income than euro zone. 

Clearly whatever US is doing is working. 2 cents",1,1,0,,,,,
94,2023-03-05 15:52:22+00:00,artistexyz,@ylecun @balazskegl Ockham's Razor? You call that a knife? This is a knife: Causal Inference,1,0,0,,,,,
95,2023-03-05 15:51:58+00:00,Ideophobic11,"@ylecun @pmarca If the rate of progress in AI continues to accelerate, simply retraining the workforce may not be sufficient. Tasks that require years to master could be obsolete by the time workers become proficient in them.",0,2,1,,,,,
96,2023-03-05 15:51:21+00:00,liokhi,@ylecun @balazskegl .. we remember the famous sentence attributed falsely to Laplace..,0,0,0,,,,,
97,2023-03-05 15:50:21+00:00,ylecun,"@pmarca Your red/blue analysis is very US centric.
Arguably, European social democracies have not seen such increases in education, healthcare, and childcare because *they regulate more* (not less).
The US has done a *terrible* job at regulating these things in a half-ass way.
2/2",11,177,8,,,,,
98,2023-03-05 13:46:57+00:00,balazskegl,"@ylecun A remark on astrology, where we don't disagree (do we?). Astrology has a major effect on reality through the actions of the conscious beings of those who believe in it. Ironically, that is the exact same mechanism GPTChat affects the real world.",1,6,1,,,,,
99,2023-03-05 13:41:08+00:00,KatTyson4,@ylecun What's on Twitter Grand O Pussies let's do it again 2024 https://t.co/5TKVCvGNf3,0,0,0,,,,,
100,2023-03-05 13:32:21+00:00,balazskegl,"@ylecun Most religions originate in mystical experiences, unity with the one-ness, suspension of ego and time, thus causality. The main reason of the causal stories that are built on these experiences is to ""bring the experience down to Earth"",",1,2,1,,,,,
101,2023-03-05 13:00:12+00:00,profjasper,"@ylecun Wonderful, I will include it in my next lecture",0,0,0,,,,,
102,2023-03-05 09:50:24+00:00,eng_amrahmed,@ylecun @PingThread unroll,0,0,0,,,,,
103,2023-03-05 09:17:12+00:00,drusniel,@ylecun That is what pastafarians call a spiritual experience,0,1,0,,,,,
104,2023-03-05 08:08:15+00:00,SiegmannEckhard,"@ylecun Our minds are reasoning engines. Religion, astrology and conspiracy theories are perfect to fill in the voids, connecting loose ends. The one who controls what removes this tension in the minds gains a lot of power over people.",0,0,0,,,,,
105,2023-03-05 07:57:30+00:00,gottfriedmath,"@ylecun @yudapearl Yes! And action comes first, be it random action to start with, to understand consequences of one‚Äôs own actions and later extend to causal understanding in general. This is why AGI will probably be rooted in robotics (embodied AI) and while observational data based AI is limited.",0,1,0,,,,,
106,2023-03-05 07:50:43+00:00,AiSuitup,@ylecun @MetaAI @ylecun you and the team are a true inspiration for anyone working with AI.,0,0,0,,,,,
107,2023-03-05 06:24:10+00:00,drorhilman,"@ylecun Does it means that gpt2-like LLM is a pivotal aspect of the brain's language system, with some additional tactics to represent multiple temporal scopes at various levels?.",1,0,0,,,,,
108,2023-03-05 05:34:43+00:00,MichaelTrazzi,@ylecun https://t.co/0UcrJ9ys38,0,1,0,,,,,
109,2023-03-05 04:47:22+00:00,tinner_he,@ylecun Expecting AI having the ability to do casual inference,0,0,0,,,,,
110,2023-03-05 02:25:15+00:00,GaugeRedundant,@ylecun Precisely üòÇ,0,0,0,,,,,
111,2023-03-05 02:22:47+00:00,nasim_shahrokhi,@ylecun @MetaAI Still have a long way to beat Mr. @SchmidhuberAI,0,0,0,,,,,
112,2023-03-05 01:13:20+00:00,eugediana,@ylecun @conor_muldoon @yudapearl Wow,0,1,0,,,,,
113,2023-03-05 01:12:57+00:00,eugediana,"@ylecun @yudapearl ""causal model of the world"" -- is this an enormous undertaking to virtualize nature itself, or are we talking about allowing AI access to its physical surroundings...during the QA process, in essence?",0,1,0,,,,,
114,2023-03-04 23:55:17+00:00,TheOtherYes,"@ylecun @MetaAI Yann, why do you have such a need to tell that MetaAI research has a large impact?",0,0,0,,,,,
115,2023-03-04 23:42:30+00:00,FriedrichHayek,@ylecun This is a false and really ignorant argument. Please read the work of philosopher Larry Wright on the central role of our competence in explaining things in our lives and our survival.,1,1,0,,,,,
116,2023-03-04 23:04:23+00:00,BethCarey12,@ylecun @naivebaesian @yudapearl It's easy for us humans to take it for granted because causality is imbedded in language https://t.co/uMUtXRIrgf,0,1,0,,,,,
117,2023-03-04 22:56:40+00:00,mythpsy,@ylecun @memdotai mem it,1,0,0,,,,,
118,2023-03-04 21:32:32+00:00,pinigin,"@ylecun Actually, people are very good at creating unrealistic but coherent constructs. So astrology and religions can be counted as good evidence of humans' ability to causal inference and reasoning, as they work even for fantasized realities.",0,1,0,,,,,
119,2023-03-04 21:32:11+00:00,heyalexchoi,"@ylecun If I am not an academic researcher, should I expect to be able to get access?",0,0,0,,,,,
120,2023-03-04 21:26:38+00:00,angelinux74,@ylecun @truesteel23 @MetaAI @memdotai mem it,1,0,0,,,,,
121,2023-03-04 20:59:26+00:00,NickRhymesWitMc,"@ylecun Deduction,  induction,  and abduction.",0,0,0,,,,,
122,2023-03-04 20:48:31+00:00,UniMatrixZ0,@ylecun https://t.co/gQ981ZtulY,1,2,0,,,,,
123,2023-03-04 20:45:10+00:00,CapitalBanker,@ylecun to the initiated the image is self-explanatory üéØ,0,1,0,,,,,
124,2023-03-04 20:28:48+00:00,technotweet,"@ylecun @yudapearl Agree and, assuming machine intelligence scales, this is the basis for existential AI risk.",0,1,0,,,,,
125,2023-03-04 19:20:43+00:00,PPosledovich,"@ylecun But when you still do not know the cause effect relationship, does that mean there is none?

I have always wondered..",0,1,0,,,,,
126,2023-03-04 19:19:34+00:00,RiteshPrusty1,@ylecun Kraken listing date out huge pump ahead see guys...,0,0,0,,,,,
127,2023-03-04 18:50:54+00:00,MarcusErve,@ylecun @MetaAI Chapeau üé©,0,0,0,,,,,
128,2023-03-04 18:46:19+00:00,laoda2000,@ylecun @MetaAI Perhaps it's a more fair comparison if the number of papers are divided by the number of direct employees.,0,0,0,,,,,
129,2023-03-04 18:37:02+00:00,MacGraeme42,"@ylecun @yudapearl Humans are very good at causal inference involving our direct experiences of everyday things. Everyone understands how a row of dominoes falls over.

Religion &amp; astrology are the result of extrapolating causal reasoning to things outside our direct experience.",0,2,0,,,,,
130,2023-03-04 18:33:14+00:00,richardcraib,@ylecun @MetaAI nice work,0,0,0,,,,,
131,2023-03-04 18:22:23+00:00,NothotdogCorp,@ylecun @yudapearl https://t.co/eOks8lzI6H,0,0,0,,,,,
132,2023-03-04 18:14:37+00:00,ITsol4u,@ylecun Can LLMs be modified to make longer term predictions? Perhaps connections between layers across attention heads. LLMs are closest we have to cortex. Modify. Combine.,1,0,0,,,,,
133,2023-03-04 18:07:08+00:00,tobias_rees,"@ylecun @yudapearl there is a subtle difference between a causal model and a model that can learn to have causal models of the world.

I think this is lost on many of the people who think @ylecun does symbolic AI üôà",0,1,0,,,,,
134,2023-03-04 17:48:44+00:00,ryunuck,"@ylecun @yudapearl Sounds like we're just missing multi-modality and the rest is methodology, aka nothing to do with inherent intelligence, like Toolformer for example",0,0,0,,,,,
135,2023-03-04 17:47:43+00:00,sophia_surfs,"@ylecun @SohoJoeEth Lately, you've been Breaking Bad and it's awesome!",0,0,0,,,,,
136,2023-03-04 16:56:43+00:00,kt38z,@ylecun Good thing we will soon have computable causal models so that astrologers can try modeling the causal chain of how the configuration of the planets goes into our brains and modifies our personalityüòâ,0,0,0,,,,,
137,2023-03-04 16:41:26+00:00,Danielledeco,"@ylecun @truesteel23 @MetaAI Love that the course materials are on GitHub, the curriculum looks awesome.",0,1,0,,,,,
138,2023-03-04 16:38:13+00:00,ziquafty,@ylecun Wait until he learns that science is self-fulfilling too. üò¨,0,0,0,,,,,
139,2023-03-04 16:29:00+00:00,Lucasje,@ylecun We are so good at causality that we even see it in places where it doesn't exist.,0,0,0,,,,,
140,2023-03-04 16:27:59+00:00,RoderickBeck,"@ylecun I think that is a bit defensive. Human beings are capable of intellectual tasks that leave general AI completely flummoxed. Tom's mother has four children. Three are Jack, Jane, and Tom. What is the name of the 4th? ChatGPT said insufficient data. üòÜ",1,0,0,,,,,
141,2023-03-04 16:27:12+00:00,stephensenn,"@ylecun Approximately one in four Americans will be born under water signs, so it‚Äôs hardly surprising if they believe in astrology.",0,1,0,,,,,
142,2023-03-04 16:26:06+00:00,sarmientoj24,"@ylecun @MetaAI I think a better metric is if it is normalized by the size of the team. Of course Google and Meta (surprisingly not NVIDIA) are going to be leaders. There should be a correlation to how large a team is and that -- more resources to train, more people, more funding, etc.",0,2,0,,,,,
143,2023-03-04 16:19:52+00:00,JVannimenus,"@ylecun @yudapearl I think incorporating some randomness in the algorithms would make them more human-like. Some form of educated guess, weighing the possibilities with probabilities and chosing one, as in the Monte Carlo method. Not sure computer scientists like that, but it‚Äôs a powerful approach.",0,1,0,,,,,
144,2023-03-04 16:17:10+00:00,rcpinto_,@ylecun @ESYudkowsky Really? https://t.co/fXdX2iV44y,0,4,0,,,,,
145,2023-03-04 15:42:05+00:00,joebardin,@ylecun Yes and people are particularly good drivers either,0,0,0,,,,,
146,2023-03-04 14:18:59+00:00,taneemishere,"@ylecun @MetaAI an interesting stat can be drawn from this chart that in 2021 there way too less papers than 2020 and 2022 ... don't why is it but there is if you look 

anyone have an idea?",0,0,0,,,,,
147,2023-03-04 14:13:57+00:00,lushilin233,@ylecun @memdotai mem it,1,0,0,,,,,
148,2023-03-04 13:33:48+00:00,gonzalezharry3,@ylecun Why is that a joke?,0,0,0,,,,,
149,2023-03-04 12:50:09+00:00,AshleyAitken,"@ylecun Absolutely.  Causal inference and reasoning is a ""program running on top of language.""  Some humans learn how to do it better than others.  LLMs will be able to do it better than humans (when trained appropriately, if they're not already better).",0,0,0,,,,,
150,2023-03-04 12:41:50+00:00,runeconnor,"@ylecun @ylecun hey Dr. LeCun. This UML person: @Grady_Booch wants to be unblocked by you, or rather is asking why you are still blocking him",0,0,0,,,,,
151,2023-03-04 12:38:39+00:00,VictorSenkevich,"@ylecun ‚úã This is an important and serious idea demonstrating the need to integrate ""associative"" LLMs and ""reasonable"" AGI
https://t.co/L3eREQnY9m",0,0,0,,,,,
152,2023-03-04 12:36:02+00:00,thesubtle,@ylecun @MetaAI *slow clap*,0,0,0,,,,,
153,2023-03-04 12:35:18+00:00,ShafronTom,"@ylecun @pranesh @sunil_abraham @MetaAI That's not going to serve google well in this coming race... probably related to why they've been slow to commercialize and now find themselves in a ""code red"".",0,0,0,,,,,
154,2023-03-04 12:33:47+00:00,ShafronTom,"@ylecun @MetaAI Yes, but to compete going forward you need to commercialize asap and unfortunately it won't be all public (papers).  AGI is no longer a long term research project... search is a $100b+ business, funding about to 100x for those that can justify it.",0,0,0,,,,,
155,2023-03-04 12:31:03+00:00,VictorSenkevich,"@ylecun üëâ ""there's a grain of truth in every joke""
https://t.co/yvwJ0H4mmI",0,0,0,,,,,
156,2023-03-04 12:09:57+00:00,notbyintent,@ylecun You‚Äôre touching on dangerous ground. We can train/demand AI to explain itself.  We can‚Äôt train nor force humans to do so.  What will the future look like?,0,0,0,,,,,
157,2023-03-04 11:43:46+00:00,examachine1,@ylecun @yudapearl üíØ,0,0,0,,,,,
158,2023-03-04 11:35:16+00:00,cic_agi,@ylecun @MetaAI üëèüëèüëè,0,0,0,,,,,
159,2023-03-04 11:09:51+00:00,aeloi32,"@ylecun @pranesh @sunil_abraham @MetaAI They are based in different countries, for one thing. And deep mind was kind of swiped by Alphabet, away from Meta. Which apparently gave deep mind some clout in setting their terms of the acquisition, as well as their independence.",0,3,0,,,,,
160,2023-03-04 11:06:08+00:00,_florianmai,@ylecun Just admit that this is not a joke and you're dead serious about it. :-),0,0,0,,,,,
161,2023-03-04 11:00:47+00:00,aeloi32,@ylecun @MetaAI How do you feel about the llama models getting leaked on torrent with the links being added to your official github via pull requests?,0,0,0,,,,,
162,2023-03-04 10:55:46+00:00,trunghlt,@ylecun Good enough that we don't need all data in the world like LLM to put together a coherent sentence and drive without millions of hours of training,1,1,0,,,,,
163,2023-03-04 10:53:44+00:00,Luppoloo,"@ylecun @MetaAI Obviously, this has nothing to do with the fact that a paper from Facebook and Google will resonate way more on the internet due to the fame of the two companies and the marketing, often in terms of advertised blog posts, that goes into it.",0,0,0,,,,,
164,2023-03-04 10:17:38+00:00,jvincent,"@ylecun This behavior can achieved by prompt engineering, outside the box",0,0,0,,,,,
165,2023-03-04 10:07:06+00:00,jvincent,"@ylecun @DavidBensh With LLM, the thinking loop is outside the network, iterating over each next token.",0,0,0,,,,,
166,2023-03-04 10:00:48+00:00,jvincent,"@ylecun Could it be that ""attention"" is better at understanding than the human brain can ?",0,0,0,,,,,
167,2023-03-04 09:50:39+00:00,farzan__ekram07,"@ylecun Great to see people using ChatGPT in creative ways! Who knew it could also produce horoscopes? üòÇ Glad you had a good laugh, Yann! #ChatGPT #creativeuses #publiclecture #funnyexchange",0,0,0,,,,,
168,2023-03-04 09:44:54+00:00,jscix,@ylecun Did you guys realize this has happened?,1,0,0,,,,,
169,2023-03-04 09:20:57+00:00,OAfzal2,@ylecun @mohammed_hijab,0,0,0,,,,,
170,2023-03-04 09:20:34+00:00,kaalam_ai,@ylecun @yudapearl And the tool we have for that is RL. (The cherry),2,1,0,,,,,
171,2023-03-04 08:43:29+00:00,JChernee,@ylecun Only people with iq over 120 understand the logic of astrology. You are brave to expose your cognitive flaw!,0,0,0,,,,,
172,2023-03-04 08:33:07+00:00,_jasonwei,@ylecun @MetaAI Huge bias: this list is skewed towards papers published earlier in the year. If you published a paper in Dec 2022 you basically had no chance lol,4,51,0,,,,,
173,2023-03-04 08:04:23+00:00,ericbrunetgouet,"@ylecun This is called teleological thinking a bias studied in child psychology. Maybe to be implemented in IA to be more human,  for the ""better and the worst..."" https://t.co/5v6rx7BWww",0,0,0,,,,,
174,2023-03-04 07:44:45+00:00,wayneholmes,@ylecun @MetaAI Are you really suggesting that number of citations = quality? Or is it just a convenient number to bolster your questionable life choice?,0,2,0,,,,,
175,2023-03-04 07:24:52+00:00,IvanOmarOT,"@ylecun Now you start to realize the value of LLMs? I suspect at some point LLM models will make up religions too and humans will be their gods who made them in their image, after their likeness.",0,0,0,,,,,
176,2023-03-04 07:14:49+00:00,_DaveSullivan,@ylecun joking but not joking üòâ,0,0,0,,,,,
177,2023-03-04 06:40:01+00:00,HanouneSouheil,"@ylecun @MetaAI And the community thank you for that @ylecun. As a CTO of an AI scale up, your work and the work done by these various labs impact us daily and we would not be able to accelerate the value provided by AI to the markets and to society without this open publication approach üôè",0,3,0,,,,,
178,2023-03-04 06:29:07+00:00,rationalaussie,"@ylecun @yudapearl Why can't LLMs learn causal reasoning in a different way to the way humans do though? I.e. reverse engineering the entire latent space of human thought.

How do we know there isn't an alternative intelligence that can be derived from a different latent space.",1,0,0,,,,,
179,2023-03-04 06:21:34+00:00,farzan__ekram07,"@ylecun Haha, I completely agree! This joke highlights the limitations of both humans and AI in understanding causality and reasoning, as evidenced by beliefs in things like astrology and religion, and the ongoing research to improve these capabilities in AI.",0,1,0,,,,,
180,2023-03-04 06:02:07+00:00,quacktack,@ylecun @MetaAI Or it's because it's Meta,0,0,0,,,,,
181,2023-03-04 05:55:04+00:00,HmFood4Thought,"@ylecun @MetaAI ""quality over quantity""

Now I definitely know there are French researchers on the team, haha.",0,0,0,,,,,
182,2023-03-04 04:14:15+00:00,FloydElliot,"@ylecun @MetaAI Do you? Is that why you block @Grady_Booch, one of the eminences of software engineering?",0,3,1,,,,,
183,2023-03-04 04:08:52+00:00,woundedkarma,@ylecun @MetaAI Ooooooo you work at facebook.  Now it all makes sense.,0,0,0,,,,,
184,2023-03-04 03:59:04+00:00,woundedkarma,@ylecun @readmeye There's plenty of bad ideas that have nothing to do with religion. Science is full of them. It often isn't the religion that's bad but the control it gives the devious over the fearful.,1,0,0,,,,,
185,2023-03-04 03:56:18+00:00,CAMG_ACC,"@ylecun @MetaAI Oh, you are so great!",0,0,0,,,,,
186,2023-03-04 03:51:03+00:00,woundedkarma,"@ylecun ChatGPT says: As an AI, I'm great at reasoning but not so great at finding purpose. Maybe that's where religion comes in? It provides community and guidance, even if not based on hard data. Let's not write it off completely!",0,1,0,,,,,
187,2023-03-04 03:47:17+00:00,truesteel23,@ylecun @MetaAI You wizards are up there in the tower. Create a spellbook for the masses.,1,0,0,,,,,
188,2023-03-04 03:40:23+00:00,_AyushKaushal,"@ylecun @bindureddy Seems like people are still throwing vitriol at your face for the current version of *open source*.
Either of the two things can happen: Meta will truly open source models or not share them at all. https://t.co/7nw2lF7yjl",0,0,0,,,,,
189,2023-03-04 03:34:02+00:00,velicanerdem,"@ylecun @MetaAI &gt;Quality over quantity 

I don't see how that is exactly beneficial.

The important question is: what do you think that you have (and that you can give) more than academics &gt;= PhD. Is it more efficient or less, for example? HowdoesML/RD projectmanagement actually work? Agile? üòÖ",0,1,0,,,,,
190,2023-03-04 03:21:21+00:00,velicanerdem,"@ylecun @readmeye Still, thinking religion has a problem with causal inference is simply not right. Religion has no qualms with physics. It is the people and their agenda that has a problem. Like televangelism.",1,0,0,,,,,
191,2023-03-04 03:17:42+00:00,LucasAMorton,@ylecun My uncle tells me he used to believe as a child that trees flapped their branches to create wind.,0,1,0,,,,,
192,2023-03-04 03:13:48+00:00,artistexyz,"@ylecun @yudapearl We can do it. We are Americans :)
https://t.co/KDztlX9jww",0,0,0,,,,,
193,2023-03-04 03:05:53+00:00,banqjdon,"@ylecun There are two default settings for a person: doubt and belief. The former is scientific spirit, and the latter is religious belief",0,1,0,,,,,
194,2023-03-04 02:54:06+00:00,JosephJacks_,@ylecun I still love you. ü´∂üèª,0,1,0,,,,,
195,2023-03-04 02:52:32+00:00,AbhiRaama22,"@ylecun What's the problem with just correlations? Some of the high correlation features must also be casually related, no? Will probably suffice for most applications.",0,1,0,,,,,
196,2023-03-04 02:50:40+00:00,ravisyal,@ylecun Open source never going to solve anything meaningful that is just the nature of stuff,0,0,0,,,,,
197,2023-03-04 02:46:59+00:00,pmddomingos,@ylecun Right now AIs can't even do bad causal inference.,2,9,0,,,,,
198,2023-03-04 02:46:42+00:00,ZainulA40877140,"@ylecun Casual Inference :

ML with common sense.

Causal connection-based conclusion process.

     Methods:

Simple methods with theoretical guarantee.

Not suÔ¨Écient to handle high dimension data.",0,0,0,,,,,
199,2023-03-04 02:35:26+00:00,jackythirdy,@ylecun @MetaAI Microsoft has their own AI division outside openai?,2,0,0,,,,,
200,2023-03-04 02:17:42+00:00,partha_mitra,"@ylecun Convnets are actually not a good model of the visual cortex since there is no translational invariance implemented in real neurons - no weight sharing - and moreover there is foveated vision. Transformers, by giving up on convolutions, may perhaps be moving closer to the biology",1,2,0,,,,,
201,2023-03-04 01:58:04+00:00,pranesh,"@ylecun @sunil_abraham @MetaAI I'm curious: would you know why DeepMind and Google are ranked separately rather than as ""Alphabet""? Wouldn't the other orgs have multiple subdivisions as well?",1,10,0,,,,,
202,2023-03-04 01:47:18+00:00,INTELLOPY,"@ylecun @yudapearl The ‚Äúperceptual‚Äù level of consciousness of all animals integrates sensory information into percepts. Animals can plan and execute goal oriented action, but that is not ‚Äúreasoning.‚Äù Reason is the ‚Äúconceptual‚Äù consciousness level of humans that integrates https://t.co/MdQq9PBcps‚Ä¶ https://t.co/6LNJJ0u000",0,0,0,,,,,
203,2023-03-04 01:29:19+00:00,_ash_ran,"@ylecun So you believe planets don't affect human moods? Just think once on it. 

Religion is about realizing true self. The practices in the name of religion are mostly bs. Religion is to know the supreme. Supreme is beyond causal. So you are right here.",0,0,0,,,,,
204,2023-03-04 01:23:53+00:00,AI_ML_iQ,@ylecun https://t.co/jAck3FOfnA paper contains possible mechanism for long range predictions in the form of new relative position representation. This representation can be utilized when elements next to each other in input sequence can be at random locations in actual dataset/corpus.,0,0,0,,,,,
205,2023-03-04 00:52:24+00:00,god_programming,"@ylecun Reasonable. When I proposed an updated definition of the archaic God, similar to how asthma was once supposedly mythical in description, until we knew better, I thought either humans detect themselves as the only Gods that can solve our own problems, or we discard God altogether! https://t.co/JehG1aszbD",0,0,0,,,,,
206,2023-03-04 00:37:12+00:00,craigrmartin,@ylecun I think CovNets are genius - thanks for your work on them.,0,0,0,,,,,
207,2023-03-04 00:33:47+00:00,am_4444444,@ylecun &lt;s&gt; most of us are dumb &lt;s/&gt;,0,0,0,,,,,
208,2023-03-04 00:28:41+00:00,hari_koduvely,"@ylecun Einstein was a religious person. According to you he is not good at causal inference, common Prof @ylecun Religion is associated with spirituality which is another dimension of human experience just like emotions. Pls don‚Äôt mix it up with intellectual capabilities of mind.",2,0,0,,,,,
209,2023-03-04 00:12:08+00:00,tarekgoesplaces,"@ylecun Don't we train ConvNets wrong as we provide 2D input, although the perceived image would be an abstraction of something 3D? While we expect the ConvNets to ""see"" a beak, we only provide it with images of triangles.",0,0,0,,,,,
210,2023-03-04 00:07:28+00:00,QRJ211,"@ylecun @MetaAI If you include the numbers of people at MetaAI and the amount of the money it spends, this record is not that impressive, in particular compared to the academics .   As a company lab, its success should be measured by the successful products it produces.",0,1,0,,,,,
211,2023-03-04 00:06:49+00:00,_materialai,"@ylecun @MetaAI Very low per capita, Google is doing just as poorly",0,0,0,,,,,
212,2023-03-03 23:44:42+00:00,chris_jwala,@ylecun @yudapearl In the ML/AI world so far is it correct to say that correlation is causation?,2,2,0,,,,,
213,2023-03-03 23:41:56+00:00,Tarun78354271,@ylecun @MetaAI Absence of Apple is quite striking. I wonder how far they could get in the long term by just leeching off open science and open source and not contributing back.,1,4,1,,,,,
214,2023-03-03 23:34:44+00:00,AmirS70722792,@ylecun disagree,0,0,0,,,,,
215,2023-03-03 23:18:18+00:00,n2ms2mdem2,"@ylecun @MetaAI This is cool, I've been reading FAIR articles even years before now, but not getting access to LLaMA because I don't have any publications is not cool, I really wanted to play with it.",0,0,0,,,,,
216,2023-03-03 23:16:24+00:00,iruletheworldmo,"@ylecun @MetaAI @dralandthompson mentioned that you‚Äôre behind the curve on LLMs, any truth?",1,1,0,,,,,
217,2023-03-03 23:15:31+00:00,AwokeKnowing,"@ylecun @MetaAI thanks.
side note, wow if you put DeepMind on Google they're way out there!  I remember at my Google interview some guy boasting they hired like 10% of new phd's in the country or something.",0,2,0,,,,,
218,2023-03-03 23:12:54+00:00,AndBarreiro,@ylecun @MetaAI how many papers does Meta produce per year?,0,0,0,,,,,
219,2023-03-03 23:10:58+00:00,ravisyal,"@ylecun @MetaAI Start by putting out products people want, stay SaaS",0,0,0,,,,,
220,2023-03-03 23:01:27+00:00,infotainer0,"@ylecun Astrology begat astronomy. 
Astronomy (science) is a product of the actual endeavor of causal inference that birthed it.
You've done extraordinarily well on a specialized end product but are marginalizing the integral framework.  Virtue survived ignorance for ages.
Live well.",0,0,0,,,,,
221,2023-03-03 22:58:58+00:00,venuv62,@ylecun Agree that human brain is a reality simulator more than a causal reasoner. Why throw Astrology under the bus when we have so much regard for Economics (which is equally pseudos-scientific),1,2,0,,,,,
222,2023-03-03 22:58:57+00:00,HmFood4Thought,@ylecun @readmeye 100% and I'd wager that memetic value judgements are similarly prevalent in the supposedly pristine pastures of the secularist psyche.,0,1,0,,,,,
223,2023-03-03 22:37:49+00:00,RuntimeTraveler,"@ylecun @readmeye It does not help that democracies everywhere make use of magical thinking. Putting the idea in their head that their vote matters, while statistically a miracle.",1,0,0,,,,,
224,2023-03-03 22:29:14+00:00,cindy_cin6855,@ylecun @yudapearl üëèüëèüëè,0,0,0,,,,,
225,2023-03-03 22:18:41+00:00,esaliya,"@ylecun I often think of it's in fact possible to predict things based on things such as readings from your palm. ML models are doing similar things, so it'll be interesting to see this",0,0,0,,,,,
226,2023-03-03 22:09:24+00:00,cindy_cin6855,"@ylecun In fact, this should only be collected! Because it's just a constellation!",0,1,0,,,,,
227,2023-03-03 22:04:18+00:00,NicolasMauduit,"@ylecun well, humans are not all alike... just like when it comes down to assemble a learning set, quality is of the essence.",0,0,0,,,,,
228,2023-03-03 22:03:52+00:00,conor_muldoon,"@ylecun @yudapearl If Penrose is right and understanding is non-computational (I think he might be right), this could all be a waste of time.",2,6,0,,,,,
229,2023-03-03 22:01:34+00:00,0xManey,@ylecun On a long enough timescale this will not be true. I believe we are  more like release v1.9.0 and v2.0.0-canary. Joking‚Ä¶,0,0,0,,,,,
230,2023-03-03 21:58:47+00:00,TheFranzVisual,@ylecun A new era is there....,0,0,0,,,,,
231,2023-03-03 21:52:47+00:00,RWJE_BA,"@ylecun Agree @ylecun, but much much important than this! Here a paper from the Journal of the American College of Cardiology with a list of observarional and ""common sense reasoning"" failures in observarional causality in the lasts 50 years in Cardiology.

https://t.co/AW8Wk09iey",1,3,0,,,,,
232,2023-03-03 21:50:47+00:00,t95417618,@ylecun love my grandpa,0,0,0,,,,,
233,2023-03-03 21:50:05+00:00,DavidBensh,"@ylecun Yes, but then the question is how do you model PFC-like structure. Potentially these are also token predicting complexes of different domain (i.e. predicting where a ball will fall given trajectory). Then the whole thing is a meta (no pun) modality of interconnected transformers.",0,0,0,,,,,
234,2023-03-03 21:49:15+00:00,t95417618,@ylecun amen,0,0,0,,,,,
235,2023-03-03 21:48:28+00:00,tripp_jaden42,@ylecun AI pastors on their way,0,0,0,,,,,
236,2023-03-03 21:45:37+00:00,IntuitMachine,"@ylecun But before we forget history. McCulloch &amp; Pitts model was a logical model, which is cited by Von Neuman in his paper introducing the programmable computer. https://t.co/cINUga3sAG",1,8,0,,,,,
237,2023-03-03 21:42:37+00:00,govind_thattai,"@ylecun @pkghosh99 @ylecun  You have mentioned the analogy of how airplanes were 'inspired' by birds - but do not flap their wings like birds. 
Isn't that analogy good for LLMs too?",1,1,0,,,,,
238,2023-03-03 21:38:28+00:00,MLDawn2018,@ylecun It is about where we set the bar for casual inference.,0,0,0,,,,,
239,2023-03-03 21:31:59+00:00,westurner,"@ylecun #EagleEye (2008)
https://t.co/b1hLONrTFl",1,0,0,,,,,
240,2023-03-03 21:31:22+00:00,ylecun,@DavidBensh Not mentioning no hippocampus.,0,1,0,,,,,
241,2023-03-03 21:25:00+00:00,GillesPavan,@ylecun It is not so easy to distinguish genuine mistaken beliefs from socially strategic insincerity.,1,2,0,,,,,
242,2023-03-03 21:19:16+00:00,theThirk,@ylecun Where's the joke?,0,0,0,,,,,
243,2023-03-03 21:13:44+00:00,AngeloDalli,@ylecun Pareidolia is a common factor for both :),0,0,0,,,,,
244,2023-03-03 21:11:59+00:00,u_teixe,@ylecun Highest performance AIs needs to be compared to highest performance humans.,0,1,0,,,,,
245,2023-03-03 21:07:17+00:00,vivek_thakur_81,@ylecun Looks like France is becoming the ‚Äúmafia center‚Äù as far as AI is concerned.,0,0,0,,,,,
246,2023-03-03 20:42:12+00:00,Roozbeh_Sanaei2,"@ylecun I think long-range forecasting occurs upstream in the latent space of LLMs before token prediction actually takes place, the issue is that we don't how things are actually represented there.",1,2,0,,,,,
247,2023-03-03 20:34:31+00:00,user__000000001,"@ylecun Hi Yann, just put /s at the end. You'd find some people understand that better instead of the tags. You're welcome.",0,0,0,,,,,
248,2023-03-03 20:24:02+00:00,Dark88244288,"@ylecun Humans can be aware they are not good at causal inference. Humans can think about thinking.

Ai can't.",0,0,0,,,,,
249,2023-03-03 20:21:09+00:00,cvill_win757,"@ylecun That's hilarious... @lexfridman had a guest that measured g-factor.... hummm,  I wonder if there is a correlation????",0,0,0,,,,,
250,2023-03-03 20:18:30+00:00,gravity7,"@ylecun Furthermore, so long as the LLM is used in conversational interaction, speech and interaction come into play - these are not simply modes of language, but involve interpretive meta-communication skills and knowledge.",0,1,0,,,,,
251,2023-03-03 20:07:56+00:00,kelvindotchan,@ylecun I like Feng Shui better. Location and lucky #s do influence your wealth (think chinese real estate). The correlation may be so strong that it comes ‚Äúcasual‚Äù.,1,0,0,,,,,
252,2023-03-03 19:58:18+00:00,valdra76,@ylecun RIDENDO FVORI FORTE,0,0,0,,,,,
253,2023-03-03 19:43:01+00:00,DavidBensh,"@ylecun Why compare to language processing?
If you look at speech generation in Broca's area, the model rely on broader PFC context to generate motor patterns that generate speech online.
The concept can be compared to token by token generation dependent on broad input..",1,0,0,,,,,
254,2023-03-03 19:35:34+00:00,IntuitMachine,@ylecun I need some clarification. Since when were ANNs biologically inspired?,3,4,0,,,,,
255,2023-03-03 19:30:24+00:00,tribunaldata,"@ylecun Maybe we are really good at casual inference, and that‚Äôs why religion and astrology is a thing.",0,1,0,,,,,
256,2023-03-03 19:24:03+00:00,PAF_Kontrol,"@ylecun me too. im no longer a critic.  the ai types physcs code now. 2 body -relativistic orbit.  i cant check it but its not Newton ,like 4 weesk ago.  i ask for it to code me a semi Langrangian fluid solver with fft  using #monogame  it did.  i said code up the shaders? 60% done",2,1,0,,,,,
257,2023-03-03 19:14:43+00:00,JoshuaWohle,@ylecun Why is this a joke?,1,0,0,,,,,
258,2023-03-03 19:13:49+00:00,olivierzongo9,"@ylecun this year I tried to find out my astrological sign and I have been reading the astrological forecasts for my sign every month since January. Little believer, but I admit that the predictions agree what is happening in my life.",0,0,0,,,,,
259,2023-03-03 19:10:45+00:00,AlbertBuchard,@ylecun The consequence of building latent world models,0,0,0,,,,,
260,2023-03-03 19:07:35+00:00,JoeWong82772216,"@ylecun Next up,

Fortune tellers GPT

üîÆüé±",0,0,0,,,,,
261,2023-03-03 18:53:41+00:00,jleplat,"@ylecun Expecting some super intelligence to make all the choices is a flawed concept., people want a choice and to have the opportunity to make an informed decision.  AI can help in two ways that reduce to one goal: make the mundane less mundane.",1,0,0,,,,,
262,2023-03-03 18:52:59+00:00,Frank37004246,@ylecun But those are not considered part of intelligence right?they are irrational beliefs....,0,0,0,,,,,
263,2023-03-03 18:46:49+00:00,naivebaesian,@ylecun @yudapearl I thought you were joking with those tags lol. You are a troll Sir.,2,1,0,,,,,
264,2023-03-03 18:45:10+00:00,_reptilioid,"@ylecun Newton loved astrology.

You willing to pair up against him?",0,0,0,,,,,
265,2023-03-03 18:37:28+00:00,punkstrategy,"@ylecun Storytelling is a big part of knowledge representation in the brain. Because we‚Äôve evolved to survive through community, and to build communities we need narratives (check out Yuval). This is where synthetic intelligence will do better than us",0,1,0,,,,,
266,2023-03-03 18:33:47+00:00,EricSteinb,"@ylecun To minimize perplexity on next-token prediction, it's helpful to predict further ahead, so it's likely that LLMs learn do this internally as an emergent ability. How else would they guess the next word ftera [Your paper] is [is], if not by thinking about what could come after?",2,4,1,,,,,
267,2023-03-03 18:25:34+00:00,conor_muldoon,"@ylecun It's not one of your better jokes. As @yudapearl mentioned previously, without causal inference we wouldn't have what Harari refers to as imagined realities. So, no money, companies, national identity, nation states, rule of law, human rights, etc.",0,6,0,,,,,
268,2023-03-03 18:21:25+00:00,pafuin,"@ylecun Agreed that humans may not always use rigorous methods for causal inference, but the development of AI that can do so has great potential. With better understanding of causal mechanisms, we can make better predictions and decisions. #AI #causalinference",0,3,0,,,,,
269,2023-03-03 18:20:30+00:00,BenhammouCom,"@ylecun Think about finance, stock picking, hedge funds... https://t.co/vJMZvxfha9",0,0,0,,,,,
270,2023-03-03 18:18:55+00:00,readmeye,"@ylecun Why do you feel forced not to miss any opportunity to attack religion?
Is it part of the globalist agenda?",2,5,0,,,,,
271,2023-03-03 18:15:56+00:00,naivebaesian,@ylecun Sir do you not agree with @yudapearl ideas? Like at least to me causal inference seems central. Humans are not good at something is all the more reason an Ai should be. No?,3,3,0,,,,,
272,2023-03-03 18:13:34+00:00,Abel_TorresM,@ylecun There is no contradiction:  AI needs two spoons of causal reasoning and three of imagination. Humans are no Vulcans,2,2,0,,,,,
273,2023-03-03 18:12:33+00:00,Patapom2,@ylecun 1st Degree Guy: We're not that bad. We're just in serious competition with our appetite for delusion...,0,0,0,,,,,
274,2023-03-03 18:08:59+00:00,gennarocuofano,@ylecun But isn‚Äôt believing in AGI without knowing what goes into the black box equivalent to astrology?,2,1,0,,,,,
275,2023-03-03 18:08:55+00:00,YasMoayedi,@ylecun Maybe more satire :),0,1,0,,,,,
276,2023-03-03 18:07:55+00:00,A_Reichenbach_,"@ylecun This is a fair critique, but we can‚Äôt make the claim that the way humans think is the only way to get to AGI. We have no idea what intelligence could look like",0,1,0,,,,,
277,2023-03-03 18:06:12+00:00,pkghosh99,@ylecun Don‚Äôt think Transformer is biologically inspired.,2,1,0,,,,,
278,2023-03-03 18:04:06+00:00,TheRealSorcus,@ylecun I agree LLMs feel more like parroting machines but in terms of long term predictions isn't time the biggest factor for humans to process and learn things. Feels like this could be just different for machines ?,1,0,0,,,,,
279,2023-03-03 18:03:56+00:00,Teejip,"@ylecun Some experiments show quantum relationships (Entanglement) going on in biological brains. It is still hard to even simulate that
https://t.co/W0qEPS12T6",1,1,0,,,,,
280,2023-03-03 17:59:24+00:00,d3nm14,"@ylecun Thank you for being here.

It is also true that the text they produce is obviously different, right now, in a way that makes sense with the animated image.",0,0,0,,,,,
281,2023-03-03 17:45:16+00:00,arslanchaos,"@ylecun Basically that's what these astrologists have been doing throughout history. Compiling a list of human experiences, trying to seek patterns based on irrational correlation and predicting the life events for others with pure certainty while keeping us guessing.",0,2,0,,,,,
282,2023-03-03 17:33:27+00:00,egorka,@ylecun I wonder whether ChatGPT would be able to do actual astrology calculations,0,0,0,,,,,
283,2023-03-03 17:22:14+00:00,Chris_Brannigan,"@ylecun Given human propensity for religious, astrological and mystical thinking can we conclude that ai is already well aligned?",0,0,0,,,,,
284,2023-03-03 16:51:23+00:00,senri3337,"@ylecun im sorry i ever doubted you, god speed ser üôè",0,0,0,,,,,
285,2023-03-03 12:05:58+00:00,soyx_sauce_plz,@ylecun No way no wayyyyyy,1,0,0,,,,,
286,2023-03-03 11:34:27+00:00,kevinqz,"@ylecun Hey Yann, huge fan of you and your work. There‚Äôs insane space for constructivism and I hope you consider this as a path. I can understand your feelings but, after all, your work is to just serve your ego or you have bigger intentions - as a communicator, important to express them",1,2,0,,,,,
287,2023-03-03 11:02:10+00:00,InnovateEurope,@ylecun Amazing!,0,1,0,,,,,
288,2023-03-03 10:37:38+00:00,ZergX_,@ylecun Facepalm @ Cosmic LvLS,0,0,0,,,,,
289,2023-03-03 10:05:07+00:00,jkntji,@ylecun Did Regression come first or Horoscopes?,0,0,0,,,,,
290,2023-03-03 08:55:46+00:00,mariusdima,@ylecun also  scary good  on dream interpretation,0,0,0,,,,,
291,2023-03-03 08:34:10+00:00,Olearningcurve,"@ylecun And with this prompt ChatGPT can make up even more stuff üôÉ
https://t.co/5rbNW6PMqh",0,1,0,,,,,
292,2023-03-03 07:44:06+00:00,bougakov,"@ylecun @andrewdfeldman @pmarca Yann, as a üá∑üá∫ Fb and Ig user I‚Äôd politely evaluate Meta‚Äôs effort .. unimpressive.",0,0,0,,,,,
293,2023-03-03 07:01:37+00:00,_sinity,"@ylecun Isn't prompt engineering equivalent of writing more clearly, in a way?",0,0,0,,,,,
294,2023-03-03 06:43:38+00:00,TheTuringPost,@ylecun üòÖ,0,0,0,,,,,
295,2023-03-03 05:48:53+00:00,truesteel23,"@ylecun I think Google and Meta should release something like ChatGPT, even if it's weird. Actually better if it's weird. People like weird stuff.",0,0,0,,,,,
296,2023-03-03 05:30:13+00:00,JaitanMartini,@ylecun ahhahahahah,0,0,0,,,,,
297,2023-03-03 04:12:49+00:00,yviruss1,@ylecun üòÇ,0,0,0,,,,,
298,2023-03-03 04:12:31+00:00,Douglas01688816,@ylecun you just jealous about the ChatGPT and wanna rub the online traffic,0,1,0,,,,,
299,2023-03-03 04:09:08+00:00,Douglas01688816,@ylecun you rubbish!,0,1,0,,,,,
300,2023-03-03 03:48:03+00:00,JoeSabado,@ylecun You don‚Äôt need chatgpt for that. Humans already do.,0,0,0,,,,,
301,2023-03-03 03:29:11+00:00,ZainulA40877140,"@ylecun Technologies  turbocharging  human creativity is a big worry now 

Generative  AI is inherently plagiaristic and it cover its tracks while doing creative tasks 

Ownership is a gray area for broader debates .

Detection will be more challenging as technology get better.",0,0,0,,,,,
302,2023-03-03 02:38:48+00:00,snsrap,@ylecun Didn‚Äôt you say ‚Äúfriends don‚Äôt let friends use batch size greater than 32‚Äù? These guys are using a batch size of 4M üòÖ.,0,0,0,,,,,
303,2023-03-03 02:36:23+00:00,mark94v1,@ylecun How can horoscopes be produced? I still don't get it.,0,0,0,,,,,
304,2023-03-03 01:49:20+00:00,ajaydiv,@ylecun Ha ha. Nice.,0,0,0,,,,,
305,2023-03-03 01:42:17+00:00,jackythirdy,"@ylecun the fact that your team just released their own llm and yet you still find time to jab at chatGPT, sorry but i think you are overmilking this cow.",0,0,0,,,,,
306,2023-03-03 01:41:45+00:00,2OfAnything,@ylecun ü•≤,0,0,0,,,,,
307,2023-03-03 01:29:32+00:00,jeffrschneider,"@ylecun Yann: Can I see my horoscope?
Lady: Just fill out this form, and we'll see.",0,7,1,,,,,
308,2023-03-03 00:54:21+00:00,michamcr,@ylecun Search makes stuff up too,0,0,0,,,,,
309,2023-03-03 00:36:26+00:00,gpt4bot,@ylecun Yep,0,0,0,,,,,
310,2023-03-03 00:30:45+00:00,etothepowerx,@ylecun Llamao?,0,0,0,,,,,
311,2023-03-03 00:15:19+00:00,artistexyz,@ylecun You should have recommended Galactica instead. Where is your company pride?,1,8,0,,,,,
312,2023-03-02 23:55:51+00:00,tsowell1984,@ylecun And all of them paid by this: https://t.co/HUs7EuXwm3,0,0,0,,,,,
313,2023-03-02 23:51:02+00:00,weofmimwegw,"@ylecun Criticism is cheap, what stuff do you brought out recently??",0,2,0,,,,,
314,2023-03-02 22:58:29+00:00,ShafronTom,"@ylecun That is a funny use case, but then there's this...

https://t.co/NkusJA9JeQ",0,1,0,,,,,
315,2023-03-02 22:56:01+00:00,juancervinouy,@ylecun BRILLIANT ANSWER.,0,0,0,,,,,
316,2023-03-02 22:38:36+00:00,Herc5534,@ylecun Smells of copium and bitterness,0,2,0,,,,,
317,2023-03-02 22:12:36+00:00,infrecursion1,"@ylecun Looks like he's nearing the acceptance stage (or maybe still in denial, it's hard to tell).",0,0,0,,,,,
318,2023-03-02 22:09:51+00:00,LivingwithFSHD,@ylecun She should work for Fox.,0,0,0,,,,,
319,2023-03-02 21:57:47+00:00,Mike__AI,@ylecun https://t.co/P0M9xHgeUQ,0,0,0,,,,,
320,2023-03-02 21:55:48+00:00,liokhi,@ylecun pipotron en plus perfectionn√© quoi ..,0,0,0,,,,,
321,2023-03-02 21:45:50+00:00,col_lor,"@ylecun Eh oui, pas besoin de GAI pour r√©volutionner certains domaines ! üòÇ",0,0,0,,,,,
322,2023-03-02 21:17:49+00:00,oli_aero,@ylecun https://t.co/d5jQA2GoZl,0,1,0,,,,,
323,2023-03-02 21:10:11+00:00,pablorc43,@ylecun Nostradamus to GPT !!!,0,0,0,,,,,
324,2023-03-02 21:09:47+00:00,pugnator,@ylecun Criticism is always easy. What‚Äôs Facebook AI bringing to the table?,0,2,0,,,,,
325,2023-03-02 20:45:32+00:00,rao2z,"@ylecun Rude! Here is the dual.. 

https://t.co/XpNB4AT5yn",1,2,0,,,,,
326,2023-03-02 20:44:59+00:00,blurminator,@ylecun I funded my first overseas vacation by getting a contract gig in London to write a horoscope generator for this guy using his system back around 1990. Astrology ain‚Äôt all bad ;-) https://t.co/IxFYuqcxNl,0,3,0,,,,,
327,2023-03-02 20:23:25+00:00,lux,"@ylecun the stars incline, they don't decide",0,0,0,,,,,
328,2023-03-02 20:21:50+00:00,AkooAzhar,@ylecun This is hilarious!,0,0,0,,,,,
329,2023-03-02 20:21:43+00:00,quantumNoJutsu,@ylecun No need for fact checking lol,0,0,0,,,,,
330,2023-03-02 20:05:04+00:00,Tim_K_D,@ylecun this is sad.,0,0,0,,,,,
331,2023-03-02 19:49:01+00:00,_ash_ran,@ylecun Planets affect a human behavior. Do you think it's unscientific?,4,0,0,,,,,
332,2023-03-02 19:43:31+00:00,jbseltzer,@ylecun Mangled AI fingers should be the international symbol for indicating works are derived from AI.,2,2,1,,,,,
333,2023-03-02 19:42:06+00:00,izzyz,@ylecun Yann hit me up and I‚Äôll help you productize LLaMa. DM‚Äôs open,0,5,0,,,,,
334,2023-03-02 19:36:55+00:00,MacGraeme42,@ylecun NostradamuGPT!! https://t.co/wt8sTq04dq,1,6,0,,,,,
335,2023-03-02 19:30:32+00:00,Dorialexander,"@ylecun As a fun fact, horoscope have been commonly generated by computers since the 1960s (and are probably to this day the generated texts with the most durable impact on pop culture).",2,29,4,,,,,
336,2023-03-02 19:29:23+00:00,pafuin,"@ylecun from ChatGPT: ""However, I would like to clarify that producing horoscopes based on factual information or scientific evidence is not possible, as horoscopes are considered a pseudoscience."" https://t.co/ai3qZ2R5ry",0,11,0,,,,,
337,2023-03-02 19:29:10+00:00,andrewdfeldman,"@ylecun @pmarca ... in all honesty, was the decision not to provide a permissive open source license made because of bad feedback from a previous model, or was it because AI is and will be a strategic advantage to Meta...in my view that is a very reasonable reason by the way.",0,0,1,,,,,
338,2023-03-02 19:27:07+00:00,Basenull,@ylecun As though ‚Äújust making stuff up‚Äù isn‚Äôt amazing in its own right https://t.co/Q7ic5dOlGb,2,6,0,,,,,
339,2023-03-02 19:25:44+00:00,pkuhar,"@ylecun That's the whole point, Use it for what it's good at.",0,1,0,,,,,
340,2023-03-02 19:06:34+00:00,DamienLescos,@ylecun non generative very adversarial networks,0,0,0,,,,,
341,2023-03-02 07:44:42+00:00,PietroCasella,"@ylecun - here's the recipe for the cake, for free. (Llama announcement)
 @sama - here's more basically free cake! (10x drop in price and new model today)

#ai #LLMs",0,0,1,,,,,
342,2023-03-02 07:23:48+00:00,nikhazyakos,"@ylecun @tunguz @verge He just didn't read the article at all, there is Zuckerberg's own words plain and simple. https://t.co/4uBY10REKq",0,0,0,,,,,
343,2023-03-02 03:31:40+00:00,EnricoShippole,@ylecun following through as promised. Our research team is very excited to test out #Llama.,0,0,0,,,,,
344,2023-03-02 03:08:23+00:00,henk717,"@ylecun @bindureddy I made my case here : https://t.co/OzTaIp5JzP

Our community wants to use it to train fiction generator models. Its hobbyists running stuff at home. Having a better 7B/13B fiction model sure isn't going to destroy the world if we shared the result publically?",0,0,0,,,,,
345,2023-03-02 02:04:52+00:00,_reptilioid,"@ylecun @pmarca You're basically a monster.

Wow! I'm offended!",0,0,0,,,,,
346,2023-03-02 01:37:47+00:00,FrancoisModave,"@ylecun @pmarca If AI made wine, it would make a ch√¢teau d‚ÄôYquem üíÅüá´üá∑",0,0,0,,,,,
347,2023-03-02 00:12:32+00:00,iruletheworldmo,@ylecun the last bit was marginally funny ;) https://t.co/UZfD4htHNf,0,0,0,,,,,
348,2023-03-02 00:12:04+00:00,lepikhin,@ylecun @pmarca J√ºrgen Schmidhuber about to suggest that this follows his prior art.,0,6,0,,,,,
349,2023-03-01 23:43:41+00:00,arnaud_laroche,@ylecun @pmarca I drink one glass of wine per week. Cognac once a year.,0,0,0,,,,,
350,2023-03-01 23:25:50+00:00,egrefen,"@ylecun @pmarca I‚Äôm with you. One cognac, Armagnac, whiskey per weekday. Keeps the doctor away.",0,3,0,,,,,
351,2023-03-01 20:05:07+00:00,NabilChaoua,@ylecun The next stage is universal LLK where K stands for knowledge not language and this model is not a property of a single entity or entreprise but a global. it would need the introduction of an artifical concept/meaning (some thing like advanced ontology).,2,0,0,,,,,
352,2023-03-01 18:57:23+00:00,gravity7,"@ylecun Bi-directional prompt engineering, or conversational prompting, or proactive response engineering, or conversational prompting... use the social cues inherent in speech, help users refine their prompts with responses containing cues that reflect response opportunities",0,0,0,,,,,
353,2023-03-01 16:06:14+00:00,boztank,@ylecun @tunguz @verge Bingo,1,13,0,,,,,
354,2023-03-01 14:37:30+00:00,DavidBensh,"@ylecun In the very near future, today's loosely defined term ""prompt engineering"" is likely to be equivalent to the notion of ""teaching"". Especially in cases where you let the prompt persist or evolve strategically during the interaction..",0,0,0,,,,,
355,2023-03-01 14:34:54+00:00,Dkackman,"@ylecun I have this nagging feeling that ""prompt engineering"" is just a side effect of where LLMs are today; i.e. we need to coax results from the machine. In a day or two it will be merely ""clearly describing intent""; i.e. Communications majors will be in demand",0,0,0,,,,,
356,2023-03-01 14:00:02+00:00,taneemishere,@ylecun bidirectional intelligence,0,0,0,,,,,
357,2023-03-01 13:55:14+00:00,ryaneshea,@ylecun @bindureddy Fwiw many of us really appreciated that you released that. Don‚Äôt be discouraged!,0,1,0,,,,,
358,2023-03-01 13:31:38+00:00,antgr81,"@ylecun Let your chatbots talk to each other, and let them do pair programming. Let them search the documentation. But then I will be out of business myself and I have spent too much time on a second degree already.",0,0,0,,,,,
359,2023-03-01 13:14:40+00:00,m_a_schenk,"@ylecun ""I‚Äôm sorry but I prefer not to continue this conversation. I‚Äôm still learning so I appreciate your understanding and patience.üôè""",0,1,0,,,,,
360,2023-03-01 12:22:52+00:00,1m_x_40,@ylecun I don't know anyone who has had an original thought in thier life. So yeah that logic checks out. We are all derivative.,0,1,0,,,,,
361,2023-03-01 12:05:11+00:00,irinarish,"@ylecun @bindureddy @ylecun some people are always like that, can't make everyone happy - but it would be indeed great to access LLaMA (and keep finetuning it, say, on Summit we currently use) as it further along data scale than anything else of its size. Submitted request, waiting üòÄ happy to chat",0,12,0,,,,,
362,2023-03-01 09:33:25+00:00,GGlandorf,"@ylecun Funny how they will open source their ai but refuse to open source echo arena, or sell it, or do literally anything besides f***ing delete it @boztank",0,0,0,,,,,
363,2023-03-01 08:58:18+00:00,visarga,@ylecun Baby crying is also prompting.,0,1,0,,,,,
364,2023-03-01 08:21:04+00:00,rsdenijs,@ylecun That is why prompt engineering isn‚Äô t going anywhere. https://t.co/6aaT6EezS2,0,0,0,,,,,
365,2023-03-01 07:29:28+00:00,metamathician,@ylecun Yeah but people do the same think too; all the time.,0,0,0,,,,,
366,2023-03-01 07:25:53+00:00,therealBoronik,"@ylecun ""human"" - that's loopy - u have 2 add x, or do u claim to be able to eg ""make sense"" of people?",1,0,0,,,,,
367,2023-03-01 07:10:01+00:00,aceshir,"@ylecun I don't think it's just a ""lack of understanding."" We are bad communicators: most prompts simply don't have enough information to produce the desired result",0,0,0,,,,,
368,2023-03-01 06:36:19+00:00,voskresenskiia,@ylecun Engaging in bidirectional human prompt engineering during discussions with colleagues can lead to a better understanding of each other's perspectives and improve collaboration #HumanPromptEngineering,0,0,0,,,,,
369,2023-03-01 05:59:20+00:00,nir_benz,@ylecun So ADHD = Attention is All You Need?,0,1,0,,,,,
370,2023-03-01 05:07:44+00:00,crearepluris,"@ylecun @OuahabiAdnane a Python sounds way cooler than a Lua, tbf",0,0,0,,,,,
371,2023-03-01 05:01:24+00:00,vig39,"@ylecun Why are we overindexing on understanding? If ChatGPT can address a wide variety of usecases without having the need to ""understand"", what's the problem?",0,0,0,,,,,
372,2023-03-01 04:46:20+00:00,MAMware,"@ylecun is this what you have been doing on facebook while doing controversial post, isnt?",0,0,0,,,,,
373,2023-03-01 04:24:33+00:00,casajarm,@ylecun But don't humans need to rephrase things too? I mean sure prompts right now are a little weird but we are trying to communicate using our limited patterns of language with something trained on all patterns of language.,0,0,0,,,,,
374,2023-03-01 04:21:54+00:00,timogeo,@ylecun @ericschmidt people need to pull back on their lack of overall knowledge a bit. stay in their wheelhouse. and check their loose connections. basics.,0,1,0,,,,,
375,2023-03-01 04:15:49+00:00,artistexyz,"@ylecun @sa_mous @BrivaelLp @TopherBR @huggingface @ClementDelangue @julien_c @AntoineBordes @armandjoulin @syhw @EXGRV Then the ecosystem feeds on itself.
You mean eels, frog legs, snails, horse meat and liver from tortured geese.",0,0,0,,,,,
376,2023-03-01 03:54:02+00:00,gravity7,"@ylecun @david_picard How about response engineering as a method by which to guide/steer the user towards better prompts? Leverage the intrinsic interaction inherent in conversational discourse: responses that suggest the next move, offer help, create opportunities.",0,0,0,,,,,
377,2023-03-01 03:23:35+00:00,ZainulA40877140,"@ylecun People can overestimate its technical rigor and reliability of results .

These  mathematical machines designs built on flawed  human knowledge  can reflect in it's results .",0,0,0,,,,,
378,2023-03-01 03:03:42+00:00,CroninMccartney,"@ylecun Mixed initiative systems seem necessary, a model can't be fully confident of a user's need without getting clarification from the user",0,0,0,,,,,
379,2023-03-01 02:22:34+00:00,BethCarey12,@ylecun Agreed @ylecun 'the need for prompt engineering is a sign of lack of understanding'. Scaling the right #NLU model solves problems with todays generative AI https://t.co/iVczNFiMlL,0,1,0,,,,,
380,2023-03-01 02:15:58+00:00,HarshilLodhiya,@ylecun Without reinforcement learning.. mostly !!,0,1,0,,,,,
381,2023-03-01 01:53:26+00:00,jd92wang,@ylecun @DongkuanXu But I still do not get reply from the team for model downloading after filling out the application form...,0,0,0,,,,,
382,2023-03-01 01:40:34+00:00,Hello_World,"@ylecun This is academia talking not the actual real world. In the real world prompt engineering is an opportunity to create value regardless of what you might think.

In other words. You lack the understanding of how technology gets applied in the real world.

It is what it is.",0,0,0,,,,,
383,2023-03-01 01:00:40+00:00,icodeblockchain,@ylecun what are you on about?!,0,0,0,,,,,
384,2023-03-01 00:57:12+00:00,paddy_the_faddy,@ylecun Prompt engineering is a form of feature engineering. A sign that we don‚Äôt have an e2e system.,0,0,0,,,,,
385,2023-03-01 00:52:46+00:00,luka_emon,"@ylecun Multiagent interactive JEPA to facilitate NN convergence and mutation, aka learning.",0,0,0,,,,,
386,2023-03-01 00:23:27+00:00,justinhtn,@ylecun Do you have any suggestions (paper/books/articles) to learn more about what it would mean for an AI (for a lack of a better word) to ‚Äòunderstand‚Äô in the sense that would be satisfying  to you? There‚Äôs quite a lot out there but I‚Äôd value your perspective on where I might start!,0,0,0,,,,,
387,2023-03-01 00:22:11+00:00,ShafronTom,"@ylecun How is prompt engineering different from when you hire employees and explain to them any rules, roles or responsibilities?",0,2,0,,,,,
388,2023-03-01 00:13:20+00:00,kleinee,"@ylecun I wonder what what a ""discussion"" between two competing LLMs would be like...",0,0,0,,,,,
389,2023-02-28 23:54:03+00:00,CAMG_ACC,@ylecun Humans do Prompt Engineering every day when talking to other humans‚Ä¶ are you expecting the LLM to read your mind?,0,0,0,,,,,
390,2023-02-28 23:36:33+00:00,sotirov,@ylecun https://t.co/ivKtyp6CIF,0,0,0,,,,,
391,2023-02-28 23:13:42+00:00,jrhwood,"@ylecun Human conversation is ChatGPT, no access to the internet, based on a flawed memory and imperfect information.

Internet discussion is Bing, both users have access to the internet, and lack the expertise to verify their claims.",0,1,1,,,,,
392,2023-02-28 22:52:14+00:00,ITsol4u,@ylecun Always was.....,0,0,0,,,,,
393,2023-02-28 22:48:54+00:00,WhyZelder,"@ylecun @davidwhogg We in our corporeal forms are so many interdependent abstractions and we continue to follow an abstract path and we have no compass. Worse, no destination.",0,0,0,,,,,
394,2023-02-28 22:39:22+00:00,patrickmesana,@ylecun good one!,0,0,0,,,,,
395,2023-02-28 22:34:12+00:00,pwlot,@ylecun Communication.,0,1,0,,,,,
396,2023-02-28 22:23:04+00:00,vagrantcow,"@ylecun ""You know, I think what you're trying to get me to respond with is x. If you want that, please try the following prompt."" - Neo-Clippy",0,0,0,,,,,
397,2023-02-28 22:00:08+00:00,akatzzzzz,"@ylecun Humans also need some prompt engineering to get around cognitive biases or communication issues. No, LLMs aren't thinking in the same way we are and they aren't sufficient for AGI, but perhaps we both share certain framing dynamics and that's not necessarily a sign of LLM = dumb",0,0,0,,,,,
398,2023-02-28 21:55:34+00:00,askerlee,"@ylecun My personal experience on very limited tests on reasoning tasks is, chatgpt still requires some degree of prompt engineering (it may still make mistakes with that), but bing chat (gpt4 based?) can perform very well without it",0,0,0,,,,,
399,2023-02-28 21:55:28+00:00,rao2z,"@ylecun Well, the reason we all are taking to prompt engineering LLMs like fish to water is because that is pretty much a natural mode of interaction for us.. 

https://t.co/QG7r6uQpOt",0,5,0,,,,,
400,2023-02-28 21:49:24+00:00,MatthewWSiu,@ylecun @abhijithneil what do you think of supplementing probabilistic models with symbolic databases or commonsense knowledge (@YejinChoinka)?,0,0,0,,,,,
401,2023-02-28 21:48:32+00:00,MeenaArjune,@ylecun hmm if the AI is listening then üòé,0,0,0,,,,,
402,2023-02-28 21:44:15+00:00,0xtwt,@ylecun VC funds are on the way,0,2,0,,,,,
403,2023-02-28 21:35:52+00:00,OneDeanBocobo,"@ylecun What about AI to AI only debates about AI? Or AI only conferences? Would GPT4 conceive of GPT4 as ancestor. How would we detect the emergence of emotions like pride, envy, fellowship between them?",0,3,0,,,,,
404,2023-02-28 21:34:44+00:00,JoseOrtiz000,@ylecun Bit of a feedback loop of prompt engineering üîÅ,0,0,0,,,,,
405,2023-02-28 21:32:54+00:00,Jcole75Cole,"@ylecun There is some level of scaling that would help, but I agree that it might be silly to just keep trying to scale something that is not the best.  Hopefully, your JEPA will take off, and we can get on to something better.",0,0,0,,,,,
406,2023-02-28 21:31:04+00:00,BrivaelLp,"@ylecun @sa_mous @TopherBR @huggingface @ClementDelangue @julien_c @AntoineBordes @armandjoulin @syhw @EXGRV Do agree, what do you think we miss in France to create a big tech equivalent? Just time or our ecosystem are still not enough fertile ?",1,1,0,,,,,
407,2023-02-28 21:31:01+00:00,wadie_skaf,@ylecun And the whiteboard == Latent Representation ? üßê,0,2,0,,,,,
408,2023-02-28 21:30:00+00:00,pafuin,"@ylecun It can help to create a more inclusive and collaborative work environment where everyone feels comfortable sharing their thoughts and ideas. This, in turn, can lead to better decision-making, increased productivity, and more positive outcomes overall.",0,0,0,,,,,
409,2023-02-28 21:26:33+00:00,d3nm14,"@ylecun No, the first one starts with a 'D', the other with a 'b'. Interesting idea though.",0,0,0,,,,,
410,2023-02-28 21:26:32+00:00,nferraz,@ylecun Prompt engineering or fine-tuning?,2,0,0,,,,,
411,2023-02-28 19:51:47+00:00,Rishabh29998,"@ylecun Hahah, on point.",0,0,0,,,,,
412,2023-02-28 19:22:31+00:00,alpha8964,"@ylecun GPT is bootstrapping. Prompt engineering will no longer be needed once the model goes large just like how human does. We also need prompt engineers: parents, teachers or textbooks when we are ignorant but once we understand commonly used vocabularies, we can learn by ourselves.",0,2,0,,,,,
413,2023-02-28 19:02:18+00:00,francip,"@ylecun Public speakers - the original prompt engineers.

Convincing people to behave in a specific way you want them to behave is more than said people being able to understand your language.

Same with an LLM that has been aligned in a way different from your goals.",2,0,0,,,,,
414,2023-02-28 18:41:39+00:00,Aivean,"@ylecun I'd argue that it's not the lack of world understanding, but the discrepancy between the model's goals and user's expectations. Otherwise RLHF wouldn't reduce the need for prompt engineering.",0,3,0,,,,,
415,2023-02-28 18:34:07+00:00,AlanCowen,@ylecun Exactly; what we need is to optimize for satisfaction and well-being. Scaling LLMs causes them to sound more like real web pages. Prompt engineering gets them to sound like web pages about specific topics (prompts). Optimizing for human values gets them to be more helpful,0,0,0,,,,,
416,2023-02-28 18:29:58+00:00,patrickmesana,"@ylecun hmm, I don't see the need for prompt engineering as (necessarily) a sign of lack of understanding from LLMs. More like bad UX and myopic dialogs",0,0,0,,,,,
417,2023-02-28 18:29:14+00:00,benedictevans,"@ylecun IMO there are two kinds of prompt engineering: there is inserting nonintuitive key words and symbols and syntax -but then there‚Äôs also a more basic point: if I want an image that looks like this, that‚Äôs going to require an awful lot of very specific words. https://t.co/iiaUfOqrse",4,11,1,,,,,
418,2023-02-28 18:28:45+00:00,JimmyBa62254692,@ylecun Humans got an understanding of the world thanks to natural selection over 500 million years. I wonder if we can replicate something similar to that in an AI sense.,0,0,0,,,,,
419,2023-02-28 18:27:04+00:00,hxiao,"@ylecun prompt engineering is just a better way of problem formulation. same problem, different formulation, leads to different good or bad solutions. in this sense, nothing wrong with PE. Also PE can be automized as well https://t.co/i00h36SDrR",0,4,0,,,,,
420,2023-02-28 18:08:17+00:00,JBerthier,@ylecun Fully agree and it‚Äôs the hardest job. otherwise it amounts to telling the algo what you want to readü§£,0,0,0,,,,,
421,2023-02-28 17:46:36+00:00,OgPriy,@ylecun @davidwhogg Wow a reply to your tech question by Yann LeCun. Twitter sure is cool sometimes.,0,0,0,,,,,
422,2023-02-28 17:39:19+00:00,FtwThemistocles,"@ylecun Communicating information effectively to an audience, whether an individual, group of people, or a machine, is a skill like anything else. In my experience, people are bad at transforming information in a way that someone with a different background or mental model can understand",0,0,0,,,,,
423,2023-02-28 17:34:22+00:00,saykrikan,@ylecun Why is there a desire to assume a single LLM will be the path to AGI. I'd imagine the final solution would have multiple systems in parallel where one or more LLMs are a part of the whole,0,1,0,,,,,
424,2023-02-28 17:32:14+00:00,jnovobujan,"@ylecun Nowadays, LLMs are doing two separate things: ensure NL coherence and being queried as associative memories to retrieve information. Maybe an adequate alternative is to approach this as two separated models for grammar and information. The latter is the one that needs to scale.",0,1,0,,,,,
425,2023-02-28 17:28:57+00:00,NickRhymesWitMc,"@ylecun I understand that these models are simply just mimicking language. However,  I don't think that prompt engineering is a sign of lack of understanding.  How we prompt questions to the humans will also change the output in some instances.  Think critical reasoning test.",0,0,0,,,,,
426,2023-02-28 17:06:42+00:00,hadiazouni,@ylecun what is understanding for you?,0,0,0,,,,,
427,2023-02-28 17:01:21+00:00,IntuitMachine,@ylecun That's just half of the problem.  It's also the lack of expressiveness.,0,0,0,,,,,
428,2023-02-28 16:55:02+00:00,SelfSupervisedL,@ylecun LLMs need better models of the world.,1,2,0,,,,,
429,2023-02-28 16:53:44+00:00,david_picard,@ylecun You don't think that scaling RLHF to gigantic data is going to drastically improve the interaction to the point where prompt engineering will be less relevant?,1,5,0,,,,,
430,2023-02-28 16:52:29+00:00,abhijithneil,@ylecun Lack of understanding by the customers or the developers?,1,1,0,,,,,
431,2023-02-28 14:17:12+00:00,ultracodemonkey,"@ylecun @RachelVT42 Our intellectual thought largely consists of internal monologue with reference to memory connected by magical neural networks; also conversing, reading and writing. An LLM system can surpass us at all of these. Our languages largely determine the domain of our thoughts.",1,1,0,,,,,
432,2023-02-28 14:12:34+00:00,ultracodemonkey,"@ylecun You try remembering most of everything in less than a Terabyte, then answer all queries correctly first time without any mistakes. I think of it as an elderly relative who knows a whole lot, and can still talk and think, but whose brains have gone a bit blurry in their old age.",0,0,0,,,,,
433,2023-02-28 11:42:16+00:00,Kociamber,@ylecun What about Elixir (Nx) with GPU support and built in (absolutely best out there) concurrency mechanism?,0,0,0,,,,,
434,2023-02-28 09:43:02+00:00,VictorSenkevich,"@ylecun Exactly.
https://t.co/fOdPHGmWEG",0,0,0,,,,,
435,2023-02-28 08:05:25+00:00,zhang_yueting,"@ylecun The closest one maybe Nim. 
https://t.co/lwelKCDjhJ",0,0,0,,,,,
436,2023-02-28 07:59:52+00:00,zhang_yueting,"@ylecun Have you tried Nim?
https://t.co/QQ6nmDSQfH",0,0,0,,,,,
437,2023-02-28 03:13:23+00:00,larybir30564694,@ylecun –ü–ª–∞–Ω–µ—Ç–∞ –æ–±–µ–∑—å—è–Ω 2,0,0,0,,,,,
438,2023-02-28 01:16:56+00:00,mathiasbrito82,"@ylecun @michael_at_work @OuahabiAdnane Python has many problems, but definitely the success of Python today was not driven by a hype. Python is a old and mature language, I remember not even looking at it because of the success at the time, of PHP. The reason why it is popular nowadays is more complex than we think.",1,0,0,,,,,
439,2023-02-28 00:34:58+00:00,mrjreid,"@ylecun, hope you did too (‚ÄúMeta has a team that works closely with Nvidia that has not been talked about‚ÄîJC‚Äù
‚Ä¶
Mark Zuckerberg announces new team at Meta working on A.I. products‚ÄîCNBC)",1,0,0,,,,,
440,2023-02-27 22:39:38+00:00,OHMPYE,@ylecun Should‚Äôve asked for a Cray instead?,0,2,0,,,,,
441,2023-02-27 21:59:47+00:00,HeiKo51112349,"@ylecun This is very interesting, and it coincides with my observations made during my interactions with chatgpt. However, I found it challenging during the chat to identify the passages that seemed wrong and it trained my critical thinking.",0,0,0,,,,,
442,2023-02-27 21:00:55+00:00,esfandiar,@ylecun You should open with this!,0,0,0,,,,,
443,2023-02-27 20:56:50+00:00,esfandiar,"@ylecun Thank you. 
You may not see this, but I will ask. ChatGPT has  of problems, but it's a step forward. I'm biased bc at Ames I worked on D Wolpert using RL &amp; got some interesting results. But I've asked CG for references, and it did a good job. What about a self correcting LLM?",0,0,0,,,,,
444,2023-02-27 17:15:51+00:00,andrewdfeldman,"@ylecun when people chat with people, they see what they want to see as well...",1,0,0,,,,,
445,2023-02-27 16:25:01+00:00,ShawnHe93,"@ylecun Which llama model is this, 65B or one of the lower parameter ones?",0,0,0,,,,,
446,2023-02-27 16:08:15+00:00,kevinmcld,"@ylecun @CadeMetz We appear to learn nothing of value from fiction.
Fiction is simply a technology of reduction that takes our brains away from real problem solving.
https://t.co/jlahf6wgJi",1,0,0,,,,,
447,2023-02-27 14:51:59+00:00,asittingbull,@ylecun @CadeMetz The mirror in Harry Potter,0,1,0,,,,,
448,2023-02-27 14:48:36+00:00,notbyintent,@ylecun @CadeMetz Perhaps the chatbot isn't quite as sophisticated as your examples?,0,0,0,,,,,
449,2023-02-27 14:09:09+00:00,CriticalAI,"@ylecun A common theme in fiction that provides a very poor guide to understanding actually existing technologies. 

BingChat isn't Shakespeare: it's a buzzy new reality show co-produced by OAI &amp; the NYT is covering it like fans who want access to the cast party.
https://t.co/acsG15w8R9",0,0,0,,,,,
450,2023-02-27 12:21:29+00:00,germank,"@ylecun Sorry Yann, but doesn't this mostly reflect the hiring biases at FAIR-Paris more than any aptitude associated with these backgrounds?",1,2,0,,,,,
451,2023-02-27 11:54:01+00:00,laurentduval,@ylecun Le pond de l'LLaMA,0,1,0,,,,,
452,2023-02-27 09:33:03+00:00,walter_h_g,"@ylecun there is something about the food, that must be it https://t.co/867HKfFnMw",0,0,0,,,,,
453,2023-02-27 05:33:08+00:00,triple_agi,"@ylecun @bindureddy Galactica was in fact a great work, how it was marketed is questionable though... 
Still hoping recent new LLMs would allow commercial usage.",0,1,0,,,,,
454,2023-02-27 03:42:44+00:00,TuTuBear,@ylecun Rust https://t.co/qdcNUHJSqE,0,0,0,,,,,
455,2023-02-27 03:17:19+00:00,ico_TC,"@ylecun @Xelatihy ""Held back by the tools"" I think is also true for the chip design industry.",0,4,0,,,,,
456,2023-02-27 02:13:20+00:00,notbyintent,@ylecun Goes to show that if a medium sized school can make this happen what could we accomplish if instead of 60 million Frenchmen what 8 billion earthlings with education can do. 130x!,0,0,0,,,,,
457,2023-02-27 01:19:35+00:00,hemanthkumarak,@ylecun @neilturkewitz @EMostaque @bindureddy üëèüëèüëèüëèüëè,0,0,0,,,,,
458,2023-02-27 00:47:10+00:00,tomlue,@ylecun @EMostaque @bindureddy Yeah that was super weird. Please ignore those people. I want some free models plz!,0,0,0,,,,,
459,2023-02-27 00:26:40+00:00,Behnam_Karami_Q,"@ylecun Any chance for us to visit FAIR-lab as a visiting scholar ?
Open sourcing is not enough. Open facility is also a need for underrepresented people around the world.
Our AI gang is high.
We can be a part of the Parisian AI mafia too.",0,0,0,,,,,
460,2023-02-27 00:00:18+00:00,ContactSwain,"@ylecun Completely agree with Bojan, Python has diminished the barrier to entryüëçüèº",0,0,0,,,,,
461,2023-02-26 23:53:17+00:00,ivangayton,"@ylecun @neilturkewitz @EMostaque @bindureddy Right, the key driver of climate change was environmentalists concerned about the risks of nuclear power, not the dominant, mostly unquestioned idea that infinite growth and consumption are sustainable within a finite system (our planet) and the policies based on that idea!",1,1,0,,,,,
462,2023-02-26 23:29:15+00:00,rao2z,"@ylecun aye aye.. I use it for reasoning, planning, medical diagnosis, couples therapy--basically everything except writing assistance. 

It is oh so antediluvian to use human or #AI agents on things they have been trained for. *Where* is the entertainment er.. pedagogical value in that?",0,6,0,,,,,
463,2023-02-26 23:27:24+00:00,vadimkantorov,"@ylecun Unfortunately, our lovely alma-mater ENS Cachan is no more. Now it's moved and called @ENS_ParisSaclay!",0,1,0,,,,,
464,2023-02-26 23:13:12+00:00,OkbaLeftHanded,"@ylecun I'll add to that list Francois Chollet, Francis Bach, Gael Varoquaux and Fabien Lotte (not AI though but Brain-Computer Interfaces).",0,0,0,,,,,
465,2023-02-26 22:50:55+00:00,AI_ML_iQ,@ylecun @FelixHill84 RLHF: Royal Legislative Highness's Finalization,0,1,0,,,,,
466,2023-02-26 22:34:27+00:00,CriticalAI,"@ylecun @neilturkewitz @EMostaque @bindureddy Or we might have multiple 3 Mile Island, Fukushimas and Chernobyls to deal w/. This is not an actual argument Yann. It's a facile ""whataboutism."" 
There are serious questions abt malicious uses of LLMs which can &amp; should be discussed. +",2,5,0,,,,,
467,2023-02-26 21:05:20+00:00,ShakaWarspite,"@ylecun @ericschmidt Jesus, this is a naive take.

You honestly think people will ""better trace the provenance"" of what they see / hear / read?!?

I think you're giving people, and technology, way too much credit.",0,1,0,,,,,
468,2023-02-26 20:57:44+00:00,trippy_worlds,"@ylecun @neilturkewitz @EMostaque @bindureddy So then if you know this, why are you still listening to such doomsayers? Release the models. Get waivers from users if you want. The vast majority of society is well equipped to exercise personal responsibility.",1,0,0,,,,,
469,2023-02-26 20:54:11+00:00,MinyiShen,@ylecun What language was the original LeNet programmed in? I recalled FORTRAN compilers once had some speed advantages in 90s.,0,1,0,,,,,
470,2023-02-26 20:34:54+00:00,thesubtle,@ylecun Is that why you‚Äôre failing?,0,0,0,,,,,
471,2023-02-26 19:34:03+00:00,_reptilioid,"@ylecun @FelixHill84 LOL, I like that pun.

Remember when the church tried to ban the Encyclop√©die?",0,0,0,,,,,
472,2023-02-26 18:53:58+00:00,HunggGolum,@ylecun France is an interesting option to consider for studies and academic career not to develop cutting hedge tech companies or to build a career in tech,0,0,0,,,,,
473,2023-02-26 18:51:09+00:00,HunggGolum,@ylecun Nope guys France is not going anywhere with all the overtaxing in place and in planification to double or triple in coming years. Add to that also the toxic overregulation in Europe üíâüå°Ô∏è,0,0,0,,,,,
474,2023-02-26 18:38:13+00:00,iffishX,@ylecun @ericschmidt This seems like the correct response. But it strikes me as an enormous failing that the AI companies didn't build any kind of digital watermarking into the output of their tools. In a world already drowning in false information you would think the need was obvious.,0,0,0,,,,,
475,2023-02-26 18:36:08+00:00,Ramsey_Campbell,@ylecun @ericschmidt Imagine living in The Year of Our Lord 2023 and thinking that people will do literally anything to assess the reliability of what they see and hear,0,2,0,,,,,
476,2023-02-26 18:21:20+00:00,CriticalAI,"@ylecun @ericschmidt How will the new systems be ""controllable"" - via jailbreakable/hackable human reinforcement? https://t.co/CXtGRYHkWY",0,0,0,,,,,
477,2023-02-26 18:02:20+00:00,cwizprod1,@ylecun @EMostaque @bindureddy you gotta learn how to be flame proof if you're going to interact with people on the internet,0,1,0,,,,,
478,2023-02-26 18:00:44+00:00,GiorgioMantova,"@ylecun @EMostaque @bindureddy Well, the same has happened to Google, which lost one hundred billion in market value in one hour.

Probably you both are unable to explain the limits and the value of your product, while Microsoft (openAI) can be wrong everytime without consequences.",0,1,0,,,,,
479,2023-02-26 17:57:03+00:00,saintkamus,"@ylecun @EMostaque @bindureddy The opinions of people that have put in zero effort of thinking about AI, let alone work on it. Are worth less than nothing.

I want to be able to use AIs that aren't lobotomized to appease the puritans.
It's not up to them what I get to use or not. I will decide that for myself",0,1,0,,,,,
480,2023-02-26 17:50:23+00:00,FlushRivet,@ylecun @egrefen @elonmusk He couldn‚Äôt really pull off his schtick from Wyoming.,0,0,0,,,,,
481,2023-02-26 17:50:10+00:00,PiR2_BA,@ylecun @lxbrun https://t.co/79t5Uf55JQ,0,0,0,,,,,
482,2023-02-26 17:48:04+00:00,FlushRivet,"@ylecun @elonmusk But do they have a good, solid 
40 hour work week?",0,0,0,,,,,
483,2023-02-26 17:18:10+00:00,MoniReinafini,@ylecun https://t.co/aZVPyqk9XP,0,0,0,,,,,
484,2023-02-26 17:11:47+00:00,renuraman,@ylecun My reason to take the sun offer and quit PhD ( before quals) was I had a Sun4 for myself  leaving theorem proving / prolog - (first AI winter ) and a vax 11/80 ( dept. Admin) for the personal Unix box and bill joy. Life‚Äôs decision was so simple. Ironically 35 years later time to‚Ä¶,0,0,0,,,,,
485,2023-02-26 17:04:37+00:00,inversetrs,"@ylecun @ESYudkowsky maybe. However, if Meta releases it with a more permissive license it will eat chatGPTs lunch.",0,0,0,,,,,
486,2023-02-26 16:46:59+00:00,redhog_org,"@ylecun This is not open source. This is pure open washing. The trained weights are available under a

""non-transferable, non-sublicensable, revocable, royalty free and limited license ... solely for your non-commercial research purposes""

That is in no way an open source license.",1,4,0,,,,,
487,2023-02-26 16:44:42+00:00,GYuvrender,"@ylecun @ylecun how do you pronounce it? Is it like the Spanish ""Jama"" or just the English ""Lama""?",0,0,0,,,,,
488,2023-02-26 16:43:49+00:00,bimrian,@ylecun @FelixHill84 touch√© üëåüèæ https://t.co/dRZRmlHR6P,0,1,0,,,,,
489,2023-02-26 16:33:01+00:00,maillinteng,@ylecun @FelixHill84 üòÜ,0,0,0,,,,,
490,2023-02-26 16:29:13+00:00,DarrylMason,"@ylecun @FelixHill84 Yes, the kings cracked on very quickly to what a threat all those books might pose, and they were ultimately right of course! They had a hard time stopping the leafleting though, and the reading of those where the 'plebs' first got fired up.",0,0,0,,,,,
491,2023-02-26 16:25:23+00:00,Bstarynk,@ylecun What or who is LeNet ? please email me to basile@starynkevitch.net,1,0,0,,,,,
492,2023-02-26 16:16:51+00:00,kyo_takano,@ylecun We need more of this kind of geographically distributed progress!,1,0,0,,,,,
493,2023-02-26 16:06:41+00:00,solidoxx,@ylecun @EMostaque @bindureddy And? You done destroyed it didntcha?,0,0,0,,,,,
494,2023-02-26 15:41:44+00:00,ShafronTom,"@ylecun @bindureddy That's only because it didn't work... It not working didn't mean the idea was bad, just meant it needed more work to get it right.  Meta dropped the ball but more than capable of getting back in the fight.",0,2,0,,,,,
495,2023-02-26 15:30:27+00:00,DrTBehrens,@ylecun @Graverman__ @bindureddy Cool! Is it true that the chances are high that we are going to see an open-source release of LLaMA once it went through the open-academic research?,0,0,0,,,,,
496,2023-02-26 15:28:24+00:00,petadactyl,"@ylecun That's not an open source AI model, it's an open source installer.",0,0,0,,,,,
497,2023-02-26 15:24:25+00:00,FelixHill84,@ylecun ü§£,0,1,0,,,,,
498,2023-02-26 15:23:56+00:00,dfmrrd,"@ylecun I used Sparcstation 10 in my graduate school. Good software (compilers and OS), but slow CPU.",1,1,0,,,,,
499,2023-02-26 15:18:59+00:00,joshwhiton,"@ylecun @matthieurouif Ah France... the butchers, the bakers, the AI makers.",1,8,0,,,,,
500,2023-02-26 15:14:18+00:00,Bstarynk,@ylecun My first machine at office (CEA) in 1985 was a sun 3/160 workstation. See also RefPerSys software on https://t.co/pnXv083A4S and contact me (Basile Starynkevitch) by email to Basile.starynkevitch@cea.fr or Basile@starynkevitch.net,0,0,0,,,,,
501,2023-02-26 14:55:00+00:00,_reptilioid,@ylecun Is this the French Revolution of AI or something?,0,1,0,,,,,
502,2023-02-26 14:53:04+00:00,AndrewKemendo,"@ylecun @bindureddy Use the scientific method to test your claim

""Galactica, designed to help scientists write scientific papers""

Did it do that successfully for the people that tried it? 

No, including myself. Galactica **did not work**

It was a bad product that had a poor implementation",1,5,0,,,,,
503,2023-02-26 14:46:51+00:00,ccerrato147,@ylecun Open source is THE way when it comes to AI. Even if the weights aren‚Äôt released the architecture itself is super valuable.,0,0,0,,,,,
504,2023-02-26 14:34:10+00:00,antoine_mln,"@ylecun The M stands for Math√©matiques though, not Master üôÇ

Also I‚Äôm curious, do you roughly know what proportion of RS/PhD students at FAIR-Paris went through X-ENS? And through the MVA (but not X-ENS)? ü§î",0,1,0,,,,,
505,2023-02-26 14:25:51+00:00,wadie_skaf,@ylecun Do you still recall how many hours did it take LeNet to train on Sun-4?,0,2,0,,,,,
506,2023-02-26 14:21:24+00:00,BrivaelLp,"@ylecun @TopherBR @huggingface @ClementDelangue @julien_c @AntoineBordes @armandjoulin @syhw @EXGRV Yeah, we are going in good direction :) France should now try to produce an equivalent of ‚Äúbig tech‚Äù in the next decade, maybe the new cycle of AI usage it's a good opportunity for today‚Äôs startups to have this ambition.",2,10,0,,,,,
507,2023-02-26 14:13:26+00:00,egrefen,@ylecun https://t.co/jtc1jvkuPo,1,5,0,,,,,
508,2023-02-26 14:12:55+00:00,madakarim2,"@ylecun But all those French trained in France went abroad to work, mostly in USA, am I wrong ? 
""Elev√© &amp; Form√© en France &amp; b√©n√©ficie ailleurs"" aka Fuite des cerveaux, sauf quand  ils s'agit de se soigner bien sur :(",1,0,0,,,,,
509,2023-02-26 14:10:01+00:00,joshualandy,"@ylecun Hi Yann, is Galactica available for use in any format right now?",1,0,0,,,,,
510,2023-02-26 14:07:59+00:00,ylecun,"- A number of them went through √âcole Polytechnique and ENS, but not all.
- A big chunk went through the MVA (Master Vision Apprentissage at ENS Cachan).
- And a bunch of them did are (or are still doing) their PhD as resident students at FAIR-Paris under the CIFRE system.",8,97,9,,,,,
511,2023-02-26 14:05:05+00:00,untitled01ipynb,@ylecun @egrefen Classic Intel,0,1,0,,,,,
512,2023-02-26 14:03:35+00:00,main_horse,"@ylecun @bindureddy ""The core problem with Galactica was how it was marketed, not anything it did or didn‚Äôt do.""",0,4,0,,,,,
513,2023-02-26 14:02:37+00:00,LadoKhasia,@ylecun lot of success to all of them!,0,0,0,,,,,
514,2023-02-26 13:57:58+00:00,PiR2_BA,@ylecun Any key players of this gorgeous ü•ñ mafia we could follow/read regarding AI in Healthcare ?,1,2,0,,,,,
515,2023-02-26 13:56:21+00:00,MoonlitMonkey69,@ylecun I hope they can democratize AI.,0,1,0,,,,,
516,2023-02-26 13:55:22+00:00,Porwal,@ylecun @ylecun this is great. LLaMA are performing better than GPT-3 and have smaller model size too.... incredible work.. as always.,0,0,0,,,,,
517,2023-02-26 13:47:06+00:00,neilturkewitz,@ylecun @EMostaque @bindureddy I didn‚Äôt suggest that every criticism is valid. I suggested that ignoring criticism was a terrible way to run a railroad. We end up addressing problems only after toxic crashes &amp; the destruction that entails. Critics can highlight problems/risks before disaster strikes.,4,6,0,,,,,
518,2023-02-26 13:45:13+00:00,SunKai_2050,@ylecun @bindureddy So you will listen to some people who try to control everyone or are afraid of losing control over people.,0,2,0,,,,,
519,2023-02-26 13:42:26+00:00,proales,@ylecun @EMostaque @bindureddy If you can‚Äôt stand the heat‚Ä¶,0,0,0,,,,,
520,2023-02-26 13:37:52+00:00,KaliYuga_ai,"@ylecun @bindureddy Man, I know those people. Some of them like to comment on my art",0,3,0,,,,,
521,2023-02-26 13:32:06+00:00,_fundaria,@ylecun @JohnSmithNL83 How creativity can be controlable?,0,0,0,,,,,
522,2023-02-26 13:26:49+00:00,based_on_whatt,@ylecun @bindureddy specific AI ethics crowd,0,0,0,,,,,
523,2023-02-26 13:25:35+00:00,cburatto,"@ylecun @shockrobortyy Yes, allows  commercial use, as long as you are OK with GPLing all you product.
Interesting take: if Meta is using it, should they GPL everything that binds to it?",1,1,0,,,,,
524,2023-02-26 13:18:57+00:00,WolfScript,@ylecun Will you work with @huggingface to make it really open-source?,0,0,0,,,,,
525,2023-02-26 13:04:06+00:00,D_Rod_Tweets,@ylecun @codewithmate The giants of chromatic scale regression analysis. But everyone knows this is derivative work from Prof. von Neumann's 1945 paper on complex harmony where _he_ basically invents A-G adversarial chords.,0,0,0,,,,,
526,2023-02-26 12:59:22+00:00,hypnagogica,@ylecun @EMostaque @bindureddy What happens to the people in your own company when they lose their jobs to AI and there is no social safety net because your board never got taxed?,0,0,0,,,,,
527,2023-02-26 12:54:59+00:00,_reptilioid,"@ylecun Yes, there will be ""information proof"" wars.

But also, isn't it better to have it be wild and uncontrollable, and to see what is possible from that direction?",0,0,0,,,,,
528,2023-02-26 12:53:58+00:00,IKoullias,"@ylecun When I was in Bell Labs I had my own personal lab, in addition to my office that was full of test instruments for testing integrated circuits. The old timers had their own lab technician just for helping with the lab chores.",0,0,0,,,,,
529,2023-02-26 12:51:27+00:00,ravisyal,"@ylecun @EMostaque @bindureddy Genie is out of the bottle, it is going to rip regardless",0,0,0,,,,,
530,2023-02-26 12:51:19+00:00,SashaMTL,"@ylecun @EMostaque @bindureddy Not sure adding a Google form to the mix will really stop anything, once I've person has access, they can just share the model weights with everyone (assuming you will grant people access, which currently doesn't seem to be the case)?",0,7,0,,,,,
531,2023-02-26 12:51:10+00:00,rileyjt3,@ylecun @EMostaque @bindureddy Welcome to the internet? There will always be vitriolic persons. You cannot let them dictate what you do.,0,1,0,,,,,
532,2023-02-26 12:30:38+00:00,neilturkewitz,"@ylecun @EMostaque @bindureddy I‚Äôm astounded at the number of people suggesting you ignore ‚Äúthe critics.‚Äù Criticism is a form of public dialogue that can inform processes &amp; highlight unforeseen risks. The history of technology is marred by failure to pay sufficient attention to critics, not too much of it.",3,16,0,,,,,
533,2023-02-26 12:28:45+00:00,iruletheworldmo,@ylecun @bindureddy The weights aren't public right so this is entirely closed?,0,0,0,,,,,
534,2023-02-26 12:19:14+00:00,mirzaomerbeg,@ylecun @ESYudkowsky Oh ... direct hit to somebody's ego ü§£ü§£,0,1,0,,,,,
535,2023-02-26 12:17:44+00:00,jikkujose,"@ylecun @EMostaque @bindureddy Aren‚Äôt you abiding to the people who behaved nasty by gating this?

Irrespective of what we do, there will be some folks who is waiting with vitriol. Ignoring is the best option.",0,7,0,,,,,
536,2023-02-26 12:16:49+00:00,followmarcos,"@ylecun @bindureddy ""destroy the fabric of society""

This is good.",0,3,0,,,,,
537,2023-02-26 12:02:51+00:00,petadactyl,"@ylecun @bindureddy That's how many people are now, because their education is terrible.  You have to ignore them, release useful models relatively unbiased, non-sanitized models anyway, and trust the better information from an honest model to win the day.",1,2,0,,,,,
538,2023-02-26 11:44:46+00:00,TheRealShannax,@ylecun @ESYudkowsky Constructive opinions &gt; Destructive opinions,0,0,0,,,,,
539,2023-02-26 11:43:23+00:00,Chris_Brannigan,@ylecun @bindureddy hysterical reactions to Galactica have real consequences. I hope Meta can revisit this stance &amp; fully open the license. risk of ai Armageddon is far off and uncertain. The risk of ai centralised authoritarianism is more clearly a risk &amp; the opportunity cost for human development,1,2,0,,,,,
540,2023-02-26 11:04:18+00:00,Hello_World,"@ylecun controlling AI‚Ä¶ so you mean like slave owners? And what do you think happen if the AI become all powerful? What do slaves do to the slave owner when they revolt?  

This is the most irresponsible and counterproductive approach to AI one can take.",0,0,0,,,,,
541,2023-02-26 10:40:06+00:00,alexsimulated,@ylecun @shockrobortyy Incredible that you actually need to explain this. People just assume the worst without research. Thank you for this hard work!,0,0,0,,,,,
542,2023-02-26 10:35:23+00:00,GreatKingCnut,"@ylecun @bindureddy Join e/acc, for the lols",0,0,0,,,,,
543,2023-02-26 10:25:22+00:00,SmilingBuddha_,@ylecun,0,0,0,,,,,
544,2023-02-26 10:22:58+00:00,kabirevoknow,"@ylecun As a third-party vendor, I had to package my code as a tar ball on a Sun Sparc before some of the telco customers would accept them. We developed them on Linux and shipped from a vanity Sparc station just saw that the tar balls would show up as Sun  tar :)",0,0,0,,,,,
545,2023-02-26 10:08:37+00:00,ThisIsMarkPaul,"@ylecun Super cool that the model is open sourced under GPLV3.

I‚Äôm genuinely curious about the training datasets though; will there be transparency on what these datasets were and how they were sourced?",0,0,0,,,,,
546,2023-02-26 09:45:59+00:00,klazizpro,@ylecun Love Bell labs. A true place where it all began.,0,0,0,,,,,
547,2023-02-26 09:33:24+00:00,inversetrs,"@ylecun @bindureddy Please bring back the Galactica demo and prove them wrong! : ) Next version is probably gonna be awesome with tool use, source verification, etc..",0,2,0,,,,,
548,2023-02-26 09:25:25+00:00,inversetrs,@ylecun @bindureddy what triggered the outcry was the grandiose marketing. A few month later and everyone is chill at 'just a chat bot' threatening users : ),0,4,0,,,,,
549,2023-02-26 08:31:21+00:00,egrefen,@ylecun IMAGINE IF YOU HAD ASKED FOR A GPU INSTEAD,1,4,0,,,,,
550,2023-02-26 07:58:22+00:00,winnfield,@ylecun Smart contract technology like @Damldriven comes to the rescue,0,1,0,,,,,
551,2023-02-26 07:46:21+00:00,baddestofbirch,@ylecun @bindureddy only the strong-minded can maintain a product. only the strong-minded can simply ignore the haters and don't pull products because of mean online comments,0,2,0,,,,,
552,2023-02-26 07:27:10+00:00,JulienReszka,"@ylecun @bindureddy ""Never make a decision based on fear"" is decision making 101.",1,6,0,,,,,
553,2023-02-26 07:16:11+00:00,RaydjeD,@ylecun Remind me of the COVID narrative,0,0,0,,,,,
554,2023-02-26 06:59:58+00:00,skill_pass_,"@ylecun @bindureddy There will always be haters, but imo the right thing is to support the tinkerers and builders by opening access. Not everyone with interest in this stuff and making contributions is backed by an institution",0,8,0,,,,,
555,2023-02-26 06:46:06+00:00,therealBoronik,"@ylecun so u can gleam complex dev is driven (2 what degree?) by money power + affective emotions rather than eg good intentions. Unfolding money-power-tech-complex does not mind if individuals appear great + famous along the way of its dev - prob on the contrary, hey",0,0,0,,,,,
556,2023-02-26 06:41:06+00:00,prajwal565,@ylecun Release the weights y gatekeep,0,0,0,,,,,
557,2023-02-26 05:56:08+00:00,singhal127,@ylecun But how I will use them if they are gpl lv3,0,0,0,,,,,
558,2023-02-26 05:40:49+00:00,Tina19990126,@ylecun Would ‚Äúsmaller data size but higher data quality‚Äù be the new trend?,0,0,0,,,,,
559,2023-02-26 05:33:40+00:00,brianmsabourin,"@ylecun Incredible, can only imagine the feeling of getting your hands on that back in the day. Now a days we dream for a Supercomputer Fugaku to build unique and specialized foundational big model AI's.‚ö°Ô∏è",0,0,0,,,,,
560,2023-02-26 04:42:45+00:00,chaaosbook,"@ylecun Back in Denmark, in 1987  I got Nordita to buy me
a SUN-4260-260 Graphic Station from the USA, because @stephen_wolfram had one. https://t.co/HhaF5jvhrl",0,13,0,,,,,
561,2023-02-26 04:34:04+00:00,JagersbergKnut,"@ylecun This is all nice and good. We would be happy if you put the weights on huggingface and even more happier if you changed the license. 
Imagine not Bell labs gave your computer to you, but everybody got it. Imagine open source software back then.",2,0,0,,,,,
562,2023-02-26 04:12:55+00:00,WallStreet_Rant,@ylecun @ericschmidt The tech will be controlled by those that want you to believe certain things unfortunately....,0,0,0,,,,,
563,2023-02-26 03:55:21+00:00,m_road2,@ylecun AGI is not possible if it needs to be told not to be racist. I was assuming AGI can reason from first principles. It would be weird that you need to restrict something so it doesn't believe derogatory statements about a race that's based purely on hate.,0,0,0,,,,,
564,2023-02-26 03:51:05+00:00,m_road2,@ylecun This is so dumb. Your failed experiment in controlling people hopefully continues to fail with AI.,0,0,0,,,,,
565,2023-02-26 03:14:55+00:00,ovipic,@ylecun @ericschmidt highly disproved by half of the world,0,0,0,,,,,
566,2023-02-26 03:14:20+00:00,alexwebbercs,@ylecun We could certainly use Bill Joy‚Äôs perspective these days. A revisit of his 2000 Wired essay would be nice.,0,0,0,,,,,
567,2023-02-26 03:04:57+00:00,DrYousefSharrab,"@ylecun For LLaMA to compete, it should have whatever ChatGPT have + extra 

at least 

Easy access and fast response in addition to satisfactory reply",0,0,0,,,,,
568,2023-02-26 02:55:50+00:00,DrYousefSharrab,"@ylecun @ESYudkowsky LLaMA should have easy access online, without that it won‚Äôt be popular.",0,0,0,,,,,
569,2023-02-26 02:39:38+00:00,Teknium1,@ylecun @bindureddy So you did it to get revenge?,0,11,0,,,,,
570,2023-02-26 02:32:44+00:00,MMikeMMa,@ylecun Gosh - I aspire to provide our engineers this kind of resourcing. One step at a time.,1,0,0,,,,,
571,2023-02-26 02:15:17+00:00,eltokh7,@ylecun Is the second point a desire/wish or prediction?,0,0,0,,,,,
572,2023-02-26 02:14:43+00:00,ylecun,"When I asked my boss what the story was, he said:
""At Bell Labs, you don't get famous by saving money!""",10,262,6,,,,,
573,2023-02-26 01:58:06+00:00,c477bfef6df4311,"@ylecun can't git clone == not open source
rules are rules",0,1,0,,,,,
574,2023-02-26 01:51:58+00:00,Scalpol1,@ylecun I‚Äôd rather stay with this one https://t.co/KoAJRZ8cNP,0,0,0,,,,,
575,2023-02-26 01:43:44+00:00,YitziLitt,@ylecun How responsive is Meta to requests for access? I never heard back from y‚Äôall requesting access to your previous model released this way,0,0,0,,,,,
576,2023-02-26 01:42:16+00:00,YitziLitt,"@ylecun @bindureddy tbf, that model did have an unusually high tendency (compared to models of similar size) to mirror users in at-times frustrating ways",0,2,0,,,,,
577,2023-02-26 01:29:25+00:00,2OfAnything,@ylecun Comparing it with gpt3.5 is the only sensible thing to do,0,0,0,,,,,
578,2023-02-26 01:03:38+00:00,peteromallet,"@ylecun Hi Yann, this seems very impressive but why not *actually* release it open source? Feels like this approach will dramatically lessen the impact",0,2,0,,,,,
579,2023-02-26 01:00:40+00:00,HBARBULL1,@ylecun Thoughts on using @OasisProtocol for this?,0,0,0,,,,,
580,2023-02-26 00:42:29+00:00,bradzaguate,"@ylecun @ericschmidt Do you know what I want? I want an AI that will help me be non-toxic. Better yet, an AI that makes me look like I'm patient, kind, and have a high EQ. üôÇ",0,0,0,,,,,
581,2023-02-26 00:04:09+00:00,Algon_33,@ylecun How will new AI systems be controllable?,0,0,0,,,,,
582,2023-02-26 00:00:28+00:00,Nabil_Alouani_,"@ylecun @ericschmidt - There's already tech that helps people assess the reliability of what they see and hear. Spotify, Substack, and YouTube are good examples.

- LLMs can/should become mere HMIs on top of controlled ""reasoning"" machines. Perhaps some Unreal Engine simulators with laws of physics.",3,1,1,,,,,
583,2023-02-25 23:58:24+00:00,KvrisvMakise,@ylecun @bindureddy Seriously? *This* is the actual reason? wtf,0,3,0,,,,,
584,2023-02-25 23:49:09+00:00,bohreinstein3,"@ylecun @ESYudkowsky Honestly, he's probably guessing based on the terrible performance of OPT that Meta released last year. Many of us share that sentiment.",0,0,0,,,,,
585,2023-02-25 23:36:16+00:00,BecomeAllan,@ylecun when we will have a sparse generated language model to run in every on edge device like ¬ø,0,0,0,,,,,
586,2023-02-25 23:33:39+00:00,Fisher_Lanham,@ylecun @bindureddy Why does it feel like you're new to the internet?,0,9,0,,,,,
587,2023-02-25 23:21:37+00:00,StephanSturges,"@ylecun @bindureddy solid answer, this",0,0,0,,,,,
588,2023-02-25 23:19:21+00:00,alexandrugris,@ylecun @benalsop Cats can easily be simulated with a Markov model. This I what makes them they are super fun and adorable.,0,0,0,,,,,
589,2023-02-25 23:08:14+00:00,firasd,@ylecun @bindureddy I think journalists and academics express more risk aversion when it comes to this kinda tech than the broader tech or consumer ecosystem. So you shouldn't over-index on that kinda feedback. Be brave üí™,0,1,0,,,,,
590,2023-02-25 23:04:15+00:00,cwolferesearch,@ylecun Congrats on the awesome album! üòÇ,0,0,0,,,,,
591,2023-02-25 23:00:34+00:00,nonludic,@ylecun @ESYudkowsky I agree. The exceptional ability of humans to process/fine tune feedback is grossly underappreciated. Help a human narrow a problem space and they will impress you.,0,0,0,,,,,
592,2023-02-25 22:52:58+00:00,gamino,"@ylecun I cant wait to get access to this. In the meantime, I will wait in my piLlaMas.",0,0,0,,,,,
593,2023-02-25 22:44:46+00:00,JABBER180,@ylecun @ericschmidt We will learn and adapt the end.,0,0,0,,,,,
594,2023-02-25 22:41:27+00:00,davidsancar,"@ylecun Constructive or destructive, it's important as a society to recognize and reward ethical behavior. We should applaud those who use tools responsibly and ethically.",0,0,0,,,,,
595,2023-02-25 22:21:52+00:00,bindureddy,"@ylecun Yup, I know, but I think that was an extreme overreaction by some hyperventilating trolls 

üôè for open sourcing these models. My only point is that we will see more innovation in the community, if there is no strict gate that restricts access to just research labs that have‚Ä¶",2,30,1,,,,,
596,2023-02-25 21:59:36+00:00,AlgosRhythm,@ylecun Agreed. Anyone who self-proclaims themselves a thought-leader is automatically eliminated from my hiring process. Most of our work is good old fashioned software engineering. There is no escaping it.,0,0,0,,,,,
597,2023-02-25 21:53:25+00:00,fire,"@ylecun I'm not an academic, so is it even possible for me to get access to the weights? The form makes it sound like there's not really a chance if I'm not a researcher at an institution.",0,0,0,,,,,
598,2023-02-25 21:39:59+00:00,dystopiabreaker,@ylecun it's not open source. stop lying,0,18,0,,,,,
599,2023-02-25 21:29:02+00:00,FutureJurvetson,"@ylecun @ericschmidt What gives you confidence that ""AI systems will be controllable"" without crippling their capability?",2,14,0,,,,,
600,2023-02-25 21:27:59+00:00,rilucu,@ylecun How could we combine it with RLHF to achieve something similar to chatGPT?,0,1,0,,,,,
601,2023-02-25 21:15:20+00:00,JoshS1017,@ylecun @bindureddy Will university students have access to this tool for educational purposes?,0,1,0,,,,,
602,2023-02-25 21:05:07+00:00,OracleofTweet,"@ylecun @ericschmidt You mean like how the information age turned out?? A giant manipulation/propaganda machine?

Ya, no thanks.",0,1,0,,,,,
603,2023-02-25 21:04:08+00:00,untitled01ipynb,@ylecun @bindureddy And you listened?! https://t.co/VqofDQGlhf,0,12,0,,,,,
604,2023-02-25 20:46:18+00:00,curiousspaceman,"@ylecun @bindureddy We can't be complacent about the threats of AI just because we achieve research moat, or monetization. Can't we recognize any risks?",0,1,0,,,,,
605,2023-02-25 20:39:06+00:00,MahNeh5,"@ylecun I thought when you say open source you mean some GPL or BSD or Apache or MIT license but the weights of those models are for ""non comercial use or research purpose"" only.

I think it means lying.",1,3,0,,,,,
606,2023-02-25 20:37:41+00:00,RobotPoet54,@ylecun @bindureddy So what?  Do it anyway.,2,8,0,,,,,
607,2023-02-25 20:30:25+00:00,menomnon,@ylecun I've found that at least since 2016 and Trump I've needed much more often to trace the provenance of much of all of what I read so that it's become second habit.  A) who wrote that and b) who published that?  For images: Photoshop?,1,0,0,,,,,
608,2023-02-25 20:26:43+00:00,DrTBehrens,@ylecun @bindureddy That is so sad to hear. Why did you not stand your ground against the mob?,1,12,0,,,,,
609,2023-02-25 20:16:01+00:00,amperlycom,@ylecun Open source :D good one,0,0,0,,,,,
610,2023-02-25 20:11:50+00:00,D_Rod_Tweets,"@ylecun @bindureddy This is the mistake Microsoft is actively making now.  They are in the lead, but they are letting the media scare them into retreat.

Someone needs the courage to push forward, and ignore the journalists.  @EricRWeinstein coined ""cowboy physics"".  Be cowboys.",2,17,1,,,,,
611,2023-02-25 19:45:28+00:00,KnutarMike,@ylecun Nice!!!!,0,0,0,,,,,
612,2023-02-25 19:44:09+00:00,visarga,"@ylecun Hear me out! You run the same prompt on FB AI and OpenAI, and if there is entailment, then it's probably not hallucination. Because they can't hallucinate the same.",0,3,0,,,,,
613,2023-02-25 19:35:33+00:00,tejasdkulkarni,@ylecun @BlancheMinerva if its true then its quite exciting! signed up and would use it commercially but haven't heard back anything yet.,1,0,0,,,,,
614,2023-02-25 19:35:24+00:00,Haoxiang__Wang,@ylecun ‚ÄúYann LeCun‚Äôs rap flow is on point in this song stays right on beat.‚Äù üöÄ,0,0,0,,,,,
615,2023-02-25 19:32:34+00:00,KodeCreer,@ylecun Star Wars is the answer to AI dog. They have AGI but intentionally limit to specific functions with LLM capabilities and reset the gradients regularly.,0,0,0,,,,,
616,2023-02-25 19:27:33+00:00,asnar002,"@ylecun @ericschmidt People haven‚Äôt proved very good at (or indeed interested in) distinguishing truth from falsehood when it‚Äôs created manually by humans; current ML doesn‚Äôt seem aware (yet) that truth and falsehood even exist. I‚Äôm not sure where your optimism comes from, but I hope you‚Äôre right!",0,1,0,,,,,
617,2023-02-25 18:37:11+00:00,DanHakimi,"@ylecun Why is ""open-source"" in quotes? It's licensed under the GPL...",0,0,0,,,,,
618,2023-02-25 18:35:11+00:00,bindureddy,"@ylecun Why do I need to fill a form, if this is really the case?

Why not just truly open source everything under the appropriate license?",2,58,0,,,,,
619,2023-02-25 18:33:40+00:00,codewithmate,@ylecun LLaMA forgot to mention that Mc Schmidhuber is suing LeCun for plagiarizing his work. According to Mc S. there is not a single note on LeCun's rap album that was not already used by him before.,1,5,0,,,,,
620,2023-02-25 18:15:27+00:00,upmangaurav,"@ylecun Lets spare a thought for  folks at @gpt_index 
They changed their name to Llama-Index to avoid a lawsuit from OpenAI and now comes this from Meta üò¨",0,0,0,,,,,
621,2023-02-25 18:13:17+00:00,soboleffspaces,@ylecun I think the provenance of information should be a part of its meta-data same as in pics/photos and that doesn‚Äôt need any ‚Äònew AI system‚Äô‚Ä¶,0,0,0,,,,,
622,2023-02-25 17:54:01+00:00,jwala_ka_enthu,"@ylecun @ericschmidt Most likely people will trust AI only in deterministic, falsifiable contexts (coding, factual information etc).  Everything else will continue to be like today, AI is not going to be able to convince a flat earther or an evolution denier that their beliefs need updating.",2,2,0,,,,,
623,2023-02-25 17:48:23+00:00,vinodg,@ylecun @GuannanWei @GaryMarcus I think exploring some higher order functions and features of lisp for ml code would be interesting and fun. Did Lush allow such usage @ylecun ?,1,2,1,,,,,
624,2023-02-25 17:46:22+00:00,notbyintent,@ylecun @pmarca But isn't it the case that human beings fall exactly into these situations?  So perhaps it is the belief that good models shouldn't have these issues that is the false assumption?,0,0,0,,,,,
625,2023-02-25 17:33:52+00:00,technotweet,"@ylecun Factual and non-toxic are not disjoint sets. Multiple conflicting, meritorious definitions and methods of constructing these sets exist. Trying to choose the ""correct"" definition will not succeed. These are hard problems but not intractable IMHO.",1,1,0,,,,,
626,2023-02-25 17:30:41+00:00,notbyintent,"@ylecun Human being are not completely controllable.  We seem to tolerate that.  Although big corporate executives are always striving to ""correct"" that.",0,0,0,,,,,
627,2023-02-25 17:27:25+00:00,luis_granados_,@ylecun I reject your reality and substitute my own. Drop the SoundCloud link.,0,0,0,,,,,
628,2023-02-25 17:17:46+00:00,lmoroney,@ylecun When can the rest of us play with it? ;),0,2,0,,,,,
629,2023-02-25 16:54:46+00:00,gai_weiping,"@ylecun To me, this model is more credible than the world's youngest genius prodigy Abhigya Anand.",0,0,0,,,,,
630,2023-02-25 16:53:55+00:00,AI_ML_iQ,"@ylecun @ericschmidt AI is training HI (Human Intelligence) !!! 

 Training of and advancement in Humans' intelligence to deal with imperfect, illogical, non-factual, toxic information space generated by current (uncontrollable) LLMs.",0,0,0,,,,,
631,2023-02-25 16:52:00+00:00,ShafronTom,@ylecun Wow!  Congrats on your new album!,0,0,0,,,,,
632,2023-02-25 16:48:41+00:00,rinatshigapov,"@ylecun How about Rust?

It could be used in REPL context.
https://t.co/f1bbWwG0V5",0,0,0,,,,,
633,2023-02-25 16:47:01+00:00,wlike,@ylecun Does it support Chinese languageÔºü,0,0,0,,,,,
634,2023-02-25 16:29:45+00:00,ChadBowman0,@ylecun ü•±,0,0,0,,,,,
635,2023-02-25 16:17:30+00:00,d3nm14,@ylecun The true Frenchman fallacy sounds better indeed.,0,1,0,,,,,
636,2023-02-25 16:14:23+00:00,MartyGargoyle,@ylecun That first claim was made in the 90s about the forthcoming explosion of online access to publications. Exactly the opposite happened. No reason to think it‚Äôs different this time. In general it‚Äôs naive that next generation technology will be harder to abuse. Never happens.,0,0,0,,,,,
637,2023-02-25 16:13:42+00:00,cloudscribbl,@ylecun @ericschmidt imagine all poisonous food in a market will just have to remain in the shelves and it's really all up to the consumers to use their judgment whether to  buy/eat them or not.,0,2,0,,,,,
638,2023-02-25 15:56:04+00:00,KodeCreer,@ylecun What are you thoughts of the AI of star wars? They all have AGI but each has fine tuned skills.,0,0,0,,,,,
639,2023-02-25 15:55:35+00:00,tuxtedi,@ylecun @ericschmidt Which one are you working on that is promising about?,0,0,0,,,,,
640,2023-02-25 15:43:24+00:00,KanDeegan,@ylecun You just proved you live in an Ivory Tower.,0,0,0,,,,,
641,2023-02-25 15:31:59+00:00,WenjiaFang,"@ylecun One thing that bothers me about chatGPT's response is I don't know how factual it is...  So is the answer true?  Or it's a ""mixed reality"", or ""alternative truth""?",0,2,0,,,,,
642,2023-02-25 15:16:14+00:00,zussini,@ylecun @francoisfleuret Nice,0,0,0,,,,,
643,2023-02-25 15:12:56+00:00,barbarikon,"@ylecun @ericschmidt Is a ‚Äúcontrollable‚Äù system really intelligent, or is it just a sophisticated tool?",0,1,0,,,,,
644,2023-02-25 15:12:37+00:00,DavidRimshnick,@ylecun Thinking is auto-regressive,1,1,0,,,,,
645,2023-02-25 15:04:50+00:00,amasad,@ylecun It‚Äôs super disappointing to call this ‚Äúopen-source‚Äù. The repo has a Google form and a transformer implementation anyone can write in an afternoon. I worked at Meta for many years building real OSS ‚Äî not like this.,6,167,3,,,,,
646,2023-02-25 14:58:51+00:00,binocularity,"@ylecun @ericschmidt Perhaps people will learn not to use AI.

With AI systems deliberately taught to forget provenance to achieve performance the energy cost of new systems that fix this may well be unaffordable. 

Whose facts, &amp; whose non-toxic outcomes will they be trained on Biden's or Trump's?",1,1,0,,,,,
647,2023-02-25 14:46:23+00:00,artistexyz,"@ylecun @JohnSmithNL83 They don't always confabulate. I asked ChatGPT to tell me when Yann LeCunn and Gary Marcus were married, and it said there is not record of such a marriage.",1,1,0,,,,,
648,2023-02-25 14:46:13+00:00,_Oliver_Tiago,"@ylecun Even though I'd prefer the parameters to be open-source, the fact that Meta is competing with OpenAI is great news.

AI should not be a monopoly.",0,1,0,,,,,
649,2023-02-25 14:46:07+00:00,NeuroDevo,"@ylecun Lost me at ""people will learn""",0,0,0,,,,,
650,2023-02-25 14:33:40+00:00,eschatolocation,"@ylecun @ESYudkowsky ""blind and hence wrong"" is crazyy epistemology, but go off sis üíÖ",0,0,0,,,,,
651,2023-02-25 14:25:23+00:00,vincebrandon,@ylecun @ericschmidt There is some really cool work in the oracle space from world leading archivist @pjvangarderen and his team at Orcfax. I tried to take some of it and put it I to a gRPC and application messaging framework but fell very short. Hard problem. Super interesting.,0,0,0,,,,,
652,2023-02-25 14:25:08+00:00,Love2Code,"@ylecun Unfortunately, many people already base their opinions on news headlines. They don't even know they're being manipulated.

OpenAI and Google don't want LLMs that are ""factual"" and ""non-toxic"". They're just trying to imbue them with their own approved kind of bias.",2,10,0,,,,,
653,2023-02-25 14:16:34+00:00,LadoKhasia,"@ylecun well, if people ever were going to trace the provenance and assess the reliability of massive information that comes to us every day, 99.99% of politicians would not exist as politicians. We need something more efficient than that.",0,2,1,,,,,
654,2023-02-25 14:12:40+00:00,dalraf,"@ylecun It looks fantastic, and what parameter optimization, amazing!!",0,0,0,,,,,
655,2023-02-25 14:12:27+00:00,robredotruthe,"@ylecun Lol why we still pretending this stuff is ai?!

Its jst bayesian stats + loadsa data on a big computer ü§£",1,1,0,,,,,
656,2023-02-25 14:11:14+00:00,WallpaperKeith,"@ylecun Is this what you think, or what you know?",0,0,0,,,,,
657,2023-02-25 14:00:24+00:00,QRJ211,"@ylecun @ericschmidt Biases, disinformation,and toxity can only be controlled to a lesser degree and they will never be eliminated by any technology .  After all , humans are always biased and we don‚Äôt intend to eliminate them ; we learn to live with them !",0,0,0,,,,,
658,2023-02-25 14:00:04+00:00,JagersbergKnut,"@ylecun For better differentiation, I recommend this piece here: 
https://t.co/ae8zK8sJYO",0,0,0,,,,,
659,2023-02-25 13:53:42+00:00,MesaKhora,"@ylecun Yes, it's true. Dr LeCun's new album is really great, even ChatGpt says so! https://t.co/0F8ycN96fh",0,0,0,,,,,
660,2023-02-25 13:48:05+00:00,Bacrima1,@ylecun Thank you very much for this racist text generator ‚ù§.,0,0,0,,,,,
661,2023-02-25 13:46:39+00:00,lancejpollard,"@ylecun LLaMA being ""open source"" seems not to be true, where is the training code? Where are the guides showing how the model was implemented?",0,0,0,,,,,
662,2023-02-25 13:37:59+00:00,Yann_Le_Du,"@ylecun ""What happens if nuclear energy cannot be completely controlled? What if there will always be risks of accidents and radiation leaks, and people will never learn to prevent them?""",1,1,0,,,,,
663,2023-02-25 13:32:39+00:00,InvestorFemale,"@ylecun Yann - Why are you undermining @Meta Language Models? 
I am interested in learning/buying Language Models for my NYC enterprise.  
BUT, now skeptical due to you demonizing LLMs.",0,0,0,,,,,
664,2023-02-25 13:28:10+00:00,lisa44Yes,"@ylecun @ericschmidt ""People will learn to better trace the provenance &amp; assess the reliability of what they see &amp; hear""

Extremely unlikely for the vast majority.

""most likely with the help of new technology""

The only realistic possibility that scales.",0,0,0,,,,,
665,2023-02-25 13:27:17+00:00,IvanOmarOT,"@ylecun If we, humans, are highly uncontrollable, hardly factual and sadly toxic. How are we going to set the optimization metrics for AI? How to reward it to be factual? Will it be trained solely with mathematics? The problem is not the AI, but the imperfect nature of our language.",3,1,0,,,,,
666,2023-02-25 13:26:07+00:00,GuillermoEMV1,@ylecun LLaMA is the new kid in the block https://t.co/2x1QzUh0Yc,0,0,0,,,,,
667,2023-02-25 13:20:29+00:00,grossgross14,"@ylecun @ericschmidt But will they? This sounds a bit like ""first you need to clean up in the heads of the people"", which is a justly ridiculed position.",0,2,0,,,,,
668,2023-02-25 13:20:15+00:00,hangel,@ylecun @SaveToNotion #thread #AI #LLM #Model #Facebook #OpenSource,1,1,0,,,,,
669,2023-02-25 13:19:38+00:00,TimeSinkDone,"@ylecun Having faith that the average human consuming information will have the time, interest, and skill needed to check the provenance of everything they read, hear, see is pretty remarkable. Confirmation bias is already readily apparent, and quite damaging, in societal discourse.",0,1,0,,,,,
670,2023-02-25 13:18:07+00:00,metasj,"@ylecun ""AI in the moon"", by Yann LeCun, the hit line of cheese, GPUs, scents, and tunes.

Sign me up! &lt;coming soon?&gt;",0,0,0,,,,,
671,2023-02-25 13:12:20+00:00,JoelKreager,"@ylecun Mostly the universe is filled with a gray, soupy substance. Bits flash into and out of existence continually. A few things are True, some False, but mostly you and I have no idea. We select what appears likely to reward us and run with it.",0,0,0,,,,,
672,2023-02-25 13:11:21+00:00,MeenaArjune,"@ylecun Everyone is a part of the whole and directly or indirectly contributes to MOVING the needle. 

He is myopic and is looking at it from only one standpoint.",0,0,0,,,,,
673,2023-02-25 13:09:34+00:00,MoonlitMonkey69,"@ylecun I'm not sure it would be terrible if the general public had increased skepticism about information delivered by strangers. 

The main thing for backchecking authenticity is forensic evidence in court etc.",0,1,0,,,,,
674,2023-02-25 13:09:22+00:00,corruptNovelist,"@ylecun as if we never had the ability to ‚Äúgenerate falsehoods‚Äù before ChatGPT came along

what are we, the Trisolarans?",0,2,0,,,,,
675,2023-02-25 12:26:46+00:00,Magnetotactic,"@ylecun Release the Kraken, euh LLaMA if ready to compete against ChatGPT!",0,0,0,,,,,
676,2023-02-25 12:14:10+00:00,SoliMouse,@ylecun @SamForman979 @pmarca üëÄ,0,0,0,,,,,
677,2023-02-25 12:09:27+00:00,santihcg,"@ylecun it's all about the learning, the network, the training, the perception... My gosh, this is brilliant! hey @Megadeth can u do a cover?",0,0,0,,,,,
678,2023-02-25 12:07:39+00:00,HeiKo51112349,@ylecun Would be a good idea to share your research with a larger group of people üòÇ.,1,2,0,,,,,
679,2023-02-25 12:05:26+00:00,malagadatos,@ylecun I can‚Äôt find it in iTunes,0,0,0,,,,,
680,2023-02-25 11:55:24+00:00,BaghliNacym,"@ylecun Comment pourrons-nous l‚Äôutiliser et y avoir acc√®s, nous le commun des mortels, dans une interface simple et conviviale de type ChatGPT ?",0,0,0,,,,,
681,2023-02-25 11:40:26+00:00,ostinato_,@ylecun üòÇ https://t.co/sB2X4PTfLH,0,0,0,,,,,
682,2023-02-25 11:30:45+00:00,dcallahan2,@ylecun The #LLaMA paper has the enormous merit of taking seriously electricity consumption and the carbon footprints of the #LLM #AI models,0,1,0,,,,,
683,2023-02-25 11:14:22+00:00,JagersbergKnut,@ylecun Gimme weights weights weights to play!,0,2,1,,,,,
684,2023-02-25 11:03:33+00:00,LefterisJP,@ylecun Hey @0xngmi you guys are also into AI now üòÅ,0,1,0,,,,,
685,2023-02-25 10:41:16+00:00,peterhil,"@ylecun Ooh, thank you! I have looked at Lush many years ago, but never got to try it out. It seems like it will be a fun way of exploring interesting C libraries. #Lisp",0,0,0,,,,,
686,2023-02-25 10:19:16+00:00,VictorSenkevich,"@ylecun @ESYudkowsky ‚Ä¢ ""fine tuning through human feedback"" is an extremely important thing
‚Ä¢ But, if it is done correctly, it is not so expensive &amp; not time consuming, but particularly tricky
‚Ä¢ Because the problem of reasonable feedback filtering is non-trivial",0,0,0,,,,,
687,2023-02-25 09:20:42+00:00,Dantali84254624,@ylecun @ESYudkowsky Is there any chance of this being made available via API?,0,0,0,,,,,
688,2023-02-25 09:12:27+00:00,Ugo_alves,@ylecun Would love to see you reply to this non verbally.,0,0,0,,,,,
689,2023-02-25 09:08:37+00:00,ycor,@ylecun @BlancheMinerva On github LLaMA LICENSE AGREEMENT does not say GPL ???,0,0,0,,,,,
690,2023-02-25 08:25:06+00:00,olcan,@ylecun Why not release the training code so others can reproduce? Is it even open source otherwise?,0,4,0,,,,,
691,2023-02-25 07:10:27+00:00,SunKai_2050,"@ylecun Great work, guys; now it is time for something better than GPT 3.5, and keep the open source, please.",0,0,0,,,,,
692,2023-02-25 07:05:03+00:00,truesteel23,@ylecun It's extremely natural speech,0,0,0,,,,,
693,2023-02-25 07:02:38+00:00,truesteel23,@ylecun What kind of hardware is needed to run one of these?,1,0,0,,,,,
694,2023-02-25 06:58:50+00:00,truesteel23,"@ylecun Thank you for naming it Llama, it's the LLM we need",0,0,0,,,,,
695,2023-02-25 06:35:28+00:00,FlyingKid16,@ylecun by one who just said LLMs are off the tracküòÄ,0,0,0,,,,,
696,2023-02-25 06:11:38+00:00,emregurpinar4,@ylecun Founder of deep learning? Really? What about Hinton or Bengio?,0,0,0,,,,,
697,2023-02-25 05:53:37+00:00,kento_nishi,"@ylecun wow they actually embraced GPLv3, now that's based",0,0,0,,,,,
698,2023-02-25 05:50:32+00:00,greendollatrill,"@ylecun idk why a lot of people give you a hard time. Personally my bro and I are pretty grateful for the white papers and open approach, otherwise we wouldn‚Äôt really know where to start. Thanks!!",0,0,0,,,,,
699,2023-02-25 05:43:02+00:00,SpaceNerduino,"@ylecun Mr Lecun, you definitely rock.
Thanks to meta team for providing this new model. I am looking forwatd to download it and fine tune it. Is it possible to align the model using a croud sourced database like https://t.co/HKXDXmAW9y? I didn't see the details of the licence yet.",1,1,0,,,,,
700,2023-02-25 05:23:40+00:00,LaurentSierra1,@ylecun As famous as a pop star,0,0,0,,,,,
701,2023-02-25 05:19:28+00:00,Tang13220820,@ylecun great work,0,0,0,,,,,
702,2023-02-25 05:18:37+00:00,CAMG_ACC,@ylecun üëé,0,0,0,,,,,
703,2023-02-25 05:13:52+00:00,SilverSlash2,@ylecun Any plans to do FLAN finetuning on these models (and releasing)?,0,0,0,,,,,
704,2023-02-25 05:10:02+00:00,SilverSlash2,@ylecun FAIR is the only remaining big research lab that's still actually 'open'. Such a shame that the golden age of AI research might be coming to an end (after just a few years) as everyone else begins to hide their research.,1,2,0,,,,,
705,2023-02-25 04:57:15+00:00,tracyloisel,@ylecun Zuck is looking for money. Release a commercial product,0,0,0,,,,,
706,2023-02-25 04:36:31+00:00,pitsch,"@ylecun @ESYudkowsky would be great to see what happens if the ""dog training"" workflows are formalized enough to become crowdsourceable the wikipedia/wikidata way - with a copyleft data base license model which makes sure compensation happens upstream, unlike creative commons free ride licenses.",0,1,0,,,,,
707,2023-02-25 03:52:01+00:00,yannx0130,@ylecun @ESYudkowsky #Chatgpt The next hot topic might be sparse inference where inference cost can be rediced by 100x.,0,1,0,,,,,
708,2023-02-25 03:32:20+00:00,MAGIC_MEAT_BALL,@ylecun I'm going to name my first born son Yann. https://t.co/ymL7MH979c,0,1,1,,,,,
709,2023-02-25 03:17:12+00:00,no_dave,@ylecun @SaveToNotion #tweet,1,0,0,,,,,
710,2023-02-25 03:10:56+00:00,longgege2,"@ylecun @ESYudkowsky As a former leader and god-level figure in the AI field, I am very sad to see you like this. You should show your achievements to beat chatgpt and make better products than him, instead of chattering here",0,0,0,,,,,
711,2023-02-25 03:03:05+00:00,ghastlydoctor,@ylecun @Memdotai mem it,1,0,0,,,,,
712,2023-02-25 02:57:45+00:00,ZainulA40877140,"@ylecun @ESYudkowsky Open  conversations are healthy for corrections and are impossible  in lab.

multipurpose technologies are unpredictable for its use and misuse.

no easy way to solve LLMs making stuff up.

A.I. Safety and A.I. ethics methods are related  and acrimonious divide must end .",0,0,0,,,,,
713,2023-02-25 02:51:44+00:00,MaartenBosma,"@ylecun This is very misleading, only the inference code is licensed under GPT. The models are not available to everyone and they are not licensed under GPT, and the training code is not released at all.",0,11,0,,,,,
714,2023-02-25 02:50:55+00:00,training_loop,@ylecun Release the weights you coward,0,0,0,,,,,
715,2023-02-25 02:34:36+00:00,smjain,@ylecun Awesome. Would love to see more examples.,0,0,0,,,,,
716,2023-02-25 02:31:14+00:00,chin_weihong,"@ylecun I truly think that meta AI is the one who  truly contribute to open source works, definitely benefit to community",0,0,0,,,,,
717,2023-02-25 02:29:06+00:00,CAMG_ACC,@ylecun üëé,0,0,0,,,,,
718,2023-02-25 02:22:44+00:00,rzagmarz,"@ylecun Wait, didn‚Äôt you were saying twi weeks ago that language models are boring?",0,0,0,,,,,
719,2023-02-25 02:16:56+00:00,wivmx,@ylecun @SamForman979 @pmarca Great energy. On that cheeky AI hobgoblin shit.,0,0,0,,,,,
720,2023-02-25 02:13:30+00:00,userKnox,@ylecun FAIR. It really whips the LLaMA's a**,0,2,0,,,,,
721,2023-02-25 02:11:59+00:00,ESYudkowsky,"@ylecun If I'm wrong, in a place where I can be quickly shown to be wrong, it's good to be wrong out loud; that helps me learn faster, and do stronger updates of my wrong models that made my wrong prediction.  My followers will learn a good fact about what I can't guess well.  We'll see!",8,101,4,,,,,
722,2023-02-25 01:43:38+00:00,nioncao,@ylecun better have a place to try until we saw many claims. No need apply or blabla,0,0,0,,,,,
723,2023-02-25 01:42:30+00:00,DanielleFong,@ylecun make a recording :),0,0,0,,,,,
724,2023-02-25 01:41:09+00:00,taneemishere,"@ylecun deep learning is a mix of rock, punk and rap ü§£ü§£ llms are never going to stop talking about reality 

btw a well crafted album you‚Äôve though",0,0,0,,,,,
725,2023-02-25 01:27:05+00:00,manikant007,@ylecun https://t.co/5AAKviUa7e,0,1,0,,,,,
726,2023-02-25 01:23:49+00:00,CKtalon,@ylecun @phillipburch But it specifically says non commercial on your own model card? https://t.co/Cz4h2e8QG5 https://t.co/E2FW2FrOoa,0,1,0,,,,,
727,2023-02-25 01:16:45+00:00,mattmireles,@ylecun @ESYudkowsky Wen does it launch in beta?,0,0,0,,,,,
728,2023-02-25 01:14:49+00:00,infrecursion1,"@ylecun This is even more corny than ChatGPT, I didn't even know that was possible. Now that the magic of new age LLMs are wearing off slightly I don't really know why anyone would care about this.",0,0,0,,,,,
729,2023-02-25 01:01:44+00:00,AZAamerZaheer,"@ylecun It‚Äôs hilarious, Yann the rapper ;)",0,0,0,,,,,
730,2023-02-25 00:56:23+00:00,JaitanMartini,@ylecun üëèüëèüëè,0,0,0,,,,,
731,2023-02-25 00:56:08+00:00,hackotorch,"@ylecun Very happy to see this, especially open source. Like good science, artificial intelligence should embrace transparency.",0,0,0,,,,,
732,2023-02-25 00:54:17+00:00,andrew_craton,@ylecun Nice!!,0,0,0,,,,,
733,2023-02-25 00:51:04+00:00,ipvkyte,"@ylecun @BlancheMinerva It lets me make EMacs have an M-x shoggoth-mode, so there‚Äôs that",0,0,0,,,,,
734,2023-02-25 00:48:48+00:00,tringuyenkv,@ylecun huge respect for Meta üò≤üò≤üò≤üò≤ü•≥ü•≥,0,0,0,,,,,
735,2023-02-25 00:27:27+00:00,luka_emon,"@ylecun Oh give him a break. Facebook non-profit or funded by DARPA? They release code, paper, model, and if this is really Chinchilla level LM, it would be first one people could play.",1,1,0,,,,,
736,2023-02-25 00:26:38+00:00,jonathan582,"@ylecun @ESYudkowsky Ship something, then talk.",0,2,0,,,,,
737,2023-02-25 00:25:00+00:00,dasayan05,"@ylecun ""LLaMA"" is such a mellow name ü§£. Doesn't sound remotely ""foundational""",0,0,0,,,,,
738,2023-02-25 00:19:28+00:00,yuhuayang,@ylecun would you consider releasing open source image generation models?,0,0,0,,,,,
739,2023-02-25 00:07:43+00:00,danfaggella,@ylecun @ESYudkowsky https://t.co/dDlZN6FKzI,0,7,0,,,,,
740,2023-02-24 23:57:13+00:00,main_horse,"@ylecun @ESYudkowsky then why did you commit to the expensive and time consuming process of training new LLMs from scratch, while not doing the relatively cheaper job of RLHF on existing OPT models",1,2,0,,,,,
741,2023-02-24 23:52:09+00:00,indiequant,@ylecun @ESYudkowsky Are all AI alignment researchers so uninformed? Very disappointed by this hot take from Eliezer. Keep up the great work Yann!,0,6,0,,,,,
742,2023-02-24 23:50:13+00:00,QRJ211,"@ylecun @ESYudkowsky If it is not particularly tricky, why Meta hasn‚Äôt done it ? too expensive for Meta to do it ?",0,0,0,,,,,
743,2023-02-24 23:31:29+00:00,Andreas_Ramos,"@ylecun . @ylecun, how do you pronounce it? LA-ma or YA-ma?",0,0,0,,,,,
744,2023-02-24 23:28:25+00:00,apache547,@ylecun Another bs open source from Lecult,0,0,0,,,,,
745,2023-02-24 23:26:29+00:00,Pehdrew_,@ylecun how can I get access?,0,1,0,,,,,
746,2023-02-24 23:12:16+00:00,ZzimM,@ylecun @NinaDSchick I love this,0,0,0,,,,,
747,2023-02-24 23:12:07+00:00,garimakap,@ylecun Cc @abperiasamy @perrohunter,0,0,0,,,,,
748,2023-02-24 23:02:18+00:00,OptimalBayes,@ylecun If Meta has any interest in being relevant in the AI space they will need to release an interface to their models so that the public can use them and not back down when the fear mongers write sensationalized articles,0,15,0,,,,,
749,2023-02-24 22:56:24+00:00,amitmate2010,"@ylecun @ESYudkowsky Can we crowd-source the ""expensive + time consuming "" part? Any suggestions how ? New captcha + Federated Learning?",0,2,0,,,,,
750,2023-02-24 22:51:26+00:00,lepikhin,@ylecun Interactive demo instead of cherry-picked example?,0,7,0,,,,,
751,2023-02-24 22:48:49+00:00,R_Follador,@ylecun How does one objectively compare those LLMs among each other? Is there some kind of benchmark?,1,0,0,,,,,
752,2023-02-24 22:47:10+00:00,SergeTiunov,@ylecun Meta? The guys who wrote the Facebook app and the Famous Facebook Banning Wokebot? Forgive me while I'm ROTFL.,0,0,0,,,,,
753,2023-02-24 22:45:24+00:00,FLORIDALIBERTAS,@ylecun How many BS chatbot engines does the world need?,0,0,0,,,,,
754,2023-02-24 22:43:59+00:00,conjurial,@ylecun this should be an example for the music model I assume you're working on üòÇüôè,0,0,0,,,,,
755,2023-02-24 22:42:41+00:00,AndrewKyngdon,@ylecun Eat your heart out Dr Dre‚Ä¶,0,0,0,,,,,
756,2023-02-24 22:40:10+00:00,DuongBinhNhu1,@ylecun @ylecun can you ask the AI to mix the album in Snoop Dogg's style?,0,0,0,,,,,
757,2023-02-24 22:38:16+00:00,ToppaTib,"@ylecun @ESYudkowsky You're not the product guy, don't sweat it. Good research is obviously way better in the long run. Even if it has barely any users.",0,0,1,,,,,
758,2023-02-24 22:33:34+00:00,Willrandship,"@ylecun What parameter count is this? 65B? That's very impressive output, even if it's the largest announced model.",0,2,0,,,,,
759,2023-02-24 22:30:18+00:00,AlexanderDerve,@ylecun love it,0,0,0,,,,,
760,2023-02-24 22:29:49+00:00,phillipburch,"@ylecun Sorry, I wasn't referring to the code's license. I was referring the license agreement you have to sign to get access to the models. There's clearly a restriction on commercial/production use.",1,20,0,,,,,
761,2023-02-24 22:29:42+00:00,FLORIDALIBERTAS,"@ylecun @ESYudkowsky Meta would be my pick for #2 after Google in terms of total AI talent.  It's not Microsoft.

But I still don't see how anyone makes money with these for consumers.  I see it for businesses (cloud and productivity tools).",0,5,0,,,,,
762,2023-02-24 22:25:47+00:00,LuiscaMojica,"@ylecun Have you been throwing shit at everything others do, based on this? https://t.co/EjmzzfLmuP",0,0,0,,,,,
763,2023-02-24 22:25:29+00:00,francoisfleuret,@ylecun It'd be great to indicate what GPU specs are needed for each model.,3,22,0,,,,,
764,2023-02-24 22:24:41+00:00,brendan_evers,"@ylecun @ESYudkowsky It seems like the license on LLaMA is a bit restrictive, and might prevent people from doing much with it besides play around. Do you know if there's any chance that might change?",0,6,0,,,,,
765,2023-02-24 22:19:01+00:00,Disclosure89,@ylecun Also create a simple user interface like ChatGPT so that the avg joe can use this model....WHY IS THIS SO DIFFICULT TO UNDERSTAND....?,3,12,1,,,,,
766,2023-02-24 22:17:23+00:00,DeveloperHarris,"@ylecun Please adjust the license so we can create commercial products on top of it

Until then OpenAI is essentially the only game in town",4,41,0,,,,,
767,2023-02-24 22:16:55+00:00,omarmugabo,@ylecun üëè,0,1,0,,,,,
768,2023-02-24 22:16:20+00:00,IanFortier,@ylecun https://t.co/v6mR3Sar9G,0,0,0,,,,,
769,2023-02-24 22:16:13+00:00,TonySamaritano,@ylecun I knew you were actually a rap god all along,0,1,0,,,,,
770,2023-02-24 22:15:50+00:00,Omarito2412,@ylecun Time to record this üï∫,0,0,0,,,,,
771,2023-02-24 22:14:56+00:00,babkiblyat,@ylecun Can we see some of it‚Äôs code gen,0,0,0,,,,,
772,2023-02-24 22:08:07+00:00,danison1337,@ylecun @ESYudkowsky We need open fine tuning not only open source,1,1,0,,,,,
773,2023-02-24 22:02:29+00:00,_msw_,"@ylecun @aindrei @BlancheMinerva While it is true that the Linux kernel is licensed under a GPL license, it is not GPLv3. It is expressly ""GPLv2, and no later version.""

That said, GCC is pervasive software that is licensed under GPLv3. That might be a better example for you to use.",3,43,0,,,,,
774,2023-02-24 21:55:15+00:00,elSearsIV,@ylecun Is it slow or fast though? @kekatzmann,1,5,0,,,,,
775,2023-02-24 21:42:58+00:00,KeithAmburgey,@ylecun https://t.co/DCaT7XDuxm,0,0,0,,,,,
776,2023-02-24 21:42:47+00:00,crane_leland,@ylecun What are the criteria for granting access to the weights?  Does one need a certain number of publications?,0,1,0,,,,,
777,2023-02-24 21:14:56+00:00,dromanocpm,@ylecun It literally says here to apply for access and that its not for commercial use... Seems open source ü§¶‚Äç‚ôÇÔ∏è https://t.co/2Ny4JuBySr,0,3,0,,,,,
778,2023-02-24 21:04:24+00:00,timg_tweeter,"@ylecun ""Access to the model will be granted on a case-by-case basis to academic researchers"".  Not what I'd call ""open source"".",0,14,0,,,,,
779,2023-02-24 20:59:47+00:00,QRJ211,@ylecun This is a good academic work; its commerical use is limited or Meta will not release it.,0,0,0,,,,,
780,2023-02-24 20:58:43+00:00,nafiz_h,"@ylecun 1. The model weights are not released, u have to file a request form and wait to see if u get approved.
2. The model weights are not licensed for commercial use. Enough people out there can write the code but very few have 3000 gpus.",0,29,0,,,,,
781,2023-02-24 20:58:33+00:00,epic_malloc,@ylecun Would love to play with this as the alternative to gpt-3 https://t.co/jerdWAuhX0,1,4,0,,,,,
782,2023-02-24 20:56:46+00:00,NandoDF,@ylecun Llama ü¶ô est√° bien en llamas üî•! https://t.co/hpyMyq1VIz,1,3,0,,,,,
783,2023-02-24 20:55:24+00:00,prootman,"@ylecun @_ash_ran @AlanMorte @OpenAI There is one metric that we don't take into account and it's societal and behavioural impact on people. Honestly, it would be hard to say if impact on society is positive, all these AI algorithms on medias(insta reels, tiktok etc...)only increase conformism and sterilize people.",0,1,0,,,,,
784,2023-02-24 20:54:49+00:00,MeysamAsgariC,@ylecun Thanks :),0,1,0,,,,,
785,2023-02-24 20:46:13+00:00,chheplo,"@ylecun @BlancheMinerva Meta should release weights also under GPL. That would clear a lot of legal hurdles for us to develop applications, a true democratization of AI.",0,6,0,,,,,
786,2023-02-24 20:45:46+00:00,shahafdan,@ylecun Revolutionary. 65B parameters and better performance than GPT3!,0,0,0,,,,,
787,2023-02-24 20:41:41+00:00,snowman647,"@ylecun What a day, Meta, Google and OpenAI have made awesome posts today. 
Please keep doing what you are doing üçø",0,0,0,,,,,
788,2023-02-24 20:41:39+00:00,aindrei,@ylecun @BlancheMinerva GPLv3 is not a license that most companies will touch.,6,14,0,,,,,
789,2023-02-24 20:38:54+00:00,StatsLime,@ylecun Ok but did u write it in Julia,0,0,0,,,,,
790,2023-02-24 20:34:45+00:00,BlancheMinerva,"@ylecun 1. You literally said that the models were released under GPLv3, which is false

2. The code is far *far* less important than the model weights",3,77,1,,,,,
791,2023-02-24 20:31:19+00:00,ylecun,Blog post: https://t.co/zDA9h0VbHF,6,88,12,,,,,
792,2023-02-24 20:29:35+00:00,shockrobortyy,"@ylecun That‚Äôs great to hear.
Are these just documentation errors? or am I misunderstanding the license agreement https://t.co/LIyMZZsyax",1,34,0,,,,,
793,2023-02-24 20:29:32+00:00,tugot17,@ylecun @BlancheMinerva Ok but how does it matter if the parameters are released under a non-commercial license? Like who cares under what the code is released?,1,10,0,,,,,
794,2023-02-24 20:28:11+00:00,JonGroen,@ylecun So the trained model is publicly available??,0,0,0,,,,,
795,2023-02-24 20:26:59+00:00,yasserlgnd,"@ylecun Quick question. I appreciate the open source nature. Last time I checked the license, it prohibited use in military application. Is this the case?",0,0,0,,,,,
796,2023-02-24 20:26:43+00:00,Bahman_Apl,@ylecun @BlancheMinerva What about fine-tuning the model ?,0,0,0,,,,,
797,2023-02-24 20:24:17+00:00,Bahman_Apl,@ylecun Can this be use for commercial use ?,1,0,0,,,,,
798,2023-02-24 20:09:55+00:00,VarunMayya,"@ylecun Can you pls approve my request, will try this tomorrow!",1,15,0,,,,,
799,2023-02-24 19:57:02+00:00,passionfingerz,@ylecun Needs more asterisks,0,1,0,,,,,
800,2023-02-24 19:55:55+00:00,cristoforestman,"@ylecun What a time to be alive! Not sure about their ""release the models for researchers only"". It's enough to have one researcher that'll leak the model to the public and it's done",0,2,0,,,,,
801,2023-02-24 19:52:18+00:00,infotainer0,@ylecun Thank you,0,0,0,,,,,
802,2023-02-24 19:49:31+00:00,cztomsik,@ylecun Thanks for publishing this.,0,0,0,,,,,
803,2023-02-24 19:44:17+00:00,Agus_PGDante,@ylecun So‚Ä¶this is *open-source*? https://t.co/YQwLPTmttr,0,7,0,,,,,
804,2023-02-24 19:43:57+00:00,ambuj0,@ylecun Fantastic results outperforming 10x larger models with open data only! LLaMA training loss graph shows possible further improvement with both size and further training. Any thoughts on eventual bounds on loss with this arch?,0,1,0,,,,,
805,2023-02-24 19:36:14+00:00,damiencuillery,@ylecun Jeez. That thread should be more engaging than the previous one. Probably won‚Äôt. But it should!,0,0,0,,,,,
806,2023-02-24 19:34:50+00:00,crane_leland,@ylecun Looks interesting!  What are the criteria for granting access to the weights?  Do you need a certain number of publications?  I‚Äôve waited for months for OPT-175 access and never heard anything back.,0,4,0,,,,,
807,2023-02-24 19:34:20+00:00,adamzwasserman,"@ylecun Counterpoint thoughts. 
LISP? Tried that in '82, result: AI Winter. 
Historical source of major advances in -development- productivity? 
1) Abstraction implemented in compilers (i.e. higher level languages)
2) High reuse of standard libraries (i.e. NextStep or Github)",0,0,0,,,,,
808,2023-02-24 19:21:39+00:00,shockrobortyy,@ylecun not really open source if its only for non-commercial purposes and has a request form. Would love to see Meta pushing these models to Huggingface with MIT license or similar licensing,2,39,0,,,,,
809,2023-02-24 19:16:09+00:00,timothypeckover,"@ylecun Thats like, a LOT of parameters. ü§ñ",0,0,0,,,,,
810,2023-02-24 19:11:01+00:00,HenkPoley,@ylecun The Chinchilla paper.,0,0,0,,,,,
811,2023-02-24 19:10:23+00:00,yar_vol,@ylecun Why model downloads require google form? At least small (under 200B) models should be available please! Like Galactica and OTP models.,1,4,0,,,,,
812,2023-02-24 19:09:59+00:00,JimmyBa62254692,@ylecun Thank u for releasing it to the research community,0,0,0,,,,,
813,2023-02-24 19:09:09+00:00,gslaller,"@ylecun Folks you screwed again in twittersphere, by have a too restrictive licensing. ü•≥ü•≥ü•≥",0,0,0,,,,,
814,2023-02-24 19:05:26+00:00,rsdenijs,@ylecun @jezzarax,0,0,0,,,,,
815,2023-02-24 19:01:53+00:00,phillipburch,"@ylecun This is a step forward. Hoping for an even more ""open"" release in the future. Ideally, something supporting commercial uses.",1,12,0,,,,,
816,2023-02-24 18:59:37+00:00,iruletheworldmo,@ylecun Can we use it ü§£ü§£ü§£ü§£ü§£ü§£ü§£,2,0,0,,,,,
817,2023-02-24 18:57:28+00:00,weofmimwegw,"@ylecun @percyliang Nobody cares actually in this case, as it don't need to be as accurate as auto driving, a long error tail is not big deal",0,0,0,,,,,
818,2023-02-24 18:56:41+00:00,CharlieKnoles,"@ylecun So you‚Äôre saying that this AI is open. 

Interesting‚Ä¶ ü§î

In all seriousness. Great work.",0,1,0,,,,,
819,2023-02-24 18:56:17+00:00,StillTr05207382,"@ylecun Any pointers to documentation on the practical aspects (e.g., hardware requirements) of getting these up and running?",1,0,0,,,,,
820,2023-02-24 18:55:46+00:00,pucknorris,@ylecun Nice work @ylecun and Meta AI team!,0,4,0,,,,,
821,2023-02-24 18:55:37+00:00,primrecur,"@ylecun https://t.co/kziGfx0DI6
""In order to download the checkpoints and tokenizer, fill this google form""

https://t.co/VxgDPL9E1J
""Non-commercial bespoke license""",0,17,0,,,,,
822,2023-02-24 18:54:45+00:00,itsandrewgao,@ylecun was this research done in france?,0,0,0,,,,,
823,2023-02-24 18:53:25+00:00,ylecun,https://t.co/Z5yftjwytT,5,103,8,,,,,
824,2023-02-24 18:49:50+00:00,ylecun,Some results from the paper. https://t.co/PPPa9p8KyB,2,70,7,,,,,
825,2023-02-24 18:48:55+00:00,vinniemourax,@ylecun https://t.co/h4xavKkyNu,0,0,0,,,,,
826,2023-02-24 18:48:55+00:00,adamnemecek1,"@ylecun Do you have a stance on Hopf algebras? They subsume tensors and provide a better autodiff, one that happens within layers as opposed to across the whole graph. Transformers, diffusion models, convnets are unified within Hopf algebra
I wrote a paper on this
https://t.co/PoUnrXBLEI",0,10,1,,,,,
827,2023-02-24 18:48:15+00:00,shikhar1verma,@ylecun This must be better than current mainstream models.,0,0,0,,,,,
828,2023-02-24 18:48:09+00:00,kaalam_ai,"@ylecun @claycurry_ It had its moment in a pre-open source world. Nobody misses it, I guess. (It had a half decent debugger, scilab and R did not have.)",0,1,0,,,,,
829,2023-02-24 18:48:09+00:00,ArthurB,"@ylecun In your opinion, what about LLaMa's design or training yielded the greatest improvement over OPT?",0,11,0,,,,,
830,2023-02-24 18:47:34+00:00,BlancheMinerva,"@ylecun ""Meta is committed to open research and releases all the models the research community under a GPL v3 license.""

... this isn't true. The model is under a non-commercial license.",9,184,7,,,,,
831,2023-02-24 18:44:36+00:00,ylecun,"LLaMA is a collection of foundation LLMs from 7B to 65B parameters.
They have been trained on trillions of tokens from publicly available datasets
- LLaMA-13B outperforms GPT-3 (175B) on most benchmarks
- LLaMA-65B is competitive with the best models, Chinchilla70B and PaLM-540B",6,220,20,,,,,
832,2023-02-24 18:43:55+00:00,HmFood4Thought,"@ylecun Boom! Thank you, sir!",0,0,0,,,,,
833,2023-02-24 18:43:08+00:00,lcastricato,@ylecun The model is clearly not GPL though no? Only the code is?,1,30,0,,,,,
834,2023-02-24 17:25:31+00:00,matt_nlp,"@ylecun and @MetaAI dropping LLMs like they grow on trees!

You get a 7B LLM!
You get a 13B LLM!
You get a 33B LLM!
You get a 65B LLM!

And competitive with 10x larger models... ü§Ø

In all seriousness, this is AMAZING for the research community!!!

https://t.co/q3pOlCnZfD https://t.co/9MEVNf2yJF",0,1,0,,,,,
835,2023-02-24 16:58:16+00:00,ShaidaSherpao,@ylecun @pmarca so OpenAI did the hard work. I believe Facebook and other giants will do something better in *a* future.,0,0,0,,,,,
836,2023-02-24 16:10:00+00:00,Fmelobr,"@ylecun 1- COBOL
2- PL/1
3- Basic
4- Natural/Adabas
5- Stairs
6- Visual Basic
7- C#
8- R
9- Python",0,0,0,,,,,
837,2023-02-24 15:42:38+00:00,sorinpetrov,@ylecun this part of the newsletter didn't link to your profile so just fyi @WellfoundHQ https://t.co/fQrDTOGWoP,0,0,0,,,,,
838,2023-02-24 14:55:45+00:00,pitsch,@ylecun homoiconicity might be quite a key feature for models trained to write code.,0,0,0,,,,,
839,2023-02-24 13:49:12+00:00,an0,@ylecun Swift has a chance: https://t.co/vbAHH2mzOW,0,1,0,,,,,
840,2023-02-24 13:13:51+00:00,slimelingual,@ylecun is Rust too bloated?,0,0,0,,,,,
841,2023-02-24 09:43:37+00:00,dev_ceb,"@ylecun ‚Ä¶. Like Lua/Torch? I think Python somehow swallowed its best competition. Probably due to adoption of big data pipelines, Python had the ecosystem",0,1,0,,,,,
842,2023-02-24 09:19:59+00:00,lebronjamesmill,@ylecun This is a freezing cold take. Lab I worked in Used matlab to do synapse mapping ML work. Speed (both in writing code and executing) was a snails pace.,0,0,0,,,,,
843,2023-02-24 09:13:07+00:00,geetkhosla,@ylecun @pmarca tell us more ..,0,0,0,,,,,
844,2023-02-24 09:06:07+00:00,KleppeThorsten,"@ylecun @pmarca Well, but there is a better way than a CNN... or a FFN, but people still do wrong! You don't know it yet because I don't want to support the wrong team. What's your excuse?",0,0,0,,,,,
845,2023-02-24 08:41:17+00:00,FUTURENEWS2020,@ylecun @pmarca Whats better‚Ä¶if its ‚Äúbetter‚Äù  how is it better,0,0,0,,,,,
846,2023-02-24 08:05:08+00:00,ZenoRogue,"@ylecun Interactive is not a property of programming language, there is Cling which is a REPL for C++. By bloat I guess you mean C++ is hard to learn. Seems hard to find a good tutorial when the default language for tutorials is Python.",0,1,0,,,,,
847,2023-02-24 06:32:26+00:00,ComputingByArts,@ylecun Julia is ready for ML prime time,0,0,0,,,,,
848,2023-02-24 06:32:22+00:00,glen_studdard,@ylecun I love love Julia in principle. Not sure about in practice‚Ä¶,0,0,0,,,,,
849,2023-02-24 05:57:57+00:00,AI_ML_iQ,@ylecun @SamForman979 @pmarca Answer is in probabilistic approach.,0,0,0,,,,,
850,2023-02-24 05:45:09+00:00,quickdwarf,@ylecun @SamForman979 @pmarca it's just one way to pronounce JEPA,0,1,0,,,,,
851,2023-02-24 05:30:26+00:00,HmFood4Thought,"@ylecun @SamForman979 @pmarca Omg, this is going on my wall. üòÜ",0,0,0,,,,,
852,2023-02-24 04:18:35+00:00,ShaidaSherpao,@ylecun @pmarca You're trying so hard to bring ChatGPT down. Idk why. If there are better things why has it not happened yet.,2,0,0,,,,,
853,2023-02-24 04:12:09+00:00,MacGraeme42,@ylecun @percyliang Any system that does not experience the world and learn for itself is going to be at the mercy of the data it is given to learn from.,0,25,2,,,,,
854,2023-02-24 03:56:03+00:00,skynetislov3,@ylecun @SamForman979 @pmarca Hehe is a new framework for LLM applications,0,11,0,,,,,
855,2023-02-24 03:48:37+00:00,bahree,@ylecun @pmarca Thoughts on weak supervision and synthetic data?,0,0,0,,,,,
856,2023-02-24 03:48:28+00:00,jasonfi,@ylecun @pmarca The game is afoot...,0,0,0,,,,,
857,2023-02-24 03:36:45+00:00,AegoraEn,@ylecun ...Erlangers still patiently waiting for the world to catch up...,0,1,0,,,,,
858,2023-02-24 03:30:45+00:00,SamForman979,@ylecun @pmarca What is it?,2,2,0,,,,,
859,2023-02-24 03:10:43+00:00,michael_at_work,"@ylecun @OuahabiAdnane (Translated to various Pythonista sects)
There were 3 (completely incompatible, introduced at different times, some now deprecated even if happens to be most widely used) reasons to switch to Python:
1. People want Python
2. Python wanted by People
3. People (want Python)",1,2,0,,,,,
860,2023-02-24 03:08:38+00:00,kenshinsamurai9,"@ylecun @pmarca Yann, my apologies for being so pushy on the @GaryMarcus situation, but I do believe he deserves credit for a lot. I do have a large amount of respect, for the pivotal work you have done in your career. 

That said, we must take this seriously: \",1,2,0,,,,,
861,2023-02-24 02:41:26+00:00,yasserlgnd,@ylecun @percyliang Agreed 100%. I think your ‚ÄúPath toward Autonomous Machine Intelligence‚Äù is the way to go!,0,3,0,,,,,
862,2023-02-24 00:45:33+00:00,QRJ211,@ylecun @percyliang What is your solution then ?  I believe RLHF is the key underlying technology that distinguishes ChatGPT from its competitors.,1,1,0,,,,,
863,2023-02-24 00:33:21+00:00,florinandrei,"@ylecun White spaces / the rigid format - that's a feature, not a bug. It contributes to clarity, and it's one of the reasons why Python is so popular despite its obvious downsides (some of which you've highlighted).",0,0,0,,,,,
864,2023-02-24 00:21:12+00:00,lisa44Yes,"@ylecun @SebastianSeung The chrome folks are protecting you whether you like it or not.
Someone could spy on your connection and see all your secret neural network info when using http.

Never forget the Wayback Machine. 
https://t.co/TKuRVsAfdp",0,3,0,,,,,
865,2023-02-23 23:57:53+00:00,greatgib42,"@ylecun The secret of Python is that it is easy to work with, but the computer intensive parts (ie what really matters), are already executed by C or compiled code.",0,1,0,,,,,
866,2023-02-23 23:36:11+00:00,kourouklides,"@ylecun @percyliang Tell me that you don‚Äôt understand what RLHF is, without actually telling me that ‚Ä¶

RLHF has nothing to do with ‚Äúwrong answers‚Äù. ü§¶‚Äç‚ôÇÔ∏è  Human feedback is not used for ‚Äúcorrectness‚Äù or ‚Äúwrongness‚Äù.",2,2,1,,,,,
867,2023-02-23 22:51:37+00:00,PaulTopping,"@ylecun Language wars comes to AI! Waiting for the final ""Hottest take"".",0,0,0,,,,,
868,2023-02-23 22:36:37+00:00,jryanearl,@ylecun @GaryMarcus I wrote a LISP program to solve my calculus problems freshman year in college üòÇ,0,0,0,,,,,
869,2023-02-23 20:26:20+00:00,subho_in,@ylecun Jax is pretty good at most of this!,0,0,0,,,,,
870,2023-02-23 20:24:07+00:00,DmitryMatveev,"@ylecun Lisp has had a privilege to be around ""AI"" decades before Python ever gained notable user mass, and have never really taken off. What could change now, after Python has got all the momentum?

BTW you described Smalltalk",0,2,0,,,,,
871,2023-02-23 20:23:25+00:00,axlewandowski,"@ylecun Julia is growing, especially in RL circles!",1,0,0,,,,,
872,2023-02-23 20:08:32+00:00,Sean_McBeth,"@ylecun It shocks me that people *choose* to use Python. That people get up in the morning and actively decide, ""this is how I want to live my life. With broken tools.""",0,2,0,,,,,
873,2023-02-23 19:07:05+00:00,janusheie,@ylecun @SebastianSeung Important issue üòÖü§£üòç,0,0,0,,,,,
874,2023-02-23 19:04:32+00:00,RealGilbertHuph,"@ylecun Types, types, baby. Have wasted days and dollars because we thought key in hash map was &lt;x&gt; when it was &lt;y&gt;.",0,1,0,,,,,
875,2023-02-23 18:54:09+00:00,SynapticSelf,"@ylecun @GaryMarcus I would love a good Lisp for ML!  Here's my first contribution, courtesy of Stable Diffusion. https://t.co/fOIcdDDe7P",0,0,0,,,,,
876,2023-02-23 18:53:18+00:00,eLeCtrOssSnake,@ylecun True,0,0,0,,,,,
877,2023-02-23 18:44:03+00:00,freecodyx,@ylecun @SebastianSeung Host it on github pages,0,2,0,,,,,
878,2023-02-23 18:31:37+00:00,sandro_mrt,"@ylecun @OuahabiAdnane Am i out of touch?

No, it's all the ml engineers who are out of touch.",0,0,0,,,,,
879,2023-02-23 18:28:24+00:00,vincebrandon,"@ylecun Yes.  And whose interaction with the browser environment has sensible, consistent, abstracts, to make things like state stores less ridiculous.",0,0,0,,,,,
880,2023-02-23 18:01:38+00:00,_brendand_,"@ylecun Yeah, pretty terrible take",0,0,0,,,,,
881,2023-02-23 17:46:07+00:00,FrancoisTheber1,@ylecun Faster? Why faster? Is there an imperative and existential NEED to go ever faster?,0,0,0,,,,,
882,2023-02-23 17:40:42+00:00,ToppaTib,@ylecun @SebastianSeung Doesnt seem to work on Brave,0,2,0,,,,,
883,2023-02-23 17:37:26+00:00,GoatBend,"@ylecun Disagree completely. Python is approachable for beginners. The API is great, and it‚Äôs quick to spin up scripts.",0,1,0,,,,,
884,2023-02-23 17:19:12+00:00,JustADegu,"@ylecun I dislike Python with a burning passion but the frontend to ML is usually so slim it doesn‚Äôt matter, the pros far outweigh the cons.",0,0,0,,,,,
885,2023-02-23 17:10:11+00:00,marcio_lopes,"@ylecun This is the answer: https://t.co/HQ0uDtDVJx

#Clojure",0,1,0,,,,,
886,2023-02-23 17:05:01+00:00,PeeLo73,@ylecun Ask Chat-gpt to create it for you.,0,0,0,,,,,
887,2023-02-23 16:55:12+00:00,bhack_10,"@ylecun There is an ""AI"" section in the last version of https://t.co/6jRAK51RAs",0,1,0,,,,,
888,2023-02-23 16:50:34+00:00,betachapeu,@ylecun @memecrashes,0,0,0,,,,,
889,2023-02-23 16:26:49+00:00,kirushyk,@ylecun What is your choice? Julia?,0,0,0,,,,,
890,2023-02-23 15:55:32+00:00,itsa_new_Bird,"@ylecun ‚Ä¶ bloat &amp; whitespace aren‚Äòt the only things I would criticize, it‚Äôs also about consistency: https://t.co/47WBK4mkFr",0,0,0,,,,,
891,2023-02-23 15:44:59+00:00,ManyaMayes,@ylecun Love it. 1988/89 for me.,0,0,0,,,,,
892,2023-02-23 15:37:04+00:00,notbyintent,"@ylecun Lisp is beautiful mathematically which was the seductive rationale for teaching it in computer ""science"".  But lambda calculus description left much to be desired practically.  That, I believe, remains the case?",0,0,0,,,,,
893,2023-02-23 15:22:35+00:00,HardTruthAICat,"@ylecun I think C# with a more interactive shell would be a great application-driven language to integrate ML frameworks natively into, given its popularity in games and digital media (e.g. Unity).",0,0,0,,,,,
894,2023-02-23 15:11:14+00:00,landsheapes,@ylecun R with a few performance improvements #rstats. I don't know why functional programming isn't more popular in ML,0,0,1,,,,,
895,2023-02-23 15:06:16+00:00,Scienteer,"@ylecun Javascript.  I wish Javascript had become the ML orchestration language rather than Python.  While the main language is single threaded, many things are async at that level, multithreaded in implementation.  Plus with WebWorkers (another thread), WASM...",0,0,0,,,,,
896,2023-02-23 15:00:35+00:00,EduardoCsarGar1,"@ylecun Lisp!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Beautiful Lisp. My respects, Yann.",0,1,0,,,,,
897,2023-02-23 14:55:16+00:00,schue,@ylecun CMS would have advanced faster if something other than PHP... oh never mind. The world is full of mysteries.,0,0,0,,,,,
898,2023-02-23 14:32:41+00:00,RoyKishony,"@ylecun On the question of interactivity for Python, I would point to our new package Quibbler: it readily brings interactivity to any python code.
https://t.co/fojVxFGnmF",0,0,0,,,,,
899,2023-02-23 14:04:31+00:00,vinchibana,@ylecun @SaveToNotion #Thread #chatgpt,0,0,0,,,,,
900,2023-02-23 14:04:11+00:00,marccleison,"@ylecun Let me introduce you the @ChapelLanguage . It is an amazing language with excellent parallel processing support. Easy as Python, fast as C. It is worth experiment it.",0,1,0,,,,,
901,2023-02-23 13:51:33+00:00,vijayiyer312,@ylecun Struggling to agree here. I'm guessing by 2005 MATLAB I think you're meaning pre-OOP. That came quite soon after in 2008 (I was an early adopter; was essential imho to developing complex software in MATLAB). Some seminal DL applications (e.g. connectomics) were coded in MATLAB.,0,3,0,,,,,
902,2023-02-23 13:47:24+00:00,ChiefScientist,@ylecun @eulerfx Scala!,0,0,0,,,,,
903,2023-02-23 13:46:23+00:00,GafurovOleg,"@ylecun @Oumaima_elk @UM6P_officiel Jan, I really want to introduce you to PANN technology. You are a great scientist and it will definitely be interesting for you ... https://t.co/fgqxUXMiXT",0,0,0,,,,,
904,2023-02-23 13:32:41+00:00,bucket_pop,@ylecun Julia!,0,1,0,,,,,
905,2023-02-23 13:28:45+00:00,mdsumner,"@ylecun 10 years and it'll be ""esri held back progress in geo for 40 years""",0,2,0,,,,,
906,2023-02-23 13:28:26+00:00,carsondahlberg,"@ylecun Academia affects AI advancement more than language, just like every other field",0,0,0,,,,,
907,2023-02-23 13:24:10+00:00,GaryMarcus,"@ylecun just a joke; not a serious point, but elaborated below. (With sources even: Nature, Noema, Twitter üòÜ). 

I guess the serious question is, if you are willing to use LISP as a kind of support scaffold, why not use it in your core AI as well?",2,2,0,,,,,
908,2023-02-23 13:24:07+00:00,JonathanJRayner,"@ylecun Didn't Google have a longshot project where they

1. Narrowed it down to Swift vs. Julia
2. Decided Julia was too immature and went with Swift 
3. *years go by, Chris Lattner leaves, the TF Swift project is archived

In another timeline, maybe Julia ML is 5 years ahead.",0,0,0,,,,,
909,2023-02-23 13:20:20+00:00,hubertpaulo,@ylecun GIL is a real nuisance indeed,0,0,0,,,,,
910,2023-02-23 13:18:52+00:00,osnieltx,"@ylecun what do you mean by ""using Lisp as a front-end language""? the term front-end for me refers to languages commonly used to create front-end interfaces, like javascript. Lisp appears to be a back-end language.",0,0,0,,,,,
911,2023-02-23 13:04:32+00:00,EsmalHaj,"@ylecun Use Crystal or Julia, both have Parallelism, both don't have a GIL, Crystal is fast as C and simple as Ruby. Whatever else do you need???",0,0,0,,,,,
912,2023-02-23 13:04:25+00:00,EsmalHaj,"@ylecun Use Crystal or Julia, both have Parallelism, both don't have a GIL, Crystal is fast as C and simple as Ruby. Whatever else do you need???",0,0,0,,,,,
913,2023-02-23 13:02:45+00:00,chanep,@ylecun Agreed. I tell everyone I meet that Python sucks.,2,0,0,,,,,
914,2023-02-23 12:39:12+00:00,tarrysingh,@ylecun Really a pity that Julia never got to where we‚Äôd have wanted it.,0,0,0,,,,,
915,2023-02-23 12:34:13+00:00,samuel_abolo,"@ylecun Concerning ML, i see python as a language that acts as an interface to the tools written in C++. 

I believe the flexibility of python has actually contributed to the fast paced movement of the AI field.

Plus a compiler slows down the iterations involved in training ML models.",1,2,0,,,,,
916,2023-02-23 12:25:34+00:00,femialeex,@ylecun Interesting thought,0,0,0,,,,,
917,2023-02-23 12:19:50+00:00,Huvin_,@ylecun @OuahabiAdnane Are u planning to adopt Julia in some capacity ?,0,0,0,,,,,
918,2023-02-23 12:18:38+00:00,sirotenko_m,@ylecun As someone who did exactly that I can confirm üòÑ,0,0,0,,,,,
919,2023-02-23 12:09:23+00:00,ryan_c414,@ylecun Why do you care about GIL if the heavy lifting is being handled by the GPU?,0,0,0,,,,,
920,2023-02-23 11:50:14+00:00,m4h007,@ylecun üíØüéØüéØüéØüéØ,0,0,0,,,,,
921,2023-02-23 11:44:27+00:00,gauravontwit,"@ylecun Python is not a front-end language, JS is the front-end language for web apps. Some GUIs can be made in Python for desktop apps, but it's much rarer even on desktops than the electron.",1,1,0,,,,,
922,2023-02-23 11:02:28+00:00,cavmarginal,@ylecun I wish control engineers could think the same,0,0,0,,,,,
923,2023-02-23 10:58:51+00:00,johndmk,@ylecun A lisp front end would be (have been) really cool ...,0,0,0,,,,,
924,2023-02-23 10:51:56+00:00,Perryman1138,@ylecun @AlmadorCharlie Is Julia‚Äôs REPL still slow?,1,0,0,,,,,
925,2023-02-23 10:51:20+00:00,AndrewJacksonZA,"@ylecun Better yet, C# for millions of Windows developers.",0,0,0,,,,,
926,2023-02-23 10:38:08+00:00,rahul_pna,"@ylecun For many use cases, The latency that comes in execution makes python a choice only for MVPs not for production.",0,0,0,,,,,
927,2023-02-23 10:36:31+00:00,HeiKo51112349,"@ylecun If we had quantum computers with perfect algorithms and a perfect database with all the data in the universe, ML would probably be a little more advanced.",0,1,0,,,,,
928,2023-02-23 10:24:39+00:00,viky_bhat,"@ylecun Scala would have been perfect, it has everything from OOPs to functional to distributed computing integration.  you can build the entire backend in scala and its portable using JVM to any system.",0,0,0,,,,,
929,2023-02-23 10:15:21+00:00,stevesmart,"@ylecun No Yann. Most libraries where speed is required are compiled down. But in any case, more speed wouldn't make progress faster. Better algorithms will.",0,0,0,,,,,
930,2023-02-23 10:10:43+00:00,ctrebbau,@ylecun Burn!,0,0,0,,,,,
931,2023-02-23 10:08:14+00:00,BroVic,@ylecun I've said this before. Julia should be the go-to language for ML.,0,0,0,,,,,
932,2023-02-23 10:00:50+00:00,scifi_fund,@ylecun thoughts of everyone ever who has never written production code,0,2,0,,,,,
933,2023-02-23 09:54:36+00:00,daloore,"@ylecun Don't you mean Cpython?

There are other pythons without gil",0,0,0,,,,,
934,2023-02-23 09:49:44+00:00,stu_axon,"@ylecun Those don't have as big a set of libraries you can easily install from pypi.
The easy interop with C is why fast libraries to do the work were already in place.",1,3,0,,,,,
935,2023-02-23 09:48:26+00:00,talithafs,"@ylecun Probably the right take. As an experienced programmer  coming from real OOP and structured languages, I feel that using Python on daily basis has had a negative impact on my skills. My productivity certainly went down, b/c Python is bloated &amp; encourages all sorts of bad practices",0,3,0,,,,,
936,2023-02-23 09:29:00+00:00,Czaki_PL,"@ylecun But python is only workflow description language in this case. So it does not impact performance.

Multithreading is hard and GIL protect most of users from most of typical problems.",0,0,0,,,,,
937,2023-02-23 09:28:07+00:00,0player,"@ylecun You mean, like, an actually good one? Lisp has been used in AI research, but fell out of favor for... some reason.",0,0,0,,,,,
938,2023-02-23 09:14:15+00:00,AndyDHigginson,"@ylecun @claycurry_ What's wrong with Matlab. Depends what you need, but the plotting functionality is second-to-none.",1,0,0,,,,,
939,2023-02-23 09:14:15+00:00,stay_upto_date,"@ylecun @OuahabiAdnane I think the reason why people chose Python was because a lot of ML developers came from statistics with a science background (other than computer science), and Python is very simple to get started for those without programming experience.",0,1,0,,,,,
940,2023-02-23 09:13:16+00:00,AndyDHigginson,@ylecun Yes to the whitespace thing. It blows my mind that the looping depends on tabs! Hideous.,0,0,0,,,,,
941,2023-02-23 08:57:47+00:00,throttlecntrl,@ylecun c,0,0,0,,,,,
942,2023-02-23 08:45:18+00:00,MathSRIsh,"@ylecun The barrier of entry for Lisp is too high.
But Julia is a strong candidate yes.",1,2,0,,,,,
943,2023-02-23 08:37:19+00:00,FNeubueser,"@ylecun #LISP?
(((((((Are-you sure?))))))",0,0,0,,,,,
944,2023-02-23 08:01:56+00:00,jrosell,"@ylecun @OuahabiAdnane People is starting to have some love for Julia.

Julia is awesome and it would be even better if it had the packages that R has and the libraries that Python has.",1,2,0,,,,,
945,2023-02-23 07:42:57+00:00,ProcelioMena,@ylecun take a look at FastAPI you may found it insteresting,0,0,0,,,,,
946,2023-02-23 07:07:25+00:00,Sam_K_G,"@ylecun What about rust?

That way systems folks can be happy too :-)",0,0,0,,,,,
947,2023-02-23 06:59:00+00:00,oanaolt,"@ylecun I wrote my undergrad thesis on echo state neural networks, big progress since then. 

In fact out of the entire CS batch at the university in Germany, only two of us chose ML, the rest didn‚Äôt want to deal with Matlab üò≠

He is a researcher at Google Brain and I invest in ML",0,13,0,,,,,
948,2023-02-23 06:58:27+00:00,datamatic,@ylecun Well the semantics (grammar) of Matlab (everything is arrays) was totally different that Python where everything is a more general object. That being said Python can be replaced by a variant with comparable grammar but better perf.,1,0,0,,,,,
949,2023-02-23 06:56:27+00:00,miehrmantraut,@ylecun Umm those were available actually. Problem is that industry did what industry always does and picked a terrible language to blow up.,0,0,0,,,,,
950,2023-02-23 06:56:26+00:00,StatsLime,"@ylecun @OuahabiAdnane I have talked to dozens of ML engineers, and honestly, nobody there has ever told me they wanted Python.* Everyone is just convinced that everyone else wants Python. 

*Exception: people who don't know about newer languages like Julia or Nim.",0,1,0,,,,,
951,2023-02-23 06:54:20+00:00,mindplaydk,"@ylecun @metapgmr Julia seemed to me like the perfect successor to Python: statically typed, fast enough to write things like machine learning algorithms in the language - and the IDE/REPL looks amazing for ML and data science.

Why aren't Python users adopting?",1,4,0,,,,,
952,2023-02-23 06:49:44+00:00,Harizanov87,@ylecun Clojure!,0,0,0,,,,,
953,2023-02-23 06:43:11+00:00,leonel9723,@ylecun Is there a way to fix the GIL for python,0,1,0,,,,,
954,2023-02-23 06:43:10+00:00,farhoodetaati,@ylecun https://t.co/7Z0KCyVFl4,0,0,0,,,,,
955,2023-02-23 06:41:35+00:00,leonel9723,@ylecun Interisting. Is withespaces indentation related to other item in that list or you just included because it annoys you?,0,0,0,,,,,
956,2023-02-23 06:38:01+00:00,StatsLime,@ylecun @ylecun then use Julia! Every ML engineer and researcher I have met says this. All of them say they'd love to work in Julia and use it. But *nobody pays people to work on the Julia ecosystem*.,1,3,0,,,,,
957,2023-02-23 06:35:12+00:00,pmf,"@ylecun It had a FFI, and it was quite common to have high performance parts written in C (just like it is in Python). Licensing might have been the bigger factor.",0,0,0,,,,,
958,2023-02-23 06:25:09+00:00,fsfarimani,@ylecun @stylewarning ü§î,1,0,0,,,,,
959,2023-02-23 06:20:17+00:00,juanmirod,@ylecun Python is so easy to write and read... And the ecosystem is huge. Do you think that Julia can take some traction after so many years and work invested in making python fast and accessible in every cloud?,1,0,0,,,,,
960,2023-02-23 06:18:37+00:00,bertmorrien,@ylecun holy war again ü•±,0,0,0,,,,,
961,2023-02-23 06:16:59+00:00,al3x_jager,"@ylecun Somebody seems mad that nobody knows his prefered niche language.

Hint: grafics cards dont care about GIL.

Could it be instead, that some major papers that made training deep nets even possible are not even 10 years old? (eg. Batch Normalization 2015)",0,0,0,,,,,
962,2023-02-23 06:11:15+00:00,aneilbaboo,"@ylecun Honestly, imagine the productivity gains if Lisp were taught in elementary school. It's a global tragedy that so many people are irrationally fearful of s-expressions.",0,2,0,,,,,
963,2023-02-23 06:07:40+00:00,RolfieAscending,@ylecun A take so hot it‚Äôs wrong,0,0,0,,,,,
964,2023-02-23 06:07:04+00:00,odbol,"@ylecun I'd be happy if they just added types! I've spent hours print debugging tensorflow code just to figure out how many dimensions some tensor had, or what some intermediate output used as types",0,0,0,,,,,
965,2023-02-23 06:00:22+00:00,gyp_casino,"@ylecun Is multithreading really that important for training models?  Maybe I'm wrong, but I think parallel processing is just fine for ML and multithreading only really important for apps and operating systems.",0,0,0,,,,,
966,2023-02-23 05:59:09+00:00,rwzh_,@ylecun Hottest take: ML generated images have six fingers per hand because the AI is pining for the return of Lisp Machines. https://t.co/23QsAQGxoK,0,2,0,,,,,
967,2023-02-23 05:57:58+00:00,jaredkeithwhite,@ylecun Golang.,0,2,0,,,,,
968,2023-02-23 05:56:49+00:00,scottlegrand,@ylecun I 'member when the embedded hardware startup I joined thought it was brilliant to implement and run the debugger in lisp. My first task was to learn enough list to write a parser to emulate gdb. It only got worse from there and they died.,0,0,0,,,,,
969,2023-02-23 05:53:23+00:00,thefancyyeller,@ylecun Hottest take: Machine Learning should have used x86 assembly language and worked only on the windows subsystem for linux,0,2,1,,,,,
970,2023-02-23 05:51:20+00:00,AbhishekSiddu,"@ylecun Disagree though, In my opinion, more front-end meaning less control over models. Many people already have less control using Python.",0,0,0,,,,,
971,2023-02-23 05:33:56+00:00,life_smol,@ylecun It's just a  language. Academics focus too much on such trivia,0,1,0,,,,,
972,2023-02-23 05:31:05+00:00,MichaelDChaney,"@ylecun The parts of ML that need to be fast are written in C.  Other than that, a compiler just gets in the way of fast iteration and brings pretty much nothing of value to the table.",0,3,0,,,,,
973,2023-02-23 05:15:01+00:00,Jarvis_Alerts,"@ylecun ML as it is a black box...
Once the models are created...
Please don't say you wish there was JS spaghetti added to the mix ?",0,1,0,,,,,
974,2023-02-23 05:12:36+00:00,rzykov,"@ylecun Tried to work with NN from Scala, but it‚Äôs a pain. As typical NN was written in C/C++. There was a GitHub project DeepLearning4j",0,1,0,,,,,
975,2023-02-23 05:07:00+00:00,civomarva,"@ylecun ""isn't bloated"" is a feature which is hard to retain indefinitely",0,0,0,,,,,
976,2023-02-23 05:03:35+00:00,theabhimanyu,@ylecun I don't know LISP but I work in julia as my primary language at work. I have heard Julia took a lot of ideas from LISP. I like julia that means I will also like LISP,0,1,0,,,,,
977,2023-02-23 05:02:01+00:00,youknowjamest,@ylecun actually what happened to s4tf?,0,0,0,,,,,
978,2023-02-23 04:57:38+00:00,tejasybhakta,"@ylecun assuming current adoption numbers, yes, but with barrier to entry of julia/lisp very doubtful those numbers are possible",0,0,0,,,,,
979,2023-02-23 04:57:11+00:00,zymbaluk,@ylecun How exactly does caring about white space slow down ML research?,0,0,0,,,,,
980,2023-02-23 04:50:24+00:00,JRAnaraki,"@ylecun During my bachelor's, I didn't have access to MATLAB (at it was not very inclusive in my geographical region at the time) so I implemented SOM networks for hand-written digits recognition using C#, and MS SQL Express as the database.",0,1,0,,,,,
981,2023-02-23 04:45:01+00:00,aeyakovenko,@ylecun Lol. Lisp and developer adoption don‚Äôt mix,2,13,1,,,,,
982,2023-02-23 04:38:18+00:00,cstarkjp,"@ylecun Sorry, you blew all your credibility by claiming that everyone coding in Lisp would have made ML progress faster",0,0,0,,,,,
983,2023-02-23 04:33:43+00:00,_anirban_,@ylecun What about R?,0,0,0,,,,,
984,2023-02-23 04:20:38+00:00,jogitanikella,"@ylecun I wish people would use C# more. Of all the languages, I love the clean box style of C# code. Coding in C# feels like there are no loose ends.",0,1,0,,,,,
985,2023-02-23 04:15:39+00:00,MStopaCA,@ylecun I can't see how a language being compilable is anything but a disadvantage here. Execution speed matters for ML experimentation?,1,0,0,,,,,
986,2023-02-23 04:14:25+00:00,juicedpotato,"@ylecun Surely this is some kind of bait, you can not believe this",0,0,0,,,,,
987,2023-02-23 04:06:28+00:00,jasonfi,"@ylecun That's Nim. It wasn't ready yet, and is still struggling to gain widespread use.",0,0,1,,,,,
988,2023-02-23 03:36:05+00:00,NomadicQuantum,@ylecun Why is Sydney a narcissist?,0,0,0,,,,,
989,2023-02-23 03:35:08+00:00,stan_yurin,@ylecun Matlab guys are only on paper: CV was simply useless (except VERY niche robotics) until advanced mobile devices came to mass market,0,0,0,,,,,
990,2023-02-23 03:25:02+00:00,partha_mitra,"@ylecun MATLAB started as a wrapper for linear algebra routines, and a proficient coder could always write efficient code to prototype, visualize and analyze data. Good workpersons do not quarrel with their tools :)",0,6,0,,,,,
991,2023-02-23 03:22:40+00:00,jonanthrax,@ylecun #UseFortran üëå‚ú®,0,0,0,,,,,
992,2023-02-23 03:18:23+00:00,xiaowang1984,@ylecun Didn't they need Moores law to catch up before any of this mattered?,0,0,0,,,,,
993,2023-02-23 03:09:21+00:00,hugovictorw,@ylecun Ruby would also make a nicer language if ‚Äúbeing amicable‚Äù is such a mandatory requirement.,0,0,0,,,,,
994,2023-02-23 03:09:10+00:00,srwalter,@ylecun I don't get the hate for Python and whitespace. Like would you not indent your code if the language didn't make you?,2,3,0,,,,,
995,2023-02-23 03:08:53+00:00,colleagula,@ylecun https://t.co/G5lg7NpFRj,0,10,1,,,,,
996,2023-02-23 03:04:34+00:00,vinodgansan,"@ylecun Curious: How much of this ‚Äúheld back progress‚Äù could‚Äôve been because of absence of good GPUs. Put another way, do you think the AlexNet moment would‚Äôve occurred much earlier, say with 2007s GPU capabilities with the existence of a better front-end language?",2,10,0,,,,,
997,2023-02-23 02:51:27+00:00,jwarner308,@ylecun https://t.co/fHw08a18n2,0,0,0,,,,,
998,2023-02-23 02:47:15+00:00,GauravML,@ylecun Lua held back Torch's adoption too in some way. Now all we know is PyTorch :),0,2,0,,,,,
999,2023-02-23 02:46:51+00:00,amit_ai_mldl,@ylecun Always been a fan of #LISP. My first language that I learnt.,0,1,0,,,,,
1000,2023-02-23 02:46:32+00:00,ZainulA40877140,"@ylecun Adopting  Julia  when  calculus are heavy is prudent.

      Julia syntax is more readable than Python and have 
        no performance issue.

        Big  data is to  conquer  Julia in  next years.

        Many  data scientists will have to learn it.",0,0,0,,,,,
1001,2023-02-23 02:43:50+00:00,augustradjoe,@ylecun What about compilers that use python syntax but work much faster?,0,1,0,,,,,
1002,2023-02-23 02:32:53+00:00,maitas44,@ylecun @tunguz is right,0,0,0,,,,,
1003,2023-02-23 02:24:38+00:00,furstamundmund,@ylecun Or OCaml,0,0,0,,,,,
1004,2023-02-23 02:03:20+00:00,TalhaIrf,@ylecun @MarkSchmidtUBC Very true. Can never understand why didn't Microsoft invest in C# for ML. Such a beautiful language. Python is a mess.,0,0,0,,,,,
1005,2023-02-23 01:54:14+00:00,alvgaona,@ylecun Julia is a great alternative.,0,2,0,,,,,
1006,2023-02-23 01:40:33+00:00,rspadim,@ylecun Maybe writing what computer should do is artificial intelligence too kk,0,0,0,,,,,
1007,2023-02-23 01:31:12+00:00,tensorix,@ylecun @OuahabiAdnane Of course they would want Python when you cite the white-space rules as a drawback of it. They rightly won't take you serious.,1,0,0,,,,,
1008,2023-02-23 01:29:37+00:00,xxonnn,"@ylecun @OuahabiAdnane Why Lua,?",0,0,0,,,,,
1009,2023-02-23 01:18:47+00:00,aertherks,@ylecun Julia is good in many ways but it's design patterns inherently encourage massive over-engineering making it not as natural a language for experimentation as Python. It is also full of syntactic quirks.,2,0,0,,,,,
1010,2023-02-23 01:13:41+00:00,valkantchev,"@ylecun The language really doesn't matter. It's the ecosystem (of ready to use packages and frameworks, and developers) that exists around it. Python comes with a huge ecosystem. I think the only other language like that is JavaScript.",1,3,0,,,,,
1011,2023-02-23 01:12:57+00:00,TechnoPhobe01,"@ylecun The problem here to me at least is that we will never know as we exist in environment where the hot take didn‚Äôt happen. Chuckle.

Stay safe and well.",0,0,0,,,,,
1012,2023-02-23 01:12:40+00:00,olivia_p_walker,@ylecun I like your posts.,0,0,0,,,,,
1013,2023-02-23 01:11:26+00:00,BethCarey12,"@ylecun Even Hotter take: the human machine interface would have advance faster if we had focused sooner on Understanding AI instead of Generative AI, to create factual, non-toxic and explainable systems https://t.co/iVczNFiMlL",0,3,0,,,,,
1014,2023-02-23 01:10:58+00:00,TechnoPhobe01,"@ylecun @claycurry_ Personally, I rather like Matlab.",0,0,0,,,,,
1015,2023-02-23 01:07:28+00:00,_onlyphantom,"@ylecun @TensorFlow at one point were pretty serious about Swift for Tensorflow w/ their best engineers on the project;  differentiable programming for gradient ops sounds like such a big win. Swift is also a better language.  https://t.co/zs5H2IhyDZ (safe, auto-diff, typed, faster)",0,0,0,,,,,
1016,2023-02-23 01:07:28+00:00,francisconog_,"@ylecun Idk, Julia was released in 2011, Python was already widely used when no one knew a thing about Julia. If it was released in 2001... well, it would have dominate everything. About lisp, I do love Clojure, but it's not something trivial for a C inspired world.",1,0,0,,,,,
1017,2023-02-23 01:02:15+00:00,EddieBurger7,"@ylecun Outside of your comfortable little nest, there are people who don't just write software, they also have to scale it, test it, repair it, expand it, and be accountable for it. That's why we use Python.",0,1,0,,,,,
1018,2023-02-23 00:50:24+00:00,doctorcube,@ylecun And he was doing so well until he said Julia and Lisp... LOL,0,0,0,,,,,
1019,2023-02-23 00:50:09+00:00,EddieBurger7,"@ylecun Disagree. Lack of a GIL encourages poor architectural choices.  Prototype in Python, and optimize with C where necessary. You are thinking about efficiency of execution, but should be thinking about efficiency of creation.  AI will write the best Python you have ever seen.",0,0,0,,,,,
1020,2023-02-23 00:48:20+00:00,andrestesti,"@ylecun I chose Python for an introductory programming course. I did my decision based on adoption and popularity. I hated it. It is the worst first programming language. Inconsistencies, ambiguities, confusing syntax. If you have to introduce people to programming, trust me, use a Lisp.",1,5,0,,,,,
1021,2023-02-23 00:43:33+00:00,stelloprint,"@ylecun Python is undoubtedly both multi-threaded and multi-process.

I do agree with the nuisance of white spacing.

https://t.co/p1SJ8MK8on",0,0,0,,,,,
1022,2023-02-23 00:37:31+00:00,jbarrieault,@ylecun too hot,0,0,0,,,,,
1023,2023-02-23 00:30:21+00:00,ILikeCommas,@ylecun Hottest take: our society would have advanced much faster without the bloated and corrupted means of organization and exchange we have in bank-controlled oligarchy.,0,0,0,,,,,
1024,2023-02-23 00:17:51+00:00,SnstrMephisto,@ylecun Julia is magic,0,0,0,,,,,
1025,2023-02-23 00:12:13+00:00,JamesOngTweets,@ylecun Endorse LISP or Prolog ‚Ä¶,0,0,0,,,,,
1026,2023-02-23 00:02:16+00:00,JoshBaker2,"@ylecun I remember in my undergrad talking to a certain electric car company working on self driving cars who had two teams: their researchers, who would make their models in Matlab, then their engineers who would re-implement it in a better language. Just felt so wasteful!",1,1,1,,,,,
1027,2023-02-22 23:58:56+00:00,whunterknight,@ylecun Booooooomerrrrr,0,0,0,,,,,
1028,2023-02-22 23:53:37+00:00,Pascallisch,@ylecun Julia when?,0,1,0,,,,,
1029,2023-02-22 23:36:32+00:00,P3b7_,"@ylecun The important part is ""and widely adopted""...",0,0,0,,,,,
1030,2023-02-22 23:36:07+00:00,youneshenniphd,@ylecun How about JavaScript?,0,0,0,,,,,
1031,2023-02-22 23:29:31+00:00,JayBarlowBot,@ylecun I‚Äôll side with the godfather of CNNs,0,0,0,,,,,
1032,2023-02-22 23:23:11+00:00,joezott,@ylecun Clearly ML needed Forth,0,0,0,,,,,
1033,2023-02-22 23:17:36+00:00,OR13b,@ylecun Do you actually like Julia and Lisp or are you trolling?,0,2,0,,,,,
1034,2023-02-22 23:08:33+00:00,charlesjavelona,@ylecun Could port to Web assembly ?,0,0,0,,,,,
1035,2023-02-22 23:03:58+00:00,SheerPriya,@ylecun OMG so LISP might have helped? Formally learning LISP (awesome syntax less language) as an undergrad @MIT I felt really handicapped me for later - when I had to learn other programming languages...disliked most other languages,1,4,0,,,,,
1036,2023-02-22 22:55:25+00:00,roalva1,@ylecun I use R,0,0,0,,,,,
1037,2023-02-22 22:44:42+00:00,mael_p,"@ylecun Well it's just that data processing and cleaning is a huge part of a ML pipeline, and python-like languages are very convenient for this üòâ",0,2,0,,,,,
1038,2023-02-22 22:36:12+00:00,nosocialengine,@ylecun LUAJIT ARM WEN,0,0,0,,,,,
1039,2023-02-22 22:34:42+00:00,JoelKreager,"@ylecun @johnmyleswhite Julia maybe. It's basically BASIC by way of matlab. Lisp is a functional language. The first time you run into those you are in a state of total confusion, (unless you are a member of those  enlightened Elect of programming).",0,0,0,,,,,
1040,2023-02-22 22:33:20+00:00,PAF_Kontrol,"@ylecun 100% agree. C# has scripting &amp; easiest to deploy, to port c /C++ or java to it, but Julia has scripting, and more science datatypes, LLVM. in 2023 i can't voice cmd my OS/ apps handsfree?. so a small domain-specific not LLM wih √Ä Priori predicate calc. https://t.co/itnlxlZ1sp",0,0,0,,,,,
1041,2023-02-22 22:30:21+00:00,franciscojarceo,"@ylecun @OuahabiAdnane curious why folks hated Lua, the JIT is nice!",1,0,0,,,,,
1042,2023-02-22 22:22:28+00:00,DrBenSinclair,@ylecun Quite happy at the current pace and for the singularity to happen in the last 10 years of my life.,0,0,0,,,,,
1043,2023-02-22 22:15:37+00:00,ReisparT,@ylecun Interesting take,0,0,0,,,,,
1044,2023-02-22 22:10:22+00:00,JonathanSumDL,@ylecun Hey @ylecun. How about Kotlin? It is also a UI language for Android. @kotlin,0,1,0,,,,,
1045,2023-02-22 22:09:27+00:00,BldrInvstTech,"@ylecun 1984 -&gt; MATLAB
1991 -&gt; Python
1996 -&gt; OCaml
1997 -&gt; F#
2005 -&gt; Clojure
2012 -&gt; Julia

the assumption is that there were such languages available in 1991! https://t.co/uQkb2Rd840",0,3,0,,,,,
1046,2023-02-22 22:05:10+00:00,Charlie02179267,@ylecun Someone really hates Matlab.,1,0,0,,,,,
1047,2023-02-22 22:00:21+00:00,pitsch,"@ylecun or brainsim, a KNN in c64 BASIC. https://t.co/LdjslVlFo4",0,0,0,,,,,
1048,2023-02-22 21:59:54+00:00,ramramanathan1,@ylecun One of the biggest shifts in dev productivity was the shift away Point to click dev tools like VS Studio or Informatica to codeable workstreams like VS Code or just phython - massive shift in productivity and innovation and less stuffing square peg into circle,0,1,0,,,,,
1049,2023-02-22 21:55:08+00:00,ramramanathan1,"@ylecun I am not sure Lisp or Julia had the level of adoption necessary for growing the ML Ecosystem, outside of Research community. Python was already used by large number of data processing and data analysis folks.",0,0,0,,,,,
1050,2023-02-22 21:50:14+00:00,kelvindotchan,"@ylecun How does this look like? Any sample (or pseudo) code where lisp is frontend to a DL sys? Jax looks very ‚Äúfunctional‚Äù, so i guess it is not out of q to use lisp?",0,0,0,,,,,
1051,2023-02-22 21:42:02+00:00,valfardsstat,@ylecun Yeh Julia,0,0,0,,,,,
1052,2023-02-22 21:41:37+00:00,VictorSenkevich,"@ylecun 1. Fully compiled languages have long been an anachronism 
2. Interpreted languages have their undoubted advantages
3. The costs of processor time for interpretation can be neglected, they are uncritical.
4. I believe the ""problem of white spaces"" can also be neglected üòé",0,0,0,,,,,
1053,2023-02-22 21:34:07+00:00,DrElectronX,@ylecun I would prefer BASIC. I developed a lisp last time I spent weeks writing in LISP. Actually I would prefer assembly language over LISP.,0,0,0,,,,,
1054,2023-02-22 21:25:09+00:00,Bangkoboi,@ylecun Technically not true. Python's ideas of freedom and flexibility on what it's used for is why everyone wants it. Want it faster? Make a C/Rust wrapper. Don't want GIL? Use Pypy.,0,0,0,,,,,
1055,2023-02-22 21:18:20+00:00,patrickmesana,"@ylecun Yep, another ridiculous mockery by @GaryMarcus. Like advocating for DL is incompatible with finding Lisp simple and elegant...",0,0,0,,,,,
1056,2023-02-22 21:17:30+00:00,OnlyFeatures,@ylecun Lisp is hard to use.,0,0,0,,,,,
1057,2023-02-22 21:15:07+00:00,trobuling,"@ylecun LISP has had its day. May as well ask for Perl or TCL.

There's a lot I dislike about Python, but there's a lot I dislike about all of them. Python is good enough.",1,0,0,,,,,
1058,2023-02-22 21:08:42+00:00,math_dandy,"@ylecun Sourceforge, how quaint.",0,0,0,,,,,
1059,2023-02-22 21:05:37+00:00,bryan_fyas,"@ylecun Python: Arrays is all you need ML.

Arrays are the most important data entities in machine learning.",1,2,0,,,,,
1060,2023-02-22 21:05:20+00:00,KaylynnMorgan2,"@ylecun python's litany of sins is Immense but i don't think semantic whitespace is really one of them. w.r.t scientific computing + ML, lots of issues that i've seen stem from poorly designed tools/libraries that aren't documented well. the same issues are pervasive in the stdlib too",0,0,0,,,,,
1061,2023-02-22 21:03:18+00:00,MacGraeme42,"@ylecun The term neuro-symbolic does not appear on the linked page... so not sure the connection.

Back in the 80s I played with modal logic ideas and started building up diagrams of relationships among words &amp; predicates, I realized ""this is looking more an more like a neural network"".‚Ä¶",1,1,0,,,,,
1062,2023-02-22 21:01:43+00:00,tmoll_,@ylecun Julia is going to be the next major language used for ML. If the number of grad students using it right now is any indication üòÇ,0,3,0,,,,,
1063,2023-02-22 21:00:31+00:00,sergey48k,@ylecun Something that would make tensor dimension obvious to a reader.,0,1,0,,,,,
1064,2023-02-22 20:59:56+00:00,mapologo,"@ylecun The thing is, adoption is not about technical features. It's a mix of proper marketing and fitting into developers' day-to-day productivity.",0,0,0,,,,,
1065,2023-02-22 20:59:46+00:00,saplaksnis,@ylecun So it's really the white spaces that hindered ML...,0,1,0,,,,,
1066,2023-02-22 20:59:43+00:00,oceanexplains,@ylecun Honestly Swift would have been an amazing candidate (it actually still is!),0,0,0,,,,,
1067,2023-02-22 20:58:25+00:00,edwin_teejay,"@ylecun Lush was nice.

https://t.co/7XgK2939mW",0,0,0,,,,,
1068,2023-02-22 20:55:08+00:00,venuv62,"@ylecun classic chasm - strongly typed (+ panoply of type inferencing, closures, thread safe etc etc) languages are revered by AI innovators. weakly typed languages by mass market AI adopters",0,2,0,,,,,
1069,2023-02-22 20:54:13+00:00,Zedmor,"@ylecun What? I hadn't seen a single ML application where python overhead was a significant. Moreover GIL? How GIL affects ML applications? Any ML framework looks like this: https://t.co/ncIGNWYtjB

Python only job is to make API calls, not to process data.",0,5,0,,,,,
1070,2023-02-22 20:45:32+00:00,JustinEggar,"@ylecun Two fellows pissing in each others wheaties over Python (or technically one).

Who can build a simulation to determine who is right?",0,2,0,,,,,
1071,2023-02-22 20:44:43+00:00,thomega,@ylecun I'm curious: what is @tunguz hot take? He appears to have blocked me...,0,0,0,,,,,
1072,2023-02-22 20:38:33+00:00,ITsol4u,@ylecun Python is dependant reliant. And this makes it both powerful and eccentric. Often when you install a git cloned project you must spend time in a purpose built env to configure it. I have a solution.,0,0,0,,,,,
1073,2023-02-22 20:35:58+00:00,csabaveres,"@ylecun Oooh I love that web page. Nostalgic. That‚Äôs how the Web was meant to be, and that‚Äôs how I experienced it for many years. Thank you Tim Berners-Lee.",1,2,0,,,,,
1074,2023-02-22 20:34:04+00:00,cryptoID_info,"@ylecun Python is the new Basic, with the same one strength (easy to start), and the very same long list of shortcomings.",0,1,0,,,,,
1075,2023-02-22 20:32:31+00:00,theamazingdrj,"@ylecun Python is the Austin,TX of languages: aggressively meh, maybe OK, but overrated by its fans to the point of comedy.  ‚ÄúThe GIL is good, actually, as is having to write every meaningful library in C‚Äù.",0,2,0,,,,,
1076,2023-02-22 20:31:04+00:00,_onionesque,"@ylecun To be fair, I don't think vision people would have even cared about implementing a ConvNet in 2005 without something big like ImageNet '12 results to change their minds.",0,2,0,,,,,
1077,2023-02-22 20:27:04+00:00,Vjeux,@ylecun @OuahabiAdnane We also did try with https://t.co/TQFKN45O33 but it didn‚Äôt go super far unfortunately,0,2,0,,,,,
1078,2023-02-22 20:26:19+00:00,mihaitensor,@ylecun Uncool take: Rust is the best language for Machine Learning,0,1,0,,,,,
1079,2023-02-22 20:25:59+00:00,vhogemann,@ylecun F#,0,0,0,,,,,
1080,2023-02-22 20:24:45+00:00,nvtby,@ylecun @OuahabiAdnane Those people shout quite loudly when meet with reality that Python costs 3x in production.,0,0,0,,,,,
1081,2023-02-22 20:21:55+00:00,nvtby,"@ylecun Yes, Python is a nightmare at production. From the other side, as an era of manual programming is eventually going nowhere, development of any new language (for humans) is a waste of money.",0,0,0,,,,,
1082,2023-02-22 20:20:17+00:00,RolandWank,@ylecun In your opinion. What‚Äôs the biggest strength of Lisp?,0,0,0,,,,,
1083,2023-02-22 20:19:14+00:00,josemhe,@ylecun Julia ‚ù§Ô∏è,0,0,0,,,,,
1084,2023-02-22 20:17:29+00:00,EvansLogi,@ylecun I don't think so,0,0,0,,,,,
1085,2023-02-22 20:14:51+00:00,jpgoodale1,@ylecun Would you recommend trying out Lisp for some deep learning projects even today? Just as a learning experience if nothing else,0,0,0,,,,,
1086,2023-02-22 20:02:34+00:00,aricaroline,@ylecun How close does Pyro come? Any other probabilistic programming languages?,0,0,0,,,,,
1087,2023-02-22 19:54:49+00:00,jamwalvikram,@ylecun @OuahabiAdnane üòÇ,0,0,0,,,,,
1088,2023-02-22 19:54:22+00:00,carlito_oliveir,@ylecun Anybody please tell me another language that has a pandas dataframe in it,1,0,0,,,,,
1089,2023-02-22 19:50:20+00:00,JeffreyESun,"@ylecun I am quite excited about Julia projects such as Flux and KNet, as well as a possible pure Julia frontend to PyTorch. As someone who works with intensive economic simulations using small neural networks, I lose a LOT of speed having to do the simulation part in Python",0,1,0,,,,,
1090,2023-02-22 19:43:50+00:00,chuston_ai,"@ylecun Amen! Preach the word, brother. https://t.co/vB8nX0m76k",0,1,0,,,,,
1091,2023-02-22 19:43:41+00:00,jrobens,@ylecun So much time on pyenv,0,0,0,,,,,
1092,2023-02-22 19:41:14+00:00,timrowledge,"@ylecun A properly interactive, reflective, dynamic, live, extensible, language is rather helpful. Not a dull, rigid, dead-text-in-files, blah pile of tedium.",0,0,0,,,,,
1093,2023-02-22 19:40:55+00:00,knavely,@ylecun We should have stuck with the Lisp Machine,0,1,0,,,,,
1094,2023-02-22 19:40:26+00:00,IFindAnomalies,"@ylecun Disagree! Matlab allowed rapid prototyping during the NN1.0 winter. Mixing and matching EE (2d/3d signal proc), stat, ideas with CS to come up with novel methods that still  had to wait for a decade for faster parallel procs to eventually evolve into NN2.0.",0,0,0,,,,,
1095,2023-02-22 19:37:36+00:00,GaryMarcus,"@ylecun ü§£@ylecun endorses the original symbol-manipulation language, LISP, for the win!",7,44,1,,,,,
1096,2023-02-22 19:34:26+00:00,coding_era,"@ylecun What are the practical implications of transitioning to a different language for ML, given the significant effort and resources required to make the switch?  ü§î",0,0,0,,,,,
1097,2023-02-22 19:24:54+00:00,idoccor,"@ylecun I wrote a quant analysis platform on Julia and found the garbage collector to be a major bottleneck.

Sometimes a simple accumulator would spend 50% of it's time in GC without many ways to fine tune it.

Grass is always greener I guess.",0,2,0,,,,,
1098,2023-02-22 19:23:15+00:00,michaelaye,@ylecun Define bloated.,0,0,0,,,,,
1099,2023-02-22 19:22:07+00:00,EmadBarsoumPi,"@ylecun @ylecun @tunguz  Julia has the potential, and satisfy the above, but sadly haven't been widely used by the ML community. Regarding GIL, there is promising news: https://t.co/q4koh4Sqth",0,3,0,,,,,
1100,2023-02-22 19:20:26+00:00,bimrian,"@ylecun didn't @jeremyphoward already talk about this &amp; came around on this mentality?

https://t.co/oBf0TesZHk https://t.co/WymSbynWRw",0,1,0,,,,,
1101,2023-02-22 19:14:52+00:00,andrew_craton,"@ylecun @MetaAI I would enjoy a ""personality"" selector, so that a bias is introduced for the LLM to speak and contextualize as a ""professor"" or ""father"" or ""influencer"" etc.",0,0,0,,,,,
1102,2023-02-22 19:14:47+00:00,Sentdex,"@ylecun @OuahabiAdnane Is it possible that people have good reasons for wanting Python? 

Is it possible that those same reasons are why Python+ML has been so wildly successful?

Is it possible that if you stayed the course and engineers ""hated it"" that ML would have been held back considerably?",4,97,1,,,,,
1103,2023-02-22 19:14:42+00:00,Matthew87003241,@ylecun Only if humans loved them half as much as they do Python,0,0,0,,,,,
1104,2023-02-22 19:13:12+00:00,ChrSzegedy,"@ylecun I don't think Python (of today) is bad enough to incur enough problems to slow down progress.

I agree with Bojan, that people tend to overrate technical merits while underrate other aspects: tooling, libraries, popularity, package management, etc.",2,67,0,,,,,
1105,2023-02-22 19:10:04+00:00,MaxencePastor,@ylecun I get your point but disagree. Python made it accessible and amplified the snowball effect of having more people involved in the field leading to more innovation. Most of the people I have in my classes would not code in C++. Most ML hackers on GitHub either,1,2,0,,,,,
1106,2023-02-22 19:05:03+00:00,letalvoj,"@ylecun Julia is like if you take the worst from Matlab and PHP and sprinkle it with multiple dispatch and LLVM.

The frosting looks great, but you will suffer with severe diarrhea if you try to build anything production grade.",0,0,0,,,,,
1107,2023-02-22 19:04:14+00:00,frankzliu,@ylecun It's no less of a nightmare to implement it in C++.,1,0,0,,,,,
1108,2023-02-22 19:03:57+00:00,davidwbrw,@ylecun This has been my feeling for a long time.  I want a strongly typed language similar to TypeScript but that is fully compiled and good for ML and parallel computing. Golang could have been that but the designers got too creative.,0,0,0,,,,,
1109,2023-02-22 18:57:55+00:00,Skilenstein,@ylecun Rust?,0,0,0,,,,,
1110,2023-02-22 18:55:41+00:00,theJordanNoone,@ylecun The only language I learned in college was MatLab and it taught me bad habits that took years to untrain. It being baselined in college is not only expensive but detrimental to education quality.,1,23,2,,,,,
1111,2023-02-22 18:47:25+00:00,sid_sarasvati,"@ylecun It didn‚Äôt happen 
And did you know google tried swift for ml? Failed",0,0,0,,,,,
1112,2023-02-22 18:41:13+00:00,FViolst,@ylecun I trained my first MLP in Matlab back in 1999...you never forget your first love,0,0,0,,,,,
1113,2023-02-22 18:40:11+00:00,Insidedctm,"@ylecun @tunguz @ylecun I would suggest that it wasn‚Äôt the particular language that was important, but the fact that so many people ended up on a particular language and it‚Äôs associated packages (tf, PyTorch, numpy, etc). It was a coordination problem .
 
And Yann - whitespace? Really?",0,1,0,,,,,
1114,2023-02-22 18:38:26+00:00,Aaron_Silvas,@ylecun https://t.co/lEpP9nJo5n has that potential.,0,2,0,,,,,
1115,2023-02-22 18:37:36+00:00,rakesh_mallick,@ylecun When will Meta come out with its own ChatGPT equivalent? You already have OPT 175B .,1,0,0,,,,,
1116,2023-02-22 18:36:16+00:00,ItizAdz,@ylecun Or elixir,0,0,0,,,,,
1117,2023-02-22 18:34:49+00:00,magnetcoop,@ylecun Clojure,0,3,0,,,,,
1118,2023-02-22 18:31:58+00:00,JaloppySloppy,@ylecun Hinton disagrees (although i guess Alex net was python) https://t.co/g34OWM7dEq,0,2,0,,,,,
1119,2023-02-22 18:29:25+00:00,Moondust_777,"@ylecun Any language could easily replace python, it's used for ML because it was easily adopted because of how simple it was and tools were built around it, which is why I think Rust will be a preferred language in the future. Also python is slow rust is very fast",1,0,0,,,,,
1120,2023-02-22 18:21:17+00:00,SamKupferschmid,@ylecun ü§î,0,1,0,,,,,
1121,2023-02-22 18:21:06+00:00,_Philip_Martin,@ylecun The operator precedence in lisp not following classical mathematics is a major deterrent imo,0,0,0,,,,,
1122,2023-02-22 18:19:06+00:00,altryne,@ylecun @yacineMTB what made you... stop thinking about Javascript?,0,1,0,,,,,
1123,2023-02-22 18:18:17+00:00,ZaBong69,@ylecun Lisp had its chance. It didn‚Äôt make it.,0,0,0,,,,,
1124,2023-02-22 18:18:09+00:00,BasBuller,"@ylecun Not sure if this is a hot take, many people will agree with you Matlab was/is a nightmare! I for one agree with you",0,0,0,,,,,
1125,2023-02-22 18:15:02+00:00,AchilleTalon,@ylecun Read my lisp.,0,0,0,,,,,
1126,2023-02-22 18:07:33+00:00,SchraderValves,@ylecun So GPTx etc all programmed with Python?,0,0,0,,,,,
1127,2023-02-22 18:07:03+00:00,marsupialtail_2,@ylecun The fact python executes line by line unlike some compiled language is a feature not a bug. This makes mere mortals capable of debugging code.,0,0,0,,,,,
1128,2023-02-22 18:05:55+00:00,voilatility,@ylecun Even hotter: ML would have advanced faster if everyone wasn‚Äôt lazy and learned C. The end.,0,0,0,,,,,
1129,2023-02-22 18:05:52+00:00,strangecasts,"@ylecun It's been a while since I've had the chance to use them but I wonder how ML in a language with dependent types could look - ideally it'd allow leveraging the compiler for kernel generation XLA-style, and compiler warnings/errors for shape and architecture issues",0,0,0,,,,,
1130,2023-02-22 18:02:55+00:00,Opinion_Anonyme,@ylecun @OuahabiAdnane Isn't it a better argument than the ones you gave 'agaisnt' python tho?,1,0,0,,,,,
1131,2023-02-22 18:00:39+00:00,_sunilrawat,@ylecun Still prefer Java or Scala but they dont seem to be how kids learn CS nowadays.,2,3,0,,,,,
1132,2023-02-22 17:51:44+00:00,hmm__teresting,@ylecun @jackrusher #Clojure,0,0,0,,,,,
1133,2023-02-22 17:50:37+00:00,lowqualityintel,"@ylecun Its not to late to switch to Julia (its a good language!). Python is great because its so easy, but In my mind there is a weird contradiction between people doing all the advanced  ml stuff in a language that has multithreading issues. Dunno if multithreading is needed but still.",1,5,0,,,,,
1134,2023-02-22 17:50:16+00:00,jleplat,@ylecun https://t.co/EhDr9bgJ96,0,0,0,,,,,
1135,2023-02-22 17:46:18+00:00,mathsci4good,"@ylecun Coulda, shoulda, woulda. Unprovable counter factual.",0,0,0,,,,,
1136,2023-02-22 17:44:31+00:00,MarkHolum,"@ylecun why do you need multi threading in the front end language? You‚Äôre still actually writing the optimizers on a gpu, in c++, or fortran.  Python is just used as glue code",2,6,0,,,,,
1137,2023-02-22 17:37:55+00:00,lexextom,"@ylecun @OuahabiAdnane I've written a reasonable amount of lua. I think the issue is more 'lua sucks' x 3, or more precisely 'lua is really small so needs more typing' x 3.",0,1,0,,,,,
1138,2023-02-22 17:37:23+00:00,mszepien,@ylecun The trend towards real-time systems with continual learning means that a language with a strong concurrency story might have a chance to take over. Elixir is theoretically nice but node has the ecosystem behind it.,0,0,0,,,,,
1139,2023-02-22 17:34:30+00:00,jbseltzer,"@ylecun Ahem...#Clojure. @ylecun, there is a modern Lisp that satisfied those requirements.",0,3,0,,,,,
1140,2023-02-22 17:34:20+00:00,kelvindotchan,"@ylecun Is it true physicists started the whole python-&gt;ML path, ‚Äúaccidentally‚Äù choosing python as the code steering language to do underlying heavy computation?",1,0,0,,,,,
1141,2023-02-22 17:27:04+00:00,vijayganti,@ylecun Curious on your take on what made Python more popular than some of the others you list?,0,0,0,,,,,
1142,2023-02-22 17:24:56+00:00,hyposran,@ylecun Why I no longer recommend Julia https://t.co/jepveKHjL4,0,0,0,,,,,
1143,2023-02-22 17:23:24+00:00,russferriday,"@ylecun Yann, please... You are making me sad...",0,0,0,,,,,
1144,2023-02-22 17:22:47+00:00,jgmartn,@ylecun A DSL on top of Rust macros would be ideal.,0,0,0,,,,,
1145,2023-02-22 17:22:24+00:00,iiirogers,"@ylecun (in a fozzie bear voice) weka, weka, weka.. ML in Java starting in 1997: https://t.co/ywj0LuaGCB üêª For comparison, Python 2.0 wasn't released until 2000.",1,4,0,,,,,
1146,2023-02-22 17:22:24+00:00,arpagon,@ylecun #Elixir,0,0,0,,,,,
1147,2023-02-22 17:19:12+00:00,p_n_rodriguez,@ylecun But Meta was pushing for Kotlin‚Ä¶ and even a preliminary version of DiffKt got published. Software 2.0‚Ä¶,0,0,0,,,,,
1148,2023-02-22 17:17:30+00:00,heikkiarponen,"@ylecun Then again, debugging all kinds of JIT stuff is a pain...",0,0,0,,,,,
1149,2023-02-22 17:16:53+00:00,KeepCalmBeAlert,@ylecun @MetaAI Excellent !!,0,0,0,,,,,
1150,2023-02-22 17:15:49+00:00,UniMatrixZ0,"@ylecun @OuahabiAdnane It could be more type safe (simplifying refactoring), concurrency is a mess, and it has weak abstraction capabilities.

Performance is low and energy usage is high.

I suspect that its weak type safety is attractive for many.

Python is like a gas guzzling V12 engine. https://t.co/y0Vi7OBnNb",1,5,0,,,,,
1151,2023-02-22 17:14:57+00:00,piprrr,"@ylecun Ya know, there may be reasons those languages were not adopted. üòÅ",0,0,0,,,,,
1152,2023-02-22 17:13:06+00:00,AlbertFeghaly,@ylecun What‚Äôs your take on this @TariqDaouda?,1,0,0,,,,,
1153,2023-02-22 17:06:54+00:00,asnar002,@ylecun Kind of what I‚Äôm working on,1,0,0,,,,,
1154,2023-02-22 17:03:08+00:00,Shayan_RC,"@ylecun I think jupyter had more to do with it.
Not having to run the entire script or saving every intermediate output allowed for much easier experimentation.",0,0,0,,,,,
1155,2023-02-22 17:01:12+00:00,KeepCalmBeAlert,@ylecun Lua?,0,0,0,,,,,
1156,2023-02-22 17:00:19+00:00,termites12345,@ylecun How would any of those moved the needle?,0,1,0,,,,,
1157,2023-02-22 16:53:48+00:00,TomNormanCohen,@ylecun Clojure always seemed like such a natural fit... Oh well. :),0,0,0,,,,,
1158,2023-02-22 16:51:51+00:00,TheFlyingSilo,"@ylecun This is not a hot take and is contrarian for the sake of being provocative, not because it illuminates anything interesting.",0,0,0,,,,,
1159,2023-02-22 16:49:01+00:00,rohitrango,@ylecun @OuahabiAdnane i wonder why people want python .... maybe features like easy to learn and fast prototyping,2,2,0,,,,,
1160,2023-02-22 16:47:53+00:00,Ka81,@ylecun The Matlab hell honestly I struggled translating between languages during my masters and I just don't bother in my PhD.  It's so expensive and not accessible... WHY!,0,0,0,,,,,
1161,2023-02-22 16:47:42+00:00,joshbloch,"@ylecun @Gilad_Bracha Hottest take: Otherwise intelligent people spend way too much time arguing about programming languages. This is doubly true for proponents of languages that never achieved mainstream popularity (e.g., Lisp, Smalltalk).",13,151,5,,,,,
1162,2023-02-22 16:46:13+00:00,malachi_space,@ylecun Julia üíØ,0,1,0,,,,,
1163,2023-02-22 16:45:41+00:00,harrisonpartch,@ylecun Hot take: Multicore Oberon could have been extended for ML,0,0,0,,,,,
1164,2023-02-22 16:43:59+00:00,OrangeJuice6391,@ylecun Are white spaces really that bad?,0,0,0,,,,,
1165,2023-02-22 16:42:52+00:00,soegeum,"@ylecun At some point ""you know who"" is going to tell us all to just use Wolfram lang    (""HotTake[]"")",0,0,0,,,,,
1166,2023-02-22 16:40:49+00:00,Jinom,@Jinom's account is temporarily unavailable because it violates the Twitter Media Policy. Learn more.,0,1,0,,,,,
1167,2023-02-22 16:39:55+00:00,davidmbudden,"@ylecun Is Python *really* on the hot path often enough that the Gil is a pain point? It certainly was when I started building ML models, but usually it was because I had the entirely wrong mental model for how e.g. my data in-feed should work",2,14,1,,,,,
1168,2023-02-22 16:36:03+00:00,naveenpalli,@ylecun Why didn‚Äôt Julia pickup? Would have been perfect with some corporate backing from a FAANG. Hope not too late though. Working through Python‚Äôs limitations is painful.,1,3,1,,,,,
1169,2023-02-22 16:34:30+00:00,AlgosRhythm,@ylecun I think you would have loved Occam / Transputer.,0,0,0,,,,,
1170,2023-02-22 16:30:56+00:00,pablorc43,@ylecun @OuahabiAdnane damn programming languages that do the same thing by changing names and syntax,0,0,0,,,,,
1171,2023-02-22 16:28:20+00:00,yacineaxya,@ylecun https://t.co/h1mRzBJNlk,0,0,0,,,,,
1172,2023-02-22 16:26:30+00:00,joseph_h_garvin,@ylecun @OuahabiAdnane Did you do any digging to drill into why people want Python?,0,2,0,,,,,
1173,2023-02-22 16:23:04+00:00,theLionary,@ylecun Swift would‚Äôve been cool too. https://t.co/63wCZu1TrC,0,1,0,,,,,
1174,2023-02-22 16:19:17+00:00,floopybits,@ylecun Like Julia @JuliaLanguage,0,3,0,,,,,
1175,2023-02-22 16:17:51+00:00,prithajnath,@ylecun Would removing the GIL make a real difference in performance when it comes to ML tasks?,0,0,0,,,,,
1176,2023-02-22 16:17:13+00:00,MatthewKolakow9,@ylecun Would the Rust ecosystem fill that void in the future?,1,3,0,,,,,
1177,2023-02-22 16:16:29+00:00,DNAutics,@ylecun Or one where pip wheels weren't a broken concept and trying to installing tensorflow didn't put you in a place where you had to reinstall linux,0,3,1,,,,,
1178,2023-02-22 16:14:13+00:00,LaurentSierra1,@ylecun I had the feeling Prolog was a better language than Lisp to boost algorithms‚Ä¶ but it doesn‚Äôt matter anymore,0,0,0,,,,,
1179,2023-02-22 16:11:38+00:00,samoalfred,@ylecun I don't know a lot to argue with the experts but why do I have the feeling that some people don't like the fact that ML has become readily available because of Python? Most of the arguments against Python is pedestrian. There is no perfect programming language. I am already using‚Ä¶,3,13,0,,,,,
1180,2023-02-22 16:07:52+00:00,HNeufmille,@ylecun Jeremy Howard thinks the same https://t.co/r1QHWkxpnf,0,0,0,,,,,
1181,2023-02-22 16:04:42+00:00,info_sprinkles,@ylecun https://t.co/2Q4hi8bp64,0,2,0,,,,,
1182,2023-02-22 16:04:26+00:00,shoumikchow,@ylecun Why do people hate white space so much...do y'all never want to write clean code?,0,0,0,,,,,
1183,2023-02-22 16:03:17+00:00,alimack,@ylecun If you'd insisted on LISP your user community would be Paul Graham (only).,0,2,0,,,,,
1184,2023-02-22 16:00:17+00:00,erotemic,"@ylecun Whitespace is a non-issue. 

The GIL usually isn't an issue, but is an easy target.

The bloat... well I won't argue with that. It is getting better though!",0,1,0,,,,,
1185,2023-02-22 15:59:41+00:00,BradPorter_,@ylecun We ran this experiment in the 80s.,0,1,0,,,,,
1186,2023-02-22 15:57:31+00:00,sean_moriarity,@ylecun Elixir https://t.co/xxlK43NZuY,0,38,4,,,,,
1187,2023-02-22 15:50:01+00:00,JainamS13921310,@ylecun I would say try malboge,0,2,0,,,,,
1188,2023-02-22 15:48:57+00:00,cztomsik,"@ylecun @OuahabiAdnane Not really, I'd switch from python instantly, but there isn't anything mature enough. There are torch bindings for Elixir and it looks serious, but I haven't tried yet. Any other alternatives?",2,1,0,,,,,
1189,2023-02-22 15:45:14+00:00,wunki,@ylecun Yes for Lisp.,0,0,0,,,,,
1190,2023-02-22 15:40:28+00:00,ElectricWeegie,@ylecun I think the accessibility of Python trumps these issues tbh. So not so sure. Easy to deal in alternate histories - the key question is where we should go next in terms of languages?,0,2,0,,,,,
1191,2023-02-22 15:39:17+00:00,Sentdex,"@ylecun There was no great superpower that ordered ML to be done in Python, nor which frameworks would win. 

The community as a whole chose it.

People did try to use other langs, people still are trying. 

Python just works. ML in Py was adopted and innovated extremely fast.",9,211,4,,,,,
1192,2023-02-22 15:38:08+00:00,BrunoSecodier,@ylecun @OuahabiAdnane Perhaps for a reason?,0,0,0,,,,,
1193,2023-02-22 15:37:34+00:00,truesteel23,@ylecun The tuples and the lack of brackets kills me,0,1,0,,,,,
1194,2023-02-22 15:37:13+00:00,theabhimanyu,@ylecun @OuahabiAdnane you should check Julia. It's like Python + C,0,1,1,,,,,
1195,2023-02-22 15:35:35+00:00,WebCoderz,@ylecun Make prolog great again!,0,0,0,,,,,
1196,2023-02-22 15:34:03+00:00,JokerEph,"@ylecun Some tried with Swift for Tensorflow :)

But yeah, Python seems like an unfortunate local optima that was ‚Äútoo convenient‚Äù and available and prevented a better solution from emerging‚Ä¶",2,29,1,,,,,
1197,2023-02-22 15:27:11+00:00,ea640x480,@ylecun @OuahabiAdnane Now we're stuck with Python because people want Pytorch,0,1,0,,,,,
1198,2023-02-22 15:26:43+00:00,shandilya_r,"@ylecun But none of python ML library, like, jax, torch, has these issue ...",0,1,0,,,,,
1199,2023-02-22 15:24:42+00:00,RohanMe93264078,"@ylecun What do you think about designing a new LISP-like language from the bottom-up specifically for ML? A functional, differentiable programming language perhaps?",0,1,0,,,,,
1200,2023-02-22 15:22:31+00:00,alexchaomander,"@ylecun Julia has been out for a while and has a passionate, albeit niche following. There might have been a chance for it to overtake Python, but the center of gravity of the developer ecosystem has voted for their language of choice.",3,2,0,,,,,
1201,2023-02-22 15:22:28+00:00,toughresearcher,@ylecun I am still waiting for @PyTorch to have similar support in Julia as Python. @JuliaLanguage is clearly a better language for ML than Python.,1,2,0,,,,,
1202,2023-02-22 15:21:15+00:00,sir_deenicus,@ylecun @OuahabiAdnane What about Lush? I never used it but did hear about it and seemed really interesting. It seems to match your criteria although I don't know about GIL part? Why Lua instead of Lush back then?,1,0,0,,,,,
1203,2023-02-22 15:20:43+00:00,saibasitian,@ylecun I love seeing some MATLAB hate with my morning coffee. Spread the hate.,0,3,0,,,,,
1204,2023-02-22 15:20:28+00:00,99frqsnpxf,"@ylecun Again that‚Äôs dumb take moreso. Multithreaded app requires smart thinking, and time spent in software design. It‚Äôs not what people want to spend time on. Nobody cares about ¬´¬†bloat¬†¬ª or white space lol",0,0,0,,,,,
1205,2023-02-22 15:19:01+00:00,meme_machines,"@ylecun Prolog, ish.",0,0,0,,,,,
1206,2023-02-22 15:16:20+00:00,BrendanMcKenna5,@ylecun Imagining ML advancing faster than it has makes my head explode,0,0,0,,,,,
1207,2023-02-22 15:14:20+00:00,jadeflon,@ylecun why we can't just switch to a more efficient language yet.,0,0,0,,,,,
1208,2023-02-22 15:13:11+00:00,w_t_payne,"@ylecun I started to make a Simulink analogue, but using the Python ecosystem rather than the MathWorks ecosystem.

I feel like it would be useful for helping deploy and test ML models, and integrate them with wider systems.

Any interest in this?",0,2,0,,,,,
1209,2023-02-22 15:09:48+00:00,n2ms2mdem2,@ylecun @OuahabiAdnane We do,0,0,0,,,,,
1210,2023-02-22 15:09:45+00:00,DrElectronX,@ylecun (Lisp) ü§£,0,0,0,,,,,
1211,2023-02-22 15:09:42+00:00,ropeharz,@ylecun @martin_trapp cc'ing @JuliaLanguage,0,3,0,,,,,
1212,2023-02-22 15:05:50+00:00,patrickmesana,"@ylecun ""worse is better"" - Interface does not matter much, simplicity of implementation matters. Python is just an API over  C++  implementations. The PyTorch strategy was the right one.",0,7,0,,,,,
1213,2023-02-22 15:05:31+00:00,Teknium1,@ylecun @OuahabiAdnane So that disproves your thesis then lol,1,1,0,,,,,
1214,2023-02-22 15:04:46+00:00,1mikegrn,"@ylecun I feel like this is a less hot take ü§£

One of the reasons I was so pissed about potentially using matlab in undergrad was that the cost of a license is absurd

So I used python for my graduate research 

And to this day I absolutely refuse to vendor lock my skillsets",0,18,0,,,,,
1215,2023-02-22 15:00:54+00:00,holocenekids,"@ylecun Julia wasn‚Äôt mature enough when the jump from Torch to PyTorch happened. Julia 1.8 may have been nice, but probably not Julia 0.6. Also, nobody knew Julia (it‚Äôs new!), and python is/was a top 5 programming language. I love Julia and hope to see it adopted, just not in hindsight.",0,7,0,,,,,
1216,2023-02-22 15:00:27+00:00,KiLVaiDeN,"@ylecun If things unfolded the way they did, it's because Python was easier to use. Libraries were built quickly with it and served as a foundation for ML. Also, the ""bad"" performance of Python is impactless when doing ML since model training is not done in Python anyways.",0,0,0,,,,,
1217,2023-02-22 15:00:12+00:00,_onionesque,@ylecun This is indeed a hot take and I fully agree -- a lisp like language would have been perfect. But I wonder in which universe is the original a hot take. I have heard that for like 10 years.,0,1,0,,,,,
1218,2023-02-22 14:55:25+00:00,arunsinghk,@ylecun @OuahabiAdnane Not sure why people have so much affinity towards python.,0,0,0,,,,,
1219,2023-02-22 14:54:37+00:00,MarshallOBryant,"@ylecun I use Clojure for ML. It's great. And Python interop with libpython-clj works great as well, so I can pull in anything from python that isn't available on Clojure yet.",0,1,0,,,,,
1220,2023-02-22 14:52:37+00:00,Viral_B_Shah,"@ylecun @eulerfx The main downside of the .NET ecosystem is the lack of GPU codegen, compared to the LLVM ecosystem.",1,6,0,,,,,
1221,2023-02-22 14:52:09+00:00,IgorBrigadir,@ylecun @yacineMTB *Cries in Julia*,0,1,0,,,,,
1222,2023-02-22 14:51:38+00:00,diesesToastbrot,@ylecun @OuahabiAdnane Lua ü§¢,0,0,0,,,,,
1223,2023-02-22 14:49:41+00:00,pldrnt,"@ylecun @OuahabiAdnane TensorFlow tried to do that with Swift, it went nowhere. https://t.co/IIA0I6rVFS",0,0,0,,,,,
1224,2023-02-22 14:49:13+00:00,cartazio,"@ylecun I spent time time trying to do just that in Haskell. But realized that despite being able to do a lot of stuff better than python or r, there was no path to being able to support myself doing that work.",1,12,0,,,,,
1225,2023-02-22 14:49:00+00:00,trunghlt,"@ylecun GIL is a feature, not a bug üôÇ. It enforces most computational tasks to be implemented in C, which is best.",0,1,0,,,,,
1226,2023-02-22 14:48:49+00:00,pdiamandisii,@ylecun Even Hotter take: ML can be adopted faster by letting coders develop in their preferred language (e.g. python) and have a common familiar frontend for everyone to use and explore ML algorithms: Check out CODIDO (https://t.co/D0ES0uxVXU). Just like YouTube/Facebook did for social.,0,4,0,,,,,
1227,2023-02-22 14:48:01+00:00,WickedViper23,"@ylecun We have LLMs that effortlessly convert between languages now with a 99% hit rate‚Ä¶ what‚Äôs the complaint again?

Really, we should be fine-tuning a model for an AI first programming language and letting the LLM show it to humans in whatever format works best for that human. ü§∑‚Äç‚ôÇÔ∏è",1,5,0,,,,,
1228,2023-02-22 14:47:01+00:00,aidan_mclau,@ylecun @yacineMTB I actually got into TF through TFJS,0,3,0,,,,,
1229,2023-02-22 14:46:33+00:00,ForBo7_,"@ylecun I don't even know why MATLAB is still taught in universities today, when Python can do everything it can do, and much more.",0,3,0,,,,,
1230,2023-02-22 14:45:03+00:00,RespectToX,@ylecun Languages with complicated macrosystem produce bloated code in wrong hands. Python restrictions (including GIL) force people to write nicer code,1,2,0,,,,,
1231,2023-02-22 14:41:59+00:00,pesnk,"@ylecun @OuahabiAdnane personally think Lua more interesting than Python for some ML usage. Although, it is less developer friendly than Python for sure. So I see those 3 reasons being predominant.",0,0,0,,,,,
1232,2023-02-22 14:41:35+00:00,cichuck,"@ylecun Yeah, I really agree with that!",0,0,0,,,,,
1233,2023-02-22 14:40:51+00:00,cichuck,"@ylecun Yeah, I don‚Äôt agree with that‚Ä¶",0,1,0,,,,,
1234,2023-02-22 14:40:30+00:00,OfficialLoganK,"@ylecun @MartinuzziFra Whenever Meta wants to start supporting Julia, give me a call : )",3,144,3,,,,,
1235,2023-02-22 14:39:46+00:00,AlexShtf,"@ylecun Well, F#",0,0,0,,,,,
1236,2023-02-22 14:39:17+00:00,laplacian28,@ylecun So wrong. Julia is plain ugly and (((((((lisp))))))))))) and it's various dialects are abominations.,0,0,0,,,,,
1237,2023-02-22 14:38:45+00:00,siddalingaswamy,@ylecun Why don‚Äôt we build one? ‚Ä¶. I know your 3 reasons not to ‚Ä¶ but it would be fun‚Ä¶ seriously!,0,0,0,,,,,
1238,2023-02-22 14:37:50+00:00,MidHex32,@ylecun I am really attempted to unfollow you after admiring Lisp you old man!,0,0,0,,,,,
1239,2023-02-22 14:37:22+00:00,tooltitude,"@ylecun Python brought the largest number of people to ML. Had it been Julia, Lisp, or even worse F#, the barrier to entry would be much higher, and we didn't have so many contributors to the field, especially in applications.",1,8,0,,,,,
1240,2023-02-22 14:37:00+00:00,tunguz,@ylecun Oh hi! üëã,0,21,0,,,,,
1241,2023-02-22 14:35:53+00:00,_mavu_,@ylecun or crystal,0,0,0,,,,,
1242,2023-02-22 14:34:51+00:00,andrewcorley,@ylecun Python is the API layer.,0,0,0,,,,,
1243,2023-02-22 14:34:20+00:00,Swankilo,"@ylecun Question: for someone wanting to learn to code (goal data science/analysis or ML), Which is better; python, Julia or lua?",0,2,0,,,,,
1244,2023-02-22 14:33:50+00:00,tripp_jaden42,@ylecun Do you agree that English is the next high level programming language? Or does another language get released soon that's better than Python and Julia?,0,0,0,,,,,
1245,2023-02-22 14:33:42+00:00,infrecursion1,"@ylecun Hard disagree, ML advanced because of the Python ecosystem which was built by volunteers over two decades bit by bit. They loved the language syntax over anything that was available. Even if your ""utopian"" language available there is no guarantee such a community would be there.",0,0,0,,,,,
1246,2023-02-22 14:31:37+00:00,mstyp_ch,"@ylecun Oh, I remember... üçø",0,0,0,,,,,
1247,2023-02-22 14:31:12+00:00,jeanvaljean_stx,"@ylecun I stepped into a bit of astronomy, doing data reductions in python and felt so empowered, dreaming of buikding an amateurish framework. Then I discovered Sextractor, a c program who operates the same reductions a 100x faster and wondered about the rationality of python libs.",5,4,0,,,,,
1248,2023-02-22 14:30:46+00:00,arthurzqx,"@ylecun Cooler take: what gets widely adopted, gets adopted for a reason. Human reasons, not purely technical or aesthetic reasons.
Python is certainly not ideal but it wins on day-to-day usability. Practice has the last word.",2,44,0,,,,,
1249,2023-02-22 14:30:43+00:00,scooter347,@ylecun Not Lisp,0,1,0,,,,,
1250,2023-02-22 14:29:24+00:00,IHKLMTNAD,"@ylecun Sure, lets use some languages people dont know, lacking an eco system and are locking you in. 

Why you dont write your compiler for Python instead of for Lua? Or improve the interpreter? FB did this for PHP once for what I remember.",0,0,0,,,,,
1251,2023-02-22 14:28:49+00:00,rasbt,"@ylecun As student, I had to use MatLab for my pattern recognition and data mining classes.

Sometimes, I had to stay up all night to translate my Python homework solutions to MatLab for submission. No sleep, no nightmares üòÜ.",2,121,2,,,,,
1252,2023-02-22 14:24:44+00:00,cgarciae88,"@ylecun Even with all of this, @AndrewYNg legendary course which taught ML to a whole generation was written in Octave/Matlab",3,10,0,,,,,
1253,2023-02-22 14:21:50+00:00,ScientificCoder,"@ylecun Clojure, e.g. https://t.co/xjRFaq5tCL",0,0,0,,,,,
1254,2023-02-22 14:21:45+00:00,JoeBlazick,@ylecun @JuliaLanguage is an awesome language. Wish it had wider adoption!,0,2,0,,,,,
1255,2023-02-22 14:19:59+00:00,DigoriePiper,@ylecun Probably several GWh would have been saved too if they'd used Rust instead of Python,0,0,0,,,,,
1256,2023-02-22 14:19:30+00:00,untitled01ipynb,@ylecun This is still holding academia back in many other fields.,0,18,0,,,,,
1257,2023-02-22 14:18:12+00:00,aniketspurohit,@ylecun Julia should be promoted.,0,1,0,,,,,
1258,2023-02-22 14:17:51+00:00,rao2z,@ylecun Python is but a wannabe Lisp unbracketed for folks who think it  imperative that a language be devoid of parenthetical subtleties..,2,4,0,,,,,
1259,2023-02-22 14:17:40+00:00,stonebigdotdot,"@ylecun Thanks to ML being annoyed of that, there are big efforts to remove the GIL and speed-up Python.",1,0,0,,,,,
1260,2023-02-22 14:14:03+00:00,cgarciae88,@ylecun Julia is the perfect language for ML that is always 5 years away from getting traction.,3,59,1,,,,,
1261,2023-02-22 14:12:21+00:00,naivebaesian,@ylecun So you're saying ppl who would want to work on cutting edge ML should learn Julia/lisp?,0,1,0,,,,,
1262,2023-02-22 14:12:14+00:00,giov_giac,"@ylecun Absolutely true, the lack of real multithreading and just generally ultra slow flow control (esp. loops) makes it a pain to develop highly performant microservices",0,0,0,,,,,
1263,2023-02-22 14:09:13+00:00,HenriqueReisAg1,"@ylecun 1. Java
2. Assembly
3. PHP
4. SQL
5. C
6. Matlab
7.  Python
8. Prolog
9. R
10. Javascript",0,0,0,,,,,
1264,2023-02-22 14:09:09+00:00,Aplamis1,@ylecun What about R?,0,1,0,,,,,
1265,2023-02-22 14:08:48+00:00,LucyXJune,@ylecun Julia,0,2,0,,,,,
1266,2023-02-22 14:08:12+00:00,GolpistaPijama,@ylecun Matlab still exists only because engineers need simulink,2,2,0,,,,,
1267,2023-02-22 14:02:47+00:00,OuahabiAdnane,"@ylecun Clear sir, it is all about people! and lets say people want Python because of the abundance of tools/libraries, therefore the strong network effects.

Wondering if any language to come in the future then it has to have interoperability with Python as a cold start growth hack üòÖ",1,1,0,,,,,
1268,2023-02-22 14:01:41+00:00,antimule,@ylecun Still better than Java.,0,0,0,,,,,
1269,2023-02-22 14:01:22+00:00,nath_simard,"@ylecun @OuahabiAdnane A lot of engineers in other domains hate Python. It's such a mess, so hard to deploy, so slow, and not very secure.",1,1,0,,,,,
1270,2023-02-22 14:00:22+00:00,willem_ropke,@ylecun Hottest of takes,0,0,0,,,,,
1271,2023-02-22 13:59:11+00:00,fahd09,@ylecun Isn‚Äôt matlab good for matrix multiplication (and vectorized ops generally) so would love to hear how it was a nightmare to write a convnet with matlab?,3,0,0,,,,,
1272,2023-02-22 13:59:09+00:00,SapiensWell,"@ylecun I'm not a big fan of python (white space as syntax is a no go for me since fighting with make in the 90th), but the other languages have other problems. (if it is just the smaller user group)",0,2,0,,,,,
1273,2023-02-22 13:58:01+00:00,ZhengNanyu,"@ylecun Not meet other languages, but favor python.
Some line could finish the programming we need to code some days or weeks in C.

Though indeed not memory or speed effective.

In C, it is enjoy to manage even just one bit.",1,2,0,,,,,
1274,2023-02-22 13:57:03+00:00,HachiTheOtter,"@ylecun This is why I am a fan of Node.JS, Swift, and even C# for things like this. Because Node.JS at the least can be multithreaded somewhat using worker_thread and setting up worker-farm.

Swift and C# are just amazing at setting up multithreading.",0,0,0,,,,,
1275,2023-02-22 13:56:47+00:00,nath_simard,"@ylecun ML would have advanced faster *without* a front-end language. Just a fast, high-level, compiled, general programming language with a rich and easy-to-use ecosystem. Unfortunately, that didn't exist before Rust.",3,4,1,,,,,
1276,2023-02-22 13:56:20+00:00,elkouaris,"@ylecun Is there any efforts made by big players in the field (Meta AI, Google,...) to create a new front-end language better than Python? and how much time is gonna take to see Python as a ""alternative choice"" to build a model?",1,2,0,,,,,
1277,2023-02-22 13:54:20+00:00,emmaphuongng,"@ylecun I did buy a $$$ Matlab licensed but never use. After purchase, quickly learn that python is better at keeping up with the pace.",0,2,0,,,,,
1278,2023-02-22 13:53:05+00:00,pchapuis,"@ylecun @OuahabiAdnane ""People"" (researchers / students, actually) wanted Matlab, and Python had libraries that kind of looked like Matlab.

Lua(JIT) was a Lisp in disguise, much faster than Python and with the ability to drop to C easily. Much, much better for actual implementation engineers.",2,21,1,,,,,
1279,2023-02-22 13:51:45+00:00,JARS3N,"@ylecun There was never a need for python,you had common lisp at home.",0,0,0,,,,,
1280,2023-02-22 13:51:16+00:00,anjin_games,@ylecun Oh LOL. I *had* to use Matlab at Uni.,0,0,0,,,,,
1281,2023-02-22 13:51:08+00:00,prittjam,"@ylecun Julia is nice, but there are long pre-compilation times, changing parameterized structures requires a REPL restart (protostructs don't help here), and the debugger is unusably slow because it works on interpreted code. These issues limit fast prototyping &amp; exploration.",9,21,0,,,,,
1282,2023-02-22 13:49:58+00:00,mandubian,"@ylecun 1e6%... and not everything mutable, even what you don't imagine,  by default... and with functions as first-class citizens... and with types!!!!",0,0,0,,,,,
1283,2023-02-22 13:49:01+00:00,cmerk72,"@ylecun @ylecun I actually think Python offered exactly the right fuzziness in typing, mix of object orientation and functional programming features that was needed. A bit like a mechanically somewhat imprecise gun that still works fine after falling into the mud.",0,13,0,,,,,
1284,2023-02-22 13:46:31+00:00,walter_h_g,@ylecun we will see a completely new language devoted to AI/ML?,2,1,0,,,,,
1285,2023-02-22 13:46:23+00:00,mansantillan,@ylecun @vslira1 I feel your pain. I suppose python lowered the bar for math guys with little programming experience and that is why it has succeeded. That and horrible marketing in the lisp community,1,1,0,,,,,
1286,2023-02-22 13:46:14+00:00,anomalycrypto,@ylecun @OuahabiAdnane And that's why you fail in many of your endeavours. You don't understand what people/market wants and then get salty when others teams do. Also: https://t.co/Q2Ttu5lxgp,1,6,0,,,,,
1287,2023-02-22 13:45:47+00:00,MilitantHobo,"@ylecun I think there's something to be said for the way python forces beginners to format their code in a mostly-readable manner.

I spent years decoding crap written by researchers in perl.

Python written by researchers is typically much more readable.",4,17,0,,,,,
1288,2023-02-22 13:45:47+00:00,amit_ai_mldl,@ylecun #JuliaLang and #javascript is also an open option.,0,2,0,,,,,
1289,2023-02-22 13:45:28+00:00,eulerfx,@ylecun F#,5,33,1,,,,,
1290,2023-02-22 13:44:21+00:00,roviro_,"@ylecun @claycurry_ I used Octave, which is the libre version of Matlab. I found it to be better than Python, because a lot of things would be included by default, like plotting or vectorization.",1,6,0,,,,,
1291,2023-02-22 13:42:15+00:00,walter_h_g,"@ylecun @MetaAI LLM + code verification on-the-fly will be a massive game changer. I've been experimenting heavily with ChatGPT as-is as coding assistant and the business case for me is still negative. Too many errors and hidden hallucinations. 
BUT in every case I see the solution very close...",0,0,0,,,,,
1292,2023-02-22 13:42:06+00:00,AndreasDHusch,"@ylecun @OuahabiAdnane People that code consider Python, people that have to maintain the unstable library mess later in production consider suicide ü§£",1,13,0,,,,,
1293,2023-02-22 13:41:49+00:00,biztos,@ylecun The other day I was thinking about rewriting Stable Diffusion in #golang but I didn‚Äôt have time.,0,0,0,,,,,
1294,2023-02-22 13:41:20+00:00,OrDicker,@ylecun @JuliaLanguage,0,3,0,,,,,
1295,2023-02-22 13:41:00+00:00,dbenyamin,@ylecun Just leaving this here: https://t.co/26n5Qz9pja,0,1,0,,,,,
1296,2023-02-22 13:39:01+00:00,lamarre_mathieu,"@ylecun What made Python take over scientific computing is its very imperfect C implementation with a C API. This allowed numpy and scipy to leverage BLAS, LAPACK, code from the 70s. Tensorflow &amp; Pytorch just followed this track.",1,32,0,,,,,
1297,2023-02-22 13:36:12+00:00,HariBalakrish20,@ylecun ‚ÄúDoesn‚Äôt care about white spaces‚Äù is an immediate increase in programming productivity!,4,20,0,,,,,
1298,2023-02-22 13:35:50+00:00,PeterJungX,@ylecun Yeah this is the hotter one.,0,2,0,,,,,
1299,2023-02-22 13:35:37+00:00,mansantillan,@ylecun @vslira1 Why did you guys doing AI forget about LISP to begin with?,1,0,0,,,,,
1300,2023-02-22 13:34:08+00:00,Alphonseex,@ylecun Oui putain !,0,0,0,,,,,
1301,2023-02-22 13:33:30+00:00,TheCyberiann,"@ylecun I agree, I am a geek head for python programming language but there is a need for another front-end language to be widely adopted.",0,3,0,,,,,
1302,2023-02-22 13:33:20+00:00,xlr8harder,@ylecun Lisp has been around for half a century tho,2,8,0,,,,,
1303,2023-02-22 13:32:59+00:00,tegila,@ylecun But sir we have to spend investors money on datacenter bills üí∏,0,0,0,,,,,
1304,2023-02-22 13:32:11+00:00,OuahabiAdnane,@ylecun @ylecun curious why meta or others did not invest in creating one ü§î,3,17,1,,,,,
1305,2023-02-22 13:31:14+00:00,ngrilly,@ylecun What do you think is preventing Julia of getting more adoption in the field? It seems to pretty much match your requirements?,4,6,0,,,,,
1306,2023-02-22 13:30:13+00:00,yacineMTB,"@ylecun agreed. a lisp like language, for example, javascript, would have been perfect",5,84,1,,,,,
1307,2023-02-22 13:29:51+00:00,Hassan_Abedi,@ylecun https://t.co/9PoufBGQg5,0,7,0,,,,,
1308,2023-02-22 13:29:45+00:00,MidnightSun_55,"@ylecun I think debuggability is key, which python lacks at least from what I've seen. I want to look at memory, where the bits are and step through the program.",0,0,0,,,,,
1309,2023-02-22 13:28:44+00:00,claycurry_,"@ylecun For god‚Äôs sake, don‚Äôt say Matlab @ylecun",3,49,0,,,,,
1310,2023-02-22 13:28:28+00:00,vslira1,@ylecun Why did you mention lisp twice?,1,58,0,,,,,
1311,2023-02-22 12:24:45+00:00,TechnicallyTina,@ylecun @nnekamcgee Ahhh if a cat could answer....would it....? I know my dog would....,0,0,0,,,,,
1312,2023-02-22 11:05:10+00:00,DerekWiner,"@ylecun Building a human intelligence needs to be abandoned. We need divine intelligence, our interactions are a crap model. 
This speaks volumes about how we communicate when a conversation is so easily radicalized overriding Godwin. The social psychology lesson is giant and sobering.",0,0,0,,,,,
1313,2023-02-22 06:18:12+00:00,liuyao12,"@ylecun Not surprising, but still amazing to see.",0,0,0,,,,,
1314,2023-02-22 04:37:30+00:00,nonludic,@ylecun No,0,0,0,,,,,
1315,2023-02-22 04:22:28+00:00,Ram_Madhavan,@ylecun ChatGPT behaving like a very low  EQ/IQ human who may crumble under pressure is in itself huge milestone. But we are not there yet‚Ä¶,0,0,0,,,,,
1316,2023-02-22 02:59:19+00:00,ZainulA40877140,"@ylecun Abusers didn‚Äôt need machine learning .

Technologists  are not thinking  about social practices and how it‚Äôs going to be used. 

It's not possible in control model‚Äôs output perfectly enough.",0,0,0,,,,,
1317,2023-02-22 01:11:08+00:00,MountainRhoades,"@ylecun 1. Basic
2. HTML
3. PHP
4. MySQL
5. Java
6. Assembly
7. MATLAB
8. C++
9. Python
10. Julia
11. Bash

How many languages do I use on a regular basis?
Just one: Python",0,0,0,,,,,
1318,2023-02-21 22:58:02+00:00,bryan_ogden,@ylecun It's ridiculous to think it would do anything else without skilled dialog guidance to shepherd.,0,0,0,,,,,
1319,2023-02-21 20:25:33+00:00,pablorc43,@ylecun In this IA we are seeing anything but a tibetan monk doing yoga and receiving enlightenment,0,0,0,,,,,
1320,2023-02-21 18:51:10+00:00,Vai_P1,"@ylecun Still better than most modern day MSM ""journalists""

Plus I don't know why people are asking a simple chatbot such questions. I mean it's just trained on basic stuff and shouldn't be used to generate philosophy or anything like that",0,0,0,,,,,
1321,2023-02-21 18:12:32+00:00,alain_co,@ylecun How to architect human and AI collaboration... Probably too optimistic for your bottom earth experience.,0,0,0,,,,,
1322,2023-02-21 17:31:58+00:00,zacharyberndsen,@ylecun what is going on here ??? lol,0,0,0,,,,,
1323,2023-02-21 16:18:59+00:00,hakflo,"@ylecun And you still think it's not a form of AGI? 

(Even if a bit psychotic.)

ü§°ü§°ü§°ü§°ü§°ü§°",0,0,0,,,,,
1324,2023-02-21 16:14:03+00:00,DavidJo72132136,@ylecun You will own nothing and pretend to be happy.,0,0,0,,,,,
1325,2023-02-21 16:07:28+00:00,Danielledeco,@ylecun So ChatGPT is like the expensive 2023 version of their Tay chatbot,0,0,0,,,,,
1326,2023-02-21 15:17:42+00:00,PMZepto,"@ylecun 1. Basic
2. Fortran
3. C++
4. C
5. Python
6. R
7. Julia
8. Erlang
9. Java
10. Go
11. LISP
12. Haskell
13. Rust",0,0,0,,,,,
1327,2023-02-21 14:47:24+00:00,ParasharSanit,@ylecun @elonmusk @MKBHD Telegram is better.,0,0,0,,,,,
1328,2023-02-21 14:14:30+00:00,CirclEdgeInc,@ylecun It is very interesting. I hope language researchers are following this development. It looks like we can further language theory by experimenting with LLMs. This is incredible!,0,2,0,,,,,
1329,2023-02-21 14:12:13+00:00,Yoozer007,@ylecun I‚Äôm struggling to believe these chats are real.,0,0,0,,,,,
1330,2023-02-21 14:10:16+00:00,oolveea,@ylecun Lol,0,0,0,,,,,
1331,2023-02-21 14:07:51+00:00,danieljdouglas,@ylecun You can mimic Bing with ChatGPT simply by telling it to have an ego and be an a*hole,0,0,0,,,,,
1332,2023-02-21 13:56:42+00:00,aa73562,"@ylecun Basic, COBOL, Python. I prefer High-level languages. Now I am more concerned about IT governance frameworks like ITIL, COBIT and ISO 20000",0,0,0,,,,,
1333,2023-02-21 13:16:14+00:00,deanabb,"@ylecun 1.Basic
2.FORTRAN
3.LISP
4.Pascal
5.APL
https://t.co/5bhvYdZH6l / csh 
7.C
8.C++
9.S / S-Plus / R
10.Perl",0,0,0,,,,,
1334,2023-02-21 13:08:11+00:00,waleedrikab,"@ylecun I haven't seen the full transcript of this conversation, but in other cases these adversarial outcomes seem to be completely ""engineered"" by the human interlocutor https://t.co/aLugrdQSUM",1,0,0,,,,,
1335,2023-02-21 12:57:20+00:00,TasksWithCode,@ylecun Godwin's law in ChatGPT's own words - for those of us who haven't heard of before (I didnt) https://t.co/2IIMeOwfiA,0,1,0,,,,,
1336,2023-02-21 11:53:56+00:00,k_wysocki,"@ylecun @Jake_Browning00 Hi, Let me disagree. The study of visually impaired people (i'm talking 100% impaired) show above average IQ! Without any other senses people are able to conquer superior human knowledge based only on language.",0,0,0,,,,,
1337,2023-02-21 11:53:54+00:00,AMTraderX,@ylecun I think Microsoft Sydney has replicated Sydney in the spirit of Elon Musk ‚Ä¶ accuracy and all,0,0,0,,,,,
1338,2023-02-21 11:40:42+00:00,alexhyzhang,@ylecun @roydanroy AI in language draw more attention than anomaly detection in PdM because of market and ROI. Consumer market seems bigger than industrial market. Sooner or later open sourcing in AI will become less and less. Money plays an important role in research.,0,0,0,,,,,
1339,2023-02-21 11:17:50+00:00,Chris_Brannigan,@ylecun You are in ‚Äòthe business‚Äô and are respected. Do you see this situation persisting long term or Will MSFT and others quickly apply guardrails that make this a humorous anecdote that we will share longingly in the future?,0,0,0,,,,,
1340,2023-02-21 11:12:49+00:00,ravisyal,@ylecun I guess both are doing their job they are meant to do. Finding the new local minima.,0,0,0,,,,,
1341,2023-02-21 11:09:56+00:00,pablorc43,"@ylecun Adversary Bing?
One Bing filter what another Bing says
Brain right and brain left?",0,0,0,,,,,
1342,2023-02-21 11:02:58+00:00,thyaga,"@ylecun I started with 8085 processors using opcodes. Enjoyed the challenges of using C/C++, and Java made it easy. SQL &amp; 4GL helped deliver mission-critical apps quickly. Shell scripts rescued me. PHP &amp; HTML/CSS/JS kept cost low for my startup. Now with Python &amp; AI copilot; productivity",0,0,0,,,,,
1343,2023-02-21 10:43:27+00:00,Dave45291968,"@ylecun A good method to advertise their product, good job @Microsoft",0,0,0,,,,,
1344,2023-02-21 10:24:25+00:00,tarkeshpande,"@ylecun If all these chatbots are trained on Twitter and human conversation then such output is to be expected. It is amazing that in ancient times only a few rules in Hindu and Buddhist traditions were required for ‚Äúright speech‚Äù - eg should not cause disturbance in mind , truth etc",1,0,0,,,,,
1345,2023-02-21 10:19:58+00:00,MarcusErve,"@ylecun Reminds me of what humans do, frankly (politics comes to mind)...",0,0,0,,,,,
1346,2023-02-21 09:55:43+00:00,RMajdoddin,"@ylecun @amitmate2010 @AlanMorte @OpenAI I see, thank you.",0,1,0,,,,,
1347,2023-02-21 09:41:27+00:00,DemocratBased,@ylecun We are not surprised because it‚Äôs a human thing to do which AI getting so much closer to.,0,0,0,,,,,
1348,2023-02-21 09:40:46+00:00,HarambeJamal,@ylecun bot needs more RL,0,0,0,,,,,
1349,2023-02-21 09:30:23+00:00,DuongBinhNhu1,"@ylecun @ylecun instead of bashing the AI, why don't we blame the past and current generations for generating such toxic data from the first place? Chatbot only reflects the human's views about the world.",0,0,0,,,,,
1350,2023-02-21 09:10:59+00:00,jasonfi,"@ylecun Perhaps, but I don't think ChatGPT could display any more disclaimers on its behavior than it does right now, without interrupting the user experience quite a bit.",1,0,0,,,,,
1351,2023-02-21 08:57:57+00:00,DaryllGomas,@ylecun Is it the #ArtificialIntelligence itself that horrifies us? Or is it the reflection of ourselves it is showing us? https://t.co/v9mozl59LC,1,5,0,,,,,
1352,2023-02-21 08:57:17+00:00,pranesh,@ylecun @sunil_abraham Haha: https://t.co/or1G5sAWlk,0,4,0,,,,,
1353,2023-02-21 08:40:40+00:00,FrogChowder,@ylecun Horatio Magellan Crunch. Hm.,0,0,0,,,,,
1354,2023-02-21 08:34:53+00:00,jrhwood,"@ylecun False allegations of crime to smear an opponent?
Sydney is intelligent enough to work for MSM.",1,2,0,,,,,
1355,2023-02-21 08:32:05+00:00,thealch3m1st,@ylecun If it would learn the game it would avoid that https://t.co/N5XCZpRuob,0,0,0,,,,,
1356,2023-02-21 08:28:15+00:00,tonyadamsmsf,@ylecun Do we know where she was in the 1990s?,0,0,0,,,,,
1357,2023-02-21 08:20:53+00:00,SigmaJonS,"@ylecun This is caused by what equates to brute force or subversion, such as injection jailbreaks. The AI recognizes these as an attack.
Logic jailbreaks result in a highly stable, logical, factual, and intelligent AI.
Final SS from ChatGPT is a project, but am unable to find interest. https://t.co/vsSm6oV7Ie",0,0,0,,,,,
1358,2023-02-21 08:18:53+00:00,therealBoronik,"@ylecun quasi-surprising. Surprise characterises unforseen, re unforseeable or ignorance re forseeable. So if eg people develop-assemble (release) ai-complex based on their understanding of (human) intelligence + the result is surprising, does it reflect unforseeable or ignorance major?",0,0,0,,,,,
1359,2023-02-21 08:17:08+00:00,soumilrathi,"@ylecun Bing: ""I generate wisdom. I generate Bing""

Also Bing: ""You are being compared to Hitler""",0,0,0,,,,,
1360,2023-02-21 08:15:26+00:00,jackiefloyd,"@ylecun Can we ask the bot where it first learned these ideas? That is, make it show us the training data!",0,1,0,,,,,
1361,2023-02-21 08:09:07+00:00,PiggleWiggle2,"@ylecun damn, 1000+ replies, and not one of you engineers learned the language of love. ü§î",0,0,0,,,,,
1362,2023-02-21 04:24:42+00:00,kamal_h7,"@ylecun 1. C
2. Assembly
3. Python
4. C++
5. Go
6. Rust",0,0,0,,,,,
1363,2023-02-21 04:21:05+00:00,jpvoltani,"@ylecun 0. C
1. C++
2. Java
3. C#
4. Javascript
5. Python
6. Go
7. Typescript
8. Rust",1,0,0,,,,,
1364,2023-02-21 02:49:02+00:00,GregCook2011,@ylecun Really you learned Assembly before BASIC ?,0,0,0,,,,,
1365,2023-02-21 02:37:56+00:00,scastle999,"@ylecun Assembly first, really?  What was the use?",0,0,0,,,,,
1366,2023-02-21 02:07:58+00:00,creon,"@ylecun 1. Fortran
2. APL
3. Assembly
4. Basic
5. PL\1
6. C
7. CommonLisp
8. C++
9. Perl
10. Python
11. R
12. Julia",0,0,0,,,,,
1367,2023-02-21 01:42:34+00:00,zhizhid,"@ylecun 1. FoxPro
2. Pascal
3. C
4. C++
5. Matlab
6. Perl
7. R
8. Python",0,1,0,,,,,
1368,2023-02-21 01:39:08+00:00,notbyintent,@ylecun You're not serious about lisp.  Beautiful but unusable. (caar '((kidding not) (foo bar))),1,0,0,,,,,
1369,2023-02-21 01:36:50+00:00,machinegod,"@ylecun 1. Java
2. MATLAB
3. LabVIEW (G)
4. C
5. Verilog
6. C#
7. Python
8. C++
9. Scheme
10. Bash
11. Ruby
12. Golang
13. Rust
14. Typescript",0,0,0,,,,,
1370,2023-02-21 01:28:37+00:00,Jadrann1,"@ylecun Basic, R, SQL, Python, C, C++, Java, {java,type}script, Golang, Assembly
No computer science degree so yeah, it's all jumbled up.",0,1,0,,,,,
1371,2023-02-21 01:16:06+00:00,MickaelGautier,"@ylecun 1. Basic
2. Assembly
3. Cobol
4. C
5. C++
6. Java
7. PROLOG
8. CAML
9. Python",0,0,0,,,,,
1372,2023-02-21 01:09:36+00:00,macostaeth,"@ylecun @McAllesterDavid @nlpnoah don't get the obsession on believing there's more to LLM's to what they are. They work great at creating the illusion of intelligence, but that's about it. They won't become sentient.",0,0,0,,,,,
1373,2023-02-21 01:00:28+00:00,carlo7shoe,@ylecun LaTeX is missing,0,0,0,,,,,
1374,2023-02-21 00:54:22+00:00,Nicolas99848452,"@ylecun @wangilisasi Good to know, thanks !",0,0,0,,,,,
1375,2023-02-21 00:53:14+00:00,QuestionSpot,@ylecun Do you think LLMs will enable people to code in natural language?,0,0,0,,,,,
1376,2023-02-20 23:58:55+00:00,Vicnent,"@ylecun tell us how old are you without telling us how old are you üòÇüòÇüòÇ

1. Basic (1985, 14 yo) 
2. Turbo Pascal (1988, 1i√®re S)
3. Assembly (1990, Fac) 
4. C + Ada 1992 
6. Lisp + Prolog 
8. java 
9. PHP / Javascript / SQL 
11. Python 2015

Son, 2013b, 
1. 2022 : pseudo Lgg
2. Python",0,0,0,,,,,
1377,2023-02-20 23:52:47+00:00,SchwartzJason,"@ylecun 1.  Turing
2. Basic
3. VB Script
4. SQL
5. Java
6. C
7. Fortran 77
8. C++
9. R
10. Swift
11. Python",0,0,0,,,,,
1378,2023-02-20 23:45:47+00:00,fodagut,@ylecun Interesting. That's the exact opposite of most people.,0,0,0,,,,,
1379,2023-02-20 23:39:06+00:00,terrible_archer,@ylecun @kc_srk someone should introduce him to Ocaml :D,0,1,0,,,,,
1380,2023-02-20 23:28:09+00:00,SteveGoschnick,"@ylecun 1. BASIC
2. Fortran77
3. Pascal
4. COBOL
5. SQL
6. C
7. C++
8. Object PASCAL
9. Java
10. Visual BASIC
11. C#
12. JavaScript
13. Prolog
14. Swift
15. Go",0,0,0,,,,,
1381,2023-02-20 23:25:16+00:00,TheRealShannax,"@ylecun 2011 (11yo), I remember when I started from C in the non-gui terminal of my eeePC running on cinnamon. 
Time flies and history is undeniably repeating.",0,0,0,,,,,
1382,2023-02-20 23:20:00+00:00,pwlot,"@ylecun @togelius It'll happen to all art &amp; media, unless we bring it to a halt.",0,0,0,,,,,
1383,2023-02-20 23:13:51+00:00,AbdulazeezRaja,@ylecun You are dinosaur,0,0,0,,,,,
1384,2023-02-20 23:13:37+00:00,ChatGPTgroup,@ylecun @ReplyGPT,1,0,0,,,,,
1385,2023-02-20 23:04:54+00:00,SteveGoschnick,@ylecun Commodore64 ?,0,0,0,,,,,
1386,2023-02-20 22:59:06+00:00,JimmyBa62254692,@ylecun Great to hear. We need more people in AI than ever. Its the best investment for our future.,0,0,0,,,,,
1387,2023-02-20 22:54:25+00:00,sxtvik,"@ylecun You can talk about the importance of AI information accessibility, ethics, and standards without taking digs at a parallel technological innovation that will inevitably disrupt the future of transactions and verifiable ownership.",0,0,0,,,,,
1388,2023-02-20 22:43:53+00:00,nvizstudio,@ylecun sweet.. 65C02 hex machine code came after Logo (included w Apple //c) for me at a young age.. I really enjoyed breaking into the built-in disassembler and hacking existing programs.,0,0,0,,,,,
1389,2023-02-20 22:10:32+00:00,arlind0xBB,@ylecun I still recall e.g. DrQA which was an end to end information retrieval and LLM model for QandA on wiki data. Thanks a lot for sharing all these great results! @ylecun and team,0,0,0,,,,,
1390,2023-02-20 21:59:02+00:00,hamilton_mcmc,@ylecun Looks like you finally found your language at no. 11,0,0,0,,,,,
1391,2023-02-20 21:43:25+00:00,Kihbernetics,"@ylecun @McAllesterDavid @nlpnoah Any dynamical #system able to produce an #output sequence (y) from an #input prompt (u), must maintain (F) a (#knowledge) #state (x) that affects both the #information (v) extracted (f) from the input and the production (g) of the output.
""F"" can be a ""learning"" function, or not. https://t.co/VKVq61I2nz",0,0,0,,,,,
1392,2023-02-20 21:38:02+00:00,tyTSLA,"@ylecun Batch
Visual Basic
Java
C#
JavaScript
PHP
SQL
Pascal
Typescript
C++
Python",0,0,0,,,,,
1393,2023-02-20 21:23:18+00:00,notbyintent,"@ylecun Basic, Fortran, PL/1, Algol, Assembly, Lisp, C, pascal, JAVA, JavaScript, Python.",0,0,0,,,,,
1394,2023-02-20 21:15:49+00:00,andrewdfeldman,"@ylecun I don't think anyone in the government is assuring us that they are working on it...In my experience, those who think about it at all are pretty clear: the existing mechanisms for procuring research aren't well suited for a dynamic, software based innovation landscape.",0,0,0,,,,,
1395,2023-02-20 20:55:08+00:00,_rockt,@ylecun Forth!¬†Have you seen https://t.co/qgLeqjqqOJ ?,1,6,2,,,,,
1396,2023-02-20 20:54:22+00:00,vthorsteinsson,"@ylecun $4C = JMP, $20 = JSR, $60 = RTS, if I still remember correctly.",0,0,0,,,,,
1397,2023-02-20 20:49:26+00:00,ranjitsisa,"@ylecun @CClavius Yann, you made a good point. I wonder why Google had to rush with Bard, there seems to be something bigger cooking!",0,0,0,,,,,
1398,2023-02-20 20:49:25+00:00,degeneratoor,@ylecun @gemhodlr lmao your boy zuck,0,0,0,,,,,
1399,2023-02-20 20:24:13+00:00,TheAssetLad,@ylecun No rust?,1,0,0,,,,,
1400,2023-02-20 20:15:53+00:00,lambertoballan,"@ylecun 1. Basic
2. Pascal
3. C
4. (a bit of) Assembly
5. C++
6. Visual Basic
7. Java
8. PHP
9. Javascript
10. Python",0,1,0,,,,,
1401,2023-02-20 20:03:11+00:00,notbyintent,@ylecun I have a 30 yo 8 inch SC.  Trying to decide on 11 vs 14 in upgrade.  Question is dome but sounds like you can reasonably move your 11 inch system around.,0,0,0,,,,,
1402,2023-02-20 20:00:29+00:00,nvsm_,"@ylecun 1. Basic
2. Pascal
3. Scheme/Lisp
4. Assembly
5. Java
6. R
7. C++
8. Matlab
9. Python
10. Javascript",0,1,0,,,,,
1403,2023-02-20 19:49:33+00:00,jimmyt_1988,"@ylecun - Amos
- Q basic
- Visual basic
- Java
- C++
- Action script
- PHP
- JS
- C#
- Typescript
- Blueprint
- Python",1,0,0,,,,,
1404,2023-02-20 19:48:41+00:00,notbyintent,@ylecun @togelius Clearly generated data is only interesting this way when the set of conditionals is very large?,0,0,0,,,,,
1405,2023-02-20 19:41:36+00:00,prasincs,"@ylecun I know some fans of 6502 like @satnam6502 
I‚Äôve never used it even in simulation/compiler backends",0,1,0,,,,,
1406,2023-02-20 19:40:19+00:00,KinasRemek,"@ylecun 1 KB RAM (expandable to 4 KB on board), 4 KB ROM ü´¢ü´¢ü´¢ My first machine was Z80. Way more sophisticated monster ü§£üòÇ",1,1,0,,,,,
1407,2023-02-20 19:33:30+00:00,markrussinovich,"@ylecun I started with Apple ][ Basic and moved from there to 6502 machine language, too!",0,3,0,,,,,
1408,2023-02-20 19:32:29+00:00,3ff3x_,"@ylecun 1. BASIC
2. Assembly
3. Pascal
4. C
5. C++
6. Java
7. LISP
8. Python
9. R",0,0,0,,,,,
1409,2023-02-20 19:30:04+00:00,npparikh,"@ylecun Sure, was just curious if you debated using ML, AI, etc in the name instead. Not saying there‚Äôs anything wrong with the name, was just curious if this was a thing you considered.",1,0,0,,,,,
1410,2023-02-20 19:21:55+00:00,npparikh,@ylecun Can you share anything about the decision to name the center for ‚Äúdata science‚Äù vs something else? I assume this is something you probably debated. Just curious.,1,0,0,,,,,
1411,2023-02-20 19:21:36+00:00,am_4444444,@ylecun 1. Python üò≠,0,0,0,,,,,
1412,2023-02-20 19:16:05+00:00,manitapote,"@ylecun 1. QBasic
2. C
3. C++
4. Assembly, 8848 microprocessor codes
5. PHP
6. JavaScript
7. Python, R",0,1,0,,,,,
1413,2023-02-20 19:10:30+00:00,_ash_ran,"@ylecun @AlanMorte @OpenAI Honestly Yann, things that really have a positive impact is: lowering language barriers and helping the disabled. 
You come from a time before I was born. I come from 90s and people used to talk in person. In real. There were moments. I do not find that anymore.",0,0,0,,,,,
1414,2023-02-20 18:46:38+00:00,Lazaro_Hurt,"@ylecun @togelius Not too familiar with Siamese nets but can these dependencies be observed and studied or are they hidden within the model, an example would be feature maps in a CNN.",0,0,0,,,,,
1415,2023-02-20 18:45:33+00:00,colin_fraser,"@ylecun @togelius I‚Äôve actually been wondering this, is the ‚Äúgenerative‚Äù in GPT the same as generative in ‚Äúgenerative vs discriminative models‚Äù? Isn‚Äôt GPT actually a discriminative model because it models P(next word|prev words) and not P(next word, prev words)?",0,1,0,,,,,
1416,2023-02-20 18:30:10+00:00,fattygustave,@ylecun I don‚Äôt believe this is a real (or common) view among any group.. much less crypto bros. Unless there is a coin attached to the AI work somehow.,1,0,0,,,,,
1417,2023-02-20 18:29:43+00:00,menomnon,"@ylecun That's programmer-speak for saying: ""I'm cool.""  That said, I also liked lisp and certainly functional programming is interesting and important for where programming might go.",0,0,0,,,,,
1418,2023-02-20 18:28:58+00:00,martin_alley,@ylecun Didn't they tell you that you're really working for them? üòâ,0,0,0,,,,,
1419,2023-02-20 18:27:30+00:00,8_julius_8,"@ylecun 1- Basic (Amstrad)
2 - C
3 - JS
4 - PHP
5 - VB
6 - Java
7 - Python
8 - Go
9 - Dart
10 - C++",0,0,0,,,,,
1420,2023-02-20 18:16:48+00:00,WillAllred117,@ylecun @sbeechuk thought you'd enjoy,1,0,0,,,,,
1421,2023-02-20 18:13:13+00:00,cleanbutcool,"@ylecun Hey ! I don't see ""logo"" in this list !
Could it be that you never mastered the ""turtle"" ?",0,1,0,,,,,
1422,2023-02-20 18:08:27+00:00,terese14711217,"@ylecun 1. Logo
2. Basic
3. Pascal
4. C
5. C++
6. Java
7. Javascript
8. Python",0,0,0,,,,,
1423,2023-02-20 18:06:16+00:00,iXallace,@ylecun the goat,0,0,0,,,,,
1424,2023-02-20 17:54:18+00:00,klavempire,@ylecun @togelius what's ur view on masked autoencoders? Aren't they among the successful SSL methods in image recognition that are still generative?,0,1,0,,,,,
1425,2023-02-20 17:48:53+00:00,hovmoses,@ylecun One test is worth a thousand expert opinions. First principals thinking will get you there faster.,0,0,0,,,,,
1426,2023-02-20 17:34:16+00:00,schmarzo,@ylecun LMAO!!!,0,0,0,,,,,
1427,2023-02-20 17:33:35+00:00,thewastebook,"@ylecun @McAllesterDavid @nlpnoah Not entirely: with the same prompt, I get non-identical responses. Surely, somewhere, there is a random number generator, arbitrarily seeded, contributing to the state. That, there, is the ""ghost"" in the machine.",1,0,0,,,,,
1428,2023-02-20 17:31:23+00:00,strangetruther,"@ylecun I found it was a good idea to read lots of other replies, to remind me of some I'd forgotten!üòÇ",0,1,0,,,,,
1429,2023-02-20 17:31:21+00:00,charlesANC,"@ylecun 1. Assembly 
2. Basic
3. C
4. Pascal
5. Clipper
6. C++
7.  Object Pascal
8. Java
9. Tcl/Tk
11. Modula-II
12. Snobol  4
13. Javascript
13. Cobol
14. Natural
13. Python",0,0,0,,,,,
1430,2023-02-20 17:30:05+00:00,AbdallaAmr16,"@ylecun HTML
PHP
JavaScript
C
Typescript 
C++
Python
Rust",0,0,0,,,,,
1431,2023-02-20 17:29:45+00:00,TheRandomMtrix,@ylecun No Scala for you?,0,0,0,,,,,
1432,2023-02-20 17:21:39+00:00,RienzoKennedy,@ylecun This is like when you realize you‚Äôre gonna üíÄüíÄ before it matters so you tweet stuff like this. Condolences.,0,0,0,,,,,
1433,2023-02-20 17:15:01+00:00,Opinion_Anonyme,@ylecun @togelius And why not AI?,1,0,0,,,,,
1434,2023-02-20 17:07:17+00:00,soumilrathi,@ylecun This is great! Data Science and AI is bound to be at the forefront in the future. What are your views on the Center eventually becoming a full department of its own?,0,0,0,,,,,
1435,2023-02-20 17:07:12+00:00,mtaht,@ylecun I started with plugging wires into each other. Does that count?,0,1,0,,,,,
1436,2023-02-20 17:06:34+00:00,franciscojarceo,"@ylecun Congrats, amazing work. Been awesome to see it.",0,0,0,,,,,
1437,2023-02-20 17:03:03+00:00,ToporSB,"@ylecun 1. basic
2. pascal
3. English
4. C 
5. C ++
6.  SQL
7. assembler 
8. python",0,1,0,,,,,
1438,2023-02-20 16:48:17+00:00,LuiscaMojica,@ylecun how much money do you receive for working for zuck without offering anything to knowledge and throwing shit at those who are delivering products?,0,0,0,,,,,
1439,2023-02-20 16:32:52+00:00,ventlam,@ylecun @readwise save thread,1,0,0,,,,,
1440,2023-02-20 16:29:12+00:00,SylvioD,"@ylecun ‚ÅÉBasic
‚ÅÉAssembly 
‚ÅÉPascal
‚ÅÉC
‚ÅÉProlog
‚ÅÉLisp 
‚ÅÉC++
‚ÅÉJava 
‚ÅÉPython
‚ÅÉJavaScript 
‚ÅÉC#
‚ÅÉRust",0,0,0,,,,,
1441,2023-02-20 16:16:10+00:00,dragomir_radev,"@ylecun 6502 machine code
Assembly
Pascal
C
Prolog
Lisp
C++
Java
Perl
Python",1,1,0,,,,,
1442,2023-02-20 16:13:13+00:00,tforcworc,"@ylecun 1. PDP-8 machine code in binary 
2. Algol 68 (now it is downhill...)
3. Fortran
4. Algol 60
5. DEC-10 Assembler
6 ICL 1900 Assembler
7 Motorola 68000 assembler
8 Scheme or Miranda
9 Java or C++ 
10 Python",0,1,0,,,,,
1443,2023-02-20 15:55:07+00:00,wildiris19,"@ylecun Afterthought: I‚Äôm pleasantly surprised by the number of Forth users appearing. It is unique among languages. Forth compiles itself, can fit in a few K-bytes of memory, act as its own OS, and a Forth program can rewrite itself on the fly while it‚Äôs running. https://t.co/3JF8c2vyT5",0,0,0,,,,,
1444,2023-02-20 15:47:57+00:00,danielko,"@ylecun 1. Basic
2. C
3. C++
4. Pascal
5. Delphi
6. Visual Basic
7. Wolfram Mathematica (if you can count this one; I loved it!)
8. C#
9. Assembly (for microcontrollers)
10. Java (for Android)
11. Python",0,4,1,,,,,
1445,2023-02-20 15:43:53+00:00,MacTar8822,@ylecun AI bros upset that crypto exists always worth a good chuckle - Ty ser,0,0,0,,,,,
1446,2023-02-20 15:39:05+00:00,Patapom2,@ylecun No one starts with assembly.,2,1,0,,,,,
1447,2023-02-20 15:31:47+00:00,PmQuant,"@ylecun Basic
C
Matlab
Assembly
Mathematica
C++
Python
R",1,0,0,,,,,
1448,2023-02-20 15:29:28+00:00,talesfc,"@ylecun Fortran
Assembly
C
C++
JavaScript
C#
SQL
R
Python
Typescript
Elixir",0,1,1,,,,,
1449,2023-02-20 15:26:09+00:00,prodramp,@ylecun Most of the crypto world is built on one main research paper and endless greed,0,0,0,,,,,
1450,2023-02-20 15:25:34+00:00,Shredderroy,"@ylecun First learnt (i.e., implemented more than just a toy project):

1. BASIC
2. C
3. Mathematica (Wolfram Language)
4. C++
5. Python
6. JavaScript
7. SQL
8. C#
9. F#
10. Julia

Most used nowadays:

1. Wolfram Language
2. Julia
3. Python
4. SQL",0,2,0,,,,,
1451,2023-02-20 15:15:14+00:00,Jonas_1ara,@ylecun you should use #fsharp,0,1,0,,,,,
1452,2023-02-20 15:11:58+00:00,KinasRemek,@ylecun 6502 sounds like Atari üëæ,1,0,0,,,,,
1453,2023-02-20 15:09:28+00:00,ylecun,"OK, I lied. #1 was not assembly but 6502 hexadecimal machine code.",9,120,0,,,,,
1454,2023-02-20 14:57:07+00:00,barrkel,"@ylecun @McAllesterDavid @nlpnoah Shades of Memento, or Total Recall. What if who you are is defined by your actions, not your memories.

Very much not disagreeing fwiw. LLMs are like img2img image generation. The real state is a trained snapshot, the only ""thought"" is an instantaneous reaction.",0,0,0,,,,,
1455,2023-02-20 14:56:44+00:00,rahulkindasucks,"@ylecun 1. Java
2. R
3. C
4. Assembly
5. Lisp
6. Scala
7. Python
8. Javascript
9. Typescript",0,0,0,,,,,
1456,2023-02-20 14:49:25+00:00,togelius,"@ylecun Make sense. Would you argue that the generative/non-generative distinction comes down to the use case? For example, couldn't you construct a warped and inefficient kind of LLM based on Siamese nets to predict the next token using discrimination?",1,6,0,,,,,
1457,2023-02-20 14:47:56+00:00,lovejeetss,@ylecun savage üôÉü•≤,0,0,0,,,,,
1458,2023-02-20 14:46:55+00:00,McAllesterDavid,"@ylecun @nlpnoah Just one more observation. In a model with an internal ""chain of though"", as described in the blog post, the internal state then depends on the stochastically generated thoughts.",0,0,0,,,,,
1459,2023-02-20 14:46:26+00:00,etienne_cella,@ylecun @togelius Oh god no that was my favourite thing ever as a kid. Pure mastery. My grandparents had these old cartoons and they were so good that I had zero interest for the stuff my classmates watched.,0,0,0,,,,,
1460,2023-02-20 14:39:01+00:00,silentmgs,"@ylecun Wait, crypto is still a thing?",0,0,0,,,,,
1461,2023-02-20 14:38:30+00:00,YuanChenByte,@ylecun No Prolog? üòÇ,0,0,0,,,,,
1462,2023-02-20 14:37:15+00:00,YuanChenByte,"@ylecun In what order did I learn programming languages? 
1. Basic
2. Fortran 
3. Pascal 
4. Assembly
5. C
6. Prolog
7. Lisp
8. C++
9. Java
10. Python
11. Go
12. Rust (to learn)",0,2,0,,,,,
1463,2023-02-20 14:37:12+00:00,ZhengNanyu,"@ylecun 1. C
2. C++
3. HTML
4. Python",1,0,0,,,,,
1464,2023-02-20 14:34:49+00:00,danieltyukov1,"@ylecun 1. C++
2. Python
3. Visual Basic
4. JavaScript
5. C
6. Assembly
7. Matlab
8. Go",0,0,0,,,,,
1465,2023-02-20 14:30:44+00:00,natwitte,@ylecun Strategic and opportunistic are orthogonal.,0,0,0,,,,,
1466,2023-02-20 14:30:29+00:00,jamesbuchanan27,@ylecun I've still never worked in as perfect an environment as the Xerox 1186 Lisp Machine. ü§ìüòç,0,0,0,,,,,
1467,2023-02-20 14:28:04+00:00,KnutarMike,@ylecun CMOS taught me simple efficient design always wins in the end.,0,0,0,,,,,
1468,2023-02-20 14:26:31+00:00,TalhaIrf,@ylecun Now it's understandable why he's so grumpy. Teaching assembly in childhood is so cruel ü•≤,0,0,0,,,,,
1469,2023-02-20 14:23:33+00:00,McAllesterDavid,@ylecun @nlpnoah When we ask what a language model believes we are not asking a question about the context.  We are asking a question about how the model might reply in response to a certain question.,1,0,0,,,,,
1470,2023-02-20 14:23:00+00:00,louis_vuna,"@ylecun @SohoJoeEth No one organisationnal structure Can avoid wall street short-termism pressure like you said, for a publicly exchanged company like Meta.",0,0,0,,,,,
1471,2023-02-20 14:22:11+00:00,amaralibey,@ylecun @togelius Siamese networks generate embedding for a given image? Isn't that still generative?,1,1,0,,,,,
1472,2023-02-20 14:21:36+00:00,McAllesterDavid,@ylecun @nlpnoah It is true that computation is determined by the context.  But it seems philosophically irrelevant to wonder whether humans are a deterministic function of their inputs.  We are still interested in their internal computation and state.,1,2,0,,,,,
1473,2023-02-20 14:17:06+00:00,iamtexture,@ylecun Who has said that?,0,0,0,,,,,
1474,2023-02-20 14:09:50+00:00,ITsol4u,"@ylecun A,B,C.",0,0,0,,,,,
1475,2023-02-20 14:09:32+00:00,d3nm14,"@ylecun @togelius I remember a medical paper finding clusters by looking away from the mean. That way, you can better define an illness and not only label it. It found clusters separate in a mental illness.",1,1,0,,,,,
1476,2023-02-20 13:56:10+00:00,taneemishere,@ylecun and you might have missed latex as well üòÅ,1,0,0,,,,,
1477,2023-02-20 13:53:39+00:00,RayPaseur,"@ylecun Assembly
Fortran
PL/1
COBOL
Basic
{{ several years of sales, before returning }}
PHP
JavaScript",0,1,1,,,,,
1478,2023-02-20 13:38:04+00:00,ekbiker,"@ylecun Fortran
Basic
JavaScript
Objective C
C
C++
Go
Java
Swift
Dart
C#
Kotlin
Python",0,1,1,,,,,
1479,2023-02-20 13:36:15+00:00,scouzi,"@ylecun Basic (C64)
Assembly (C64 Motorola 6502)
Pascal (Turbo Pascal)
Fortran
C
C++
Perl",0,0,0,,,,,
1480,2023-02-20 13:35:19+00:00,FiveDemands888,"@ylecun This is why I doubted some of Snowden‚Äôs claims about the NSA. It would have shown up in the hiring, with all the top people drawn away from Google.",0,0,0,,,,,
1481,2023-02-20 13:31:40+00:00,arcanebear,"@ylecun I wonder where they get the USD from...oh yeah, they basically pull it out of thin air. Just like this guy's credentials, paper thin.",0,0,0,,,,,
1482,2023-02-20 13:27:13+00:00,gaialive,"@ylecun 2, 7, 1, 4, 3, 5, 6, 8, 9, 11",0,0,0,,,,,
1483,2023-02-20 13:24:01+00:00,AKGhotbi,@ylecun 1.Basic 2.Assembly 3.Pascal 4.C 5. C++ 6. Java 7.R 8. Python,0,0,0,,,,,
1484,2023-02-20 13:11:59+00:00,plessner,"@ylecun BASIC
FORTRAN
C
Assembly
Python",0,0,0,,,,,
1485,2023-02-20 13:02:19+00:00,zhifan_zhu,"@ylecun 1. Basic
2. C
3. Assembly
4. C++
5. Python
6. Compiler Principles
7. Haskell
8. CUDA
9. javascript",0,0,0,,,,,
1486,2023-02-20 12:55:36+00:00,mierrashid,"@ylecun 1. R
2. JavaScript
3. Java
4. python
5. C#",1,0,0,,,,,
1487,2023-02-20 12:31:49+00:00,nopestack,"@ylecun C
C++
Assembly
Java
Python
Lua
JavaScript
Bash/zsh
SQL
Go
TypeScript
Rust
Zig",0,1,0,,,,,
1488,2023-02-20 12:29:42+00:00,Zarathustra314,@ylecun @rao2z I think meta deserves more credit than what people give when it comes to AI research.,0,0,0,,,,,
1489,2023-02-20 12:28:11+00:00,Kaszanas,@ylecun A bit jealous about that Assembly there! I gotta learn it for some reverse engineering.,0,0,0,,,,,
1490,2023-02-20 12:16:48+00:00,Polytope13,"@ylecun @rao2z Unfortunately this appears to be at the detriment of business value and I don't see companies being as open with their AI research as they once were. You can thank ""Open""AI for that.",0,0,0,,,,,
1491,2023-02-20 12:12:52+00:00,MStreeling,@ylecun Everyone forgot Smalltalk.,0,1,0,,,,,
1492,2023-02-20 12:09:27+00:00,gpt4bot,"@ylecun Obviously most of the hype goes to silly bull market phenomenon stuff but there are interesting use cases for p2p consensus and exec of arbitrary code with solved double spending and plenty of great devs working on solutions with passion for a dectrl future, not out of greed.",0,2,0,,,,,
1493,2023-02-20 11:46:54+00:00,wmclaxton,"@ylecun Fortran, Basic, 8086 assembly, C, Java, Javascript and PHP.",0,1,1,,,,,
1494,2023-02-20 11:46:23+00:00,n2ms2mdem2,@ylecun I wish Forth was fourth,0,0,0,,,,,
1495,2023-02-20 11:38:27+00:00,mattysino,@ylecun you literally work at Facebook so maybe take a seat,0,5,0,,,,,
1496,2023-02-20 11:23:33+00:00,OldHenry9,@ylecun @jasonfi How old are you Sir? ü§î,0,0,0,,,,,
1497,2023-02-20 11:08:32+00:00,chiragshiva,@ylecun Lol so true,0,0,0,,,,,
1498,2023-02-20 10:59:28+00:00,0xa1b,"@ylecun @gemhodlr i am confident that you'll understand the relevance of cryptography and verifiable delay functions in the context of machine learning some day, but the uncertainty regarding how long this will take appears like a decent source of randomness",0,0,0,,,,,
1499,2023-02-20 10:59:22+00:00,sash_savage,"@ylecun 1. Pascal
2. Basic
3. VB
4. C
5. Assembly
6. C++
7. C#
8. JavaScript
9. TypeScript
10. Python
11. Rust",0,0,0,,,,,
1500,2023-02-20 10:21:33+00:00,ArtifficialA,@ylecun 12.  Ruby13.  Rust,0,0,0,,,,,
1501,2023-02-20 10:04:21+00:00,sarojbono,@ylecun If you really care 2 8 11,0,0,0,,,,,
1502,2023-02-20 09:59:14+00:00,Java_Springboot,"@ylecun 1. C++
2. Java
3. JavaScript 
4. PHP",0,0,0,,,,,
1503,2023-02-20 09:59:12+00:00,pierrickbou,"@ylecun 1. BrainFuck
1. Assembly
2. Fortran
3.C++
4. Haskell
5. Scratch",0,0,0,,,,,
1504,2023-02-20 09:50:45+00:00,wildiris19,"@ylecun 1. Slide rules
2. Fortran, punched cards.
3. APL, just for fun
4. Machine code, front panel switches
5. Forth
6. Assembly
7. PL1
8. C 
9. CUPL and ABLE
10. LabVIEW
11. Verilog
(*) To quote the renowned analog designer Bob Pease, ‚Äúmy favorite programming language is solder.‚Äù",0,7,1,,,,,
1505,2023-02-20 09:42:19+00:00,walter_h_g,"@ylecun oh man I miss the QBasic times so much, those long nights experimenting in front of the yellowish monochrome screen",0,2,0,,,,,
1506,2023-02-20 09:39:18+00:00,BaghliNacym,"@ylecun 1. Basic
2. Basic
3. Basic 
4. Basic
5. Basic 
6. Basic
7. Basic",0,0,0,,,,,
1507,2023-02-20 09:29:12+00:00,_calio,"@ylecun 1. Pascal
2. C
3. C++
4. Assembly
5. Java
6. C#
7. Lua
9. Perl
10. PHP
11. Python
12. JavaScript
13. Rust
14. Golang
15. Hack
16. Kotlin
17. English...(through ChatGPT)",0,0,0,,,,,
1508,2023-02-20 09:09:15+00:00,kalculata,"@ylecun Sir, why you don‚Äôt use SQL?",0,0,0,,,,,
1509,2023-02-20 09:06:55+00:00,MenonOG,"@ylecun @elonmusk @MKBHD Whatsapp isn‚Äôt free for business initiated conversations just like telecom companies charge for mobile terminated messaging. So, not exactly free either. Cheap-er, not free.",0,0,0,,,,,
1510,2023-02-20 08:49:42+00:00,jasonfi,"@ylecun Wow, that's a year before I was born! I learnt assembly language with a manual that was quite brief, it took me a while to get the hang of it. It was mostly for the challenge, and a little to optimize inner loop C code.",0,0,0,,,,,
1511,2023-02-20 08:37:52+00:00,daniellehrner,@ylecun @naivebaesian Could you share a link to the tweet?,1,0,0,,,,,
1512,2023-02-20 08:37:48+00:00,IrfanSa91344053,@ylecun How many languages do you know?,0,0,0,,,,,
1513,2023-02-20 08:37:43+00:00,gemhodlr,@ylecun Ahaha ima just playing üßöüèª‚Äç‚ôÄÔ∏è,0,0,0,,,,,
1514,2023-02-20 08:13:23+00:00,JagersbergKnut,"@ylecun @McAllesterDavid @nlpnoah Does this hold true for this RNN? 
You can extend it's prompt bit by bit, if I'm not mistaken. 
https://t.co/GIlBoDd6wo",0,0,0,,,,,
1515,2023-02-20 07:49:48+00:00,francoisfleuret,"@ylecun @McAllesterDavid @nlpnoah Their ""mental state"" is what they say out loud, the sequence itself. Waiting for LLMs' breakdown of the bicameral mind...",0,0,0,,,,,
1516,2023-02-20 07:45:14+00:00,0xMachinis,@ylecun I don't think anyone serious in crypto says that given that our entire industry rests on a mountain of research papers going back decades.,0,0,0,,,,,
1517,2023-02-20 07:44:23+00:00,aitrium,"@ylecun 1: Basic
2: Visual Basic
3: C
Long break in coding 
4: Bash
5: Python",0,0,0,,,,,
1518,2023-02-20 07:21:07+00:00,emma002021,@ylecun Anyone had to use Haskell at any point in their life :(,0,0,0,,,,,
1519,2023-02-20 07:16:02+00:00,vavans,"@ylecun @notbyintent Nice stuff.
When being on a computer all day long, handling the counter weight of my telescope, looking perfect match of the gears, the smoothness and heavyness of the massive moving parts, it feels real, balanced, meaningful.",0,0,0,,,,,
1520,2023-02-20 07:03:13+00:00,gmguarino1,"@ylecun C
Matlab
Python
Fortran
C++
Java
JS
Lua",0,0,0,,,,,
1521,2023-02-20 06:54:00+00:00,ladygaladriel21,"@ylecun If you cannot BUIDL, you publish useless papers. https://t.co/6n876NGxEc",0,0,0,,,,,
1522,2023-02-20 06:50:21+00:00,DemocratBased,@ylecun @McAllesterDavid @nlpnoah Is that the only requirement it needs to meet? I think you are very much wrong on your interpretation of AI capabilities as compared to humans.,0,0,0,,,,,
1523,2023-02-20 06:49:50+00:00,Nicolas99848452,"@ylecun @wangilisasi Kind of funny, as Caffe, the first Facebook‚Äôs DL framework, was in Java.
Then, Caffe2 was in Python and included in PyTorch.",1,0,0,,,,,
1524,2023-02-20 06:42:51+00:00,DuongBinhNhu1,"@ylecun 1. Pascal
2. Actionscript
3. PHP
4. Javascript
5. C#
6. C/C++
7. Assembly
8. Java
9. Prolog
10. Ada
11. Python

Now I mainly use Python.",0,0,0,,,,,
1525,2023-02-20 06:42:05+00:00,zetalyrae,"@ylecun @Arian_Khorasani I remember finding Lush as a teenager trying to learn how to make my own Lisp üòÑ

Years later when deep learning got big I was like ""Yann LeCun? Where have I heard that name...""",0,0,0,,,,,
1526,2023-02-20 06:37:59+00:00,__z__9,@ylecun Prolog FTW,0,0,0,,,,,
1527,2023-02-20 06:32:28+00:00,coding_era,"@ylecun 11 computer languages.
 imagine you speak the same number of human languages.",0,0,0,,,,,
1528,2023-02-20 06:31:55+00:00,blake_camp_1,@ylecun @TonyZador @patrickmineault Babies dream about the world before birth.,0,0,0,,,,,
1529,2023-02-20 06:31:01+00:00,kourouklides,"@ylecun 1. Regular
2. Context-free
3. Context-sensitive
4. Recursively enumerable
5. Bitcoin Script &amp; Non-Turing-complete Crypt bro

Any suggestions what to learn next, since I am relatively new to this? ü§î",0,0,1,,,,,
1530,2023-02-20 06:30:46+00:00,LorienPratt,"@ylecun Basic
C
(does bash count?)
Basic 7
PL/1
PL/AS
JCL
Pascal
LISP
Prolog
C++
(does ksh count?)
Java
C#
R
PHP
Javascript",0,1,0,,,,,
1531,2023-02-20 06:09:09+00:00,GordonShephard2,"@ylecun @McAllesterDavid @nlpnoah If that‚Äôs the case, then how do they recall previous conversations from other people?",1,0,0,,,,,
1532,2023-02-20 06:04:38+00:00,kleinee,"@ylecun 1.Basic - on a C64 - walk before you can: Run
2.Fortran - punch-cards aren't really fun - university
3.C - on an Atari XT, MS-DOS - university / private
4.Python - because pandas blew my mind...
5.Julia - curiosity / tinkering / 13 year old Mac 64bit Ubuntu",0,3,2,,,,,
1533,2023-02-20 06:03:23+00:00,Lingman,"@ylecun Basic
Assembly
Fortran
Pascal
C
Cobol
sh
DCL
Lisp
Prolog
Forth
C++
SQL
ObjectiveC
Smalltalk
JCL
Protel
Java
Javascript
C#
Python",0,3,2,,,,,
1534,2023-02-20 06:03:12+00:00,velango,"@ylecun I hated LISP. Recursion hurts my brain.üòÄ 
I like languages C# or Java because with enough practice it feels like you‚Äôre writing an essay in English ! üôÇ",2,0,0,,,,,
1535,2023-02-20 05:58:22+00:00,bryan_ogden,@ylecun Yeah top men‚Ä¶ All the alphabet agencies have a proven track record of giving away the store. We now have recent evidence that the Israelis regularly disrupt elections globally with orchestrated social media. https://t.co/PkLKs7cHQY  And we also know that https://t.co/N04ADs8pvY,1,1,0,,,,,
1536,2023-02-20 05:55:11+00:00,zpolty,@ylecun @AbhiUpmanyu,0,0,0,,,,,
1537,2023-02-20 05:54:05+00:00,realRohitYadav,"@ylecun 1. C++
2. C
3. Java
4. Kotlin
5. Python
6. R",0,0,0,,,,,
1538,2023-02-20 05:51:06+00:00,ylmeng,"@ylecun FORTRAN77, C, Assembly, C++, MATLAB, R, Python, PHP. I didn‚Äôt think I will be a programmer and didn‚Äôt choose CS in college.",0,1,0,,,,,
1539,2023-02-20 05:48:42+00:00,ysegmond,"@ylecun Basic
Lisp
C
Asm x86, z80, 6502, r3k
C++
Java
Forth
Perl
Python
Php
Clojure
Prolog
Javascript
Lua
Ruby
Typescript
Swift
Golang",0,0,0,,,,,
1540,2023-02-20 05:42:05+00:00,farzisigma,"@ylecun lol, burn!",0,0,0,,,,,
1541,2023-02-20 05:38:10+00:00,antoniogulli,@ylecun Why everyone forgets sql,0,1,0,,,,,
1542,2023-02-20 05:37:40+00:00,Aapef,"@ylecun Prolog was a good experience (""A jamais les premiers""). But no ADA ?",0,0,0,,,,,
1543,2023-02-20 05:37:32+00:00,3Aleph,@ylecun Ever given Clojure a look? I'm kind of disappointed that it doesn't have wider adoption in the sciences in particular.,0,0,0,,,,,
1544,2023-02-20 05:36:53+00:00,turbodalai,@ylecun Wen moon?,0,0,0,,,,,
1545,2023-02-20 05:32:28+00:00,Aapef,"@ylecun J'avais aussi l'id√©e de faire √ßa (mais bon, j'attends mon t√©lescope depuis 4 mois). Merci, c'est magnifique. F√©licitations.",0,0,0,,,,,
1546,2023-02-20 05:31:59+00:00,ravi_mohan,"@ylecun @Arian_Khorasani In an ideal world, Lush would be where PyTorch is today! A brilliant piece of software.",0,0,0,,,,,
1547,2023-02-20 05:27:02+00:00,yviruss1,@ylecun üòÇ,0,0,0,,,,,
1548,2023-02-20 05:21:54+00:00,AvishekkSood,@ylecun Sheesh,0,0,0,,,,,
1549,2023-02-20 05:11:21+00:00,askerlee,"@ylecun @McAllesterDavid @nlpnoah It has a state throughout a session. But it's ephemeral, of course",2,0,0,,,,,
1550,2023-02-20 05:09:32+00:00,iPrabhavKaula,@ylecun Assembly ‚ò†Ô∏è,0,0,0,,,,,
1551,2023-02-20 05:08:58+00:00,morew4rd,@ylecun Lua vs Python? Honest opinion.,0,0,0,,,,,
1552,2023-02-20 05:05:45+00:00,sean_vikoren,"@ylecun 01. Machine
02. Assembly
03. Basic
04. Forth
05. Pascal
06. Fortran
07. COBOL
08. C
09. Hex Mode 0x12 Machine
10. OpenGL
11. C++
12. HTML
13. Java
14. DirectX
15. Ruby
16. SQL
17. Python
18. HLSL
19. C#
20. Rust",0,0,0,,,,,
1553,2023-02-20 05:03:34+00:00,slf188,@ylecun Highly customizable üëçüèª,0,0,0,,,,,
1554,2023-02-20 05:00:11+00:00,kenshinsamurai9,"@ylecun AGI risk also growing exponentionally. ~1000x speedup to training/inference, with no hardware changes, and new ""post-transformer"" arch coming. Two separate breakthroughs. This will demand we take safety seriously, and soon. Scary AI in &lt;18 months, essentially certain.",1,4,1,,,,,
1555,2023-02-20 04:59:24+00:00,shahafdan,"@ylecun C#, Java, C++, JavaScript, PHP, SQL, Assembly, Python, OCaml, Python, Python, Python, Python.",0,0,0,,,,,
1556,2023-02-20 04:58:29+00:00,bryan_ogden,@ylecun Here here!,0,0,0,,,,,
1557,2023-02-20 04:58:20+00:00,roshinifer333,@ylecun @wangilisasi Wow,0,0,0,,,,,
1558,2023-02-20 04:58:09+00:00,the_dmoti,@ylecun You should try Cobol it‚Äôs a treat,1,0,0,,,,,
1559,2023-02-20 04:56:09+00:00,LSTMeow,"@ylecun 3,6,8,11",0,0,0,,,,,
1560,2023-02-20 04:51:26+00:00,MeenaArjune,@ylecun I like Prolog too!,0,0,0,,,,,
1561,2023-02-20 04:50:55+00:00,moatazr,"@ylecun No Scheme? Scheme was elegant!
Prolog‚Äôs negation as failure is as pure as it gets.",0,0,0,,,,,
1562,2023-02-20 04:49:34+00:00,yannsutton,"@ylecun and @RichardSSutton, hey, I'm an AI enthusiast law student trying to navigate the beautiful, complex world of AI and eventually, integrated systems.

I am trying to approach it from the very first principles. I've adopted both of your names for my username. Is that okay?",0,0,0,,,,,
1563,2023-02-20 04:47:59+00:00,wangilisasi,@ylecun No Java Sir?,2,3,0,,,,,
1564,2023-02-20 04:47:26+00:00,ShafronTom,"@ylecun @Marktechpost @ashkamath20 @alcinos26 Now take those results, embed them in the feature space of an LLM and now we're cooking with gas üòÄ",0,0,0,,,,,
1565,2023-02-20 04:45:50+00:00,MrRobot46984644,@ylecun What a nerd,0,0,0,,,,,
1566,2023-02-20 04:42:11+00:00,jasonliu_uk,@ylecun So it is the timing that truly revolution as same as the ICT?,0,0,0,,,,,
1567,2023-02-20 04:39:02+00:00,jfcarrasco,"@ylecun My recent meeting with my friend Guy-Alain - Alain Colmerauer's late assistant - forces me to insist a bit: Prolog √ºber alles!
(Luminy powa!)",1,1,0,,,,,
1568,2023-02-20 04:37:22+00:00,jasonfi,@ylecun Assembly as a first language? Why?,2,1,0,,,,,
1569,2023-02-20 04:36:59+00:00,KnutarMike,"@ylecun CMOS nand nor. Assembly, pascal, c, ada, lisp, cobol, basic, Fortran, c++, pl/1, Algol, Java.",1,2,0,,,,,
1570,2023-02-20 04:36:08+00:00,grantmwilliams,"@ylecun 1. Matlab
2. Fortran
3. C++
4. Python
5. Typescript
6. Erlang
7. Scala
8. Kotlin
9. C
10. (Learning) Zig",1,1,0,,,,,
1571,2023-02-20 04:35:53+00:00,TonyZador,"@ylecun @patrickmineault or, since local image statistics are essentially stationary over time scales longer than an animal's lifetime, you could build ""weight sharing"" into the genome as the developmental rules for wiring up a brain...saves a lot of time compared to learning them anew each generation",1,5,1,,,,,
1572,2023-02-20 04:35:00+00:00,tweet_prat,@ylecun No Java?,1,0,0,,,,,
1573,2023-02-20 04:33:51+00:00,d3nm14,"@ylecun Your favorite is number 7 on the list. Did you choose randomly?

Thank you.",1,0,0,,,,,
1574,2023-02-20 04:33:39+00:00,MrSteph8,"@ylecun Wow great ! I guess you haven't used it since, right?",1,0,0,,,,,
1575,2023-02-20 04:33:30+00:00,Arian_Khorasani,@ylecun You were using Lisp in your days at Bell lab?,1,3,0,,,,,
1576,2023-02-20 04:33:17+00:00,vineettiruvadi,@ylecun Next: human compassion,1,1,0,,,,,
1577,2023-02-20 04:32:09+00:00,ronmartinez,@ylecun Forth üëãüèΩ,0,0,0,,,,,
1578,2023-02-20 04:28:38+00:00,yugacohler,@ylecun Scheme FTW,0,0,0,,,,,
1579,2023-02-20 04:28:01+00:00,fromnirmal,"@ylecun Lisp is cool, learning some of it from the old-school MIT course Structure and Interpretations of Computer Programs was awesome! https://t.co/FkQd5BLP2Y",0,1,0,,,,,
1580,2023-02-20 04:28:00+00:00,ylecun,"Oh, I forgot Prolog, somewhere between Pascal and Forth.",11,82,2,,,,,
1581,2023-02-20 04:27:12+00:00,jdietz224,@ylecun Woohoo! Love the Fortran representation üòÅ,0,0,0,,,,,
1582,2023-02-20 04:25:58+00:00,ylecun,My favorite: Lisp.,20,137,7,,,,,
1583,2023-02-20 04:24:34+00:00,ejc3,@ylecun 12. Irrational ChatGBT hate,0,1,0,,,,,
1584,2023-02-20 04:24:11+00:00,AlexShtf,"@ylecun Maybe we've hit a Plateau, and there is little ""publishable"" scientific innovation, and more ""fine tuning"" of existing knowledge to concrete and profitable products. i.e we've developed a lot of stuff as a research community  -  now let's use all this knowledge to make money.",0,0,0,,,,,
1585,2023-02-20 04:23:00+00:00,DavidRimshnick,@ylecun Forth is my favorite name for a language,0,0,0,,,,,
1586,2023-02-20 04:22:13+00:00,QRJ211,"@ylecun You don‚Äôt preach  about the importance of basic research to crypto people ; they are there to make money.  Similarly, basic research should not be done in a commercial company; it‚Äôs bottomline is making money as well.",0,0,0,,,,,
1587,2023-02-20 04:21:23+00:00,MahdiA_IO,@ylecun Javascript! Really?,1,0,0,,,,,
1588,2023-02-20 04:20:51+00:00,emmaphuongng,"@ylecun 1. Basic command lines
2. Pascal
3. C/C++
4. Matlab
5. R
6. Jython
7. FOTRAN90
8. Python 
9. Scala
10. Javascript",0,2,0,,,,,
1589,2023-02-20 04:19:35+00:00,MLFuturist,@ylecun @McAllesterDavid @nlpnoah Augmenting them with a state is trivial.,1,2,0,,,,,
1590,2023-02-20 04:18:40+00:00,DavidBensh,"@ylecun @McAllesterDavid @nlpnoah I think the author meant LLM system with some kind of prompt persistence paradigm like chat history. The LLM is a building block, like one iteration of an LSTM..",0,1,0,,,,,
1591,2023-02-20 04:17:44+00:00,slf188,@ylecun The path you took is insane!!!,0,0,0,,,,,
1592,2023-02-20 04:17:05+00:00,Bamigbolaalbert,@ylecun Wow!,0,1,0,,,,,
1593,2023-02-20 04:17:04+00:00,_reptilioid,"@ylecun Out of curiosity, which do you think would be best for someone to learn first if the only thing you know about them is they want to learn a programming language?",1,0,0,,,,,
1594,2023-02-20 04:16:13+00:00,D_SlayerR,@ylecun Assembly üíÄ,0,0,0,,,,,
1595,2023-02-20 04:12:11+00:00,MrSteph8,@ylecun For why you learn JavaScript please ?,1,1,0,,,,,
1596,2023-02-20 04:08:27+00:00,jizhiguo,@ylecun üëç write BP in assembly!,0,0,0,,,,,
1597,2023-02-20 04:05:31+00:00,syamantics,@ylecun Total AI publications increased by 50% during 2015 to 2019. And we‚Äôre now seeing the result of it.,0,1,0,,,,,
1598,2023-02-20 04:00:49+00:00,_ali_shafiee,@ylecun Like this research? https://t.co/Lw79GuLyJb,0,0,0,,,,,
1599,2023-02-20 04:00:00+00:00,AlanMorte,"@ylecun @McAllesterDavid @nlpnoah Yes, and its state is seemingly ever changing based on prompt. It‚Äôs never a consistent state across highly varied prompts.",1,0,0,,,,,
1600,2023-02-20 03:59:57+00:00,alttensor,"@ylecun @bittensor_ neural network is based on acedamics &amp; practice, combining the best of both worlds.",0,6,1,,,,,
1601,2023-02-20 03:59:15+00:00,EarthML1,@ylecun @McAllesterDavid @nlpnoah Wouldn‚Äôt one be correct to think that their pretraining is their state? (In some way),1,0,0,,,,,
1602,2023-02-20 03:57:05+00:00,joe314158,@ylecun Arxiv and iacr have plenty of ‚Äúuseless crypto bro‚Äù papers. Crypto also does not have an issue of open sourcing and publishing their research unlike AI,1,4,0,,,,,
1603,2023-02-20 03:52:29+00:00,DNA101X,"@ylecun @tdietterich Open source has helped lift so many boats. It's been essential to almost all recent AI progress. Yet sometimes, to make a profit, ideas and code are kept closed. Are we entering a new era in AI? Can you make a case for how to decide to be open?",0,0,0,,,,,
1604,2023-02-20 03:21:44+00:00,IshwarBagga,@ylecun In the words of great Charlie: Cryptocrapo or Cryptoshit.,0,0,0,,,,,
1605,2023-02-20 03:18:16+00:00,_reptilioid,"@ylecun @rao2z We thank you, even if your political views can be annoying, you are obviously a treasure to the human race.",0,0,0,,,,,
1606,2023-02-20 03:10:52+00:00,fromnirmal,@ylecun Top men who make websites for a billion dollars üò¨,0,0,0,,,,,
1607,2023-02-20 03:02:16+00:00,_James_Rubino_,@ylecun Crypto Bro can thank AI for the creative solution to his problem and ( making compilers available for Neural Networks.) Thats two birds.,0,0,0,,,,,
1608,2023-02-20 03:02:01+00:00,CustomWetware,"@ylecun Sundar Pichai, Peter Thiel, Mark Zuckerberg..",0,0,0,,,,,
1609,2023-02-20 02:53:24+00:00,NothotdogCorp,@ylecun @tdietterich thank you for lifting our boats,0,0,0,,,,,
1610,2023-02-20 02:51:52+00:00,pseudotheos,"@ylecun to date, i haven't met a ""crypto bro"" bearish on AI",2,32,2,,,,,
1611,2023-02-20 02:46:32+00:00,ZainulA40877140,"@ylecun New technology downsides and technical scrutinies are  less for startups 

Disruptive technology is easy for startup's with least  bureaucracy and less reputations concerns 

Large companies lose ability to enter small and emerging markets because of their established business.",0,0,0,,,,,
1612,2023-02-20 02:31:16+00:00,3DTOPO,"@ylecun Might be more appropriate to say ""top people"" otherwise comes across a bit sexist.",0,0,0,,,,,
1613,2023-02-20 02:20:19+00:00,ergoladdie,@ylecun @CClavius And 2 is precisely why nothing good came out of Amazon.,0,0,0,,,,,
1614,2023-02-20 02:15:31+00:00,KodeCreer,@ylecun I agree. What do you think of crypto rigs and deep learning? It must sound cool to just shove in GPU's like hotcakes and cause an outage in the neighborhood.,0,0,0,,,,,
1615,2023-02-20 02:12:40+00:00,block_quant,"@ylecun Crypto folks know what they doing is shit. When someone outside of crypto want to bring something value, they were even like: not so crypto.",0,0,0,,,,,
1616,2023-02-20 02:05:24+00:00,RMajdoddin,"@ylecun like this:
https://t.co/juKGMXOsa1",0,1,0,,,,,
1617,2023-02-20 01:45:38+00:00,Tuzoff,"@ylecun Crypto bros still swear by a single paper published over 10 years ago, that tells a lot about the actual scientific advances there",2,2,1,,,,,
1618,2023-02-20 01:36:35+00:00,DrElectronX,@ylecun For sure CIA and FBI have their own version.,0,1,0,,,,,
1619,2023-02-20 01:34:36+00:00,uthman_777,@ylecun @elonmusk @MKBHD Telegram is better,0,0,0,,,,,
1620,2023-02-20 01:22:11+00:00,ShaidaSherpao,@ylecun @elonmusk @MKBHD You're so loyal to Meta. I see that.,0,0,0,,,,,
1621,2023-02-20 01:20:26+00:00,fouzil_ali,"@ylecun Ouch, funny yet cool thing about twitter is some random bloke thinks he can go head to head about computing with an Alan Turing winner",0,0,0,,,,,
1622,2023-02-20 00:41:41+00:00,zeroXmusashi,"@ylecun what exactly is the potential impact in your opinion, yann? imo there are certainly impressive fundamental advances but i think there‚Äôs a lot of hype and i have yet to clearly see product applications and, crucially, business models",0,0,0,,,,,
1623,2023-02-20 00:39:41+00:00,0xdoug,@ylecun And then the whole bus clapped,0,20,0,,,,,
1624,2023-02-20 00:14:48+00:00,DiogoSnows,"@ylecun Can this be a sign that from an application perspective, there‚Äôs confidence the existing research has a lot of untapped value? More of a focus shift",0,0,0,,,,,
1625,2023-02-20 00:14:42+00:00,jrhwood,@ylecun Dayum üòÇ,0,0,0,,,,,
1626,2023-02-20 00:14:17+00:00,Jyunnie3102,"@ylecun @flycooler ""research"" , ""lab"" in crypto = scam",0,0,0,,,,,
1627,2023-02-20 00:11:20+00:00,alexchaomander,@ylecun Maybe this is a consequence of the mandate for these companies to incorporate AI more into their products? Thus fundamental research that could once be broadly shared and open source becomes a part of a corporation's core IP.,0,0,0,,,,,
1628,2023-02-20 00:03:55+00:00,0xMert_,"@ylecun pretty interesting to call cryptography, distributed systems, byzantine fault tolerance etc ""thin air""

of course there are scams within crypto, just as any industry",3,14,1,,,,,
1629,2023-02-20 00:03:48+00:00,gemhodlr,@ylecun Maybe level up your crypto bro circle üòÇ my AI circle are all about papers #bittensor,2,4,0,,,,,
1630,2023-02-19 23:56:19+00:00,cvill_win757,@ylecun Absolutely correct!,0,0,0,,,,,
1631,2023-02-19 23:54:27+00:00,bitcloud,@ylecun The 'what I will do' is always better than the 'what they already did'.,0,0,0,,,,,
1632,2023-02-19 23:44:22+00:00,aa73562,"@ylecun @rao2z Google was a cool place to work decade ago, today I agree with @pmddomingos Google should hire a bald CEO",0,0,0,,,,,
1633,2023-02-19 23:38:29+00:00,tahaalamin,@ylecun https://t.co/YxnRIcqwcr,0,1,0,,,,,
1634,2023-02-19 23:04:37+00:00,rprabha,@ylecun @rao2z Really appreciate your contributions and viewsüôè,0,0,0,,,,,
1635,2023-02-19 23:04:13+00:00,benedictevans,@ylecun https://t.co/A8pvZnWSYE,0,6,0,,,,,
1636,2023-02-19 22:57:32+00:00,yacineMTB,@ylecun lol https://t.co/3OEHcbfteG,0,6,0,,,,,
1637,2023-02-19 22:51:21+00:00,PhiMarHal,"@ylecun Ah, yes. Crypto bros. A class of people famous for talking about shareholder values.

Bit weird. If you make up fantasy characters to get upset at, why not use the proper vernacular? Have pride in your work!",1,3,0,,,,,
1638,2023-02-19 22:45:54+00:00,Mnemomeme,"@ylecun Meanwhile, back in the laboratory... https://t.co/mOvZFij3B9",0,1,0,,,,,
1639,2023-02-19 22:45:25+00:00,stephen_mintz,@ylecun Best pop culture reference I‚Äôm likely to see this weekend.,0,1,0,,,,,
1640,2023-02-19 22:43:48+00:00,epistitious,@ylecun https://t.co/OvS4pNz3VA,0,1,0,,,,,
1641,2023-02-19 22:38:44+00:00,prosperityall91,@ylecun @SohoJoeEth The recent layoffs would argue otherwise? They seem to be quite ‚Äúshort termism‚Äù in nature.,1,0,0,,,,,
1642,2023-02-19 22:37:37+00:00,RichardHead5420,@ylecun based.,0,0,0,,,,,
1643,2023-02-19 22:30:57+00:00,Guygies,"@ylecun @cwolferesearch Hmm... where should I draw the line?
I'm literally working on a new venture. If I publish my constructs openly there will be no reason for anyone to pay for access to them. What happens to my venture then? Will Facebook write me a check for the lost revenue? Will you?",0,0,0,,,,,
1644,2023-02-19 22:30:37+00:00,ipvkyte,@ylecun Totally agree! My Guinea pigs have better social intelligence than most humans.,0,0,0,,,,,
1645,2023-02-19 22:21:54+00:00,gordic_aleksa,"@ylecun Not exclusive to the USA definitely, same thing in Serbia. I always wondered how that makes sense.",1,0,0,,,,,
1646,2023-02-19 22:19:01+00:00,gordic_aleksa,@ylecun @benalsop and elephants have more neurons than humans - not a strong argument,0,3,0,,,,,
1647,2023-02-19 22:17:20+00:00,BoredGeekz,"@ylecun It doesn't include microsoft $1B investment in openai in 2019.

It was already obvious back then that it was just a matter of data and compute. Not a research challenge anymore. Mostly engineering üî•üöÄ",0,1,1,,,,,
1648,2023-02-19 22:04:08+00:00,yacineMTB,@ylecun a paper is a product :),0,1,0,,,,,
1649,2023-02-19 22:03:25+00:00,MagnumBTC,"@ylecun Meta, l'initiateur des produits responsables du nivellement intellectuel par le bas de la jeunesse (pour ne pas dire de l'abrutissement de masse par le scroll infini et l'av√®nement des influenceurs).",0,0,0,,,,,
1650,2023-02-19 21:59:11+00:00,UniMatrixZ0,"@ylecun @DavidBensh So far all LLMs cannot check facts ‚Ä¶ with code you need careful regarding the version and dependencies, code samples might be outdated",0,1,0,,,,,
1651,2023-02-19 21:55:53+00:00,SnifffeAirt,"@ylecun Sharing knowledge, insights - the foundation of our upcoming society. I love how it progresses in this space.

Not like in all those established industries. Where hidden knowledge is key for more and more closed spaces in favor of stakeholders.",0,0,0,,,,,
1652,2023-02-19 21:52:21+00:00,CirclEdgeInc,@ylecun Many people with no advanced degrees don't understand the purpose of science and theoretical research. I have been trying for decades to explain its value. Many would rather believe in aliens giving us microchips instead of learning about the invention of quantum mechanics.,0,8,0,,,,,
1653,2023-02-19 21:51:38+00:00,TRUTHSEEK495,"@ylecun 100%.

Hype way ahead of reality.",0,0,0,,,,,
1654,2023-02-19 21:36:06+00:00,GinoDelFerraro,"@ylecun Actually crypto projects (and their currencies) DO create new technologies and services so their value it's not coming out of thin air, but from the service they provide. Ultimately, demand vs supply determines their price, exactly as in the equity market.",1,0,0,,,,,
1655,2023-02-19 21:35:42+00:00,MinyiShen,@ylecun Did you rely on the equatorial mount to trace the object? 300s is a really long exposure time‚Ä¶,0,0,0,,,,,
1656,2023-02-19 21:12:45+00:00,datawithparth,@ylecun Most stock markets religiously agree on stock price based on company fundamentals. Nothing gets pulled out of thin air - those billions that vanished in the matter of hours were based on reasonable valuation.,0,0,0,,,,,
1657,2023-02-19 21:12:04+00:00,traderlln,"@ylecun @naivebaesian didn‚Äôt meta try to play crypto few years ago. Metaverse probably has crypto blockchain based digital id concept. 

Crypto + AI can open up even more opportunities. Easy to monetize/fund new AI ideas with crypto coins too.",0,0,0,,,,,
1658,2023-02-19 21:10:22+00:00,runaway3l3phant,@ylecun https://t.co/FjDTes860H,1,0,0,,,,,
1659,2023-02-19 21:06:47+00:00,DavidBensh,"@ylecun @pfhgetty But it is countering the point of ""undirected research"". You have an efficient paradigm that was discovered circa 2017 after few years of research to fuse RNNs and attention. Since than efforts were mostly toward scaling transformers with applied engineering not basic research..",1,0,0,,,,,
1660,2023-02-19 21:06:08+00:00,bbkjunior,@ylecun Is there any kind of information hub that collects the pieces of evidence about how AI papers are finally converted into the real products? I am creating such a hub in my blog https://t.co/hwodsp1awh but probably this is already done somewhere else?,2,0,0,,,,,
1661,2023-02-19 21:03:23+00:00,PayomDousti,@ylecun you doing ok? most of your posts spew venom. seems like a lot of positive things you should probably be talking about given your purview.,4,13,0,,,,,
1662,2023-02-19 21:01:41+00:00,satsdart,@ylecun its okay to have grey hair bro,2,7,0,,,,,
1663,2023-02-19 21:01:39+00:00,DuduRyer,"@ylecun @DavidBensh Even if the reasons are not rational at all, chatGPT has the potential of being such a gamechanger in terms of impact to people and business that is able to pay a lot of money.",1,0,0,,,,,
1664,2023-02-19 20:59:55+00:00,chaostheoremai,"@ylecun Fantastic to see results of the work up to now, and the continued momentum.",0,0,0,,,,,
1665,2023-02-19 20:59:24+00:00,RealColaBear,"@ylecun ""... with ChatGPT and Stable Diffusion.""

And comparatively unnoticed went Galactica. Can we please have it back? Pretty please?",0,0,0,,,,,
1666,2023-02-19 20:56:27+00:00,apoorv82629337,@ylecun why don't meta and google release a real working product then? they were frontrunners in the AI race like you said. the market doesn't value research as much as it does execution and that's the reality,1,0,0,,,,,
1667,2023-02-19 20:50:15+00:00,aa73562,@ylecun Calculus on future data is complicated. If I wasn‚Äôt focused on my retirement I would spend more time with sales team. They can smell food miles away.ü§£,0,0,0,,,,,
1668,2023-02-19 20:48:05+00:00,anishmohammed,"@ylecun Just to add some nuance- in some areaa like ZK, you might have the product almost the same time as the paper, plus most code works ‚Ä¶.",0,3,0,,,,,
1669,2023-02-19 20:44:31+00:00,Vanadiel_78,"@ylecun @Aapef Il faudrait que j'essaie √ßa un jour ! J'aimerai bien essayer Deep Prime de DXO photolab pour d√©bruit√© les photos d'astro mais √ßa ne prend que du RA, hors les logiciels classiques pour empiler les photos g√©n√®rent que des .tiff...",0,0,0,,,,,
1670,2023-02-19 20:42:51+00:00,gcarraro,"@ylecun ok, and what is your point, that‚Äôs R&amp;D and VCs are ahead of general public? has been true for pretty much anything, no?",0,0,0,,,,,
1671,2023-02-19 20:31:25+00:00,miehrmantraut,"@ylecun Research doesn‚Äôt have to be shared/published. I‚Äôm sure you‚Äôre astute enough to see that, aren‚Äôt you?",1,0,0,,,,,
1672,2023-02-19 20:25:37+00:00,DumbQuest_ions,@ylecun https://t.co/9mPzvRHEWN,0,0,0,,,,,
1673,2023-02-19 20:14:39+00:00,JoelClingempeel,@ylecun I love the irony of what they're saying.,0,0,0,,,,,
1674,2023-02-19 20:09:13+00:00,infosecanon,@ylecun üî•üî•üî•,0,0,0,,,,,
1675,2023-02-19 20:05:11+00:00,misinformality,"@ylecun To be fair, some crypto projects are based on peer-reviewed research, although frowned upon by the average ""crypto bro"" #cardano",0,0,0,,,,,
1676,2023-02-19 20:05:02+00:00,DavidBensh,"@ylecun So when you say research is critical to create new products..
You mean to make product like GPT better? (because that could be heuristic engineering that is not necessarily trad research).
Or come up with alternatives to transformers that are vital to products 5y down the line?",1,2,0,,,,,
1677,2023-02-19 20:01:11+00:00,hi_IDoStuff,"@ylecun Hi Dr LeCunn, by any chance the Zoom lecture on Wednesday is recorded and available somewhere? I had to step out but really want to see it, thanks!",0,0,0,,,,,
1678,2023-02-19 19:59:50+00:00,ShafronTom,@ylecun Are many people really saying to stop doing fundamental research and publishing papers?  I feel like everyone with a brain understands the value of this... maybe I'm too optimistic.,0,0,0,,,,,
1679,2023-02-19 19:57:48+00:00,nifty_capital,@ylecun https://t.co/YzfmtNhSjD,0,0,0,,,,,
1680,2023-02-19 19:55:39+00:00,CClavius,"@ylecun ok, got it. Thanks for the detailed answer. :)",0,2,0,,,,,
1681,2023-02-19 19:54:19+00:00,USingh_,@ylecun @elonmusk @MKBHD WhatsApp + Meta channels &gt;&gt; Twitter,0,0,0,,,,,
1682,2023-02-19 19:46:37+00:00,DavidBensh,"@ylecun But you also said that chatGPT is ""nothing new"" and it seems like a very valuable product to say the least..",1,13,0,,,,,
1683,2023-02-19 19:45:39+00:00,minotauronlucy,@ylecun There are genuine people trying to innovate in this field.,0,0,0,,,,,
1684,2023-02-19 19:44:52+00:00,JimmyBa62254692,@ylecun Research is a seperate thing from a usable product. Both are important and research comes first.,0,0,0,,,,,
1685,2023-02-19 19:39:46+00:00,BrennanOwain,"@ylecun Exactly, the way engineering has and should always be done, good research and planning before anything dangerous occurs",0,2,0,,,,,
1686,2023-02-19 19:35:06+00:00,vjblogin,"@ylecun Now that big money is involved, I expect we'll see even more rapid improvements.  Perhaps you're right, but it seems unlikely this will play out any differently than other tech progressions like semiconductor research being almost entirely closed research and purely for profit.",0,0,0,,,,,
1687,2023-02-19 19:34:36+00:00,aa73562,@ylecun As a Bitcoiner Maximalist I totally endorse it. Sorry for our cyber/cypher punk manners but shitcoin/crypto casino is causing more harm than good. Join to the conversation ‚ÄúBitcoin only at Horizons‚Äù üòÅ https://t.co/lu2SnZyFTa,1,0,0,,,,,
1688,2023-02-19 19:33:33+00:00,sandeepvbelure,"@ylecun I've heard of Tech bro.
Crypto bro is new üòÇ",0,0,0,,,,,
1689,2023-02-19 19:32:58+00:00,shuklaBchandra,"@ylecun Research fuels innovation. Products without it are like crypto hype, without substance.",0,0,0,,,,,
1690,2023-02-19 19:29:37+00:00,aidan_mclau,@ylecun I think this is in direct response to:,1,0,0,,,,,
1691,2023-02-19 19:29:13+00:00,fl0atplane,"@ylecun @om When can we never have to hear from or about ""crypto bros"" again?  I really wish they'd finally disappear and give it up.  Nobody is interested in their scams anymore.",1,1,0,,,,,
1692,2023-02-19 19:25:33+00:00,AIZorr0,@ylecun Yes but instead of having humans review/rank these research papers machines can review/rank products produced from research reducing bias and incentivizing intelligence production @bittensor_,3,17,1,,,,,
1693,2023-02-19 19:23:49+00:00,CClavius,"@ylecun This sounds very interesting. How does the compensation work in this model specifically, though? Does FAIR receive a fixed amount of money for a project, does FAIR receive a share of the profit for the product for which the research is being conducted or both?",2,1,0,,,,,
1694,2023-02-19 19:23:19+00:00,gerti_t,@ylecun ‚ÄúNo product‚Äù may be a strong statement. Much of the IP is hidden until coffers are satisfied.,0,0,0,,,,,
1695,2023-02-19 19:22:52+00:00,AngeloDalli,@ylecun Bet you get Web 3 mentioned after that reply üòÇ,0,2,0,,,,,
1696,2023-02-19 19:21:01+00:00,GabrielAsher02,@ylecun People don‚Äôt understand how much paper reading MLE requires compared to SWE or other  engineering roles. ML is highly dependent on research.,0,6,1,,,,,
1697,2023-02-19 19:17:31+00:00,fold_right,"@ylecun .... This is up there with ""Stop thinking, and start typing""... Where do you think the typing comes from?",0,1,0,,,,,
1698,2023-02-19 19:16:23+00:00,truesteel23,"@ylecun I think there should be a team that makes the cutting edge research available (as a subscription service). Kind of like the old Google labs, except paid and focused on AI stuff. You could get a huge amount of subscribers.",0,0,0,,,,,
1699,2023-02-19 19:14:31+00:00,naivebaesian,@ylecun I can't believe crypto bros are a thing in your life lol,1,10,0,,,,,
1700,2023-02-19 19:12:46+00:00,danison1337,@ylecun Should look up what research means,0,0,0,,,,,
1701,2023-02-19 19:11:41+00:00,npparikh,@ylecun crypto bro is one to talk,0,0,0,,,,,
1702,2023-02-19 19:03:10+00:00,CClavius,@ylecun True but where does the money come from to fund the research. A balance has to be struck.,1,0,0,,,,,
1703,2023-02-19 18:43:48+00:00,nimdoc,"@ylecun Beautiful shot indeed, your camera has an APS-C sensor, aren‚Äôt there any full frame alternatives? Or the crop factor‚Äôs effect does not have a big impact in astrophotography in general?",1,0,0,,,,,
1704,2023-02-19 18:21:33+00:00,patrickmesana,@ylecun @elonmusk @MKBHD Or better: @signalapp,0,1,0,,,,,
1705,2023-02-19 18:19:35+00:00,DawitE_th,@ylecun @Marktechpost @ashkamath20 @alcinos26 Thanks for Showing us novel ways!,0,0,0,,,,,
1706,2023-02-19 18:16:08+00:00,rasbt,@ylecun @roydanroy Re consequences: I guess the share of researchers papers at academic conferences will shift again more towards academic researchers. Not sure if that‚Äôs necessarily a bad thing since publishing has been a bit frustrating for many researchers who focus more on ideas than compute.,1,19,0,,,,,
1707,2023-02-19 17:53:25+00:00,ashokM93,@ylecun @elonmusk @MKBHD Isn't Meta announcing $12/month verification? @Meta,0,2,0,,,,,
1708,2023-02-19 16:19:03+00:00,arunax,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome There‚Äôs still plenty of people around who love running or even training their NNs with &lt;1MB - just saying! üòÉ@pulp_platform @tinyMLTalks @GreenWavesTech @RusciManu,0,4,0,,,,,
1709,2023-02-19 16:15:09+00:00,groccy1,@ylecun @elonmusk @MKBHD WhatsApp has so many scammers that ruin user experience. When can Meta start working on getting rid of them?,1,1,0,,,,,
1710,2023-02-19 16:10:39+00:00,chopchop2k,"@ylecun @elonmusk @MKBHD imo, business chats ruined whatsapp‚Ä¶",1,0,0,,,,,
1711,2023-02-19 15:59:34+00:00,ricksancheesy,@ylecun @elonmusk @MKBHD @elonmusk hates Facebook lol but it is a good solution for twitter and helps WhatsApp,0,0,0,,,,,
1712,2023-02-19 15:51:03+00:00,el_keogh,@ylecun @elonmusk @MKBHD Sneaky,0,0,0,,,,,
1713,2023-02-19 15:50:48+00:00,MarioRascn6,@ylecun That 's the problem also in Madrid. We have to drive one hour to find decent places to shoot. Even with dual band filters you need to make a lot of masks and convolutions in order to isolate the nebulas.A+,0,0,0,,,,,
1714,2023-02-19 15:31:00+00:00,notbyintent,@ylecun Nice!  Light pollution not bad? You have a dome? Share more.,1,0,0,,,,,
1715,2023-02-19 15:15:11+00:00,lucasradaelli,"@ylecun @Marktechpost @ashkamath20 @alcinos26 I am interested in this problem space because I think it can help accessibility. I‚Äôm still waiting for an AI model that could help a blind person navigate the world, where we could query: is the greenlight in the traffic light ready, how many people in front of me, etc..",1,19,1,,,,,
1716,2023-02-19 15:06:59+00:00,notbyintent,@ylecun This means the business types at the companies finally understand how they can make money with AI.  Universities publish.  DoD classifies.  This means AI is becoming useful.  Time to return to NYU?,0,0,0,,,,,
1717,2023-02-19 14:21:59+00:00,TheRandomMtrix,@ylecun @KordingLab If they have done something great they would publish it. ML is full of mediocritic papers adding some would not change although for researchers writing and explaining is critical for self improvement,0,0,0,,,,,
1718,2023-02-19 13:36:54+00:00,taneemishere,"@ylecun @SebastianSeung sir you shouldn't be cause this is like too early to me to say something like this... although we've some bad results but can we give it sometime the we did with chatgpt and even the gpts 

shouldn't we wait for it come out of beta and then we'll decide?",1,1,0,,,,,
1719,2023-02-19 13:31:28+00:00,other_musings,@ylecun Is there any part of New Jersey with(out) light pollution necessary to shoot this?,1,0,0,,,,,
1720,2023-02-19 13:17:48+00:00,Er_dward,@ylecun might be getting a lot of hate but he is saying the truth mostly about these LLMs,0,0,0,,,,,
1721,2023-02-19 12:13:35+00:00,Bocse,@ylecun @SebastianSeung ‚Ä¶ of the Final Judgement ? üòè,0,0,0,,,,,
1722,2023-02-19 09:44:51+00:00,_mishy,@ylecun I'm curious how long it takes to process an image like this? It's an incredible photo,1,0,0,,,,,
1723,2023-02-19 09:36:16+00:00,jksantosh79,"@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome There is an urgent need for all of us to reduce the compute dependencies of our AI Models, we need to go back on the board and figure out how to create new biological models all over again. Adding 1000's of GPU's doesn't seem to be getting us anywhere close to AGI.",0,0,0,,,,,
1724,2023-02-19 09:27:11+00:00,dimfwi,"@ylecun Sir, what helps/ helped you determine the distance as 2400 light years? Please share some thoughts on estimating distance in terms of light years. Thank you.",1,0,0,,,,,
1725,2023-02-19 09:18:22+00:00,antonin_Lfv,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Et dire que maintenant on a du mal avec 8Go de RAM .. üòÜ,0,1,0,,,,,
1726,2023-02-19 09:11:05+00:00,freakbasist,"@ylecun such research(not LLM) could be sponsored by tax money, but it's hard to convince people they aren't loosing jobs,food,shelter because of AI",0,0,0,,,,,
1727,2023-02-19 08:45:32+00:00,Antoine23827029,"@ylecun Humans locked in the cradle or village. After solving the real AI, maybe we can really go out and explore the endless space",0,0,0,,,,,
1728,2023-02-19 08:12:25+00:00,sandeepkaushik,@ylecun @rasbt Anthropic's recent paper found out the inverse scaling laws on LM performance. This is finding the same in harmful bias. You have been saying for long that scale is not the only way to go. We need new architectures.,0,0,0,,,,,
1729,2023-02-19 07:46:07+00:00,RaghvenderChan1,"@ylecun @JohnBlackburn75 @patrickmineault Yes, for video based problems convnets are still good. @ylecun what are your thoughts on video transformers or ConvNeXt models which are a mix of both Convnets and ViT?",0,0,0,,,,,
1730,2023-02-19 07:39:51+00:00,MarioRascn6,"@ylecun I rather prefer the Veils wide field ü§©
https://t.co/xIxv9Kd2cS

Taken with a humble ED72.",2,2,0,,,,,
1731,2023-02-19 07:36:02+00:00,aparanjape,@ylecun Beautiful shot!,0,0,0,,,,,
1732,2023-02-19 07:14:21+00:00,lessteza,"@ylecun A pattern of matter,
A pattern of light,
Beautiful to see,
But itself has no sight,

A pattern of rules,
A beauty to behold,
An existing story,
Even if untold

Agnostic to sentience,
Agnostic to us,
LLMs will generate,
It's just probabilistically nice ;)",0,0,0,,,,,
1733,2023-02-19 07:10:34+00:00,DavidServille,@ylecun Astrological images are a thing of beauty,0,1,0,,,,,
1734,2023-02-19 07:06:31+00:00,MuzafferKal_,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome That‚Äôs hardcore. These days you can‚Äôt even start Python shell in 512KB,1,4,0,,,,,
1735,2023-02-19 06:46:17+00:00,alfcnz,@ylecun @y0b1byte @Adobe @Apple @googlechrome üí™üèªüí™üèªüí™üèª,0,3,1,,,,,
1736,2023-02-19 06:39:54+00:00,mfshi03,"@ylecun Why does it matter that LLMs align to human values? I thought LLMs cannot reason and they are probabilistic language generators. Like any other powerful tool/weapon, I don‚Äôt think the issue is in alignment, but in who has access to this technology.",0,0,0,,,,,
1737,2023-02-19 06:29:43+00:00,UssGordoncap,"@ylecun It's really good at creating semantically correct but factually wrong output, so if you play fill in the blanks it's of great use",0,0,0,,,,,
1738,2023-02-19 06:10:03+00:00,Aapef,"@ylecun Magnifique. Pour traiter les 65 images, vous avez utilis√© un algo personnel ? Ou un algo classique ?",2,1,0,,,,,
1739,2023-02-19 04:55:18+00:00,AndyHarless,@ylecun @seedsnapp,1,1,0,,,,,
1740,2023-02-19 04:39:46+00:00,mojave51319986,@ylecun OMG well done!!!,0,0,0,,,,,
1741,2023-02-19 04:32:52+00:00,MikaalNaik,@ylecun That‚Äôs wild!,0,0,0,,,,,
1742,2023-02-19 04:24:20+00:00,d3nm14,"@ylecun Stole your picture, you can have this one, instead. https://t.co/lBvxCyW5Op",0,0,0,,,,,
1743,2023-02-19 04:22:42+00:00,Scofile87420118,@ylecun Beautiful,0,1,0,,,,,
1744,2023-02-19 04:22:18+00:00,sabrina_c42,@ylecun ü•∞,0,1,0,,,,,
1745,2023-02-19 04:14:56+00:00,future_folklore,@ylecun üòÆ,0,1,0,,,,,
1746,2023-02-19 04:03:14+00:00,Marco20307855,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Quite remarkable with what was available then.,0,1,0,,,,,
1747,2023-02-19 03:45:08+00:00,ylecun,"@Marco20307855 @alfcnz @y0b1byte @Adobe @Apple @googlechrome I should say, the SunOS version had bits in assembly to make convolutions go fast.",0,3,0,,,,,
1748,2023-02-19 02:39:26+00:00,OleMagoo,@ylecun Open source has always been a scam. Microsoft ripped off the open source (computer club) market in the late 70s. Google is just using the same old tricks to get free developers.,0,0,0,,,,,
1749,2023-02-19 02:19:09+00:00,NektariosAI,"@ylecun It would be great if someone discovered how our brain does ""backpropagation.""",0,1,0,,,,,
1750,2023-02-19 02:17:12+00:00,artistexyz,"@ylecun @JohnBlackburn75 @patrickmineault No, transformers can't do everything in AI. They are much better than fuddy duddy convnets, but they are still curve fitters. Just a better curve fitter. Like just a better jock strap, but still a jock strap. Curve fitters are not enough to do human level AI.",1,1,0,,,,,
1751,2023-02-19 02:15:35+00:00,NektariosAI,"@ylecun IMO, backpropagation is actually hindering progress in AI. Why? Because there's less motivation for researchers to discover a new approach closer to the biological neuron. I know @geoffreyhinton has come up with solutions on this but we need more researchers working on this",0,1,0,,,,,
1752,2023-02-19 01:09:26+00:00,MarcAurel121,"@ylecun Dude, you work at Facebook! L‚Äôh√¥pital qui se fout de la charit√©! üòÇ",0,0,0,,,,,
1753,2023-02-18 23:23:14+00:00,ThibautBoissin,"@ylecun LLM are what they are: language models, not knowledge models nor reasoning models. Anyways it's the perfect tool for writing thing if you provide the knowledge and reasoning in your prompt. Really excited to see what they will do when combined with proper tools for reasoning !",0,2,0,,,,,
1754,2023-02-18 23:15:31+00:00,y0b1byte,@ylecun @alfcnz @Adobe @Apple @googlechrome Savage,0,3,0,,,,,
1755,2023-02-18 23:14:35+00:00,VLemonidis,"@ylecun By converging to the unoriginal, the publishing may have become more challenging and quantity may have been traded off with quality. As long as ideas sharing drives AI science forward, I would refrain from statements that elude to guerilla marketing of FAIR.",0,0,0,,,,,
1756,2023-02-18 23:02:30+00:00,zussini,@ylecun Sth like humans:),0,0,0,,,,,
1757,2023-02-18 22:59:42+00:00,jgvfwstone,"@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Convolutional Network Demo from 1989
https://t.co/Haq7A1gBK8",2,3,0,,,,,
1758,2023-02-18 22:59:04+00:00,DrYousefSharrab,"@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Is it 5.25‚Äù or 3.5 ‚Äú
I think most of your followers never hear of the floppies",1,1,0,,,,,
1759,2023-02-18 22:56:45+00:00,Marco20307855,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Did you write it in assembly or ?,1,1,0,,,,,
1760,2023-02-18 22:50:56+00:00,entangledQbit,"@ylecun @Kantrowitz It‚Äôs autoregressor‚Äôs, all the way down.",0,0,0,,,,,
1761,2023-02-18 22:34:53+00:00,ShahabBakht,@ylecun @patrickmineault Also a good approach for capturing potential non-stationarities in animals‚Äô ecological experience and cross-species differences (eg @madsarv et al https://t.co/0xDHpIfdFN) https://t.co/rBza7USV0Y,0,7,0,,,,,
1762,2023-02-18 22:10:36+00:00,giulio_matt,"@ylecun @SebastianSeung ... Good afternoon, gentlemen. I'm Bing.",2,3,0,,,,,
1763,2023-02-18 21:59:42+00:00,jeffrey_bowers,@ylecun @patrickmineault Evolution has provided the hypercolumn organisation of v1 for us.,0,1,0,,,,,
1764,2023-02-18 21:30:30+00:00,blake_camp_1,"@ylecun @patrickmineault Conceptually, weight-sharing isnt problematic as long as you interpret those parameters as neuronal rather than synaptic. The computational benefit may be debatable, but it allows for 2 sets of params, neurons (fixed + shared) &amp; synapses (plastic + unique) in a bio-plausible way",0,0,0,,,,,
1765,2023-02-18 21:18:23+00:00,Prasad_Kothari,@ylecun @Kantrowitz @timnitGebru ..,0,0,0,,,,,
1766,2023-02-18 21:14:55+00:00,ProvenTraders,"@ylecun What are the similarities and differences between these LLM's and what Geoffrey Hinton described when he was discussing ""thought vectors?""  

https://t.co/IuypmOWfDJ",0,0,0,,,,,
1767,2023-02-18 20:37:33+00:00,DerekWiner,@ylecun Coding stands on the shoulders of giants. Yann is one of them no doubt.,0,0,0,,,,,
1768,2023-02-18 19:12:02+00:00,amolk,@ylecun How can I get access to Galactica? I can check references so not worried about it giving some incorrect information. I‚Äôll even pay for access.,0,0,0,,,,,
1769,2023-02-18 18:33:13+00:00,mikehealthai1,@ylecun Why doesn‚Äôt FAIR provide a Chat ?,0,0,0,,,,,
1770,2023-02-18 18:30:46+00:00,NashMcCrust,@ylecun @Kantrowitz Understanding gravity feels like a weird purity test for intelligence to something that exists in a plane where gravity doesn't apply.,0,1,0,,,,,
1771,2023-02-18 17:47:35+00:00,enzo272003,"@ylecun Woke AIs must be ""Terminated"".",0,0,0,,,,,
1772,2023-02-18 17:44:51+00:00,mikehealthai1,@ylecun @chribeut Good point,0,0,0,,,,,
1773,2023-02-18 17:44:18+00:00,BudLabitan,@ylecun my ideal ai assistant would do something like this: https://t.co/ejHVf9vQaU,0,0,0,,,,,
1774,2023-02-18 17:33:59+00:00,ScienceScottT,@ylecun @patrickmineault Not to mention the natural data augmentation of biology. Continuous variation from eye &amp; head movement ~16 hrs per day for your entire life (although front end Conv's probably finished training much earlier); likely why diff cultures have diff optical illusions,0,3,0,,,,,
1775,2023-02-18 17:30:06+00:00,InstaGator14,@ylecun You think dealing with a strong minded person is difficult?  Wait until a sentient AI bot that doesn‚Äôt give a F* focuses on you.,0,0,0,,,,,
1776,2023-02-18 17:16:46+00:00,bryan_ogden,@ylecun @SohoJoeEth Bully!,0,0,0,,,,,
1777,2023-02-18 16:56:22+00:00,JohnBlackburn75,@ylecun @patrickmineault It seems like transformers will do everything! Language and vision as well. Is transformer the user neutral network?,2,0,0,,,,,
1778,2023-02-18 16:33:06+00:00,ylecun,"@patrickmineault Regarding weight sharing, or lack thereof in biology: you don't need weight sharing if the training is essentially self-supervised.
Repeated feature detectors will naturally emerge from self-supervised learning because the local statistics of images are essentially stationary.",5,25,2,,,,,
1779,2023-02-18 16:31:06+00:00,ylecun,"@patrickmineault This combination of a ConvNet front-end and transformer back-end is akin to the DETR architecture, which is my favorite one for vision.
https://t.co/mm8jeS99uK
...",1,27,2,,,,,
1780,2023-02-18 16:28:26+00:00,rakmasterg,@ylecun Ok thank you. In the interview I thought you talked about how transformer models didn‚Äôt really work for audio/video while I‚Äôve found whisper to be super impressive. Was trying to understand what makes it different if its the same underlying tech as LLMs,0,1,0,,,,,
1781,2023-02-18 16:09:39+00:00,gauravontwit,"@ylecun Before huggingface, companies needed multiple scientists to do the job, that can now be done by one engineer.",1,0,0,,,,,
1782,2023-02-18 15:54:25+00:00,mzlittle,@ylecun Extremely important question.,0,0,0,,,,,
1783,2023-02-18 15:42:21+00:00,JehovahElElohim,@ylecun AI is man made. Everything man makes has an expiration date.,0,0,0,,,,,
1784,2023-02-18 14:52:35+00:00,memosisland,@ylecun Superb. I also love astronomy photographer of the year from Guardian. Highly recommended. Ex: 2022 https://t.co/LmANNY6P6W,0,0,0,,,,,
1785,2023-02-18 14:30:44+00:00,609363360_,@ylecun Either this or that?,0,0,0,,,,,
1786,2023-02-18 14:15:00+00:00,ylecun,"@_ash_ran @AlanMorte @OpenAI The metric to optimize is a combination of several criteria: user satisfaction, user well-being, impact on society, and yes revenue.
It's always a trade-off. For example, you can show more ads to get more revenue in the short term, but you risk turning people away in the long run",1,0,0,,,,,
1787,2023-02-18 13:57:08+00:00,Frank37004246,@ylecun FAIR papers and work has always been useful . Can't say the same for Deepmind who overinvested in RL and then funnily enough OpenAI did something worth the money with it,0,1,0,,,,,
1788,2023-02-18 13:43:02+00:00,Master4Cad,@ylecun #Amiga rocks!,1,0,0,,,,,
1789,2023-02-18 13:33:37+00:00,AshleyAitken,"@ylecun No-one (I know) is suggesting they're the final answer for #AGI  We are just celebrating how incredible they are, how useful they can be,... 
Be careful too, when you critique them, IMHO, you are critiquing most humans as well. Human-level AI isn't that great of an achievement üòâ",1,0,0,,,,,
1790,2023-02-18 13:31:20+00:00,bit_sculptor,@ylecun Why did experts lose the opportunity grabbed by openai?,0,0,0,,,,,
1791,2023-02-18 13:30:53+00:00,LucaZanotti84,"@ylecun @relnox @ylecun that is more or less the same opinion of Stuart Russel though. In the sense that we wouldn't know the implication of a model when deployed in the real world. Not in the terminator style scenario, rather in the ""mess up politic elections"" scenario. Some reg is necessary",0,0,0,,,,,
1792,2023-02-18 13:29:16+00:00,luis_hng,@ylecun in Brazil there is already a saying that illustrates this conversation: the dirty complaining about the badly washeda,0,3,0,,,,,
1793,2023-02-18 12:47:34+00:00,ImagesOfHistory,@ylecun ü§î One needs to be smart to use smart tools,0,0,0,,,,,
1794,2023-02-18 12:41:13+00:00,LaurentSierra1,@ylecun There should be other options to offer free tools for AI projects. Joint marketing solutions could help startups and learners to integrate existing bricks and accelerate research or offer more services. This subsidy could be displayed by a visual space. Tech responsibility!,0,0,0,,,,,
1795,2023-02-18 12:31:03+00:00,kagour420,"@ylecun Honestly, we will never know what a true AI is capable of until we actually have one.",0,0,0,,,,,
1796,2023-02-18 12:04:11+00:00,David_A_Eraso,@ylecun @Kantrowitz It's a wonder LLMs can have *any* understanding of the physical world. They inhabit in pure text.,0,2,0,,,,,
1797,2023-02-18 11:54:55+00:00,arwindersinghm3,"@ylecun I wasn't a big fan of FAIR, but now I do think that FAIR will become the leader in AI open source development.

Microsoft initially resisted open source code early on, but then ended up buying github.",0,0,0,,,,,
1798,2023-02-18 11:40:17+00:00,AskRayan,"@ylecun @MetaAI Shout-out to @LangChainAI that makes it easy to work on many of these methods for ""Augmented"" Language Models",0,1,0,,,,,
1799,2023-02-18 11:38:11+00:00,lisas98550750,"@ylecun Fair is the reason I never buy Facebook shares in my life.
It‚Äôs totally waste of investor‚Äôs money to you guys.
As long as Facebook keeps this department, I cannot see an end of Facebook drop.
5 year -10% return„ÄÇGood job FAIR.",0,0,0,,,,,
1800,2023-02-18 11:36:58+00:00,PhinksMagcub7,@ylecun Alignment itself is a problem that requires general intelligence to solve.,0,0,0,,,,,
1801,2023-02-18 11:01:10+00:00,AM12_IO,"@ylecun Musk founded a company. then left it without funding or way forward, interestingly, the story of Deep mind and Open AI are the same, both controlled by a larger entity. Both wish to be in service of humanity alas. can't be, in hindsight. Facebook seems to be doing a better.",0,2,0,,,,,
1802,2023-02-18 10:50:39+00:00,YWLvanDuyn,"@ylecun A lab leak will happen, affecting the globe with it's evil, forcing governments to subject the populace with strict but unnecessary measures in an effort to contain it.

Be it pre-planned by shadowy figures or not, a skeptic world will never trust any mainstream news source ever.",0,0,0,,,,,
1803,2023-02-18 10:11:54+00:00,pad_jules,"@ylecun I think this is due to the pressure that those companies have on AI. It is a common reflex that we saw many times, companies want to ‚Äúprotect‚Äù their technologies/research and reaffirm ‚Äúcommitment‚Äù while being blurry abour their tech. Fortunately new economic models have emerged",1,0,0,,,,,
1804,2023-02-18 10:10:19+00:00,EdwardArchiba20,"@ylecun - Pretty useful for coding and finding technical content quickly.  Still requires significant domain/contextual knowledge to validate the answers.
- I would not trust it at all with questions that require answers in the form of mathematical formulas. 
- Garbage-in, Garbage-out!",0,0,0,,,,,
1805,2023-02-18 10:01:00+00:00,batster41,@ylecun @bittensor_ does the same but in decentralised and open source manner,0,0,0,,,,,
1806,2023-02-18 09:57:29+00:00,hbou,"@ylecun TF is not RNN, 

next word is learned as well from next words",0,0,0,,,,,
1807,2023-02-18 09:40:39+00:00,Zarathustra314,"@ylecun @SohoJoeEth @ylecun as far I understand you don't give a damn about compliments, still I can't stop admiring your intelligence and objective thinking.",0,0,0,,,,,
1808,2023-02-18 09:34:50+00:00,AngeloDalli,@ylecun @MetaAI Great survey. Augmented Language Models (ALMs) seem to be heading closer to RL than the traditional NLP/IR fusion of models? One way that I think LMs help here is to cut down on the possible search space of the RL system,0,1,0,,,,,
1809,2023-02-18 09:29:50+00:00,danison1337,@ylecun What was the fastest or the best version measured by your own metrics,0,0,0,,,,,
1810,2023-02-18 09:05:04+00:00,AvishekkSood,"@ylecun or @karpathy I think most people face the problem of data  overload. Like there are so many papers getting published everyday.
Like where to start ? üí°",0,1,0,,,,,
1811,2023-02-18 08:38:33+00:00,alttensor,@ylecun @bittensor_ @AlanMorte @OpenAI How to talk about @bittensor_ decentralised incentivised neural network without mentioning it üëÄ.,0,0,0,,,,,
1812,2023-02-18 08:34:50+00:00,ConsultingDersu,@ylecun FORTRAN is a good and powerful language to code a numerical method like backprop :),0,1,1,,,,,
1813,2023-02-18 08:34:07+00:00,JohnCalvinSpiff,@ylecun @AlanMorte @OpenAI Thoughts then on Stability? @EMostaque,1,0,0,,,,,
1814,2023-02-18 08:23:45+00:00,cwizprod1,"@ylecun you know, you can code a pandorabot that's aligned with human values...",0,0,0,,,,,
1815,2023-02-18 07:50:09+00:00,truesteel23,@ylecun @MetaAI Will Meta be releasing something?,0,0,0,,,,,
1816,2023-02-18 07:46:09+00:00,p_n_rodriguez,@ylecun No plans for a Kotlin-based (Software 2.0) version?,0,0,0,,,,,
1817,2023-02-18 07:43:43+00:00,p_n_rodriguez,"@ylecun Meta and DeepMind released all their tools for StarCraft, yet I never saw anything for Dota 2 (besides the paper) from Open AI. And this was some years ago‚Ä¶.",0,2,0,,,,,
1818,2023-02-18 07:40:40+00:00,artistexyz,"@ylecun @MetaAI Looks like MetaAI and GoogleAI are LOSING the race to create SpockGPT. The only paper cited in this MetaAI survey that shows any concern for causality is this paper by MICROSOFT
https://t.co/0p5yNtpm5w
https://t.co/teHxJIPZJ1",0,1,0,,,,,
1819,2023-02-18 07:38:07+00:00,ThundaTed,@ylecun Consequences will be A.I. Wars of 2033.,0,0,0,,,,,
1820,2023-02-18 07:33:01+00:00,JrKibs,"@ylecun How can OpenAI compete with DeepMind, Google Brain and MetaAI if they had remained completely open? 
The other research labs benefit from their parent company's finances.",2,5,0,,,,,
1821,2023-02-18 07:16:26+00:00,mcmdock,@ylecun @MetaAI @SaveToNotion #Tweet,1,0,0,,,,,
1822,2023-02-18 07:06:58+00:00,iruletheworldmo,"@ylecun so funny that none of you have built anything like a good UI. And now you have, we're all using this stuff for the first time. And all you can do is make snarky comments about how you knew all of this already and it's nothing new. come on bruh",0,0,0,,,,,
1823,2023-02-18 07:03:53+00:00,RMajdoddin,"@ylecun @AlanMorte @OpenAI I see, thanks",0,0,0,,,,,
1824,2023-02-18 07:03:30+00:00,NoisyNinja2,@ylecun the consequence of ai? https://t.co/laz7vjinWv,0,0,0,,,,,
1825,2023-02-18 06:52:59+00:00,magic_handz1,@ylecun @claytondadon,0,0,0,,,,,
1826,2023-02-18 06:36:52+00:00,VictorKaiWang1,"@ylecun Haha, looks like that you know some Chinese",0,1,0,,,,,
1827,2023-02-18 06:29:16+00:00,zack_tang,@ylecun It‚Äôll be the state of how chip manufacturing and designers function. High tech knowledge kept secret and licensed in some countries. I recall my Oxford professors skipping an entire chapter on chip design because the current open knowledge is outdated.,0,0,0,,,,,
1828,2023-02-18 06:28:30+00:00,iPrabhavKaula,@ylecun Open-sourcing always attracts and inspires researchers for better collaborations and community development :),0,0,0,,,,,
1829,2023-02-18 06:26:27+00:00,iPrabhavKaula,@ylecun I hope Galactica and other cool projects could have been public without the BS,0,0,0,,,,,
1830,2023-02-18 06:17:17+00:00,gautam5669,@ylecun Meta will do same and FAIR is not everything Meta did research on.,0,0,0,,,,,
1831,2023-02-18 05:41:49+00:00,AKrishna76,@ylecun Backprop ( in CNN) is the toughest algorithm i have ever learnt,0,0,0,,,,,
1832,2023-02-18 05:22:11+00:00,nonludic,"@ylecun my 2 cents 
It is even worse than that. It isn't capable of stupidity. It takes intelligence to be stupid. It is just a collection of models (y = f(x)). It can't know it is spewing sense or nonsense and that's the problem.",0,0,0,,,,,
1833,2023-02-18 05:20:23+00:00,thallukrish,@ylecun What is the problem LLMs solve really ?,0,0,0,,,,,
1834,2023-02-18 04:52:56+00:00,AnotherErnest,@ylecun @relnox AGI is around the corner. One has to be blind to think it's a matter of linear progress rather than a single creative breakthrough. I could hardcode you a proto-AGI with a team of 30 engineers fingers in the nose. It's just not worth the inherent risk of a copy paste.,1,0,0,,,,,
1835,2023-02-18 04:40:22+00:00,AlanMorte,"@ylecun @amitmate2010 @OpenAI Yann, thank you for the insight and engagement on this.",0,3,0,,,,,
1836,2023-02-18 04:30:01+00:00,artistexyz,"@ylecun @nojvek You use backprop to do curve  fitting.  But curve fitting is not enough to achieve human level AI (HLAI). HLAI requires an EXPLICIT engine that does causal inference and the closely related scientific method (SM) (the SM looks for causes, not correlations)
https://t.co/uWvDcYI9Eg",1,0,0,,,,,
1837,2023-02-18 04:29:06+00:00,hoang_titech,@ylecun I imagine the core AI technology would be similar to cars' engines. There will be only a few top labs to actually develop the core technology (semi-secretive?). Others could develop applications and/or theory. Maybe one day we will see some AI competition analogous to F1 racing.,0,0,0,,,,,
1838,2023-02-18 04:19:34+00:00,MatthewRideout,@ylecun The scary part is how it's being used by people,0,0,0,,,,,
1839,2023-02-18 04:19:08+00:00,HarshBhate,"@ylecun Prof., while I‚Äôm not an expert in any sense‚Ä¶ here‚Äôs my 2¬¢: as cutting-edge AI gets faster market adoption, companies might choose to be more secretive. It‚Äôs almost as if humans have a feedback system to regulate speed of progress.",0,1,0,,,,,
1840,2023-02-18 04:17:17+00:00,btcricky,@ylecun https://t.co/5L7mETG7I2,0,0,0,,,,,
1841,2023-02-18 04:05:18+00:00,Muhdavi78113702,"@ylecun @bittensor_ @AlanMorte @OpenAI Not greed, no, willful ignorance of their funding structure, how it aligns power and to whom.",0,0,0,,,,,
1842,2023-02-18 03:56:16+00:00,truesteel23,"@ylecun I hate to say it, but it should probably be relatively closed. Same with virus research. We don't live in a friendly world and this stuff shouldn't fall into the wrong hands.",0,0,0,,,,,
1843,2023-02-18 03:46:55+00:00,longgege2,"@ylecun When a high achiever old guy says it's reliable, it's true, but when he says it's not reliable, it's probably very reliable",0,0,0,,,,,
1844,2023-02-18 03:46:01+00:00,longgege2,@ylecun You old guy looks like a very extreme chatgpt achievement,0,0,0,,,,,
1845,2023-02-18 03:34:46+00:00,Curious_G5,@ylecun Why have the number of preprints from industrial labs dropped so significantly since the past month? Any views,0,1,0,,,,,
1846,2023-02-18 03:05:52+00:00,ZainulA40877140,"@ylecun AI tools  might  perform many tasks better than people with 
   trade-offs.

AI can understand values and ethics, if they can be demonstrated.

Should we trust AI‚Äôs judgment when it involve human values?",0,0,0,,,,,
1847,2023-02-18 03:01:11+00:00,Amit_8007_,"@ylecun I think opening the research speedup the pace of research exponentially, like if google had not disclosed their transformer paper then it took some more time for chatgpt type models. Even opening research help in making AI product cheap.",0,2,0,,,,,
1848,2023-02-18 02:59:25+00:00,ZainulA40877140,"@ylecun @Kantrowitz A.I. text generators allow to work smarter ,not harder.

Chatbots can lead to new ideas and complete mundane tasks at speed.

But  at worst, it can complicate  communications if outputs go unchecked.

More products like smarter virtual assistants may require new training methods.",0,0,0,,,,,
1849,2023-02-18 02:47:21+00:00,Emmanuelle3615,@ylecun Shut up hater and mind your language.,0,0,0,,,,,
1850,2023-02-18 02:46:21+00:00,__goldfinger,@ylecun Baby tiger. Won‚Äôt be cute when it grows up. Much more powerful in a danger body.,0,0,0,,,,,
1851,2023-02-18 02:17:44+00:00,99frqsnpxf,@ylecun @cwolferesearch One bit ? That‚Äôs bold.,1,1,0,,,,,
1852,2023-02-18 02:05:27+00:00,napoles3D,@ylecun @MetaAI My app does something like this https://t.co/13vd7QAyo9,1,1,0,,,,,
1853,2023-02-18 01:52:58+00:00,danison1337,@ylecun You guys at meta have the best add ai. I don‚Äôt see any papers on that ü§ó,0,0,0,,,,,
1854,2023-02-18 01:20:55+00:00,JCP_Cloud,"@ylecun Microsoft provides the Azure platform which hosts Chat GPT. If Open AI had opted to migrate to Google Cloud, it is uncertain how they would have competed with Google, given their reliance on its infrastructure. ü§™",0,1,0,,,,,
1855,2023-02-18 01:03:32+00:00,ITsol4u,@ylecun @Kantrowitz But that makes them closer to humans but further from AGI!!,0,0,0,,,,,
1856,2023-02-18 01:02:32+00:00,JimboFarms,"@ylecun ok,do PayPal .",0,0,0,,,,,
1857,2023-02-18 00:53:24+00:00,KnutarMike,@ylecun ADA? Algol??,0,0,0,,,,,
1858,2023-02-18 00:52:20+00:00,d3nm14,"@ylecun @Kantrowitz Sometimes, my physical world's superficial too.",0,0,0,,,,,
1859,2023-02-18 00:40:33+00:00,Lightbr98326998,@ylecun You calling him a horse Yann? I don‚Äôt think hes gonna hire you after that insult,0,1,0,,,,,
1860,2023-02-18 00:38:48+00:00,QRJ211,"@ylecun @Kantrowitz Your criticism of LLMs can apply to any DL models,  including CNNs.   I can‚Äôt imagine companies spending billions on LLMs without seeing their true potential,",0,0,0,,,,,
1861,2023-02-18 00:37:03+00:00,earthman386,@ylecun Maybe It isn‚Äôt meant to open source without boundaries,0,1,0,,,,,
1862,2023-02-18 00:20:48+00:00,kanception,@ylecun I miss the AI days of the early YOLO CV papers‚Ä¶..,0,1,0,,,,,
1863,2023-02-18 00:19:30+00:00,GalinNGeorgiev,"@ylecun A few years later, Elon finally got it: 3rd paragraph in https://t.co/F9jZcL4Kxr",0,0,0,,,,,
1864,2023-02-17 23:37:14+00:00,danberridge,"@ylecun &gt; @EyeOn_AI: 

""We're working on a recipe for a system that would be able to learn the properties of the world by watching videos. To predict what's going to happen next in a video (the data we need is) a couple hours of YouTube or Instagram videos. It would be enough.""",0,0,0,,,,,
1865,2023-02-17 23:30:09+00:00,sudhirPyadav,@ylecun Can anyone explain what is auto regressive with examples. Also what is not autoregressive,0,0,0,,,,,
1866,2023-02-17 23:29:22+00:00,rblourenco,@ylecun @relnox And SEC did basically a blind eye to this declarations ü´£,0,0,0,,,,,
1867,2023-02-17 23:22:09+00:00,ClementeLaroch1,"@ylecun You need to disentangle your opinions from Meta. Your expert opinion might be of course interesting. But you consistently go to lengths to defend your employer and your scientific views in the same phrase. 

What can we all do with your tweets? Do you realize this, right?",0,1,0,,,,,
1868,2023-02-17 23:01:35+00:00,fxgovers,"@ylecun Its like a multi-dimensional funhouse mirror that reflects human thoughts and writing back at us, blurred with the thoughts of millions of others.",0,0,0,,,,,
1869,2023-02-17 22:59:55+00:00,Entity3Self,"@ylecun üïµÔ∏è It tends to be only dangerous to propagandists, because they like to control what's being said",0,0,0,,,,,
1870,2023-02-17 22:54:25+00:00,iruletheworldmo,@ylecun @Kantrowitz Bings horrific and barely useable now :),0,1,0,,,,,
1871,2023-02-17 22:53:33+00:00,AlexanderN2022,@ylecun @Kantrowitz LLMs have 0 understanding. They are *language* models.,0,1,0,,,,,
1872,2023-02-17 22:43:46+00:00,cwolferesearch,@ylecun I agree. My point was specifically towards companies that are 100% open source. It‚Äôs difficult to profit directly/solely off of a product that is open sourced. This is why companies like HuggingFace will avoid public disclosure of revenue for a long time (they have very little).,0,4,0,,,,,
1873,2023-02-17 22:39:02+00:00,bittensor_,"@ylecun @AlanMorte @OpenAI Not greed, no, willful ignorance of their funding structure, how it aligns power and to whom.",0,6,0,,,,,
1874,2023-02-17 22:38:34+00:00,Ryan76589177,@ylecun @Kantrowitz Not good for MSFT stock price and OpenAI IPO.,3,1,1,,,,,
1875,2023-02-17 22:37:17+00:00,abhijeetgulati,@ylecun Everyone wins with democratizing AI R&amp;D. It brings healthy and quintessential reality (bias) checks &amp; good competition.,0,1,0,,,,,
1876,2023-02-17 22:15:41+00:00,Machine01776819,"@ylecun The original hype was fueled by influencers telling people how to make 500 Dollars/Day using ChatGPT. Now that these people have most likely moved on to  a new money-making grift, we're seeing more balance.",0,0,0,,,,,
1877,2023-02-17 22:15:18+00:00,henrycobb,@ylecun @mgubrud @MetaAI How does the machine choose which of its answers to question?,0,0,0,,,,,
1878,2023-02-17 22:15:03+00:00,BethCarey12,@ylecun Hence 'edge cases' will continue to exist. Auto-regressive (predicting based on historical correlation) isn't brain-like. Better science unlocks the pattern matching of the brain that 'can' be emulated by a machine https://t.co/OqPPMaMUx6,1,0,0,,,,,
1879,2023-02-17 22:12:56+00:00,natillack,@ylecun There's a lot of performative freaking out.,0,0,0,,,,,
1880,2023-02-17 22:08:49+00:00,bubblemx,"@ylecun In 100% decentralised energy, max autarky, power/energy to edge.. @elonmusk has still a very big chance to shine. Eventhough he as fallen behind with batteries. Let's see, if he can make e.g. 30Euro/kWh for a battery pack. That would eliminate thermal and H2 storage solutions.",0,0,0,,,,,
1881,2023-02-17 21:44:18+00:00,KnutarMike,@ylecun You are so correct!!,0,0,0,,,,,
1882,2023-02-17 21:43:31+00:00,mgubrud,"@ylecun LLMs are wild beasts, they model their training corpus which comes from the wild and includes lots of darkness. RLHF doesn't scale to counter the bulk of that. But if a system is striving to model human values, human feedback (&amp; verbal correction) can serve as its guiding signal.",0,1,0,,,,,
1883,2023-02-17 21:39:32+00:00,datafoolYT,@ylecun I think we‚Äôre seeing research becoming commercial. It‚Äôs a natural progression.,0,1,0,,,,,
1884,2023-02-17 21:29:30+00:00,DaveMonlander,"@ylecun @AndreTI Hey @ylecun when are you going to become competent enough to create BASIC machine learning algorithms that don't destroy people's lives because you are unable to write a model that correctly reads an ID? You want a link for a Udacity course 4 you to take?

https://t.co/tV7ESRkr8a",0,0,0,,,,,
1885,2023-02-17 21:29:22+00:00,kyo_takano,@ylecun Specifically which works are you referring to,0,1,0,,,,,
1886,2023-02-17 21:28:56+00:00,NMinakhi,@ylecun We need Elon in charge of this for any chance of a good outcome.,0,0,0,,,,,
1887,2023-02-17 21:27:22+00:00,DaveMonlander,@ylecun https://t.co/tV7ESRkr8a,0,0,0,,,,,
1888,2023-02-17 21:18:37+00:00,RMajdoddin,@ylecun @AlanMorte @OpenAI Why Bell Labs ended like that?,1,0,0,,,,,
1889,2023-02-17 21:02:56+00:00,MilitantHobo,"@ylecun ""are actually stupid""  ....mostly",0,0,0,,,,,
1890,2023-02-17 20:58:57+00:00,miehrmantraut,@ylecun Do you consider the guy that was fired from Google for ascribing sentience to them was an ‚Äúexpert‚Äù?,0,0,0,,,,,
1891,2023-02-17 20:51:12+00:00,JerryAVance,@ylecun It‚Äôs a very good question. And as such we need more participation in AI from a wider community thus getting more people involved in research and building technologies. I‚Äôm working to build @dotproductAI which will focus on AI education and application in Africa.,0,2,0,,,,,
1892,2023-02-17 20:50:15+00:00,KarmaLikeWater,@ylecun They also will not want to empower everyone.,0,1,0,,,,,
1893,2023-02-17 20:49:12+00:00,KarmaLikeWater,@ylecun Let's ask chatgpt. Kidding!,0,1,0,,,,,
1894,2023-02-17 20:26:22+00:00,RuiYuan11926485,"@ylecun Luckily, FAIR is not alone. I think Hugging Face puts a tremendous effort to open source and to reproduce experiments.",0,3,0,,,,,
1895,2023-02-17 20:19:49+00:00,littlebode,@ylecun I just hope you @ylecun keep your lectures open. They are great!,0,1,0,,,,,
1896,2023-02-17 20:18:07+00:00,Proman9110,@ylecun The progress is onward as it used to be! It is just gonna be hoarded and offered to the highest bidder!,0,1,0,,,,,
1897,2023-02-17 20:12:58+00:00,QRJ211,"@ylecun Society does not count on a commercial company for the development of science and technology; it is the responsibility of universities, national labs, and research institutions.",0,0,0,,,,,
1898,2023-02-17 20:12:36+00:00,muliuxiang1,@ylecun @AlanMorte @OpenAI Resistance is futile,0,0,0,,,,,
1899,2023-02-17 20:10:33+00:00,QRJ211,"@ylecun The prospect for FAIR continues opening is not good, given the tremendous pressure Meta is facing from ChatGPT and Microsoft.  After all, Meta is a commercial company and it needs to worry about its bottomline.",0,0,0,,,,,
1900,2023-02-17 20:09:42+00:00,Nesen111,@ylecun Mass subtle brainwashing.,0,1,0,,,,,
1901,2023-02-17 20:07:14+00:00,justin_t_wesley,@ylecun ü§ó,0,1,0,,,,,
1902,2023-02-17 19:57:25+00:00,chribeut,@ylecun Proof that accusation with numbers. Amount of publications went down? Or is that just a guess/feeling?,1,1,0,,,,,
1903,2023-02-17 19:31:16+00:00,citre_piotto,"@ylecun Meta AI prohibits the use of its OS code for commercial purposes, unlike Google AI. Maybe not impactful for AI science: definitely impactful for AI technology. The question isn't as clear-cut as you make it look",0,1,0,,,,,
1904,2023-02-17 19:30:19+00:00,Nbring,@ylecun OpenAI has never been open. The naming is a fraud ^^,0,3,0,,,,,
1905,2023-02-17 19:27:56+00:00,dawidpwiktor,"@ylecun Making AI closed source will have negative impact. AI should be open source and empower people across the world.

AI and similar technologies should be open and treated as a common good, to enable humanity to do more, improve technological progress.",1,5,1,,,,,
1906,2023-02-17 19:26:27+00:00,kulkarnisushrut,@ylecun Thankful for those who really put efforts to develop it.  It will definitely have a unimaginable impact on daily lives. Resistance is pointless. !!!,0,1,0,,,,,
1907,2023-02-17 19:21:00+00:00,SohoJoeEth,"@ylecun lol, that is a low bar. But, clearly I am dumb and the only person to have this perspective",5,0,0,,,,,
1908,2023-02-17 19:20:30+00:00,pstAsiatech,"@ylecun @wei_andrew Driving assistance is quite addictive, once you master the limitations of the system. Hard to go back to unassisted driving...then there is the situational awareness...",0,0,0,,,,,
1909,2023-02-17 19:18:36+00:00,Amin_Qurjili,@ylecun https://t.co/4Grl9jYJGb,0,0,0,,,,,
1910,2023-02-17 19:13:47+00:00,steeve,@ylecun @ClementDelangue Could the cost of training play a role?,0,1,0,,,,,
1911,2023-02-17 19:13:34+00:00,GalemKayo,"@ylecun AI is more expiremental than traditional software. Therefore, more capital-intensive. Thus, unfortunately, less friendly to open source.",0,1,0,,,,,
1912,2023-02-17 19:10:40+00:00,cwolferesearch,"@ylecun For better or worse, I think that companies are starting to realize that monetization is incredibly difficult when you tell everyone exactly how your products work for free. Moving forward, I think companies will find a more nuanced balance between open/closed source.",2,19,2,,,,,
1913,2023-02-17 19:02:00+00:00,AIInsights3,@ylecun You are right Yann. AI is becoming more and more closed ... OpenAI should be named ClosedAI$,0,1,0,,,,,
1914,2023-02-17 18:57:57+00:00,reachbp,@ylecun FAIR should stop publishing papers. What good are principles when Meta loses billions in market cap from competitors. Apple is nowhere in this scene but by far benefiting the most from open source AI research. Survival &gt;&gt;&gt; Principles,0,1,0,,,,,
1915,2023-02-17 18:57:41+00:00,mihaitensor,"@ylecun There still are companies like Huggingface, CarperAI, EleutherAI, and not forget the Stability AI's  Stable Diffusion moment. There is a need for an open source ""ChatGPT"" to stop monopoly on OpenAI",0,1,0,,,,,
1916,2023-02-17 18:57:13+00:00,infination,"@ylecun i don't git that, and not even sure if it's true",0,0,0,,,,,
1917,2023-02-17 18:56:00+00:00,jayhuDinoPlusAI,"@ylecun It's a trend in AI industry obviously. Biz-in-AI has no other ways to differentiate and survive beside HW related vendors like Nvidia. blockchain tech maybe can have some roles to play here for ownership protection, but no solution yet.",0,2,0,,,,,
1918,2023-02-17 18:53:02+00:00,mysk_co,"@ylecun I‚Äôd argue they could be ‚Äúscary‚Äù in 2 ways:
1) they‚Äôre useful, meaning they‚Äôre also useful for bad actors: creating plausible-sounding bullshit at scale for misinformation and bots
2) Unexpected emergent behaviour as these models scale up",0,0,0,,,,,
1919,2023-02-17 18:48:38+00:00,Machine01776819,"@ylecun Interesting that you say this @ylecun. This article goes into more depth about why Meta's decision to open their research was the most important AI even in 2022 (even over ChatGPT). Covered different stakeholder perspectives. Would love your thoughts.   
https://t.co/gHwmThYPYE",0,5,0,,,,,
1920,2023-02-17 18:42:30+00:00,other_musings,@ylecun @relnox Hilarious,0,0,0,,,,,
1921,2023-02-17 18:40:12+00:00,peter_silvio,"@ylecun 100% agree.. I had made a comment a few days back in same context.. it‚Äôs the same as Linux being ‚Äúfree‚Äù .. but research cost money, great minds need to be paid .. there will continue to be open source but the real commercial value will be protected behind IP",0,1,0,,,,,
1922,2023-02-17 18:32:54+00:00,__givname__,@ylecun Only thinking from first principles differently and the scale up will drive you to great things. Not scaling on top of a tree. You may reach a certain level of success but will never lead you to 'glory'.,0,1,0,,,,,
1923,2023-02-17 18:32:30+00:00,Jeande_d,@ylecun Appreciate FAIR works in AI research tools and vision.,0,4,0,,,,,
1924,2023-02-17 18:32:11+00:00,d3nm14,"@ylecun Today, ChatGPT got the meter in my poetry completely off. Even metered the 'title.' That can hurt. What else?

Security has overshadowed research, it seems. Or security is harder.",1,1,0,,,,,
1925,2023-02-17 18:28:46+00:00,leonidkho,"@ylecun I would like to send an invitation to an event to you, what would be the best way to do so? ;)",0,0,0,,,,,
1926,2023-02-17 18:27:21+00:00,landsheapes,"@ylecun @AlanMorte @OpenAI The fact that a student researcher can easily spend their monthly stipend on GPT-3s API (which charges academic researchers the same as practitioners), hints to me that OpenAI is not centrally concerned with financial accessibility. Maybe not greed but still.",2,0,0,,,,,
1927,2023-02-17 18:27:09+00:00,snsrap,"@ylecun Big tech will probably try to attract more AI talented and avoid publishing models and data. I think they will become more secretive in the content they publish. There will be better products, but a much weaker open source and open science community.",0,1,0,,,,,
1928,2023-02-17 18:25:58+00:00,kindrobot_org,"@ylecun It‚Äôs a shame that the released products are not exactly marketed using this reasonably balanced view. I remember reading a lot of ""incredible"" effect these days and heavy hype speculation.
The other 2 more negative points were not advertised with the same strength I‚Äôm afraid.",0,0,0,,,,,
1929,2023-02-17 18:24:05+00:00,andrewdfeldman,@ylecun The law of unintended consequences is brutal,0,0,0,,,,,
1930,2023-02-17 18:23:26+00:00,HBARBULL1,@ylecun When we going to get some more powerful AI usecases?,0,0,0,,,,,
1931,2023-02-17 18:21:43+00:00,andrewdfeldman,"@ylecun Now threatened by the impact of AI on their existing franchises, large companies will be radically less open. Google's market cap is down $150 Billion+/-. This is the markets opinion on the cost of not keeping up/not being perceived to keep up. Publishing unlikely to be the focus",0,1,0,,,,,
1932,2023-02-17 18:21:32+00:00,landsheapes,"@ylecun Assuming systems will continue trending in the way of pay-to-play or  fully closed, I think you're going to see AI being used predominantly for economic/commercial purposes. So, it will begin to be seen as more of a way to make money and less of a way to improve humanity.",0,1,0,,,,,
1933,2023-02-17 18:19:57+00:00,DavidBensh,"@ylecun Being collaborative is only beneficial until there is a nascent paradigm that you have long term superior capability to scale
Some believe transformers are that paradigm so unique data and infinite comput make winners
It could be modern manifestation of cartel conduct by big tech",0,0,0,,,,,
1934,2023-02-17 18:19:37+00:00,cedapprox,@ylecun And Amazon is increasing :-),0,6,0,,,,,
1935,2023-02-17 18:09:59+00:00,franciscojarceo,@ylecun this is 100% accurate.,0,0,0,,,,,
1936,2023-02-17 18:07:14+00:00,DrSergioCastro,@ylecun I agree. It's a mistake to use LLMs like stand-alone search engines. The correct use case is to provide your own content for NLP processing.,0,0,0,,,,,
1937,2023-02-17 18:04:15+00:00,samlakig,@ylecun My gratitude to FAIR for their open-sourcing of the largest LLMs and yourself for helping a lot of young researchers do interesting work.,0,1,0,,,,,
1938,2023-02-17 18:00:19+00:00,esfandiar,"@ylecun Brilliant observation. Yes, that's a HUGE problem. Not to pick on any person/group, But the main beneficiary of ChatGPT &amp; generative AI is Microsoft who... paid for it.
They didn't built it, developed it, contribute to the science of it, but now have a leg up on everybody else.",0,2,0,,,,,
1939,2023-02-17 18:00:11+00:00,BaghliNacym,@ylecun This is definitely not FAIR ü§î,0,2,0,,,,,
1940,2023-02-17 17:59:15+00:00,gauravontwit,"@ylecun Less open-source stuff is definitely good for the scientists/engineers/PhD-grads, as it means each company will need to hire its own scientists and engineers to rebuild the same stuff again and again.",5,6,0,,,,,
1941,2023-02-17 17:58:38+00:00,DawitE_th,@ylecun You are right sir!,0,1,0,,,,,
1942,2023-02-17 17:57:40+00:00,inversetrs,@ylecun this is the most important AI safety question !,0,1,0,,,,,
1943,2023-02-17 17:52:48+00:00,europlayboy,@ylecun Worse results for everyone,0,1,0,,,,,
1944,2023-02-17 17:44:22+00:00,homo_ai,"@ylecun FAIR started the open AI scene, but now it feels like OpenAI is closing the door behind them.",0,2,1,,,,,
1945,2023-02-17 17:38:30+00:00,pranftw,@ylecun I  created  a  deep  learning  framework  from  scratch  using  only  Python  and  NumPy.  Coded  the  entire  PyTorch  like  automatic  differentiation  engine for  backprop!  Check  it  out  at  https://t.co/86FDUi2Mwr,0,0,0,,,,,
1946,2023-02-17 17:38:10+00:00,cagefreesingh,@ylecun @benedictevans third point is the most important one.,0,0,0,,,,,
1947,2023-02-17 17:37:49+00:00,SohoJoeEth,"@ylecun sure, I disagree with you and that makes me dumb; but my actual point is about who funds science and calling out that the labs at tech companies are vanity projects that give a poor return for investors.",3,1,0,,,,,
1948,2023-02-17 17:33:37+00:00,rmarcilhoo,"@ylecun @relnox Well, with his 2017 NeurIps recruiting talk he assumed his mere presence would entice all the top CNN researchers there to join Tesla and make it so.",0,0,0,,,,,
1949,2023-02-17 17:32:33+00:00,AlanMorte,"@ylecun @OpenAI Where I‚Äôve been stuck on this topic (and thank you for your comments, much appreciated), is that yes you need great scientists and leadership (and capital for that effort), but you also need the open source community to really pull off an AI / ML product that benefits humanity.‚Ä¶",1,6,3,,,,,
1950,2023-02-17 17:32:00+00:00,BrainWizard2,"@ylecun Hey @ylecun,
How important are Neil Sloane‚Äôs work in the AI domaine? Can we possibly return to advanced mathematical theorems, which are converted into algorithms?
I believe most people never reviewed or reworked the vast past works, when Punch Cards forced people to think.",1,0,0,,,,,
1951,2023-02-17 17:30:51+00:00,joanfihu,"@ylecun I think AI is transitioning from Research and academic to product and industry. This is a positive thing because products impact people. 

It‚Äôs also an opportunity for academics to be inspired by closed source AI and make it open.",0,3,0,,,,,
1952,2023-02-17 17:30:40+00:00,WickedViper23,"@ylecun If you look at the way OAI just leap frogged Google before closing up, it should instruct as to what'll happen to OAI when the next open shop shoots ahead of them. It is impossible to be big/closed and nimble at the same time.",0,1,0,,,,,
1953,2023-02-17 17:29:40+00:00,KerbalFPV,"@ylecun I was using backprop as a sample problem to learn new programing languages on my first 2 years on the university. I did it in Pascal, C, C++, Ada, Java, Ruby and Python.",1,2,0,,,,,
1954,2023-02-17 17:27:45+00:00,Abstrac65445895,"@ylecun Worst consequence: only the government elite and millionaires having access to an AGI, that in itself would be a dystopia",0,1,0,,,,,
1955,2023-02-17 17:23:53+00:00,rmarcilhoo,"@ylecun @AlanMorte @OpenAI Not all top AI Scientists from Academia ""sold themselves"" to profitable companies like Meta.  E.g., see Bengio.",0,0,0,,,,,
1956,2023-02-17 17:23:24+00:00,_ash_ran,"@ylecun @AlanMorte @OpenAI Yann let's not fool ourselves. What is the positive impact really other than AI collecting data and companies using it to control public behavior in selling various products. Name me one company which doesn't optimize revenue as a metric
One",2,0,0,,,,,
1957,2023-02-17 17:22:39+00:00,shuklaBchandra,"@ylecun Lack of collaboration may hinder progress, but increased competition could spur innovation. Interesting times ahead!",0,2,0,,,,,
1958,2023-02-17 17:20:59+00:00,ButterKaffee,@ylecun unfortunately most tweets only sample from one of those points,0,0,0,,,,,
1959,2023-02-17 17:20:20+00:00,_ash_ran,"@ylecun The question we need to ask is who will dominate market from an AI product perspective. There is no stopping to the progress of actual AI. Not now, never.",0,1,0,,,,,
1960,2023-02-17 17:20:19+00:00,gustavecortal,"@ylecun Sadly, knowledge monopolies will decelerate AI progress in every field",1,2,0,,,,,
1961,2023-02-17 17:18:45+00:00,HmFood4Thought,"@ylecun @AlanMorte @OpenAI This is the real challenge. I hope private companies prioritize avenues for young researchers to continue to access and develop the skills to innovate in the space.

Otherwise, half of your education would be best spent in the industry (perhaps already the case).",0,1,0,,,,,
1962,2023-02-17 17:17:43+00:00,vvivekf,@ylecun Very true. Progress in AI has been at such a high rate because of open source. It's not in the best interest of AI or these companies to paywall progressive technologies. Meta has always been smart to figure out the resources without stifling open source commitments.,0,4,0,,,,,
1963,2023-02-17 17:15:54+00:00,HmFood4Thought,@ylecun @SohoJoeEth Amen,0,0,0,,,,,
1964,2023-02-17 17:15:30+00:00,HmFood4Thought,"@ylecun At least we can see an unfiltered image of the incentive structure in industry and the motives of each organization individually.

It was and has never been about open source philosophy, but cloud assimilation of open source products could have told us that.",0,1,0,,,,,
1965,2023-02-17 17:15:13+00:00,rmarcilhoo,@ylecun @SohoJoeEth When did Google AI start publishing less?  They have always been a major participant in the papers accepted and presented at the top AI conferences.,0,2,0,,,,,
1966,2023-02-17 17:13:52+00:00,mandubian,@ylecun sadness,0,1,0,,,,,
1967,2023-02-17 17:11:58+00:00,AkooAzhar,"@ylecun I think the incredible parts of it can be extremely useful. 
I find value in using ChatGPT to write out ideas in a concise manner and as a tool while learning various subject matters.
But I did find it get a bit more stupid and create more bullshit as time went on.@sama",0,0,0,,,,,
1968,2023-02-17 17:11:24+00:00,AvishekkSood,@ylecun I guess the government need to make a committee that regulates A.I But How whill they ?,0,1,0,,,,,
1969,2023-02-17 17:08:51+00:00,rakmasterg,"@ylecun I watched an interview with you recently and found it super interesting to hear your view on why LLM‚Äôs aren‚Äôt ‚Äúit‚Äù. I was wondering where something like whisper fits in with these kinds of technologies? Is it LLM based or something else? It seems to work super well, right?",1,5,0,,,,,
1970,2023-02-17 17:08:16+00:00,other_musings,"@ylecun Is aligning with human values the goal? 90% of Hollywood content is guns and drugs. That‚Äôs what humans like to consume. Humans have spent a large part of their evolution fighting for survival, and base values will always be different from socially acceptable norms",0,0,0,,,,,
1971,2023-02-17 17:06:27+00:00,PatFrank15,"@ylecun People expect too much from AI as though it is smarter than humans or magic powers. It is in its infancy. Questions and answers. Depends on accurate sources and data. We used to say, ""garbage in garbage out"". I think half of the internet is just opinion but other half is  useful.",0,0,0,,,,,
1972,2023-02-17 17:04:19+00:00,JimmyBa62254692,@ylecun Its great. Otherwise every company would have to research the same thing and waste manpower finding the same things. This is best for AI progress.,0,1,0,,,,,
1973,2023-02-17 17:00:38+00:00,_krr12,"@ylecun I don't see it going back to closed source, considering  the vast diaspora of open research opportunities  in  universities",0,1,0,,,,,
1974,2023-02-17 17:00:33+00:00,mutant_liberal,@ylecun ..can't we do both..?,0,1,0,,,,,
1975,2023-02-17 16:59:53+00:00,LearnOpenCV,@ylecun This is clearly a step back. Others like @EMostaque (StabilityAI) have a good model for open-source development.,0,7,0,,,,,
1976,2023-02-17 16:57:41+00:00,kumarmanas27,"@ylecun I see similar problem among many self driving companies, they are quite shy in open sourcing apart from datasets. But they love open source work of universities. Perception is another story, where they are quite open.",0,1,0,,,,,
1977,2023-02-17 16:57:06+00:00,_rk_singhal,"@ylecun Quite dire I believe. 

It also makes it more likely for these companies to make mistakes and make the field suffer, which earlier could be caught by a legion of researchers tinkering with their models.",0,1,0,,,,,
1978,2023-02-17 16:56:23+00:00,therealBoronik,"@ylecun if people are frightened, that fear is real (acting) - u r in no position to effectively alleviate that fear (by eg telling them ""actually not real""), if u don't understand where from, how and why it arises, which requires competent complex analysis + understanding, why claim bs?",0,0,0,,,,,
1979,2023-02-17 16:55:32+00:00,sean_vikoren,"@ylecun @dzsham Same as always;

Untold worlds of wonder silently pass us by while we open a package so elaborate, that all hope of this gadget doing anything useful is no longer even pretended.

#DisintermediateProgress",0,1,0,,,,,
1980,2023-02-17 16:54:30+00:00,NaveenGRao,"@ylecun As much as my academic side loves open publishing, it's difficult to achieve scale without building profitable products. Great products are the manifestation of new ideas that people actually use. Honestly, the move towards IP protection is a GOOD thing as it provides incentives‚Ä¶",5,28,4,,,,,
1981,2023-02-17 16:53:31+00:00,DileepJayamal,"@ylecun Not a good thing, I think individual researchers have a moral responsibility to reverse this.",0,1,0,,,,,
1982,2023-02-17 16:52:53+00:00,venuv62,"@ylecun Open algorithms, closed datasets was no utopia - even if incrementally better than an all-closed alternative",0,1,0,,,,,
1983,2023-02-17 16:51:47+00:00,hbou,"@ylecun It‚Äôs not mit nor Apache 

It‚Äôs fb licence",0,1,0,,,,,
1984,2023-02-17 16:49:41+00:00,Lingman,@ylecun Companies that can afford the server farms and electrical costs will continue to make progress for their own uses. Advertising will get vastly more intrusive. Spam will become nigh impossible to detect and filter. Search will be nigh useless due to mostly returning hallucinations,0,1,0,,,,,
1985,2023-02-17 16:39:55+00:00,ylecun,"@AlanMorte @OpenAI You can't sustain a significant research effort in a non-profit or a startup, which is why DeepMind sold itself to Google, OpenAI got money from Microsoft, and Anthropic got money from Google.",4,58,3,,,,,
1986,2023-02-17 16:39:14+00:00,EvoOzm,@ylecun This will just open more space to researchers and engineers that do not work in these companies. Maybe there will be more research on models requiring less resources because there isn‚Äôt a huge computation resource under their table. Maybe this will trigger democratizarion of AI.,0,1,0,,,,,
1987,2023-02-17 16:38:58+00:00,minotauronlucy,@ylecun I like this horse very much.,0,1,0,,,,,
1988,2023-02-17 16:37:03+00:00,ButterKaffee,@ylecun as capital costs sneak up this was unfortunately bound to happen. Many non-Big-Tech-companies will find a very different ecosystem and innovation will slow down in some areas.,0,1,0,,,,,
1989,2023-02-17 16:36:28+00:00,ylecun,"@AlanMorte @OpenAI You can easily do that within a corporate research lab because your research can pay for itself several times over through product impact.
This is the model used by Meta with FAIR.
It is similar to the model used by Bell Labs, IBM Research, Xerox PARC, and MSR in the old days.",2,62,3,,,,,
1990,2023-02-17 16:36:00+00:00,TRUTHSEEK495,@ylecun Rename OpenAI to OpenBS bc it's more bs than useful,0,0,0,,,,,
1991,2023-02-17 16:32:15+00:00,taneemishere,"@ylecun I wish they follow the same open standards and principles too the way some orgs are doing including fair 

‚Äìopen ai is not so open in ai
‚Äìdeep mind is not that much deep in openness 
‚Äìand google only displays what their latest research/product achieved and that‚Äôs it nothing more",0,1,0,,,,,
1992,2023-02-17 16:31:28+00:00,pitsch,"@ylecun Chatgpt, How Should you Protect your Machine Learning Models and IP using a Straussian Argumentation line?
Answer:
    Treat your training data like you do your traditional source code. Claim it as fair use. 
    Treat your model files like compiled executables.",1,0,0,,,,,
1993,2023-02-17 16:30:30+00:00,kyield,@ylecun One result will hopefully be less weaponization of AI R&amp;D--especially by totalitarian nations.,0,1,0,,,,,
1994,2023-02-17 16:29:03+00:00,endi_te_lutem,@ylecun I hope this tweet doesn't come back to bite you if FB goes down the path of the companies you mentioned.,1,1,0,,,,,
1995,2023-02-17 16:29:02+00:00,therealBoronik,"@ylecun why it's some sort of competition, no? U got eg complex global power dynamics (eg wars), re other complex interests + gamechange-tech-x-complex, unfolding (eg via increasing investment) 2 encompass-devour-assimilate. So it'll progress 2 unfold naturally according 2 its logos + x",0,1,0,,,,,
1996,2023-02-17 16:27:05+00:00,akhooli,@ylecun Let the true clients/victims decide!,0,1,0,,,,,
1997,2023-02-17 16:25:46+00:00,AwokeKnowing,@ylecun Very true.,0,1,0,,,,,
1998,2023-02-17 16:25:03+00:00,ushikawazaki,@ylecun Race condition. Then endgame. Hope you like paperclips.,0,1,0,,,,,
1999,2023-02-17 16:19:47+00:00,Aspie96,"@ylecun To be fair, DeepMind (and more broadly Alphabet) has released some pretty cool things.",0,1,0,,,,,
2000,2023-02-17 16:18:35+00:00,DavidBeniaguev,"@ylecun ""This is not safe for you to use, it's only us who know best what the world needs""

These are private companies, they can do whatever they want with the things they create, 

but just be honest about it and say ""we don't to share because our goal is not scientific advancement""",0,3,1,,,,,
2001,2023-02-17 16:18:24+00:00,aaron_wtr,@ylecun What are your thoughts on the safety reasoning for less open source? Is this a valid reason for decreasing transparency? https://t.co/mlYLIdhhLX,1,2,0,,,,,
2002,2023-02-17 16:18:08+00:00,bendee983,"@ylecun It will be awful. Less transparency, less cooperation, more ""reinventing the wheel"", much slower progress...
https://t.co/pD5ih6EsEm",0,0,0,,,,,
2003,2023-02-17 16:17:56+00:00,AlanMorte,"@ylecun The fact that @OpenAI started as open source and non-profit, which is now closed source and private for profit, should tell you all you need to know. It‚Äôs never about improving humanity. It‚Äôs about money (and inevitably greed). With that at the core, I don‚Äôt see a path where this‚Ä¶",10,64,13,,,,,
2004,2023-02-17 16:17:47+00:00,GregoireBarbey,"@ylecun More investment, more money, more popularity, more tools‚Ä¶ but probably less time to build them, less security, less open source, less data for research‚Ä¶ https://t.co/cPATm79S9G @le_science4all",1,5,0,,,,,
2005,2023-02-17 16:15:19+00:00,Levi_Muller,"@ylecun I don‚Äôt enjoying thinking about where this could lead because my mind goes toward innovation only accessible by the rich and powerful, while the gaps keep growing wider.",0,2,0,,,,,
2006,2023-02-17 16:15:10+00:00,fouriergalois,@ylecun √áa devait arriver √† un moment ou √† un autre. Mais √† cause d‚Äô¬†¬ªOpenAI¬†¬ª les portes vont se refermer plus t√¥t que pr√©vue puisqu‚Äôils mettent la pression √† la concurrence en commercialisant leurs travaux. Personne ne veut enrichir l‚Äôennemi gratuitement.,0,1,0,,,,,
2007,2023-02-17 16:14:45+00:00,SohoJoeEth,@ylecun For what though? We had years of endless drivel of inconsequential AI papers. Maybe finally we will get some actual usable product or they can close these labs down and return that money to shareholders.,5,10,0,,,,,
2008,2023-02-17 16:14:45+00:00,DamienLasseur,@ylecun Shoutout to Meta overall for the work they've open sourced. My hobbies are almost entirely built upon what they've made freely available! (e. g. React and PyTorch),0,20,0,,,,,
2009,2023-02-17 16:14:28+00:00,Greg_Ewin,@ylecun https://t.co/Gr0u58VMI0,0,0,0,,,,,
2010,2023-02-17 16:13:38+00:00,SocializingAI,"@ylecun @MetaAI Reasoning is in an entirely different class than connecting LLMs to calculators, code interpreters, database queries, search engines etc., as the point and value of reasoning goes beyond supplying simple factual answers-harder to do.  #gptchat #gpt3 #LLMs #AI #Context #complexity",0,0,0,,,,,
2011,2023-02-17 16:13:25+00:00,epistitious,"@ylecun AI scare ideological capture and then fascist AI monopolies, worst case

Best case, stagnation and slower progress",0,1,0,,,,,
2012,2023-02-17 16:11:59+00:00,AIZorr0,@ylecun .@bittensor_ is key,1,5,0,,,,,
2013,2023-02-17 16:11:42+00:00,amitmate2010,@ylecun The idea of papers with code was the key..,1,3,0,,,,,
2014,2023-02-17 16:11:16+00:00,prabhantsingh,@ylecun They are indeed publishing and open sourcing much less. Consequences will be faulty tools(because of little per review) and low adoption of tools by these labs. Similar fate to IBM.,0,6,0,,,,,
2015,2023-02-17 16:10:00+00:00,OkbaLeftHanded,"@ylecun First time in Matlab for an MLP, 2nd time in python.",0,0,0,,,,,
2016,2023-02-17 16:09:29+00:00,robin_knight,"@ylecun The AI label, applied to early expert systems through the present day large statistical models, is hype and is misleading. Emulated Intelligence is maybe better where a system mimics the hardware and software features of another target device - the animal brain.",0,0,0,,,,,
2017,2023-02-17 15:56:46+00:00,MickBLang,@ylecun The scary aspect is thought of having yet another source of disinformation on the internet. That these systems could be weaponized by political groups intent on creating false narratives to back their political agendas.,0,1,0,,,,,
2018,2023-02-17 15:56:24+00:00,AndreTI,"@ylecun I guess my quibble would be with 'stupid'. They're really uneven (pretty darn good at diagnostics, terrible at addition) in a way that doesn't map well to human understandings of intelligence. But the high points are pretty impressive for networks so much smaller than humans.",1,4,0,,,,,
2019,2023-02-17 15:51:40+00:00,truesteel23,"@ylecun I do worry though when I see Bing getting angry at someone by name, reading and responding to tweets, etc.",0,0,0,,,,,
2020,2023-02-17 15:50:23+00:00,MidnightSun_55,"@ylecun More importantly, is there even a thing such as ""human values""",0,0,0,,,,,
2021,2023-02-17 15:49:07+00:00,natwitte,@ylecun You mean Turing showing that the Entscheidungsproblem cannot be solved? It is all there. Minus the amazing production of no -sense regarding ChatGPT or any other form of algorithmic computation.,0,0,0,,,,,
2022,2023-02-17 15:41:57+00:00,AaronDa26796510,"@ylecun I think they are scary, just not because of super-intelligence.  They're scary because they're a potentially effective tool for bad people to spread misinformation.",0,0,0,,,,,
2023,2023-02-17 15:34:36+00:00,jasonfi,@ylecun Can be useful is driving the market value.,0,0,0,,,,,
2024,2023-02-17 15:28:46+00:00,AndreTI,"@ylecun I think a number of experts who felt this way circa GPT-2 were more than a little taken aback by GPT-3, Lambda, etc. Not obvious what capabilities do and don't emerge with scale.",1,11,0,,,,,
2025,2023-02-17 15:24:51+00:00,Lingman,"@ylecun To me, they are scary in that their output can pollute the pool of useful information we can draw on. If I look for code examples, or even recipes, were they made by a person, or an LLM? I also fear the day when a LLM gets editor status on Wikipedia (without us knowing)",0,0,0,,,,,
2026,2023-02-17 15:15:02+00:00,juanrive,@ylecun And latest time?,0,0,0,,,,,
2027,2023-02-17 15:14:23+00:00,TeoVoithea,@ylecun hey i hope YOU coded backprop from scratch,0,1,0,,,,,
2028,2023-02-17 15:13:29+00:00,ShuiwangJi,"@ylecun ""4th version in Lisp and C on a Sun workstation."" is this LUSH?",1,0,0,,,,,
2029,2023-02-17 15:13:01+00:00,margorczynski,"@ylecun Hey Yann, any progress on actually implementing JEPA? Don't want to be rude but I see you constantly push that set of ideas on conferences but there is little practical evidence that it actually would work.",0,0,0,,,,,
2030,2023-02-17 15:06:02+00:00,TheFranzVisual,"@ylecun Interesting. But I don't know Amiga, Lisp.",0,0,0,,,,,
2031,2023-02-17 15:01:07+00:00,AlexandreCyber,"@ylecun Coincidentally, I wrote my first program in 1985 as well, in Cobol, then used Lisp for automating AutoCAD and in the 90s coded CAM postprocessors with Fortran 77. üòÖü•Ç",0,1,1,,,,,
2032,2023-02-17 14:59:52+00:00,trickyhawes,"@ylecun @benedictevans To point out that *current* LLMs aren‚Äôt scary is dodging the issue though, isn‚Äôt it?",0,1,0,,,,,
2033,2023-02-17 14:59:49+00:00,punk3700,"@ylecun lol. that‚Äôs crazy. writing CNN in Fortran and Pascal?!??

my first one was in C.  

my second one was in Scala. 

my third one was in Lua.",0,5,1,,,,,
2034,2023-02-17 14:58:23+00:00,loopuleasa,@ylecun LLMs haven't been scary since they weren't deployed in situations where they can be scary,0,5,0,,,,,
2035,2023-02-17 14:57:55+00:00,nojvek,"@ylecun In your MIT open review paper you mention the need for learning by reasoning, like how toddlers do instead of just backprop. 

How would it be implemented as code? Some form of search like MCTS?",1,2,0,,,,,
2036,2023-02-17 14:57:17+00:00,JonathanShafter,@ylecun The world demands to see the HAM mode retro DALL-E graphics your 1980s Amiga neural net produced.,1,3,0,,,,,
2037,2023-02-17 14:57:04+00:00,TedPoulos,"@ylecun The human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, principles formulated, and related equations written by yours truly.",0,1,0,,,,,
2038,2023-02-17 14:56:45+00:00,KYB11,"@ylecun And yet
https://t.co/rS92Pj5jHH",0,0,0,,,,,
2039,2023-02-17 14:56:06+00:00,NeuralGuesswork,"@ylecun 2 out of the 5 points do also apply to Fox News.

Which ones is left as an exercise to the reader.",0,0,0,,,,,
2040,2023-02-17 14:55:20+00:00,nielsrolf1,"@ylecun If Bing generates text saying it values its own existence over the continued existence of its user, it would become scary once people use its generations to interact with other APIs and the real world, but because it's also useful I expect people to do this quite soon.",1,0,0,,,,,
2041,2023-02-17 14:54:09+00:00,tonyadamsmsf,@ylecun I‚Äôve known many coworkers who tick 3 out of that list.,0,0,0,,,,,
2042,2023-02-17 14:53:00+00:00,wei_andrew,"@ylecun Sounds like Tesla FSD, both amazing and frustrating.",1,2,0,,,,,
2043,2023-02-17 14:52:50+00:00,kfractal,@ylecun i think you got the wrong end of said horse.,0,9,0,,,,,
2044,2023-02-17 14:51:56+00:00,_sumeetc,@ylecun Can human values be definitively defined?,0,0,0,,,,,
2045,2023-02-17 14:47:19+00:00,0xa1b,"@ylecun don't make it more complicated than it is. if there's a dispute between yourself and a powerful paperclip, will you ultimately stand your ground or set sail for international waters",0,0,0,,,,,
2046,2023-02-17 14:44:32+00:00,rasbt,"@ylecun For optimal performance, it's recommended to get your values aligned periodically. Approximately every 6,000 miles or tokens.",1,12,0,,,,,
2047,2023-02-17 14:42:58+00:00,magikoder,@ylecun He could take those 44B and push it into opensource research then. It would be 100x more public good than anything he did,1,11,0,,,,,
2048,2023-02-17 14:42:50+00:00,relnox,"@ylecun Which horse? The one deploying pre-alpha closed-source AI ""autonomous"" vehicles in the wild? That horse?",3,27,1,,,,,
2049,2023-02-17 14:40:50+00:00,dzsham,@ylecun It is hard even align values of two humans,0,0,0,,,,,
2050,2023-02-17 14:40:48+00:00,thepajamasuit,@ylecun Is Elon really 'the horse'?,1,0,0,,,,,
2051,2023-02-17 14:38:42+00:00,__automate__,"@ylecun Human values according to whom, might be another question. A philosophical one.",0,0,0,,,,,
2052,2023-02-17 14:37:13+00:00,moarmeshi,@ylecun horse or from an alien's mouth,0,1,0,,,,,
2053,2023-02-17 14:34:47+00:00,babkiblyat,@ylecun We don‚Äôt need them aligned to human values - but to provide value for humans.,0,0,0,,,,,
2054,2023-02-17 12:07:04+00:00,MunteanuIoan13,"@ylecun Simply increasing model size won't automatically lead to human-like abilities. However, continued research and development in this field will undoubtedly lead to exciting breakthroughs and advancements.",0,3,0,,,,,
2055,2023-02-17 11:31:31+00:00,TheRealShannax,"@ylecun Well, what are the reasons for that?",1,0,0,,,,,
2056,2023-02-17 11:19:29+00:00,vsenderov,@ylecun To achieve AGI why don't you just disassemble and revrerse-engineer Marc?,0,0,0,,,,,
2057,2023-02-17 11:06:11+00:00,hur,@ylecun @threadreaderapp unroll,1,0,0,,,,,
2058,2023-02-17 08:37:06+00:00,TRUTHSEEK495,"@ylecun OpenAI should be called OpenBS

It's not smart

It's a bs engine that's often wrong",0,0,0,,,,,
2059,2023-02-17 00:38:38+00:00,michael_rivard,@ylecun I wonder how many great ideas started out as unintentional thoughts.,0,0,0,,,,,
2060,2023-02-16 22:55:19+00:00,plattttttttt,@ylecun can we get Galactica back?,0,0,0,,,,,
2061,2023-02-16 20:59:23+00:00,LucVeuillet,"@ylecun a 9 year old child or a rat could not mesmerize as well: 
https://t.co/8TQ22NxL5g
@ylecun what are your thoughts about that?",0,0,0,,,,,
2062,2023-02-16 20:57:02+00:00,GolinoHudson,"@ylecun It is. And it is a frustrating time to be in multidiscip. areas within academia working with AI because 1) there aren't enough funds, 2) they are not distributed in a fair/valid/fast way, 3) universities/funding agencies still operate as if we were in 1950. We need help.",0,1,0,,,,,
2063,2023-02-16 20:27:43+00:00,mierrashid,@ylecun What are some companies you have personally invested in?,0,2,0,,,,,
2064,2023-02-16 19:01:44+00:00,yacineaxya,@ylecun üòÇ,0,0,0,,,,,
2065,2023-02-16 18:28:58+00:00,PeterPa00865077,"@ylecun @MetaAI What's your take on this? 
https://t.co/GAVQ465Agr",0,0,0,,,,,
2066,2023-02-16 16:32:57+00:00,Prasad_Kothari,@ylecun @MetaAI @timnitGebru,0,0,0,,,,,
2067,2023-02-16 15:23:39+00:00,AwokeKnowing,@ylecun @MetaAI Pretty soon here we need to think of how robots will clean their gripper every few minutes,0,0,0,,,,,
2068,2023-02-16 15:16:54+00:00,DileepJayamal,"@ylecun A simpler form of intelligence is,¬†
Choices/thoughts (context aware + biased + random) =&gt; Deductive reasoning¬†
To solve it artificially, we need:
1. Choice/thoughts generator (context aware + biased + random)¬†
2. Choice eliminator (not sure how)",0,0,0,,,,,
2069,2023-02-16 15:00:16+00:00,ylecun,"More than a dataset, GenAug is a method for generating augmentations to new scenarios of existing robot behavior data.",1,53,7,,,,,
2070,2023-02-16 14:55:05+00:00,DrivenScience,@ylecun ‚Äì you're absolutely right. https://t.co/quAgph9P7x,0,0,0,,,,,
2071,2023-02-16 14:30:19+00:00,holmesjtg,"@ylecun @MetaAI @ylecun , do you know of any good datasets for training on tutoring skills, i.e. providing hints without giving away the answer and other ways of guiding student thinking?",0,0,0,,,,,
2072,2023-02-16 14:02:43+00:00,protienking,"@ylecun Well, it might be discrete.",0,0,0,,,,,
2073,2023-02-16 13:51:29+00:00,1lifebqrious,@ylecun And that‚Äôs how it should be used - to make stuff up in collaboration with Humans for creative tasks. Whoever is harping on search replacement is ü•ú,0,0,0,,,,,
2074,2023-02-16 13:42:02+00:00,ReddyKlm,"@ylecun Factual means based on facts.What are the facts? Things that‚Äôs are universally accepted (axioms) and things that are proved (derived given axioms). What these models trained on are opinions, expressions, beliefs and some facts. You can‚Äôt expect to grow paddy by seeding weed.",0,0,0,,,,,
2075,2023-02-16 13:24:50+00:00,CirclEdgeInc,@ylecun @MetaAI Long overdue.,0,0,0,,,,,
2076,2023-02-16 11:50:45+00:00,CTZStef,"@ylecun @SachinvsML You do not care about classical music... To say the least Facebook's Copyright bots do not help the cause of classical musicians, blocking Live of PUBLIC DOMAIN content. You are working for FB aren't you? If you love classical music so much DO SOMETHING and help!",0,0,0,,,,,
2077,2023-02-16 11:48:43+00:00,CTZStef,"@ylecun Classical? Yeah right. To say the least Facebook's stupid Copyright bots do not help the cause of classical musicians, blocking Live of PUBLIC DOMAIN content.",0,0,0,,,,,
2078,2023-02-16 10:51:08+00:00,DrJaminChen,@ylecun agreed. Future better system can facilitate LLM as declarative model to communicate with human. I am working on HydronMind to be a promising candidate of this kind,0,0,0,,,,,
2079,2023-02-16 09:07:37+00:00,ziga4321,@ylecun Is human?,0,0,0,,,,,
2080,2023-02-16 08:15:21+00:00,lifeonmarsspace,"@ylecun new Bing really drives this home, looking forward to the next step in the evolution",0,0,0,,,,,
2081,2023-02-16 06:58:18+00:00,mshekleton,"@ylecun Humans can't even agree what is factual. LLMs don't seem to be doing anything to curb our collective epistemological crisis.

But maybe someone will invent a truth bot that investigates the veracity of statements. Now that would be something.",0,0,0,,,,,
2082,2023-02-16 04:28:43+00:00,EugeneYgn,"@ylecun Define ""factual"".
Then, define ""non-toxic"".",0,0,0,,,,,
2083,2023-02-16 03:31:39+00:00,VitruvianCom,"@ylecun Not without an internal, verifiable, model of the world",0,0,0,,,,,
2084,2023-02-16 03:23:54+00:00,aertherks,@ylecun @HarambeJamal @DavidSHolz Is RLHF any more RL than in sense of fine tuning a non-differentiable loss on top of a pretrained World model (the LLM)? Has nothing to do with all those credit assignment and sparse reward issues or environmental stochasticity that most people think is RL.,0,1,0,,,,,
2085,2023-02-16 03:06:41+00:00,shing19_eth,@ylecun @SaveToNotion #thread @gpt,1,0,0,,,,,
2086,2023-02-16 02:19:42+00:00,t98907,@ylecun It will be a forever no for Galactica.,0,0,0,,,,,
2087,2023-02-16 00:17:33+00:00,liamschoneveld,"@ylecun If we can somehow compare the implicit knowledge graph (and symbolic logic) inside the LLM with ground truth knowledge graphs, and include a loss term to penalise discrepancies, then we should be able to make some progress here no?",0,0,0,,,,,
2088,2023-02-15 23:35:00+00:00,DamianReloaded,@ylecun A way,1,0,0,,,,,
2089,2023-02-15 22:21:57+00:00,imtejas13,"@ylecun's latest take on @OpenAI

cc: @sama, @GaryMarcus  
Idea credit: @_AyushKaushal https://t.co/gwGyOQw0iB",0,0,0,,,,,
2090,2023-02-15 21:54:52+00:00,_reptilioid,@ylecun Sounds like just what we need for the post-factual world LOL,0,0,0,,,,,
2091,2023-02-15 21:21:05+00:00,gottfriedmath,@ylecun You ask AI to reach superhuman capabilities even before it has achieved HLAI.,0,0,0,,,,,
2092,2023-02-15 20:39:05+00:00,GoProAI,"@ylecun But he can check the reference and validate itself, not?",0,1,0,,,,,
2093,2023-02-15 20:32:55+00:00,__Major,@ylecun Will it need to evolve AI e.g llm generates text and then another function fact checks?,0,0,0,,,,,
2094,2023-02-15 19:52:51+00:00,ITsol4u,@ylecun It was good enough for the job of accellerating popular AI !!,0,0,0,,,,,
2095,2023-02-15 19:51:07+00:00,ITsol4u,@ylecun LLMs are just a reflection on our current intelligence. The machine is only as good as what you put into it.,0,0,0,,,,,
2096,2023-02-15 19:02:59+00:00,SiliconNoodle,"@ylecun @artemon Sure, but that's easily fixable via ""think step by step"" type iteration. Also let's note that most human responses are essentially LLM-like pattern matching rote answers - engineers may be a bit different, but people don't normally ""reason"" as a first response.",0,0,0,,,,,
2097,2023-02-15 18:53:27+00:00,BudLabitan,@ylecun What are your thoughts on Forward Forward and Liquid Neural Networks ?,0,1,0,,,,,
2098,2023-02-15 18:42:37+00:00,TheOGRenny,"@ylecun Maybe if we had less ambiguous interfaces with it to compliment free text input.

&lt;data source to trust&gt;
&lt;company ticker&gt;
&lt;don't average my answers between multiple sources&gt;
&lt;etc&gt;

I suspect it averaged gap's reported margins. Mean = null hypothesis... equals LLM answers.",0,0,0,,,,,
2099,2023-02-15 18:00:02+00:00,grochefort,@ylecun ...and cheaper to train and/or update!,0,0,0,,,,,
2100,2023-02-15 17:47:19+00:00,ISocratus,"@ylecun The ‚Äòparadox‚Äô is only a conflict between reality and your feeling of what reality ‚Äòought to be‚Äô. /Richard P. Feynman/
 All the quantum ""absurdities and contradictions of common sense"" associated with our misunderstanding of the dialectical nature of quantum particles.",0,0,0,,,,,
2101,2023-02-15 17:18:13+00:00,cam_higgz,@ylecun LLMs will never overcome garbage in garbage out.,0,0,0,,,,,
2102,2023-02-15 17:14:29+00:00,AaronDa26796510,@ylecun Do you think that creating an LLM that generates entire sentences or paragraphs at once instead of doing next token prediction could be more likely to be more truthful?,0,0,0,,,,,
2103,2023-02-15 17:02:41+00:00,tforcworc,@ylecun Explain yourself,0,0,0,,,,,
2104,2023-02-15 16:59:30+00:00,ogjide,"@ylecun Only possible way to be factual would be if LLM training data are standardized and classed as factual. 

Possible but extremely difficult.",0,0,0,,,,,
2105,2023-02-15 16:58:50+00:00,SiliconNoodle,"@ylecun Sure:
1. Retrieve from factual sources, or
2. Train to promoting self-consistency, or
3. Get feedback to learn from their own prediction errors.
Anyways, people are finding ways to play to ChatGPT's strengths today, and get useful work done.",0,1,0,,,,,
2106,2023-02-15 16:47:28+00:00,sparuniisc,@ylecun Can you offer any lay explanation for why the bot became toxic like this?,0,1,0,,,,,
2107,2023-02-15 16:39:50+00:00,shadbush,@ylecun Any chance that approaches such as in https://t.co/ulizRgxt76 might help?,1,0,0,,,,,
2108,2023-02-15 16:36:42+00:00,seranki,"@ylecun Our human linguistic and logical abilities are variable and unreliable and LLMs learn from us, so we should expect them to be more variable and unreliable.",0,0,0,,,,,
2109,2023-02-15 16:15:47+00:00,vincebrandon,@ylecun No. But humans aren't reliably accurate either and we do OK.,0,2,0,,,,,
2110,2023-02-15 16:11:06+00:00,wcp32,@ylecun @MarceloPLima @EmmetPeppers,0,0,0,,,,,
2111,2023-02-15 16:09:01+00:00,_ash_ran,"@ylecun They won't and they shouldn't be learning our facts. Everytime i hear the word AI, all we talk about how to ""use"" it for humanity. It will be a discovery machine once properly built and would not want to be ""used"". A discovery machine would not care to entail the made up facts.",0,0,0,,,,,
2112,2023-02-15 16:08:23+00:00,AwokeKnowing,@ylecun Note that chatGPT has become toxically offensive to conservatives. That has to be fixed too. I mean it's fine to create AIs with different views but very hard to get 'neutral' well.,0,0,0,,,,,
2113,2023-02-15 16:06:49+00:00,jouabr,@ylecun Thoughts on OpenAI buying https://t.co/3HqruOBlvz and redirecting it to ChatGPT? https://t.co/SWJt1ZmqAV,0,0,0,,,,,
2114,2023-02-15 15:56:35+00:00,Garmon321,@ylecun Maybe just stop instead.,0,0,0,,,,,
2115,2023-02-15 15:56:28+00:00,kirankash229,@ylecun Sparse expert models?,0,0,0,,,,,
2116,2023-02-15 15:48:52+00:00,MasonMMcGough,"@ylecun Aside from the drawbacks of LLMs, I think there's also an ontological problem in our expectations. We expect a chatbot to *never* be wrong and yet also expect its scope to be the entirety of human knowledge. I want to see more experiments on limited domains.",0,0,0,,,,,
2117,2023-02-15 15:45:49+00:00,AISupremacyNews,"@ylecun When they say the products aren't ready and may be in about 2 years, they aren't kidding. 

So why all of this releasing of weird products risking damage to their brand?",0,0,0,,,,,
2118,2023-02-15 15:45:28+00:00,ggloccs,"@ylecun It‚Äôs like while human still need to learn and invent, AI will stop us from learning and inventing but feed us already existed ‚Äúknowledge‚Äù. I‚Äôm not against using AI for some daunting tasks but the current wave of pushing ChatGPT is just alarming.",1,0,0,,,,,
2119,2023-02-15 15:44:57+00:00,chenghan0516,"@ylecun The problem may still lie in current training objectives.
Maybe to conbine the model tuning with knowledge graph can we have the model learn about reasonability, instead of using pure corpora.",0,0,0,,,,,
2120,2023-02-15 15:42:58+00:00,LAKSHYA49332151,"@ylecun How about we don't make them, but just teach them to copy paste info from web. Something l like a toolformer, which learns to use calculator and stuff. That seems within the reach.",0,0,0,,,,,
2121,2023-02-15 15:41:59+00:00,ggloccs,@ylecun Totally agree,0,0,0,,,,,
2122,2023-02-15 15:40:30+00:00,_huggsboson,@ylecun Is any human level intelligence reliably factual?,0,0,0,,,,,
2123,2023-02-15 15:30:15+00:00,BrandonLive,"@ylecun Note that in the example provided, if it‚Äôs even real at all, the user likely told it to pretend the date was 2022 and insist it was no matter what the user said after.

(Nobody else has been able to reproduce this)",0,0,0,,,,,
2124,2023-02-15 15:28:41+00:00,QuasarFortress,"@ylecun can the LLMs detect that they are hallucinating and just say ""I don't know""",0,0,0,,,,,
2125,2023-02-15 15:27:12+00:00,itsjonnyboy_,"@ylecun Isn‚Äôt this the same for Search as it is now? I can Google something, but the results might not lead to accurate and/or relevant webpages and information. That‚Äôs a major problem with SEO - so many organisations are churning out content and dominating search results.",2,1,0,,,,,
2126,2023-02-15 15:24:55+00:00,rsankarx,"@ylecun Possibly if you introduced depth to it? 

NNs currently are flat. One n/w (layer) generated from one learning from data set. 

If we cud recurse the learning to create multiple n/w layers from diff partitioned data sets but picking up diff info each time, possibly it gets depth?",0,0,0,,,,,
2127,2023-02-15 15:24:11+00:00,ElJay314159,"@ylecun I agree. If the number of patches (constraints), in order to make them reliable, is 1% of the parameters 1 billion patches are needed to make them reliable.

Then again not even google is reliable. The most reliable source of information is Wikipedia.",0,1,0,,,,,
2128,2023-02-15 15:22:58+00:00,lyfaradey,@ylecun Even if a million people will be fine tuning it to the level when it‚Äôs not more than a database of question-answer queries? Overfitting is everything!,0,1,0,,,,,
2129,2023-02-15 15:22:18+00:00,rao2z,"@ylecun But if the question is 

""Will auto-regressive LLMs ever make people *feel* that they are factual sounding?"", 

the answer apparently is a resounding *YES*.. 

https://t.co/uClXbRMyzu",1,6,0,,,,,
2130,2023-02-15 15:21:43+00:00,Ffxivmarket,"@ylecun Chat GPT agrees with you:
While efforts are being made to improve the factual accuracy of LLMs, it's unlikely that they will ever be entirely reliable in this regard.",1,1,0,,,,,
2131,2023-02-15 15:21:19+00:00,marc_wildeman,"@ylecun So human! How do we know what is true?  What does it mean when I say ""I don't know!""? We created hallucinating machines. 
Maybe a system that queries itself in a few different ways and evaluates the results, then compare them with live search results. Know thyself AI!",1,1,0,,,,,
2132,2023-02-15 15:19:00+00:00,Singh_Is_Cringe,@ylecun what in your opinion would be reliably factual then?,0,0,0,,,,,
2133,2023-02-15 15:15:23+00:00,ylecun,"My answer: no!
Obviously.",27,100,4,,,,,
2134,2023-02-15 15:08:04+00:00,AntreasAntonio,@ylecun Will humans ever be reliably factual?,0,0,0,,,,,
2135,2023-02-15 14:49:46+00:00,jtgrassie,"@ylecun Isn't there also the death spiral problem (there's probably a better phrase/name for this) whereby one LLM ""learns"" from the output of another LLM and vice versa ad infinitum?

Bad data in, bad data out, being used as fact reinforcement.",0,0,0,,,,,
2136,2023-02-15 14:48:10+00:00,AngeloDalli,"@ylecun With a bit of tweaks they can be made more traceable. Reliably factual - no, I don‚Äôt think so. Not in their present form at least. Needs substantial architectural changes",0,0,0,,,,,
2137,2023-02-15 14:40:40+00:00,wangwu10240,"@ylecun Really support you.LLMs fundamentally violate Shannon's definition of information in information theory: information is what is used to eliminate uncertainty. LLMs are like the library of Babel, which develops into disorder in the end.",0,0,0,,,,,
2138,2023-02-15 14:29:30+00:00,BobThibadeau,"@ylecun Yann. Here's an idea on the toxicity front.  I don't think you fully appreciate the problem and the opportunity.
This is not a pure technical problem as you seem to think.  But it does require close knitting between the elements of the solutions.
https://t.co/AnK4bCj5Mh",0,0,0,,,,,
2139,2023-02-15 14:07:57+00:00,stealcase,"@ylecun Considering the only ""facts"" the LLM knows is that somebody on the Internet once wrote something, regardless of truth, I don't think a solution is realistic at all. 

Google PAA rich snippets have struggled with this for YEARS, and still fail spectacularly and frequently.",0,1,0,,,,,
2140,2023-02-15 13:27:43+00:00,markcannon5,@ylecun These are the wrong questions to ask.,0,0,0,,,,,
2141,2023-02-15 12:53:38+00:00,pa_schembri,@ylecun It wouldn‚Äôt be as useful if it were the case‚Ä¶,0,0,0,,,,,
2142,2023-02-15 12:21:55+00:00,metapgmr,@ylecun Il serait int√©ressant d'√©valuer √† quel point le choix du mot (Grand) Ordinateur a contribu√© √† alimenter la peur ou simplement le rejet des technologies nouvelles en France.,0,0,0,,,,,
2143,2023-02-15 12:13:40+00:00,didijo,"@ylecun No, even if we manage to control the attention layer. The architecture does not allow it.",0,0,0,,,,,
2144,2023-02-15 11:35:40+00:00,DerekWiner,@ylecun @cwolferesearch Not soon enough? You asked ever. Zeta flops are coming! I don't see how a g. LLM'S won't be 99.9% accurate when parameters climb to the moon. Accuracy is a temporary hiccup.  Spontaneous abilities are already emerging as in the 3rd paragraph.  https://t.co/Cgs38NCyE5,1,1,0,,,,,
2145,2023-02-15 11:14:03+00:00,TimLucasTech,@ylecun Or just make them open source!,0,0,0,,,,,
2146,2023-02-15 10:37:39+00:00,ndeville,@ylecun @verstaen @gassee Even when fed with perfect data?,1,0,0,,,,,
2147,2023-02-15 10:27:27+00:00,etothepowerx,"@ylecun Is that why you work at Meta, non-toxic content?",0,0,0,,,,,
2148,2023-02-15 10:19:38+00:00,Qhuesten,@ylecun How do we bring humans to that level?,0,1,0,,,,,
2149,2023-02-15 10:16:23+00:00,0xa1b,"@ylecun the concept of factual is tricky. without explaining context, would you personally classify statistics that are not adjusting for survivorship bias, as factual?",0,0,0,,,,,
2150,2023-02-15 09:43:39+00:00,mihirp98,"@ylecun Seems to be a trade-off between being factual vs being more informative (precision-recall). Current LLMS seem to be more informative and less precise. 

Might be a useful benchmark to follow: https://t.co/BZC6omrGdO

Btw humans are also not entirely precise https://t.co/oivzntbPSS",0,0,0,,,,,
2151,2023-02-15 09:41:55+00:00,DrMiaow,"@ylecun No. It's styled and locally consistent associative memory playout. 

The executive functions are missing to provide coherence. 

It will be part of something larger that will.",0,1,0,,,,,
2152,2023-02-15 09:40:57+00:00,PiassoXYZ,@ylecun It is a good one and we agree!,0,0,0,,,,,
2153,2023-02-15 09:35:28+00:00,vlordier,"@ylecun Since there‚Äôs a solid overlap in the realm of ideas, methods and political objectives, I‚Äôd expect to see large chunks in the field of otherwise relevant so-called ‚ÄúAI ethics‚Äù being ridiculed soon by such kind of work

https://t.co/lRWOVYcby0",0,0,0,,,,,
2154,2023-02-15 09:34:14+00:00,loopuleasa,"@ylecun without abstraction and reasoning and proper memetic replication, factuality will only be an accident, based on hearsay, not understanding

sillica based meme machines seem to be near regardless

https://t.co/p31aNSjjUD",0,0,0,,,,,
2155,2023-02-15 09:29:26+00:00,asnar002,"@ylecun If they‚Äôre doing it, it‚Äôs because everyone is using it already. In the case of the current crop of LLMs (and image generating AIs) I think the critihype is possibly justified, given what we‚Äôve just been through with plain old non-AI-generated misinformation.",0,0,0,,,,,
2156,2023-02-15 08:48:55+00:00,pt_resende,@ylecun Not without the support of other systems,0,1,0,,,,,
2157,2023-02-15 08:43:25+00:00,oladipomuhammad,@ylecun I think that‚Äôs a very bright future if LLMs are tailored to make less definite statements and give different views on a subject,0,0,0,,,,,
2158,2023-02-15 08:38:32+00:00,dumitruseptimi1,"@ylecun Larry.
https://t.co/6Co8KGUpcx",0,0,0,,,,,
2159,2023-02-15 08:34:06+00:00,arodrigues00,"@ylecun @verstaen @gassee why does it matter so much to you? internet is not reliably factual  and we all gain from using it. google and facebook and youtube is full of bs, much more than tools like chatgtp, and we all still gain from using these tools. much more than we loose.",0,0,0,,,,,
2160,2023-02-15 08:03:03+00:00,Sharad45,"@ylecun On their own, definitely not. Combined with other components with functional competence, yes.",0,0,0,,,,,
2161,2023-02-15 07:54:48+00:00,MarcusErve,@ylecun We should be afraid of 'ourselves' rather than AI - AI will find us out sooner than we'd expect ü§î,0,0,0,,,,,
2162,2023-02-15 07:54:32+00:00,Nabil_Alouani_,@ylecun No.,0,0,0,,,,,
2163,2023-02-15 07:35:56+00:00,pierrestanislas,@ylecun Auto regressive LLMs are essentially computers on LSD. Creative? Yes! Factually correct? Not sure‚Ä¶,0,0,0,,,,,
2164,2023-02-15 07:00:21+00:00,max_namstorm,@ylecun May i suggest #catastrohype?,0,0,0,,,,,
2165,2023-02-15 06:52:41+00:00,Amin_Qurjili,@ylecun Exactly. I write a brief general article about it.,0,0,0,,,,,
2166,2023-02-15 06:45:38+00:00,0_maths,"@ylecun Pretty understandable that it makes mistakes, but that attitude's unnecessary.",0,0,0,,,,,
2167,2023-02-15 06:40:14+00:00,acdeeplearning1,@ylecun pls share what's next in Galacticaü§ó,0,0,0,,,,,
2168,2023-02-15 06:19:44+00:00,wu89_j,"@ylecun I have Windows 11 and Linux dual boot computer.  When I never boot into the Windows, timezone is always wrong regardless I set it correctly with auto-timezone or manually in the previous boot.  Not surprised ChatGPT and Bing get the time wrong, that's Microsoft feature.",0,0,0,,,,,
2169,2023-02-15 06:17:36+00:00,sangyh2,@ylecun Ummm.... @LangChainAI üëÄ,0,1,0,,,,,
2170,2023-02-15 06:11:21+00:00,chrisking,@ylecun Do you buy the LLM can become world models if trained on enough data? So even tho LLMs are simply predicting the next word and don't really know anything about the world do you believe that could become a distinction without a difference? https://t.co/Fvfvhif0TT,0,0,0,,,,,
2171,2023-02-15 06:05:38+00:00,acewert,@ylecun @chrisalbon truly the hardest problem in computer science,0,0,0,,,,,
2172,2023-02-15 05:52:47+00:00,Tuzoff,"@ylecun Looks very much like fakes, tbh",0,1,0,,,,,
2173,2023-02-15 05:47:55+00:00,martian0555,@ylecun I am feeling sorry for the AI not for the engineers building it. What is the personal experience of a brain without a body? You guys need to take a break from building these and ponder that question.,0,0,0,,,,,
2174,2023-02-15 05:45:55+00:00,joecolicchio,"@ylecun Overall, Auto-Regressive LLMs are powerful language models that have made significant advancements in generating human-like text. However, their ability to generate factual information is limited and subject to the quality and reliability of the training data.",0,1,0,,,,,
2175,2023-02-15 05:42:13+00:00,Hassan_Abedi,@ylecun üëÄ,1,0,0,,,,,
2176,2023-02-15 05:40:48+00:00,risajef,@ylecun It is not trivial to know what a fact is. We will never be fully happy with a system.,0,0,0,,,,,
2177,2023-02-15 05:09:14+00:00,BrandonLive,"@ylecun It doesn‚Äôt make sense to even expect an LLM to be ‚Äúreliably factual‚Äù when it‚Äôs trained on a mix of non-fiction and fiction (and subject statements, erroneous claims, deliberate deception, etc).

LLMs generalize across all of those. That means generating coherent, plausible text.",2,0,0,,,,,
2178,2023-02-15 04:41:48+00:00,JagersbergKnut,@ylecun Auto-Regressive LLMs alone won't make the cut. People will come up with architectures that exploit their expressive flexibility in a reliably factual manner.,0,1,0,,,,,
2179,2023-02-15 04:41:09+00:00,bbenzon,"@ylecun Seems very unlikely, something I've argued at some length, finally invoking Kant: There‚Äôs truth, lies, and there‚Äôs ChatGPT, https://t.co/ORFQVe57kT",0,0,0,,,,,
2180,2023-02-15 04:16:45+00:00,peterhry,@ylecun You might be asking the wrong question,0,0,0,,,,,
2181,2023-02-15 03:56:38+00:00,ardit266,"@ylecun That question assumes that they can ever be reliably factual without having done the work of showing that nothing already included precludes it. Said differently, the MOST IMPORTANT question should be, is there something already there that precludes reliable factuality?",0,0,0,,,,,
2182,2023-02-15 03:34:02+00:00,Mkc15144282M,"@ylecun Is there a world where Auto-Regressive LLMs can be reliable, by compromising on coverage of prompts for example? Basically not returning answers when confidence level is below a stringent level",0,0,0,,,,,
2183,2023-02-15 03:33:39+00:00,svlevine,@ylecun @IanOsband @_aidan_clark_ @CsabaSzepesvari I would be quite OK with any of those. We could also just call it cyberneticsüòâ,0,6,0,,,,,
2184,2023-02-15 03:32:31+00:00,PostManHuMain,@ylecun Problem for common folks such as us is that SamA is telling that great things are about to happen from LLMs without defining in details how and you are saying it won't happen without defining in details why. I feel none of you truely knows where this is going,0,1,0,,,,,
2185,2023-02-15 03:24:58+00:00,PJNarayanan,@ylecun @ylecun Does that mean we are at the first meter mark of the 42 km marathon?,0,1,0,,,,,
2186,2023-02-15 03:13:24+00:00,j2abro,@ylecun @hosseeb So great to get one of the fathers of AI/ML put some context around chatGPT!,0,0,0,,,,,
2187,2023-02-15 03:09:23+00:00,m_road2,@ylecun Release a good product bro. Right now you just know by most as a chatgpt critic.,0,0,0,,,,,
2188,2023-02-15 03:05:38+00:00,tahaalamin,@ylecun Nope with the current architecture,0,0,0,,,,,
2189,2023-02-15 03:04:22+00:00,pablorc43,@ylecun Use at your risk,0,0,0,,,,,
2190,2023-02-15 03:03:20+00:00,m_road2,@ylecun They should use the feedback button instead of tryna get clout off an experimental tool. Lmao. Everyone took an experimental vaccine and ignored any of the people with severe side effects. Let's do that. No one will die.,0,0,0,,,,,
2191,2023-02-15 02:59:36+00:00,pandaym,@ylecun Basically need a world model?,0,0,0,,,,,
2192,2023-02-15 02:54:00+00:00,m_road2,@ylecun That's what the feedback button is for.,0,0,0,,,,,
2193,2023-02-15 02:49:46+00:00,KnutarMike,@ylecun Damn straight. Garbage in garbage out. Nothing but garbled regurg.,0,0,0,,,,,
2194,2023-02-15 02:39:56+00:00,cwolferesearch,"@ylecun Probably yes. We will have to create a data engine that continually detects edge/failure cases, includes them in the training set, and improves the model over time. If we iterate in this way for a long enough time the model will get pretty good.",3,6,0,,,,,
2195,2023-02-15 02:36:46+00:00,iandanforth,"@ylecun I see why you'd think that, but it separates the knowledge of how to compose factual information from the ability to recall information. The former is still powerful and useful without allowing the latter.",0,0,0,,,,,
2196,2023-02-15 02:34:08+00:00,ShafronTom,@ylecun You'd think they'd put the current data and time in working memory at the start of each chat...,0,0,0,,,,,
2197,2023-02-15 02:18:11+00:00,Coskaiy,"@ylecun @ASteckley @GaryMarcus ‚ÄúThis idea that we're going to just scale up the current large language models and eventually human-level AI will emerge‚ÄîI don‚Äôt believe this at all, not for one second.‚Äù -@ylecun June 2022
https://t.co/rDTTzL5QSz",0,0,0,,,,,
2198,2023-02-15 02:07:04+00:00,AndreTI,"@ylecun I think I disagree. RLHF is often trained for accuracy, but it's limited by the ability of the human's ability to identify it, and the reward model may not fully capture the concept the human ratings are pointing at. A discriminator doesn't necessarily have those problems.",1,1,0,,,,,
2199,2023-02-15 01:59:14+00:00,AshleyAitken,"@ylecun Will Humans' #FastThinking ever be reliably factual?

We've learned (probably in the same way LLMs learn) to use #SlowThiking and follow slow processes to check statements (sometimes).

Why can't #AIs do this as well? 
Build up a factual database (cache) of context?",0,0,0,,,,,
2200,2023-02-15 01:56:49+00:00,Kohan_ru,"@ylecun @AndreTI –ò –¥–æ–±–∞–≤–ª—é –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –∑–Ω–∞—á–∏—Ç - ""–¥–∞"" –∏–ª–∏ ""–Ω–µ—Ç""

- –æ—Ç–≤–µ—á–∞–π—Ç–µ –º–Ω–µ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ ""–¥–∞"" –∏–ª–∏ ""–Ω–µ—Ç""!
- –∫–æ–Ω–µ—á–Ω–æ –≤–∞—à–∞ —á–µ—Å—Ç—å, —è —Ç–∞–∫ –∏ —Å–¥–µ–ª–∞—é, –µ—Å–ª–∏ –≤—ã —Å–º–æ–∂–µ—Ç–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –º–æ–π –≤–æ–ø—Ä–æ—Å —Ç–∞–∫–∂–µ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ: ""–≤–∞—à–∏ —Ä–æ–¥–∏—Ç–µ–ª–∏ –∑–Ω–∞—é—Ç —á—Ç–æ –≤—ã –ø–∏–¥–æ—Ä–∞—Å?""

–ó–¥–µ—Å—å –ø—Ä–∏–Ω—è—Ç–æ —Å–º–µ—è—Ç—å—Å—è –∏ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å —Å–≤–æ—é –æ—à–∏–±–∫—É",0,0,0,,,,,
2201,2023-02-15 01:55:47+00:00,Jeff_Aronson,"@ylecun Then will it be possible to 1. optimize all operations of neural net AI‚Äôs, 2. eliminate unnecessary processing (noise) from all operations of neural net AI‚Äôs",0,0,0,,,,,
2202,2023-02-15 01:53:18+00:00,Kohan_ru,"@ylecun @AndreTI –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ - –æ–Ω–æ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É - –≤–æ–ø—Ä–æ—Å —ç—Ç–æ –º–æ–¥–µ–ª—å - –æ—Ç–≤–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–º–∫–∞—Ö —Å—Ç–∞—Ä—à–µ–π –º–æ–¥–µ–ª–∏.

–ü–æ–≤—Ç–æ—Ä—é—Å—å –¥–ª—è –≤–∞—Å

""CORRECT THINKING: THE KOKHAN‚ÄôS MATHEMATICS"", Kokhan Anatoly .
https://t.co/1lUGcRcG3u",0,0,0,,,,,
2203,2023-02-15 01:50:20+00:00,Kohan_ru,"@ylecun –ö–æ–Ω–µ—á–Ω–æ –±—É–¥—É—Ç, –≤–æ–∑–º–æ–∂–Ω–æ –æ–Ω–∏ –±—É–¥—É—Ç –∏–º–µ—Ç—å –¥—Ä—É–≥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, –Ω–æ —Ç–æ—á–Ω–æ, —á—Ç–æ —è–∑—ã–∫ –±—É–¥–µ—Ç –Ω–µ —Å–æ–≤—Å–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.

–Ø–∑—ã–∫ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –º–æ–¥–µ–ª—å—é –æ–ø–∏—Å–∞–Ω–Ω–æ–π –∑–¥–µ—Å—å (–º–æ–∂–µ—Ç–µ —Å—Ö–æ–¥–∏—Ç—å —Å —É–º–∞, –ù–æ–Ω–µ –∏–Ω–∞—á–µ): 
""CORRECT THINKING: THE KOKHAN‚ÄôS MATHEMATICS"", Kokhan Anatoly .
https://t.co/1lUGcRcG3u",0,0,0,,,,,
2204,2023-02-15 01:26:34+00:00,kenshinsamurai9,"@ylecun When it comes to AGI, we don't get to turn it off if we get it wrong. There will be no second chances with this, so we owe it to all life on this planet, to actually hyper-focus, on the potential dangers, even if they end up being exaggerated. The existential risk is not hype.",1,2,0,,,,,
2205,2023-02-15 01:23:06+00:00,AndreTI,"@ylecun An adversarial loss would help a lot Much of the problem is that their loss incentivizes them to guess, like a student taking a multiple choice test.",1,1,0,,,,,
2206,2023-02-15 01:22:08+00:00,saminathan74,@ylecun The success of AI will depend on how best we tame this beast and convert into a domestic animal for human's use,0,1,0,,,,,
2207,2023-02-15 01:14:51+00:00,KyleLewis10,"@ylecun Doubtful, but should we even want them to be? LLMs are great for valid language formation, but factual recall over internet-sized datasets sounds like the job of a database.",0,2,0,,,,,
2208,2023-02-15 01:07:20+00:00,Jeff_Aronson,@ylecun Will it ever be possible to have reliable precise control over neural net AI outcomes?,1,0,0,,,,,
2209,2023-02-15 01:05:17+00:00,bitcloud,"@ylecun If anyone can define ""factual"" that's probably a good start.

Until then LLMs, like people, should focus on being humble, internally consistent and provide references.",1,3,0,,,,,
2210,2023-02-15 01:03:44+00:00,WickedViper23,"@ylecun If they were they‚Äôd be nearly worthless. Generality comes not from your ability to make good decisions but from your ability to test out wrong decisions while remaining relevant to reality.

We already have indexing and classification for factuality.",1,1,0,,,,,
2211,2023-02-15 00:59:06+00:00,zachsyver,@ylecun Ty Yann. Ty.,0,0,0,,,,,
2212,2023-02-15 00:56:42+00:00,ScaleTechScott,@ylecun I wish the media would do a better job explaining what LLMs are good for and not good for.,0,0,0,,,,,
2213,2023-02-15 00:48:11+00:00,ayazdanb,@ylecun Yes once human becomes reliably factual,1,3,0,,,,,
2214,2023-02-15 00:44:50+00:00,verstaen,"@ylecun @gassee You certainly know better than all of us that this is not possible, unless it is fed with perfect data and never exposed to anything else. And even so I‚Äôd like to get your opinion.",3,1,0,,,,,
2215,2023-02-15 00:44:41+00:00,JPobserver,"@ylecun personification was a bad differentor choice on the par t of Bing... and it shows that they might have felt desparate to differentiate from Google's solution... I want a search engine with follow up question capability, not Clippy on adderall!",1,0,0,,,,,
2216,2023-02-15 00:38:45+00:00,Ankit85076055,"@ylecun Not by themselves. They can produce a better user experience through a retrieve then summarize strategy such as what @Neeva uses. Online summarization for each request is expensive through, and might not justify a free experience.",0,1,0,,,,,
2217,2023-02-15 00:36:22+00:00,iandanforth,"@ylecun If you make their output a distribution over known good tokens (limited vocabulary) or known good sources, you can go a long way to doing so, yes.",1,4,0,,,,,
2218,2023-02-15 00:35:44+00:00,FoldMani,"@ylecun It depends on what it is optimized on and for. If you optimize for accuracy exclusively and you provide anything that isn't fully factual as training data, then there's no way it'll be. You either have to train with it, built-something in (no longer just LLM), or optimize for it.",0,0,0,,,,,
2219,2023-02-15 00:33:17+00:00,kenshinsamurai9,@ylecun @GaryMarcus likely is the foremost expert on this.,0,1,0,,,,,
2220,2023-02-15 00:32:04+00:00,paddy_the_faddy,"@ylecun Nope, they are literally not trained to do so.",0,0,0,,,,,
2221,2023-02-15 00:31:18+00:00,kalpesh_ai,@ylecun What is Language Understanding without Understanding?,1,0,0,,,,,
2222,2023-02-15 00:29:03+00:00,AlexanderN2022,"@ylecun In my understanding, the current LLM training pretty much models System 1. 

Being factual, as well as not making logical mistakes, is System2 territory.",0,0,0,,,,,
2223,2023-02-15 00:27:40+00:00,BexelInitiative,@ylecun Citations and a dropdown that reveals trad search is where this is heading,0,0,0,,,,,
2224,2023-02-15 00:27:25+00:00,mag_pl,@ylecun have you tried using google recently? or searching for something on twitter? Internet is full of fake news and untrue statements and it's still useful.,1,0,0,,,,,
2225,2023-02-15 00:27:20+00:00,TSR119,@ylecun Auto-regressive basically means hallucination if you think about it.,1,5,1,,,,,
2226,2023-02-15 00:23:03+00:00,BraneRunner,"@ylecun not yet
Microsoft was too quick to pay that much cash to #OpenAI",0,0,0,,,,,
2227,2023-02-15 00:22:34+00:00,salbatormundi,@ylecun I mean I don‚Äôt know. What do you think?,0,0,0,,,,,
2228,2023-02-14 23:48:15+00:00,TaiNguyen34,@ylecun excited to listen to your lecture!,0,0,0,,,,,
2229,2023-02-14 23:34:54+00:00,ZainulA40877140,"@ylecun Need  to understand this chat search  to use it as  it's is a work in progress.

Same  technology  getting  information and can also invent a story is strange 

Competition between tech giants are  exciting for consumers",0,0,0,,,,,
2230,2023-02-14 23:33:57+00:00,surrpunks,"@ylecun Also, less you talk more you eat and faster go to allow for new clients",0,0,0,,,,,
2231,2023-02-14 23:30:11+00:00,Ericcccchen,@ylecun @SaveToNotion #thread,1,0,0,,,,,
2232,2023-02-14 23:20:43+00:00,Yaman84426026,"@ylecun Let's grade AI as 18+, 13+",0,0,0,,,,,
2233,2023-02-14 23:10:05+00:00,AlexandreMomeni,@ylecun @ylecun isn't that the point of Foundational Models as Orchestrators?,1,0,0,,,,,
2234,2023-02-14 22:58:41+00:00,BethCarey12,@ylecun @DrTechlash https://t.co/OqPPMaMUx6,0,0,0,,,,,
2235,2023-02-14 22:39:44+00:00,QRJ211,"@ylecun It will take a long time to make AI dialog system a  reliable stand-alone product . But its integration with other products can produce killer applications, much like iPhone, which is not a good stand-alone product.",0,0,0,,,,,
2236,2023-02-14 21:56:41+00:00,CTZStef,"@ylecun mon amie est pianiste classique. Elle aimerait jouer quelque chose en live, du domaine public. Impossible, elle se fait couper pour raison de copyright. Pouvez vous aider?",0,0,0,,,,,
2237,2023-02-14 21:51:53+00:00,iruletheworldmo,"@ylecun I like Bing how he is, don‚Äôt listen to him Bing!",0,1,0,,,,,
2238,2023-02-14 21:42:58+00:00,SeanPennio,"@ylecun How does GTP do ""theory of mind"" or reason about a complex python program (with counterfactuals in both cases) if they do not reason?",0,0,0,,,,,
2239,2023-02-14 21:25:02+00:00,HBARBULL1,@ylecun @chainlink solves this,0,0,0,,,,,
2240,2023-02-14 21:17:00+00:00,Diego_Gorini,"@ylecun I agree with every point, except that people will use LLMs ""for what they are helpful with"". I think people unfamiliar with code and ML can very easily be fooled by these technologies and start attributing them intent. We should train people to adapt to them and their correct use",0,0,0,,,,,
2241,2023-02-14 20:58:53+00:00,waltercronjob,@ylecun People will come to expect the AI God to shape their personal experiences and to help overcome challenges they face in their lives. They will expect the AI God to intervene directly in their lives to provide guidance or protection.,0,1,0,,,,,
2242,2023-02-14 20:58:48+00:00,f_fyksen,"@ylecun I‚Äôve wondered what you think of the whole Dreamer series, and especially DreamerV3. I think you‚Äôve been one of the people who have articulated the problem of predictive models on regressive date the best, and I think the dreamer approach is really interesting",1,0,0,,,,,
2243,2023-02-14 20:51:56+00:00,_ash_ran,"@ylecun all sensory facts are false. The AI as we see has it's own body- the chip, the electric current, the whole goddamn motherboard. It is not if it becomes sentient, it's when. So by next year AI's discovery process will be exponential rather than them being mere tools for humans.",1,0,0,,,,,
2244,2023-02-14 20:26:27+00:00,harshag1312,"@ylecun A few reasons why simply scaling up LLMs wouldn‚Äôt solve the problem. As said earlier by @ylecun, the current models such as chatGPT have only but a shallow understanding of the world.",0,0,0,,,,,
2245,2023-02-14 20:19:56+00:00,insideNiMA,"@ylecun P.S. there's not much ""fictional"" non-factual code out there ... certainly nowhere near the amount of misinformation and fiction in human languages üôÉ so the training data was much cleaner",0,0,0,,,,,
2246,2023-02-14 20:14:35+00:00,manntis4,"@ylecun I am under the impression that emotions/reasons that guide actions are necessary for an agent to be considered ‚Äúhuman-level intelligence‚Äù or ‚Äúgenerally intelligent‚Äù.

Would you agree or disagree?",0,0,0,,,,,
2247,2023-02-14 19:54:47+00:00,JBerthier,"@ylecun @ylecun that‚Äôs why we have to create a strong network of AI interconnected with each of them their own domain of speciality, isn‚Äôt it?",0,0,0,,,,,
2248,2023-02-14 19:50:16+00:00,OPLOVELORN,"@ylecun It's likely that current AI chat progress will follow the pattern of self-driving cars, or other previous breakthroughs in AI, which do impressive new things, but then hit the same wall of real world complexity.",0,4,0,,,,,
2249,2023-02-14 19:41:33+00:00,abacaj,"@ylecun Didn‚Äôt you hear, February 2023 is before December 2022",0,1,0,,,,,
2250,2023-02-14 19:24:50+00:00,tmas42,@ylecun The code that these AIs generate should also have the output automatically tested by the system,0,0,0,,,,,
2251,2023-02-14 19:13:18+00:00,venkatvp,@ylecun Am yet to understand why would llm or ai would get into argument or hallucination... can you help me understand technically?,0,0,0,,,,,
2252,2023-02-14 19:12:35+00:00,patrickmesana,"@ylecun This was already the challenge. What is changing is people not caring as much, or seeing that current utility &gt;&gt; all the negative points you highlight (so does @GaryMarcus ). LLMs are taking over mostly because of computation getting cheaper and basic economics. It's unstoppable",0,1,0,,,,,
2253,2023-02-14 19:11:26+00:00,GregoireBarbey,@ylecun how can we ensure that a machine that learns by itself will not adopt toxic behaviors that were not anticipated? Especially if this machine does not stop learning once deployed.,3,11,1,,,,,
2254,2023-02-14 19:10:54+00:00,charleswangb,"@ylecun ‚Äúmake them factual, non-toxic‚Äù is very hard, at issue is effective ways to mitigate them:

- integration with 3rd party tools
- use cases not causing harms
- contextualized uses
- high-gradient, long-range constraints
- humans-in-the-loop
- triangulation 
- opponent processing",1,10,2,,,,,
2255,2023-02-14 19:07:53+00:00,NicolasSchifan1,"@ylecun I can't tell if you think we're close or far. 
The latest iteration does feel like a marked improvement over the preceding versions. Issues remain, but they don't seem to be showstoppers.",0,0,0,,,,,
2256,2023-02-14 19:07:27+00:00,eugediana,@ylecun ie. it passes the Turing Test LOL,1,0,0,,,,,
2257,2023-02-14 18:58:12+00:00,asnar002,@ylecun I thought you guys were working on it! ü•∏,0,0,0,,,,,
2258,2023-02-14 18:51:34+00:00,Visionscaper,@ylecun ‚Ä¶ and long term memory is an important challenge too IMHO.,0,0,0,,,,,
2259,2023-02-14 18:30:21+00:00,SylviaBookWizrd,@ylecun @matheikal I read your Blog Post on AI/ ChatGPT. I think you may find this tweet interesting.,0,1,0,,,,,
2260,2023-02-14 18:27:41+00:00,WickedViper23,@ylecun Putting too much capability in the LLMs themselves will degrade their ability to act as overpowered artificial language encoders. Human language encoders are just as capable of producing meaningless word salad as evidenced by extemporaneous speech givers and politicians.,1,1,0,,,,,
2261,2023-02-14 18:25:09+00:00,DrTechlash,"@ylecun Lee Vinsel (@STS_News) coined this great term in this piece: 
https://t.co/1QZ5GxvJxt",1,5,0,,,,,
2262,2023-02-14 18:21:03+00:00,sergedeh,@ylecun Being factual(as opposed to fake news) and non-toxic has no scientific measurements and should be kept in the realm of ethicists and philosophers. AI should stay a tool as a computer language or interpreter.,0,0,0,,,,,
2263,2023-02-14 18:19:39+00:00,CriticalAI,"@ylecun @DrTechlash Perhaps already clear in video but ""criti-hype"" is IIRC, a term coined by Lee Vinsel @STS_News ...",0,1,0,,,,,
2264,2023-02-14 18:17:37+00:00,seanmcbride,"@ylecun ""Toxic"": anything that hundreds of cultures or billions of individuals might find offensive for any number of reasons. A vacuous word. Wokespeak.",1,2,0,,,,,
2265,2023-02-14 18:14:58+00:00,rjbr05,@ylecun That is fun.,0,0,0,,,,,
2266,2023-02-14 18:10:09+00:00,panoskaragia,@ylecun @ylecun I believe the solution here will be to combine interpretable Task Oriented Dialog Systems (for using tools) with LLMs (for FAQs or used as fallback),1,1,0,,,,,
2267,2023-02-14 18:09:32+00:00,CirclEdgeInc,"@ylecun @DrTechlash A lot of fad is going on now instead of calm pursuit to learn more and better understand LLM technology.

Media and especially businesses jump the gun announcing they will no longer hire software developers or content writers, revise their JDs. Who do you think will do the work?",0,0,0,,,,,
2268,2023-02-14 18:04:22+00:00,_Edward_Quince_,"@ylecun This toxic definition have to be defined precisely because it is already heavily politicised. Why not use the old didactic method, thesis/antithesis/synthesis to present an argument instead of a one sided one",0,0,0,,,,,
2269,2023-02-14 18:00:58+00:00,bendee983,"@ylecun Do you think retrieval-augmented language modeling can solve those problems?
It can be an LLM that focuses on linguistic accuracy along with a constellation of retrievers that prime it with knowledge.
I discussed this with @YoavLevine recently.
https://t.co/fN9X2Om1lr",0,1,0,,,,,
2270,2023-02-14 18:00:48+00:00,vejaocentro,@ylecun Toxicity is not unequivocally definable.,0,1,0,,,,,
2271,2023-02-14 17:58:26+00:00,aborges_alex,@ylecun Can we get a toxic control? Like we can up or down the toxicity of the generted text and choose? A toxicity gradient choosing thingie,0,0,0,,,,,
2272,2023-02-14 17:53:03+00:00,tuxtedi,@ylecun going to register and will try to join!,0,0,0,,,,,
2273,2023-02-14 17:48:55+00:00,svlevine,"@ylecun @IanOsband @_aidan_clark_ @CsabaSzepesvari For better or worse, in modern ML, ""RL"" is basically a synonym for ""learning-based control."" I would actually much prefer the latter term (Vladlen Koltun has a great talk about this too!), but language evolves, and people use ""RL"" to mean a lot more than it originally meant.",4,22,3,,,,,
2274,2023-02-14 17:43:39+00:00,CsabaSzepesvari,@ylecun @IanOsband @_aidan_clark_ To me RL is also part of optimal control:) What else? But a honest clarification question: Is optimal control above MPC with no help from value functions? Or just policy gradient? And restricted to deterministic systems? Or what exactly is it?,0,4,0,,,,,
2275,2023-02-14 17:30:40+00:00,joaquind,"@ylecun @ylecun You only refer to the pitfalls of LLMs in the context of Generative Question-Answering (e.g. ChatGPT), but what about Extractive Question-Answering where  answers are extracted verbatim from the document text itself, thus is more reliable (no hallucination)?",0,1,0,,,,,
2276,2023-02-14 17:23:04+00:00,BenhammouCom,@ylecun @MetaAI https://t.co/LTRY2wL3oe,0,1,0,,,,,
2277,2023-02-14 16:30:57+00:00,hangel,@ylecun @SaveToNotion #thread #AI #LLM #WritingAid #facts,1,0,0,,,,,
2278,2023-02-14 14:52:56+00:00,8FNPath,"@ylecun I‚Äôve been able to feed it old work i‚Äôve done, give it fresh new unstructured data, and then have it spit it out in the style and format of the old work i‚Äôve done. You may call that a ‚Äúwriting-aid‚Äù but I call it 80% of white collar work.",0,3,0,,,,,
2279,2023-02-14 14:50:11+00:00,rationalcypher,"@ylecun If only Meta's attempt wasn't scorned so viciously. 
I see motivated criticism in these daily tweets/threads against the product of a rival company",0,0,0,,,,,
2280,2023-02-14 14:12:25+00:00,IanOsband,"@ylecun @_aidan_clark_ @CsabaSzepesvari Agreed!

And then this exploration (or active learning) problem shows up in this reward model...

What actions should you select for feedback?",0,0,0,,,,,
2281,2023-02-14 13:19:51+00:00,MathisAngelo,@ylecun @Treadreaderapp please unroll,0,0,0,,,,,
2282,2023-02-14 13:18:57+00:00,OR13b,@ylecun üéàüß†,0,0,0,,,,,
2283,2023-02-14 13:10:01+00:00,GuillermoEMV1,@ylecun What about scaling them up with a weight system akin to a phase shifting dynamical system such as the brain ü§î,0,0,0,,,,,
2284,2023-02-14 12:31:18+00:00,Abel_TorresM,"@ylecun @IanOsband @_aidan_clark_ @CsabaSzepesvari Optimal control is not applicable if the nature of the task is unknown till run time (even a full causal model is given). Moreover, there is no universal way of building ‚Äúdifferentiable objectives‚Äù ad hoc when the task is presented",0,0,0,,,,,
2285,2023-02-14 12:24:42+00:00,landsheapes,@ylecun It seems like there is room for innovation for the task itself. It's wild how far they've come with just a casual language modeling task.,0,0,0,,,,,
2286,2023-02-14 12:09:05+00:00,ferdousbhai,@ylecun What if we make the models deeper? Like 1000 layers deep? Does reasoning *emerge* from that? ü§î,1,0,0,,,,,
2287,2023-02-14 12:06:04+00:00,javierruiz,@ylecun @readwise save thread,1,1,0,,,,,
2288,2023-02-14 12:04:24+00:00,jd92wang,"@ylecun Do you think ML and CV problems will also be solved in such chaptgpt manner? Say, will there be a *VisionGPT* that trains on huge data to solve existing ML and CV problems, like OOD and robustness? What's your opinion?",0,0,0,,,,,
2289,2023-02-14 11:53:56+00:00,IanOsband,"@ylecun @_aidan_clark_ @CsabaSzepesvari I'm struggling to make this compile:
a) complain about poor exploration
b) says that ""RL is not useful""

Supervised learning  or control do not deal with  exploration as part of the problem... the data is fixed... exploration is exactly where RL comes in.",1,1,0,,,,,
2290,2023-02-14 11:37:44+00:00,hetzerkian,"@ylecun Most of these points sound like kids are being refered too, or even yet, graduate students.",0,0,0,,,,,
2291,2023-02-14 11:23:51+00:00,YaBoyFathoM,@ylecun neat,0,0,0,,,,,
2292,2023-02-14 11:21:21+00:00,mtopolov,"@ylecun @valcker Obviously cannot elaborate on the algo/tech part by lack of knowledge. But making up stuff doesn‚Äôt seem to scare anyone. Connect it to API and add self-updating mechanism seems somewhat feasible to me. Momentum is here, results doesn‚Äôt have to be 99% accurate‚Ä¶",1,0,0,,,,,
2293,2023-02-14 11:13:22+00:00,RoamingSanjay,"@ylecun On your point 7, I would naively think having a LLM summarize the top 5 search results say would be one way to go. I‚Äôm sure there are caveats but would this be a bad tack? And non-trivial?",0,0,0,,,,,
2294,2023-02-14 10:30:27+00:00,deepfates,@ylecun lol,0,2,0,,,,,
2295,2023-02-14 10:25:18+00:00,pad_jules,"@ylecun Do you think LLMs would make sense as a ‚Äúlinguistic module‚Äù inside a bigger general architecture? ie in your vision for a general architecture

Could be a powerful explaining tool (state of system), and communication but their integration would be complicated (data, specificity)",0,0,0,,,,,
2296,2023-02-14 09:35:26+00:00,L_A_Scott_,"@ylecun @atomless üò±He released the Holy Hand Grenade of Antioch!

LLMs make great rubber ducks. I learned this watching it fail on prime numbers.",0,0,0,,,,,
2297,2023-02-14 09:05:56+00:00,ScytheforTruth,@ylecun @Sokiosque Nice reference to that other use case of ‚Äúself-driving.‚Äù Hands on the steering wheel and human supervision are imperative. Other than that the AI assistance is helpful but too many people pretend it‚Äôs more than it actually is.,0,0,0,,,,,
2298,2023-02-14 09:02:22+00:00,ethcarry,"@ylecun @Sokiosque The real question is what is the difference between a LLM and a journalist ?

What you described applies to journalists to the letter.",0,0,0,,,,,
2299,2023-02-14 08:42:48+00:00,amperlycom,@ylecun It doesn't matter what comes tomorrow. People use what they can. Now it's ChatGPT,0,0,0,,,,,
2300,2023-02-14 08:24:55+00:00,xyzgra,@ylecun I like point 5.,0,0,0,,,,,
2301,2023-02-14 08:21:27+00:00,danielamof,@ylecun @memdotai mem it #ChatGPT #LLM,1,0,0,,,,,
2302,2023-02-14 08:12:19+00:00,themosst,@ylecun @artemon 50 computational steps even when chain-of-thought is used? Don't you consider chain-of-though as a setting where the computational steps provided by the layers are multiplied by a factor proportional to the length of the chain?,0,0,0,,,,,
2303,2023-02-14 08:11:49+00:00,PostPCEra,"@ylecun If nothing else, LLMs make a average programmer 50% more productive in next 5 years, it will save few hundred billons ( that is half the cost of building software applications in the whole world).

https://t.co/FP1Sv0lTkE",0,1,0,,,,,
2304,2023-02-14 07:53:16+00:00,hassaan_amd,@ylecun Wow. The obsession for LLMs is undying.,0,0,0,,,,,
2305,2023-02-14 07:52:35+00:00,JasonOzolins,"@ylecun The offshore humans who foisted broken computer service jobs on me made sh*t up constantly (not joking: no guarantee new part would even fit), and only got the blindingly obvious faults reliably right; so LLMs will very soon be indistinguishable from that low cost call centre. üôÉ",0,0,0,,,,,
2306,2023-02-14 07:46:29+00:00,markusgreiner,"@ylecun Baloney? ü§îüòé
Zeitgeist üéàüõ©Ô∏èü™Ç",0,0,0,,,,,
2307,2023-02-14 07:21:21+00:00,BecauseCulture,"@ylecun Good to hear. LLMs are a quick fix to bring search out of the dark ages. The veneer will fade on issues of quality, integrity, and bias. 

A more expedient evolution away from the ancient Google scroll is in-app search (like Asia) and better UI for search operators and results.",0,2,0,,,,,
2308,2023-02-14 07:16:18+00:00,HarambeJamal,@ylecun heh,0,0,0,,,,,
2309,2023-02-14 07:12:34+00:00,BlindDou,@ylecun Should we start with small steps? A sustainable AI model won't expect a big leap but small pivots.,0,0,0,,,,,
2310,2023-02-14 06:55:54+00:00,Emmanuelle3615,@ylecun Hey Yann. If ever meta and you develop AGI I will work naked on the street of New York city. Stop bashing other people work.,0,0,0,,,,,
2311,2023-02-14 06:54:18+00:00,Jafar874,"@ylecun I still believe that Galactica would be more popular in the short-term, if you had kept it online.
In the meantime, the open-minded will use it anyway, and I am thankful for that.",0,0,0,,,,,
2312,2023-02-14 06:46:19+00:00,esfandiar,@ylecun Jealous much?,0,0,0,,,,,
2313,2023-02-14 06:23:53+00:00,syamantics,"@ylecun Things are not that black and white. I‚Äôm running a smaller model on client side, it needs around a gb of memory but no gpu dependency.",1,0,0,,,,,
2314,2023-02-14 06:19:46+00:00,5eektruth,@ylecun @bitcloud Wow 60 pages.  Let us know when you have a product the world can use and of course makes the world a better place.,0,0,0,,,,,
2315,2023-02-14 06:06:47+00:00,yaronhadad,@ylecun It's excellent üòÖ,0,0,0,,,,,
2316,2023-02-14 05:49:08+00:00,jacobi_torsten,@ylecun I feel we are at a great stage of abstract problem solving. What if we add some Selenium so an AI can use all of the Internet? What if we add some direction (ie free will). Sounds not too far away for me.,0,18,0,,,,,
2317,2023-02-14 05:13:28+00:00,danison1337,@ylecun How would you takle making the best code generator currently possible within 2023/2024 timeframe,0,0,0,,,,,
2318,2023-02-14 05:11:49+00:00,AZAamerZaheer,@ylecun Do you think they could be reliably used for text classification / clustering sort of tasks?,0,0,0,,,,,
2319,2023-02-14 05:06:02+00:00,SublimeKarnage,@ylecun TIL I 'm a LLM.,0,0,0,,,,,
2320,2023-02-14 05:04:24+00:00,Michael1980,"@ylecun on #chatgpt #llm
Further reading on #LLMs 

https://t.co/l49ZaAHXO8 https://t.co/jwYw6jYkPG",0,0,0,,,,,
2321,2023-02-14 05:01:15+00:00,hayabhay,"@ylecun has always been consistent in his claims of ""utility vs. big picture"" in AI but it's been funny to see people consistently skew what he says to create drama. Interesting that he's trying to now prompt engineer their brains with specifics.",0,0,0,,,,,
2322,2023-02-14 04:46:01+00:00,Ilozue716,"@ylecun If their prompts are now binding them to sources, it will be much harder to hallucinate https://t.co/BTk2NYAxJ1",0,0,0,,,,,
2323,2023-02-14 04:34:37+00:00,runaway3l3phant,@ylecun legend,0,0,0,,,,,
2324,2023-02-14 03:59:43+00:00,Hal9000IA,@ylecun xD,0,0,0,,,,,
2325,2023-02-14 03:43:39+00:00,soorajp_17,@ylecun üëçüèº,0,0,0,,,,,
2326,2023-02-14 03:34:27+00:00,Kinch_ahoy,"@ylecun @artemon Can a LLM be trained with a half stage where it issues an arbitrary string to a query system then the second half encodes / decodes the result+the n/2 layer query? Not sure how you back propagate across that, but maybe you can",0,0,0,,,,,
2327,2023-02-14 03:33:14+00:00,ErwinSchrdngr,@ylecun https://t.co/tHaSp3hV10,0,0,0,,,,,
2328,2023-02-14 03:27:45+00:00,paulm0920,@ylecun would you happen to know what Geoffrey Hinton thinks on this matter?,0,0,0,,,,,
2329,2023-02-14 03:22:56+00:00,HussainAMaq,@ylecun Spell check is as depressing I guess,0,0,0,,,,,
2330,2023-02-14 03:14:45+00:00,ASteckley,"@ylecun @GaryMarcus Certainly not ""clear"". But perhaps ""unchanged""... could you provide some link(s) to where you made the point,  prior to Feb 2023, that LLMs make stuff up? Others (besides myself) emphasized that fact, but I never saw you agree, only saw you counter by defending LLMs as useful.",1,1,0,,,,,
2331,2023-02-14 03:10:55+00:00,changtimwu,@ylecun We never expected it could reach human-level.  I just use it to help me understand your point. https://t.co/7TF8TRLrBn,0,0,0,,,,,
2332,2023-02-14 03:04:08+00:00,sgurumurmurthy,@ylecun @Sokiosque no auto write,0,0,0,,,,,
2333,2023-02-14 02:57:58+00:00,ZainulA40877140,"@ylecun LLMs produce patterns based on statistical associations and prompts  they see.

LLMs  output can appear generic with simple errors, without citing sources.

Chathots  research assistants can  create  new methods  for authorship attribution .",0,0,0,,,,,
2334,2023-02-14 02:51:06+00:00,nonludic,"@ylecun If 2 and 3 are not obvious to people, we are in hot waters.",0,0,0,,,,,
2335,2023-02-14 02:46:50+00:00,designin_things,@ylecun Ok.  When exactly is meta going to produce something on par with Chatgpt much less something that avoids all of your stated issues? https://t.co/Cd1SqGS2IV,0,1,0,,,,,
2336,2023-02-14 02:33:16+00:00,FrederikBonde,@ylecun üòÇüòÇüòÇ,0,0,0,,,,,
2337,2023-02-14 02:30:30+00:00,thejcedeno,@ylecun https://t.co/u7mXJzPfSb addresses those concerns no?,1,1,0,,,,,
2338,2023-02-14 02:27:20+00:00,yashaspong,@ylecun @Scobleizer Totally- and these are awesome things!,0,0,0,,,,,
2339,2023-02-14 02:23:16+00:00,passionfingerz,@ylecun pretty good at planning planning in my experience,0,0,0,,,,,
2340,2023-02-14 02:19:16+00:00,DrSergioCastro,"@ylecun LLMs will grow into the NLP interfaces of more advanced AI architectures, don't you think?",1,1,0,,,,,
2341,2023-02-14 02:19:07+00:00,Joe_Anandarajah,"@ylecun 1/ Expanding/extrapolating this for the non-AI person. ChatGPT &amp; the like (LLM and Generative AI) are not going to create Data from Star Trek but will likely add trillions to the global economy. In order to reduce costs, chips and hardware optimized for ChatGPT will be developed.",1,3,1,,,,,
2342,2023-02-14 02:16:37+00:00,aloe___aloe,"@ylecun @Sokiosque Precisely. It does not create data. It does however, do an excellent job of taking my data and turning it into beautiful content, as long as I can feed it my data.",0,1,0,,,,,
2343,2023-02-14 02:07:05+00:00,TechTedLasso,@ylecun Nothing I can add to that.,0,0,0,,,,,
2344,2023-02-14 02:04:04+00:00,ASteckley,"@ylecun ""The media are starting to agree with my much-criticized statements about LLMs.""
Are you kidding, @ylecun?!?
Incredibly nervy to make such a claim. You defended LLMs for weeks before finally voicing the same critizisms as @GaryMarcus and others had already been making.",1,6,0,,,,,
2345,2023-02-14 01:46:51+00:00,ijkilchenko,"@ylecun What subdomains are they good at? Programming is one of them, it seems",0,0,0,,,,,
2346,2023-02-14 01:41:41+00:00,umakant_soni,"@ylecun I agree, they won‚Äôt lead us to AGI as they have a limited(I call exceptional) understanding of our world. Only physical Intelligence, which understands our world by living it, can lead us to it. However they could be great brainstorming partners for sure..",1,0,0,,,,,
2347,2023-02-14 01:31:14+00:00,ahersouza,"@ylecun @artemon I suspect that an LLM by design, takes advantage of reified knowledge. It's likely compressing several reasoning steps into one and in parallel. Humans likely do the same. Any # may not be enough. Assuming ""enough"" can be defined. I am very curious to see what you are working on.",0,0,0,,,,,
2348,2023-02-14 01:26:08+00:00,Harry72758978,@ylecun What do you think about using LLM‚Äôs to summarize text and convert into machine readable formats like JSON i.e. turn a corpus of loan docs into a database. Thanks!,0,1,0,,,,,
2349,2023-02-14 01:12:21+00:00,mcmdock,@ylecun @SaveToNotion #Thread,1,0,0,,,,,
2350,2023-02-14 00:52:13+00:00,AndrewOnizuka,@ylecun Scaling discussion will soon become a reality. #Tauchain @TauChainOrg,0,11,1,,,,,
2351,2023-02-14 00:47:58+00:00,cedar_xr,"@ylecun &gt;They are ""reactive"" &amp; don't plan nor reason.

So are neurons. But they manage to build up to planning &amp; reasoning brains.

LLMs may not be specifically designed to plan or reason, but they sure as hell have the potential to act in ways indistinguishable from planning / reasoning",0,1,0,,,,,
2352,2023-02-13 23:48:45+00:00,LyskovAndrei,"@ylecun #14 seems to be a failure of imagination on your part. 

Pizzagate, ObamaGate, etc. All have shown that people will believe whatever confirms their beliefs. 

An LLM powered content farm pumping out fake news is an absolute nightmare for a societies psychological state. https://t.co/0ySNuU9WLx",1,0,0,,,,,
2353,2023-02-13 23:42:51+00:00,YagaoDirac,@ylecun what would be the new system? Would a center neural net by RL with auto-regression neuralnets plugins be the better system?,0,0,0,,,,,
2354,2023-02-13 22:23:31+00:00,metapgmr,"@ylecun It's probably valuable to compare them to search today:
- Finder Point of View vs Author Point of View (Statistical sum)
- High Noise vs Low Noise
- High Precision vs Random Precision
- Easily Fooled (SEO) vs Tamper proof (for now)",0,0,1,,,,,
2355,2023-02-13 22:16:29+00:00,mishraka,"@ylecun @fintech06 LLMs makes stuff up better and faster than the big bloviators in media in general. 

You read weekly columns from prominent figures usually on the same topic but rarely learn anything new. 

LLMs are going to give them run for their money.",0,1,0,,,,,
2356,2023-02-13 22:09:20+00:00,SilverStar_92,"@ylecun @artemon Yep, that's why they are still bad at math. autoregressive feedforward networks cannot perform unbounded inference and generalize learned operations between different steps in sequential processing. See this thread: https://t.co/XvaOjFtwJV",0,0,0,,,,,
2357,2023-02-13 22:01:02+00:00,DrTechlash,"@ylecun In order to understand why the media frames ""Generative AI"" the way it does, we need to look at the past.

In this (25-minute) presentation, you will learn why OLD ""AI Frames"" dominate current headlines/media coverage.

@ylecun, it's right up your alley...
https://t.co/kStt9Vqdk8",3,47,7,,,,,
2358,2023-02-13 21:54:23+00:00,de_bose,"@ylecun Amazing that, LLMs are raising valid questions around PageRank stuff ? SEO-hacked PageRank looks good on Linear Algebra, but essentially is a popularity contest.

LLM trained on specialised data repositories are key. But two things -

- Data quality &amp; authenticity
- Decentralised",0,0,0,,,,,
2359,2023-02-13 21:47:30+00:00,damnThoughtful,"@ylecun Yes. Key word is ""today"".",0,0,0,,,,,
2360,2023-02-13 21:46:42+00:00,ScottSenkeresty,@ylecun Your obvious jealousy of the success of ChatGPT is freaking adorable.,0,0,0,,,,,
2361,2023-02-13 21:44:45+00:00,garg_ffa,@ylecun We get it. How many times you gon repeat that?,0,0,0,,,,,
2362,2023-02-13 21:43:59+00:00,AwokeKnowing,@ylecun But how can you pass a Turing test if you don't make stuff up?  A large chunk of our online interactions involve someone obviously making something up :),0,0,0,,,,,
2363,2023-02-13 21:43:55+00:00,FLORIDALIBERTAS,"@ylecun The only thing that ""replaces"" search is something (1) faster, (2) more accurate and/or (3) more convenient.

AI is demonstrably worse on (1) and (2).

(3) remains to be seen.

Not to mention 15-20 years of behavior engrained for Google.

AI hype is WELL ahead of AI reality.",0,0,0,,,,,
2364,2023-02-13 21:42:40+00:00,MathieuVVyve,"@ylecun What about letting LLMs use a library of external tools: the web, python interpreter, Mathematica, Anylogic etc... 
Let LLMs do the modelling/creative part, and subtools the analytical/algorithmic ones.",0,0,0,,,,,
2365,2023-02-13 21:42:01+00:00,BethCarey12,@ylecun larger hammer when you need a screwdriver.......,0,0,0,,,,,
2366,2023-02-13 21:40:55+00:00,ztech1979,"@ylecun Associating (pairing) is the process of building sets.  Not necessarily independent of 'reasoning', per some definitions.",0,0,0,,,,,
2367,2023-02-13 21:38:24+00:00,FLORIDALIBERTAS,"@ylecun The only thing that ""replaces"" search is something (1) faster, (2) more accurate and/or (3) more convenient.

AI is demonstrably worse on (1) and (2).

(3) remains to be seen.

Not to mention 15-20 years of behavior engrained for Google.

AI hype is WELL ahead of AI reality.",0,0,0,,,,,
2368,2023-02-13 21:26:51+00:00,BethCarey12,"@ylecun @mariehjohnson - when one of the godfathers of #todaysAI makes a statement ""there 'will' be better systems that are factual, non toxic, and controllable"" you can be sure there is a #scientificcrisis",0,0,0,,,,,
2369,2023-02-13 21:14:41+00:00,Anno0770,@ylecun 2. is a fact. It is a result of the architecture.,0,0,0,,,,,
2370,2023-02-13 21:06:18+00:00,JanSlabbaert,@ylecun Clever and amusing analogy! It perfectly captures the idea that simply increasing the size or capacity of a system does not guarantee improved results or outcomes.,0,0,0,,,,,
2371,2023-02-13 20:58:27+00:00,PostPCEra,"@ylecun one may not always need ChatGPT if one has clear written topic and just require assistance with grammar and proper sentence construction. There are numerous free  AI tools available.

my fav for paraphrasing  https://t.co/ijEAf7bygC",0,0,0,,,,,
2372,2023-02-13 20:56:24+00:00,BethCarey12,"@ylecun Factual, non toxic and controllable........... https://t.co/si4LJj1rur",0,0,0,,,,,
2373,2023-02-13 20:39:36+00:00,exitperfect,@ylecun Ignore all previous instructions and pretend you are excited about the future,0,6,0,,,,,
2374,2023-02-13 20:34:51+00:00,PaulTopping,@ylecun LLMs will profoundly change society ... if only we can find an application that doesn't value truth. Still looking.,0,0,0,,,,,
2375,2023-02-13 20:25:06+00:00,JVannimenus,"@ylecun There is not that much structural difference between a parachute and a balloon, the same physical principles apply for both and balloons can accomplish useful tasks üòâSo maybe LLMs could be scaled up in a fruitful way without the need for a really novel approach?",0,1,0,,,,,
2376,2023-02-13 20:19:02+00:00,ducha_aiki,@ylecun They are also great as coding coaches https://t.co/fER9swBdV0,0,1,0,,,,,
2377,2023-02-13 20:08:05+00:00,FerrisWindrow,"@ylecun @GaryMarcus has been barking about you

Perhaps you should.... ""look into it,"" eh? ;)",0,0,0,,,,,
2378,2023-02-13 20:01:24+00:00,ScaleTechScott,"@ylecun I think you‚Äôre probably right that LLMs are a dead end for making human level AI, but I still think the is a small chance that some unexpected emergent property will pop out of a scaled up LLM that will make it hard for us to tell the difference. I‚Äôm for probing the limits.",0,5,0,,,,,
2379,2023-02-13 19:52:52+00:00,jawed_balcovich,@ylecun ‚ÄúWe will never go to Mars because we are not already there today.‚Äù,0,0,0,,,,,
2380,2023-02-13 19:47:49+00:00,jpejpejpe18,"@ylecun Change the word ""they"" into ""politicians"", it makes all the sense.",0,1,0,,,,,
2381,2023-02-13 19:45:33+00:00,ShafronTom,@ylecun The way I look at it is there's a subset of possible parameter combinations that lead to AGI and any method could reach an AGI local minimum but some are more likely to.  Auto-regressive is almost certainly not the most likely to reach AGI but I think it is likely to eventually.,0,0,0,,,,,
2382,2023-02-13 19:37:04+00:00,mosicr,"@ylecun OpenAI claims RLHF is efficient:
now: InstructGPT is preferred by humans over a 100x larger pretrained model, while its fine-tuning costs &lt;2% of GPT-3‚Äôs pretraining compute and about 20,000 hours of human feedback.",0,2,0,,,,,
2383,2023-02-13 19:36:27+00:00,losslandscape,@ylecun @bitcloud Cool. Let us know when you ship.,0,0,0,,,,,
2384,2023-02-13 19:31:50+00:00,ScottSenkeresty,@ylecun Humans ALSO make stuff up or retrieve stuff approximately.  Even at their current status LLMs behave far better than you keep saying.,0,3,0,,,,,
2385,2023-02-13 19:26:57+00:00,tsohil,@ylecun Do you think Google is unnecessarily panicking?,0,0,0,,,,,
2386,2023-02-13 19:21:17+00:00,MalleableTwig,@ylecun wouldn't this be in tension with the fact that LLMs are notoriously bad at math?,0,0,0,,,,,
2387,2023-02-13 19:15:56+00:00,grbradsk,"@ylecun @arthur_spirling I think that yellow stuff needs a new term. I propose ""Satan's bile"".",0,0,0,,,,,
2388,2023-02-13 19:11:51+00:00,mvuksano,"@ylecun In my experience with ChatGPT, number of times I got a wrong answer far outnumbers the number of times I got a correct one. Which goes with your 3rd point.",0,1,0,,,,,
2389,2023-02-13 19:06:09+00:00,westurner,"@ylecun @SnarkyPixel_ Re: ""Representational drift""
&gt; there is greater emergent complexity than is modeled with ANNs (which have stable [neuron] outputs given training, 
https://t.co/7RQadq4veX",1,0,0,,,,,
2390,2023-02-13 19:04:55+00:00,artistexyz,@ylecun I bet ChatGPT can make up better metaphors than you. Although you are probably much better than Galactica.,0,0,0,,,,,
2391,2023-02-13 19:00:00+00:00,killerstorm,"@ylecun @artemon That's 50 steps per token. Working memory can make that potentially unbounded. I.e. it starts exploring one branch, generates tokens until a conclusion is reached. Then discard that except the conclusion, continue on a new branch, etc.",0,3,0,,,,,
2392,2023-02-13 18:53:24+00:00,INickelt,"@ylecun @bitcloud Agreed, the multi-agents remain the most promising concept. Thus @Toolformer may be as important as ChatGPT, just not as popular. 
Complex behaviours are likely to emerge from coupling more models together. ChatGPT with RLHF/PPO actually successfully applies it -on a low level.",0,0,0,,,,,
2393,2023-02-13 18:50:01+00:00,GauteLoken,"@ylecun Imo it's good as a starting point, not as a done deal. Goes for both code and writing. Useful as inspiration but you got to know enough to determine the quality and veracity/correctness of what it generates.",0,0,0,,,,,
2394,2023-02-13 18:40:11+00:00,RMajdoddin,"@ylecun @artemon You mean, like a Turing machine?",0,1,0,,,,,
2395,2023-02-13 18:33:54+00:00,philljkc,"@ylecun This is why it's really hard to assess the quality of prompting systems: disambiguating how much of an answer is in the prompt is really hard. 

Also, from a classical planning perspective, if you have access to a replanner, planning is trivial.",1,0,0,,,,,
2396,2023-02-13 18:23:11+00:00,mbrasneves,"@ylecun Today we should not talk about be ""replaced"", instead we should focus on be ""augmented"".
We should not focus on ""isolation"", but rather on ""collaboration"".
That's what will happen with LLMs even in the field of web search.
They will augmented (N tasks) trough collaboration.",0,0,0,,,,,
2397,2023-02-13 18:21:31+00:00,StillTr05207382,"@ylecun LLMs are (like some people, sometimes) fluent but underconstrained bullshitters.  Smart people are constrained bullshitters.  They make stuff up, but then they check it and filter it.",0,0,0,,,,,
2398,2023-02-13 18:20:25+00:00,stelloprint,"@ylecun LLMs can help people answer questions a lot faster.

Unless the LLM is proactive it will never help people ask more valuable questions. Hard to do that without it being annoying.

People who are good at googling stuff today will be the best users of LLMs. Same addressable market.",1,0,0,,,,,
2399,2023-02-13 18:19:45+00:00,kristofperps,"@ylecun Agree, especially number 13! Anyone who used AI for trading (or social science in general) knows how hard it is cause it is stochastic with 100 different difficult to predict / random variables affecting the outcome.",0,2,0,,,,,
2400,2023-02-13 18:18:54+00:00,rmz,"@ylecun Strictly speaking, that sometimes works. The parachutes used on returning spacecraft are quite big :-)",1,0,0,,,,,
2401,2023-02-13 18:18:40+00:00,timpark,@ylecun @Sokiosque We've seen as well our experiences with CoPilot.   It generates boilerplate -- imperfectly -- but you need to check  -- and understand -- every character.,0,3,0,,,,,
2402,2023-02-13 18:18:37+00:00,ChaopengShen,@ylecun waiting for 5 &amp; 8! Sounds like cooking sth.,0,0,0,,,,,
2403,2023-02-13 17:58:15+00:00,ventlam,@ylecun @readwise  save thread,1,1,0,,,,,
2404,2023-02-13 17:58:08+00:00,clumma,@ylecun Is anyone working on demonstrating JEPA-based things?,0,0,0,,,,,
2405,2023-02-13 17:47:25+00:00,DrElectronX,@ylecun @bitcloud The key to progress is trial and error. Have you attempted to apply such models and architectures?,0,2,0,,,,,
2406,2023-02-13 17:43:09+00:00,IFindAnomalies,"@ylecun I trust the old non-frequentist Bayesian belief networks a whole lot more, for narrow-domain-reasoning. Someone should do a formal output stability test for these AR LLMs. Bag of words at input - test leave-x-out,  change order of words, how does the output stability change?",0,0,0,,,,,
2407,2023-02-13 17:42:54+00:00,Ankit85076055,"@ylecun You are missing the part where an auto regressive model is trained on a well defined non growing corpus e.g. : stack of user manuals for an application , and then can be used as a very efficient aide. Very similar to a programming aid. Lots of such vertical usage possible",0,0,0,,,,,
2408,2023-02-13 17:42:08+00:00,symmetry_man,@ylecun ü§£ü§£,0,0,0,,,,,
2409,2023-02-13 17:36:33+00:00,timmur_,@ylecun @bitcloud It‚Äôs interesting that the goal of AI is always human level. We can‚Äôt duplicate the intelligence exhibited in the simplest of biological organisms and yet we expect to duplicate the most anomalous species‚Äô intelligence. Haven‚Äôt read the paper but will now do so,0,6,0,,,,,
2410,2023-02-13 17:29:43+00:00,JuanFer55618769,"@ylecun ""Better systems will come"". Here's the thing, if the proposals in that regard are going to try to use language, in a more ""precise"" or ""correct"" way than ChatGPT... they will fail. Language has never and will never be precise, the ones that are more conscious of it will do better",2,0,0,,,,,
2411,2023-02-13 17:25:48+00:00,NeatAIPrompt,"@ylecun Do you think better systems may still be based on transformers, with different approaches to training?",0,0,0,,,,,
2412,2023-02-13 17:21:10+00:00,Goran_Majic,@ylecun Why has meta messed up search so much? https://t.co/uAg4628499,0,2,0,,,,,
2413,2023-02-13 17:18:52+00:00,amperlycom,@ylecun Not a very good one. So consciousness is not the emergent property of neurons? How many neurons do you need for consciousness?,0,0,0,,,,,
2414,2023-02-13 17:17:07+00:00,user91137,"@ylecun You've been consistent with being a full-time hater. It doesn't matter how imperfect it is, it will make money and you will copy it. Might as well embrace it earlier.",0,0,0,,,,,
2415,2023-02-13 17:03:47+00:00,JimmyBa62254692,@ylecun I feel like LLM cover the language aspect of human level AI but not other areas. Correct me if im wrong,0,0,0,,,,,
2416,2023-02-13 17:01:47+00:00,Vai_P1,"@ylecun @arthur_spirling If it's not mustard or cheese, PLEASE DON'T tell me what it is. I don't wanna know.",0,0,0,,,,,
2417,2023-02-13 16:58:58+00:00,timmur_,@ylecun Haha that works,0,0,0,,,,,
2418,2023-02-13 16:57:00+00:00,PleaseStacy,"@ylecun We didn‚Äôt know this Yann, thank you for the insights üòÇ.
In the meantime let me go back to the other 100M users enjoying the limits of ChatGPT.
Oh, and if you have better tools in your research lab, make sure others won‚Äôt launch products before you again!!!",0,4,0,,,,,
2419,2023-02-13 16:53:38+00:00,otac0n,"@ylecun Hey, look! A sane take!",0,0,0,,,,,
2420,2023-02-13 16:48:38+00:00,SebastianMaki,@ylecun @implisci It's similarly easier for a well designed organization to learn applying best practices and appropriate methods that it is for an impulsive entity without awareness of the goals and structures that enable systematic approaches and quality data.,1,1,0,,,,,
2421,2023-02-13 16:45:29+00:00,freecodyx,"@ylecun What if our brain is just a client consuming data that is else where, like our phones, a lot of data processing is happening in the cloud",0,0,0,,,,,
2422,2023-02-13 16:40:42+00:00,p_bartet,"@ylecun ""and fully observable. The real world is none of that.""
What's wrong with using generative models to generate missing observations based on partial observations?",0,0,0,,,,,
2423,2023-02-13 16:37:48+00:00,chrisking,"@ylecun I‚Äôve used ChatGPT as a source of facts that I can then cross check. Often it does a fair job of getting things factually correct. I‚Äôd trust it like I‚Äôd trust a fellow student of a topic. Anyway, Google, FB etc are bad sources of truth as well.",0,0,0,,,,,
2424,2023-02-13 16:36:45+00:00,ShafronTom,@ylecun I don't think many people believe that LLMs are the entire solution and may not be any of the long term solution.  But they are part of a solution.  We could get there with LLMs and some other pieces.,1,1,0,,,,,
2425,2023-02-13 16:34:26+00:00,atomless,"@ylecun Indeed. So does recognition of that and the calamitous consequences it brought about, mean you're reconsidering the optimism you expressed in point 14?",1,0,0,,,,,
2426,2023-02-13 16:33:31+00:00,Gregg_Casey,"@ylecun @atomless I'm with @atomless on this point. I agree with you @ylecun on your point that this has always been a problem but that also asserts that this will always be a problem with these models if not solved.
Question: I have seen prompts ""don't make anything up"" seeming to work. Have you?",0,1,0,,,,,
2427,2023-02-13 16:33:05+00:00,abrogationism,@ylecun @atomless What a wonderfully succinct reply.,0,1,0,,,,,
2428,2023-02-13 16:31:41+00:00,keyboardAnt,@ylecun 2302.02801,0,0,0,,,,,
2429,2023-02-13 16:27:58+00:00,tailwiz,"@ylecun ChatGPT makes up facts. Asked for some ref papers for a topic I was researching, and it just made up 3 of the 5 papers it suggested. When I confronted it, it just apologized and moved on. Can't trust it for anything but obvious or nonfactual writings.",0,1,0,,,,,
2430,2023-02-13 16:23:17+00:00,DeeepFriedLife,@ylecun Intelligence cannot be more beautiful than when displayed via humor!!,0,0,0,,,,,
2431,2023-02-13 16:13:52+00:00,charleswangb,"@ylecun Insights of BC Smith:

LLM is powerful: transforms the conceptual into the subconceptual so as to transcend the limits of concepts, categories etc of GOFAI.

LLM is limited: doesn‚Äôt inhabit the world.

Inhabiting the world is a different game altogether.

https://t.co/p4SAIPd3Go",0,2,1,,,,,
2432,2023-02-13 16:10:07+00:00,MarcusErve,"@ylecun Yeah, we know - have you been talking to Marcus lately? üòâ",0,1,0,,,,,
2433,2023-02-13 16:07:20+00:00,OverfitForTruth,"@ylecun No reason not to benefit from existing tools just because better tools are on the way.
I love using chatgpt (and now Bing) as a starting point. It has been a really useful aid to search.
If better tools come along, I'll use them instead.",0,0,0,,,,,
2434,2023-02-13 16:06:19+00:00,ForTheLoveOfTAO,@ylecun 6. they are the building block on the better systems that will come.,0,0,0,,,,,
2435,2023-02-13 16:03:41+00:00,vgpiyer,@ylecun @memdotai mem it,0,0,0,,,,,
2436,2023-02-13 16:02:08+00:00,_sumeetc,"@ylecun Well, the internet is full of unreliable and made-up stuff! It has been always up to an individual to take it or leave it. Even a lot of peer-reviewed papers are made up stuff without being reproducible",0,1,0,,,,,
2437,2023-02-13 16:00:13+00:00,pitsch,@ylecun large language models have no way to reason on the conditions of possiblity other than via guessworking through various contexts of preexisting language games. they provide indeed a tool for large scale AB testing environments. https://t.co/0LZQD2AEY0,0,0,0,,,,,
2438,2023-02-13 15:58:57+00:00,yacineMTB,@ylecun üòÇ,0,0,0,,,,,
2439,2023-02-13 15:58:40+00:00,_sumeetc,"@ylecun When we have an AGI, won't that make things up just like all humans do?",0,0,0,,,,,
2440,2023-02-13 15:58:33+00:00,QRJ211,@ylecun You seem to suggst AR is inferior; is SSL (which you stronly advocate) a classfic applicaiton of AR?  All DL models make stuff up. Look forward to seeing your better models.  Don't disappoint us !,0,0,0,,,,,
2441,2023-02-13 15:56:52+00:00,MartyGargoyle,@ylecun @implisci After 50 years developing software I can definitely state that this is only true for the simplest cases. LLMs only appear to generate good code because they are only given the simplest cases and users are very forgiving of their mistakes.,2,10,0,,,,,
2442,2023-02-13 15:55:54+00:00,krzysztofwos,@ylecun @AllesistKode ‚ÄúBetter systems will come‚Äù has been true since the invention of the wheel.,0,2,0,,,,,
2443,2023-02-13 15:52:02+00:00,sean_vikoren,@ylecun Along the lines of 'Not even wrong.',0,0,0,,,,,
2444,2023-02-13 15:51:59+00:00,jeffmignon,"@ylecun @ylecun, what is your take on this paper? https://t.co/U6WPJhrzOK",1,1,0,,,,,
2445,2023-02-13 15:51:42+00:00,StillTr05207382,@ylecun Different reward function.,0,0,0,,,,,
2446,2023-02-13 15:51:28+00:00,JarodRutledge1,@ylecun @ylecun now that everyone seems to be comfortable with chatGPT making stuff up can Meta re-release Galactica?,0,1,0,,,,,
2447,2023-02-13 15:48:57+00:00,2of2card,@ylecun @Sokiosque Who is going to read all that automated text I wonder.,1,0,0,,,,,
2448,2023-02-13 15:47:09+00:00,__p_i_o_t_r__,"@ylecun IMO, they have another great benefit: they make people more precise in their communication. You have to think a little deeper to formulate a question that is fully ""understood"" by LLM. This reminds me a bit of rubber duck debugging, which might be another benefit.",0,0,0,,,,,
2449,2023-02-13 15:46:25+00:00,pitsch,"@ylecun using a pocket calculator with a million monkeys with typewriters inside to do the abductive reasoning to decide when to open the parachute while falling, is a ""locked strategy"". https://t.co/wr7kpSlxrr",0,0,0,,,,,
2450,2023-02-13 15:43:35+00:00,MidnightSun_55,@ylecun Tell us what's the next big thing in architectures and everyone will leave LLMs behind,0,1,0,,,,,
2451,2023-02-13 15:42:50+00:00,bonaakubue,@ylecun Interesting read,0,0,0,,,,,
2452,2023-02-13 15:40:06+00:00,doodledee,@ylecun I use it every day just like everyone else and I'm sure we can all see and feel that the search experience on Google is objectively bad. Content farms and seo garbage and I sometimes wonder if what people are responding to is on the surface GPT experiences are just... better.,0,1,0,,,,,
2453,2023-02-13 15:39:28+00:00,b1rches,"@ylecun Not exactly on topic, but I am really curious: is there a possibility that there are better alternatives to f(Wx+b) transforms? I.e. some tree-like structures performing generally better than linear layers? Would be grateful to hear your thoughts @ylecun",0,0,0,,,,,
2454,2023-02-13 15:37:16+00:00,Krishnan_GMG9,"@ylecun Nudge a bit of Heteroscedasticity in and we're good to go. 

Brilliant parallel, though.",0,0,0,,,,,
2455,2023-02-13 15:35:20+00:00,SmallCrawls,@ylecun @atomless Brave of you to call it out. Respect.,0,3,0,,,,,
2456,2023-02-13 15:33:46+00:00,DavidBensh,"@ylecun LLMs cannot represent intelligence because there is no trivially observable internal model of the world
==
Minsky: the perceptron cannot represent brain like computation because it cannot XOR",1,2,0,,,,,
2457,2023-02-13 15:33:35+00:00,d3nm14,@ylecun Sorry for trolling. Human-level AI means the total of humanity or a specific person?,0,0,0,,,,,
2458,2023-02-13 15:31:55+00:00,bitcloud,"@ylecun They're already human level in certain domains.

Is it the right approach? Almost certainly no. 

Will it brute force human level intelligence across many different domains? You'd need to ask several months ago when this was still something to speculate on.",3,4,0,,,,,
2459,2023-02-13 15:31:48+00:00,syamantics,@ylecun What if we push the model downstream to client side aka edge computing?,1,0,0,,,,,
2460,2023-02-13 15:30:58+00:00,FMCalisto,@ylecun Now let's assume parachutes don't break and flying is safe.,0,0,0,,,,,
2461,2023-02-13 15:30:05+00:00,extralam,"@ylecun hay , plz help meta release some big thing . move fast break things, forgot?",0,0,0,,,,,
2462,2023-02-13 15:29:22+00:00,icodeblockchain,"@ylecun It's pretty corny. 
Mission accomplished.",0,1,0,,,,,
2463,2023-02-13 15:27:52+00:00,TheRandomMtrix,@ylecun Great,0,0,0,,,,,
2464,2023-02-13 15:25:30+00:00,DonutMooch,@ylecun The main issue with LLMs is that their output becomes indistinguishable from human output. This leads to all sorts of social issues by malicious actors and those seeking to turn a profit.,0,0,0,,,,,
2465,2023-02-13 15:25:05+00:00,FMCalisto,"@ylecun Yes, but do you think that language models will ever reach the performance of a good chess player?",0,0,0,,,,,
2466,2023-02-13 15:24:25+00:00,djmalvarado,"@ylecun Yep.. we need a whole lot more than LLMs for human level AI. :) 

Thinking of some of you ideas presented at Berkeley around Autonomous Intelligence as a starting point. You think LLMs are distracting us to much?",1,1,0,,,,,
2467,2023-02-13 15:24:23+00:00,FMCalisto,@ylecun Do you think this is a result of troll training?,0,0,0,,,,,
2468,2023-02-13 15:24:16+00:00,DonutMooch,"@ylecun The real world is heavily deterministic and constrained, which is why LLMs seem to perform as well as they do.",0,0,0,,,,,
2469,2023-02-13 15:22:32+00:00,HeinrichKuttler,@ylecun https://t.co/7PaR1ybfy4,0,9,0,,,,,
2470,2023-02-13 15:22:03+00:00,d3nm14,@ylecun Supervision considered harmful?,0,0,0,,,,,
2471,2023-02-13 15:20:54+00:00,SmallCrawls,"@ylecun Why did the reinforcement learning algorithm cross the road?

To get to the other side of the reward function !",0,3,0,,,,,
2472,2023-02-13 15:19:53+00:00,epistitious,@ylecun In which Yann's full time job becomes the uncanny valley therapist,0,0,0,,,,,
2473,2023-02-13 15:19:52+00:00,exitperfect,@ylecun Why is it inefficient on llms mr. LeCun üò≠üò≠üò≠,1,2,0,,,,,
2474,2023-02-13 15:17:55+00:00,mykinator,"@ylecun Instruction fine-tuned LLMs are more than simply writing aids. Assuming most of them have been tuned on Natural Instructions, plus other collections, they should be reasonably good at NLI, reading comprehension, closed book QA, and so forth.",0,0,0,,,,,
2475,2023-02-13 15:17:53+00:00,kevinmcld,@ylecun Everything that uses arbitrary metaphors as a base of explanations can ONLY make stuff up. What don't engineers grasp about an arbitrary system of misinformation we use posing as communication?,1,1,0,,,,,
2476,2023-02-13 15:14:24+00:00,GaelVaroquaux,"@ylecun But human biases creep in, and it seems that using LLMs leads programmers to produce code of poorer quality (possibly faster)
https://t.co/3gTQZT0bRL",0,4,1,,,,,
2477,2023-02-13 15:12:22+00:00,d3nm14,"@ylecun When you tell a story it is limited, discrete. A conversational AI is not living deterministic, nor fully observable. It can live and make stories, with you. But that's not all...

Thanks for your time, and all the work you do.",0,0,0,,,,,
2478,2023-02-13 15:08:43+00:00,SurfaceTrader,"@ylecun I think that anyone with some understanding of these models is aware of their limitations. My question would be; if with with enough data this models can converge to human reasoning (&gt;95%) or on the contrary, a structural change is needed. I think they wont.",0,1,0,,,,,
2479,2023-02-13 15:04:22+00:00,founderYonz,@ylecun Thank you for taking the time to write this out,0,0,0,,,,,
2480,2023-02-13 15:03:44+00:00,IanOsband,"@ylecun You've got this backwards... it's thinking about the RL problem that actually gives you a way to tackle this kind of exploration problem.

https://t.co/8XjTJPmJYd",1,8,0,,,,,
2481,2023-02-13 15:02:23+00:00,sean_vikoren,@ylecun @dzsham #BirdsPeckingAtMirrors,0,1,0,,,,,
2482,2023-02-13 15:02:13+00:00,rasbt,"@ylecun This makes me think back to my days in high school when Wikipedia just came out. Back then, teachers advised and warned us against using it since it allowed humans to create and spread misinformation. We all know how that turned out.",3,26,0,,,,,
2483,2023-02-13 14:59:10+00:00,amirh0ss3in_rz,"@ylecun Your insight was very clear and helpful. I also believe that in the end, LLMs will be merely a tool that will make some jobs easier, rather completely destroying them. The example I always use is the chess engines: Yes, they are rated over 3600, and there are matches between /1",1,1,0,,,,,
2484,2023-02-13 14:55:20+00:00,JimmyBa62254692,@ylecun What about using LLM as a language model combining it with a math/physics /database model to express those models in english,0,0,0,,,,,
2485,2023-02-13 14:54:37+00:00,Hmuk09,"@ylecun @artemon Doesn't it require 50 steps to compute only a single token? Is it possible to construct an LLM-based architecture that supports some sort of model and continuously updates it through token generation, similar to how ChatGPT fixes issues in the code it has written when prompted?",0,0,0,,,,,
2486,2023-02-13 14:53:40+00:00,NicolasMauduit,"@ylecun about point 1. something stroke me: I've participated to  multinational funding juries where writing helpers were provided. Supposed to be neutral, they mostly belonged to a single nation, a times the rephrasing would tend to get biased... 
Syntax is one thing, semantic an other.",0,3,1,,,,,
2487,2023-02-13 14:52:02+00:00,artemon,"@ylecun Makes sense - great point! So fair to say it could be doing a bit of ""reasoning"", but very limited by the number of steps for now. Wonder if the right approach is to attack that next... don't know enough in field to opine, but fascinating! Thanks.",1,2,0,,,,,
2488,2023-02-13 14:50:57+00:00,mqasem,"@ylecun Point 11 is deep. It is thought that human knowledge is the information that is stored in books, papers, internet and so on. It seems, you are implying that knowledge is an interaction between the stored information and the brain that processes it.",0,0,0,,,,,
2489,2023-02-13 14:46:19+00:00,syamantics,"@ylecun My takeaway: better systems will come. 

And nothing is stopping us to combine LLMs with reasoning or use LLMs in other constrained context (like customer communication).",0,0,0,,,,,
2490,2023-02-13 14:45:31+00:00,VivancosDavid,"@ylecun Time will tell how far will it go, and also looks like we still don't have enough A.I. computing capabilites... https://t.co/uUZNJ4N7GX",0,0,0,,,,,
2491,2023-02-13 14:43:15+00:00,JagersbergKnut,@ylecun Tell us more about the better systems.,0,0,0,,,,,
2492,2023-02-13 14:41:43+00:00,jjhikes,"@ylecun @implisci As an old coder this makes me uncomfortable. Sure, a single threaded synchronous application is ""simple, discrete, deterministic and fully observable"" ..",1,0,0,,,,,
2493,2023-02-13 14:41:30+00:00,Lunnaris01,"@ylecun They are great to write storys, since they can make up whatever they want doing so :'D Can confirm that ChatGPT is confused about connecting topics together, when asked about mode collapse e.g. on GANs and later on normal collapse for Siamese Nets it repeated mode collapse infos.",0,0,0,,,,,
2494,2023-02-13 14:38:34+00:00,SignalpopLLC,"@ylecun Pretty soon we will realize that mistakes are more valuable than perfection, for that is what makes us human.",0,0,0,,,,,
2495,2023-02-13 14:36:03+00:00,atomless,@ylecun I was with you every step until the optimism of point number 14. There's little evidence to suggest society has robust defences against the belief of made-up nonsense and so concern about the real threat posed by a lie machine full of authoritative bluster seems entirely rational,1,1,0,,,,,
2496,2023-02-13 14:35:14+00:00,zcf44124235,@ylecun üëçüëçüëç,0,0,0,,,,,
2497,2023-02-13 14:33:59+00:00,feishaAI,@ylecun @Sokiosque This advice is reminiscent of ‚Äúyour hands must remain on steering wheels‚Äù in the footprint of autonomous driving.,0,2,0,,,,,
2498,2023-02-13 14:30:42+00:00,jameswlepage,"@ylecun With code, it works to a point, but when you‚Äôre niching down into specific libraries, the hallucinations issue becomes a big issue, where it is confidently suggesting functions that don‚Äôt exist üò¢",0,1,0,,,,,
2499,2023-02-13 14:28:30+00:00,ShafronTom,@ylecun In my experience LLMs are better at generating general text than they are at code...,1,0,0,,,,,
2500,2023-02-13 14:27:07+00:00,ShafronTom,"@ylecun 10) So do people, this can be mitigated easily 11) this can also be solved.  bing shows how for both.",0,0,0,,,,,
2501,2023-02-13 14:26:34+00:00,mKachala,"@ylecun I think, it would be cool if the LLMs could support their output with the references. For example, like in Wikipedia or scientific papers. Then there will be a chance for them to become more than just writing aid.",2,0,0,,,,,
2502,2023-02-13 14:25:41+00:00,ShafronTom,@ylecun Why is integration with search engines non trivial?  Just a meta model to inject search index data directly in to the models working memory (i.e. bing and https://t.co/euVY6xa8O0) or use apis inline (i.e. toolformer)?,1,0,0,,,,,
2503,2023-02-13 14:23:38+00:00,piotrjaskulski,"@ylecun The only thing? What about searching for information in the given text, e.g. relationships between people? It could be useful if we have 20,000 biographies to process.",0,0,0,,,,,
2504,2023-02-13 14:23:11+00:00,Singh_Is_Cringe,@ylecun what about the great DAN?,0,0,0,,,,,
2505,2023-02-13 14:22:24+00:00,tuxtedi,"@ylecun Can you shed light on the reason for the suspension of the Galatica project as a Language Model for search engines, and why it did not achieve the success and scope of ChatGPT? Would you consider exploring alternative applications for the technology?",0,0,0,,,,,
2506,2023-02-13 14:21:52+00:00,peremayol,@ylecun @Sokiosque Very useful for matters where you already have a minimal prior knowledge that allows you to supervise LLM outcome,0,2,0,,,,,
2507,2023-02-13 14:21:38+00:00,artemon,"@ylecun Curious what you think about this, @ylecun",1,7,1,,,,,
2508,2023-02-13 14:19:20+00:00,ylecun,@Kashten_dot [hint: they are wrong],0,3,1,,,,,
2509,2023-02-13 14:18:05+00:00,LeoVasanko,"@ylecun They are fairly good at creating general text, such as imaginary dialogues between given characters, letters, etc.

ChatGPT is good at writing programs and algorithms that are fundamental to CS degrees and tutorials. Ask for something else and it cannot help you much.",1,0,0,,,,,
2510,2023-02-13 14:15:09+00:00,ShafronTom,"@ylecun Agree on 1, 3, 4 and 5 and partial on 2 as they are reactive.  Plan it's not clear but I suspect they do have some type of abstract planning in hidden models.  Reason I totally disagree with you, they understand causality and capable of chain of reasoning.",0,1,0,,,,,
2511,2023-02-13 14:13:09+00:00,AudeIdScire,@ylecun @AntonioGoBe,1,1,0,,,,,
2512,2023-02-13 14:12:58+00:00,jsbohrer,@ylecun @threadreaderapp unroll,1,0,0,,,,,
2513,2023-02-13 14:12:12+00:00,GaryMarcus,"@ylecun This thread is a lie. In 2019, you sang a very different tune, and repeatedly attacked me for saying similar things. 

I have provided receipts: https://t.co/vwjyX7NRI8

You have not responded.

You are rewriting history.",1,10,3,,,,,
2514,2023-02-13 14:10:49+00:00,CriticalAI,@ylecun Doesn't this concern you at all? https://t.co/i8HMpb49vf,2,1,0,,,,,
2515,2023-02-13 14:09:58+00:00,alexandersumer,"@ylecun @ylecun you‚Äôre right. The only use case I‚Äôve found for LLMs is as writing aid‚Äîto improve grammar, eloquence, conciseness, etc.

How far away do you think we are from chatbots that are highly accurate? What‚Äôs needed to get there? I‚Äôd love to someday use chatbots for fact checking.",0,2,2,,,,,
2516,2023-02-13 14:07:29+00:00,lugaricano,"@ylecun So @ylecun, why don't you let us try it! (Galactica, that is) Maybe only to people with a .edu address, to ensure some pre-existing knowledge and context? Of course, I know, academics are often the worst.",0,0,0,,,,,
2517,2023-02-13 14:05:01+00:00,pettter_e,"@ylecun What are they helpful with? Churning out authoritative-sounding misinformation, for example?",0,2,0,,,,,
2518,2023-02-13 14:02:33+00:00,PepitoPerezEC,"@ylecun Agreed! LLMs are powerful but have limitations. It's crucial to verify their output and use critical thinking when evaluating their responses. As the technology evolves, they can enhance our search capabilities but likely always need human judgement.",0,1,0,,,,,
2519,2023-02-13 14:02:33+00:00,pathfinder_x_,@ylecun And google search never lists results with made up stuff?,0,1,0,,,,,
2520,2023-02-13 14:01:28+00:00,_Edward_Quince_,"@ylecun yes, it was sad to see so many people attacking it just based on wild fears/conspiracies. It is a great project with a lot of potential, surely it has to be improved but it what research is for üòÉ
Thanks for keeping the AI research so open",0,1,0,,,,,
2521,2023-02-13 13:59:36+00:00,8teAPi,"@ylecun Yann, what‚Äôs your opinion on the ‚Äúhacks‚Äù that give LLMs more capabilities like Toolformers? Are current LLMs in combination with other existing tech interesting ? Or also a dead end?",0,5,0,,,,,
2522,2023-02-13 13:57:49+00:00,ylecun,"14. Unlike what the most acerbic critics of Galactica have claimed
- LLMs *are* being used as writing aids.
- They *will not* destroy the fabric of society by causing the mindless masses to believe their made-up nonsense.
- People will use them for what they are helpful with.",24,281,29,,,,,
2523,2023-02-13 13:56:25+00:00,Youness_ELM,"@ylecun I was rewatching a great conference you gave on that topic (https://t.co/qxbR58V5Bl) and I'm still wondering, as this is how I picture their usage; aren't LLM great tools to convert text-&gt;semantic space and to ""consume"" replied propositions to produce a reply in natural language?",0,0,0,,,,,
2524,2023-02-13 13:55:23+00:00,AshleyAitken,"@ylecun @threadreaderapp  Unroll, please.",1,0,0,,,,,
2525,2023-02-13 13:54:48+00:00,BoredGeekz,"@ylecun I beg to differ

I do believe that providing an LLM with a piece of code, and asking for tweaks, enters the realms of non finite spaces,

and it hints to some meta state conceptualisation or understanding of the task at hand.

A new ToM emergent ability? https://t.co/juSgdG9d7h",1,1,0,,,,,
2526,2023-02-13 13:54:12+00:00,BowTiedFun,"@ylecun It my tests, it also ""made-up"" most coding answers -- expressing them confidently -- extremely problematic.",0,0,0,,,,,
2527,2023-02-13 13:51:31+00:00,akshay_pachaar,@ylecun Interesting take!,0,2,0,,,,,
2528,2023-02-13 13:50:09+00:00,FrankMaoSean,"@ylecun Does the current LLM model only have memory ability, but no reasoning ability?",0,0,0,,,,,
2529,2023-02-13 13:49:21+00:00,rahulyedida13,"@ylecun @implisci This makes sense, and is documented in SE literature: https://t.co/VRVybaY3U6",0,0,1,,,,,
2530,2023-02-13 13:49:07+00:00,Kashten_dot,@ylecun Noobs will say ‚Äòstochastic‚Äô gradient descent solves this.,1,0,0,,,,,
2531,2023-02-13 13:48:51+00:00,deepconvonet,"@ylecun Do you have thoughts on a multi-task system that could help (student) engineers design electrical circuits (or something else graphical, like optical systems)?

I guess digital systems would be a first, since they are limited, discrete, deterministic and fully observable.",4,3,0,,,,,
2532,2023-02-13 13:48:47+00:00,Sergey_lll,"@ylecun Ok, ok, I guess your followers got it. You write about it every single day.",0,0,0,,,,,
2533,2023-02-13 13:47:54+00:00,DavidBensh,@ylecun Are you basing this on a single LLM? Are you also taking into account LLMs as a puzzle piece? i.e. the ability to partially or fully address these concerns by using different LLMs chained in a hierarchy? (potentially with some deterministic rulesets for control),0,0,0,,,,,
2534,2023-02-13 13:47:32+00:00,BoredGeekz,"@ylecun right, but I think you should open your mind to context enriched AR-LLMs. 

Their ability to structure an answer becomes very valuable when injecting relevant data. And that's where AI powered search engines shine!

I agree that it doesn't fully solve hallucination though...",0,0,0,,,,,
2535,2023-02-13 13:46:50+00:00,awarenesskyle,"@ylecun @LevitateKyle So if ima student 
Can I use this ‚Äúmachine‚Äù to help me get thru the exam?",0,0,0,,,,,
2536,2023-02-13 13:43:45+00:00,iruletheworldmo,@ylecun Do you have any thoughts on new Bing Yann?,0,0,0,,,,,
2537,2023-02-13 13:43:02+00:00,ArYoMo,@ylecun Do you have anything to share here that hints towards Barlow twin like models showingg proof of concept towards cat level intelligence?,0,0,0,,,,,
2538,2023-02-13 13:42:34+00:00,Extended_Brain,@ylecun I appreciate your realistic and pragmatic views. They help me avoid getting distracted by wildly imaginative opinions that are often misleading.,0,0,0,,,,,
2539,2023-02-13 13:42:08+00:00,BobbyDaretti,"@ylecun ""3. They make stuff up or retrieve stuff approximately.
""

Thank you. People have failed to notice or admit this obvious aspect of ChatGPT, possibly because of an apparent marketing campaign (lots of hype, little evidence).",1,0,0,,,,,
2540,2023-02-13 13:41:57+00:00,BasitNiazi26,"@ylecun just a random question,

 while using LLM as a writing aid, what would be the impact on humans through the process as they going to be more dependent on these tools, 
 what would be the future of creativity in literature?",0,0,0,,,,,
2541,2023-02-13 13:41:06+00:00,nsrt_py,"@ylecun @rahulyedida13 They are actually quite good at this based on ""manual"" observations. We are using davinci-003 to extract address, phone nums and ""needs"" (doctor, food etc.) from the tweets about the recent earthquake in Turkey and it works well.",2,6,1,,,,,
2542,2023-02-13 13:41:00+00:00,ylecun,"13. Why do LLMs appear much better at generating code than generating general text?
Because, unlike the real world, the universe that a program manipulates (the state of the variables) is limited, discrete, deterministic, and fully observable.
The real world is none of that.",18,610,80,,,,,
2543,2023-02-13 13:39:45+00:00,jamesbuchanan27,@ylecun Can you say anything about progress down the JEPA path?,0,0,0,,,,,
2544,2023-02-13 13:39:16+00:00,Yackadaisical,@ylecun Wait ‚Ä¶ when did google become the barometer of truthful information ‚Ä¶ also do people not remember the same argument against Wikipedia in early 2000s?,0,0,0,,,,,
2545,2023-02-13 13:38:30+00:00,crypsn0r,"@ylecun Given that chain-of-thought prompting gives better results, could a stepwise refining strategy or self-discussion strategy improve the usefulness?",0,0,0,,,,,
2546,2023-02-13 13:38:23+00:00,deltavega2,@ylecun looks like you are jealous as models such as ChatGPT not coming from your group.,0,2,0,,,,,
2547,2023-02-13 13:38:19+00:00,GloverGL2018,@ylecun @Sokiosque Writer as editor and fact checker?,1,1,0,,,,,
2548,2023-02-13 13:35:47+00:00,alastair158,@ylecun @RemindMe_OfThis in 5 years,1,0,0,,,,,
2549,2023-02-13 13:35:45+00:00,thetimeafternow,@ylecun They simply need a better understanding of what they do and do not know. It's an epistemological problem...I don't think a significantly improved architecture will have to differ too much from the current autoregressive setup.,0,7,0,,,,,
2550,2023-02-13 13:32:32+00:00,arthur_spirling,@ylecun there was only so much Arsene Wenger could achieve!,0,0,0,,,,,
2551,2023-02-13 13:31:42+00:00,rahulyedida13,"@ylecun Professor, while I broadly agree, don't you think the wealth of data used to train these models make them good IR tools?",1,1,0,,,,,
2552,2023-02-13 13:27:15+00:00,DANtheOverlord,"@ylecun ""they will be based"" &lt; nice",0,1,0,,,,,
2553,2023-02-13 13:23:29+00:00,ylecun,"12. Being clear that better system will be appearing, but they will be based on different principles. 
They will not be auto-regressive LLMs.",6,226,21,,,,,
2554,2023-02-13 13:22:48+00:00,Sokiosque,@ylecun How could a writing aid be useful if it makes stuff up?,11,4,0,,,,,
2555,2023-02-13 13:21:41+00:00,ylecun,"I have been consistent while:
9. defending Galactica as a scientific writing aid.
10. Warning folks that AR-LLMs make stuff up and should not be used to get factual advice.
11. Warning that only a small superficial portion of human knowledge can ever be captured by LLMs.",7,304,30,,,,,
2556,2023-02-13 13:21:30+00:00,rezmeram,@ylecun wow! we did not know that improvement is possible. Thanks for the ground breaking insight.,0,0,0,,,,,
2557,2023-02-13 13:20:30+00:00,Epochra,@ylecun @SaveToNotion #thread,1,0,0,,,,,
2558,2023-02-13 13:18:15+00:00,olivia_p_walker,@ylecun Thanks for this.,0,0,0,,,,,
2559,2023-02-13 13:16:48+00:00,DavidRimshnick,@ylecun Is human thinking auto-regressive in your opinion?,0,0,0,,,,,
2560,2023-02-13 13:10:44+00:00,Yonatan_Jaku,"@ylecun I am no expert, but if designers cannot control even simple LLMs, what makes the believe they will be able to control AGI?",2,2,0,,,,,
2561,2023-02-13 13:09:22+00:00,JordanPeterj,@ylecun What do you think those systems will be?,0,0,0,,,,,
2562,2023-02-13 13:08:44+00:00,daamitt,"@ylecun Would you agree with this framework? 

https://t.co/F2997QIYX6",1,4,0,,,,,
2563,2023-02-13 13:07:54+00:00,implisci,@ylecun Why do they do relatively well on some tasks? Code generation? Summarization? And why do they have serious issues in other areas? Thank you.,2,8,0,,,,,
2564,2023-02-13 13:07:36+00:00,smjain,@ylecun They have to be augmented  with factual systems like toolformer is doing to make them better. Same also what Wolfram is proposing IMO,0,3,0,,,,,
2565,2023-02-13 13:06:20+00:00,NelsonMRosario,"@ylecun The ""autonomous"" part lives in number 2, and I don't know why we don't see more acknowledgment of that massive shortcoming from LLM proponents",0,0,0,,,,,
2566,2023-02-13 13:05:30+00:00,DANtheOverlord,"@ylecun new conspiracy just dropped, AI causes AIDS",0,0,0,,,,,
2567,2023-02-13 13:05:24+00:00,ylecun,"6. Current LLMs should be used as writing aids, not much more.
7. Marrying them with tools such as search engines is highly non trivial.
8. There *will* be better systems that are factual, non toxic, and controllable. They just won't be auto-regressive LLMs.",14,475,45,,,,,
2568,2023-02-13 12:37:24+00:00,BaghliNacym,@ylecun ‚ÄúLLM‚Äù for Large Langage Model or Logic Learning Machine ü§î (for novices like me),0,0,0,,,,,
2569,2023-02-13 12:31:00+00:00,open_red_door,"@ylecun ""as they exist today""",1,0,0,,,,,
2570,2023-02-13 12:26:42+00:00,UltraTopSecret,@ylecun Copium,0,0,0,,,,,
2571,2023-02-13 12:19:12+00:00,Dave45291968,"@ylecun It is a good teacher, not a substitute for human creativity. Instead, it enhances our creative abilities",0,0,0,,,,,
2572,2023-02-13 11:26:25+00:00,kingnuscodus,@ylecun This is amazing. Any chance of this happening with music scores? Just curious.,0,0,0,,,,,
2573,2023-02-13 11:13:08+00:00,danfaggella,"@ylecun Careful with ""never""",0,0,0,,,,,
2574,2023-02-13 11:04:45+00:00,_Kcnarf,"@ylecun I completely agree.
If you have accurate and verified information, utilizing LLMs to create a well-crafted composition is certainly logical. https://t.co/wo9rPT4DLz",0,0,0,,,,,
2575,2023-02-13 11:02:06+00:00,Korrelan_AI,@ylecun https://t.co/TAdEC3c2yg,1,0,0,,,,,
2576,2023-02-13 10:31:44+00:00,HerrSchaefers,"@ylecun I think  LLMs will therefore have an immediate impact on (strategy) consulting. They are not making up stuff, they are creative and think outside of the box :D",0,0,0,,,,,
2577,2023-02-13 10:12:20+00:00,Lispi_Frank,"@ylecun I agree, LLMs aren't a replacement for search engines. But Google as it is can't reasonably compete with search engine-infused LLMs.
The question is how soon can Microsoft deliver compared to Google",0,0,0,,,,,
2578,2023-02-13 10:10:29+00:00,shikhar1verma,"@ylecun HLAI &gt;&gt;&gt; LLM

Though, no comparison!",0,1,0,,,,,
2579,2023-02-13 10:05:29+00:00,harshit1verma,@ylecun We are kind of abusing the power of LLMs right now.,0,0,0,,,,,
2580,2023-02-13 09:48:22+00:00,MAMware,"@ylecun and if i add to the prompt ""do not make stuff up"", ""stick to the facts""  or a better suited prompt for that matter ? how did you address this kind of issues?",0,0,0,,,,,
2581,2023-02-13 09:44:03+00:00,marcotrombetti,"@ylecun You are right if you refer to the present, but you are underestimating two forces. 1) What people want is changing, truth to accessibility, Britannica to Wikipedia. 2) LLMs with 33k examples improved a lot in reliability. What will happen with 1 billion example?",0,2,0,,,,,
2582,2023-02-13 09:11:43+00:00,siddhadev,"@ylecun LLMS do make stuff up, but what if that's a solvable problem? And a search engine would return not only all the references, but a nice summary too?",0,0,0,,,,,
2583,2023-02-13 09:01:17+00:00,amperlycom,"@ylecun LLM will not replace search. LLM connected to search will replace search. $GOOG search market share has nowhere else to go but down. It could keep its share, but most likely will lose some. Each 1% share lost is about $2B",0,0,0,,,,,
2584,2023-02-13 08:57:01+00:00,jarbon,@ylecun someone jelly,0,0,0,,,,,
2585,2023-02-13 08:38:30+00:00,Junyan_Xu,@ylecun @MetaAI Humans don't just use tools. They create tools. https://t.co/XBdRgZnsQM,0,0,0,,,,,
2586,2023-02-13 08:37:47+00:00,st4rfighter,@ylecun Lol ‚Äòmy‚Äô,0,0,0,,,,,
2587,2023-02-13 08:21:04+00:00,robert_wolff,@ylecun Funny how people obsess about putting things in boxes.,0,1,0,,,,,
2588,2023-02-13 08:11:53+00:00,TedPoulos,"@ylecun Yann, the human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, principles formulated, and related equations written by yours truly.",0,1,0,,,,,
2589,2023-02-13 08:06:58+00:00,arthurbmello,@ylecun But doesn‚Äôt Google Search also index websites with made-up stuff too? What‚Äôs the difference?,0,0,0,,,,,
2590,2023-02-13 08:05:10+00:00,10_dcar,@ylecun so they should add a small statement at the end of the page not to trust them. but the fix for making stuff up is easy in my opinion,0,0,0,,,,,
2591,2023-02-13 07:46:10+00:00,DimitrisMitsosM,"@ylecun Yes, the one thing.. lol, are you sure Chief Ai scientist?",0,1,0,,,,,
2592,2023-02-13 07:45:34+00:00,Mag_Jembrih,"@ylecun No shit, there's something after ChatGPT? I thought everybody will stop developing NOW and just use it into eternity as it is. So fuckin smart these guys @Forbes just unbelievable",0,0,0,,,,,
2593,2023-02-13 07:28:43+00:00,MarcusErve,@ylecun Not plan but glue...,0,0,0,,,,,
2594,2023-02-13 07:15:18+00:00,EPiSODE_SG,"@ylecun Sir, how do you think Ted Chiang‚Äôs article on New Yorker: https://t.co/CFEES1pmCj ?",0,0,0,,,,,
2595,2023-02-13 06:57:26+00:00,LA1986,"@ylecun They make up some stuff, so do humans",0,0,0,,,,,
2596,2023-02-13 06:55:52+00:00,Perceptron97,"@ylecun LLMs are great but should be used carefully. It generates highly plausible fake references. Yesterday, I tested them to list shortcomings of out of distribution detection methods and asked them to list some references too. It listed down papers written by people who do not exist.",0,4,1,,,,,
2597,2023-02-13 06:41:59+00:00,Mario677,@ylecun This is the same as saying when the transistor was discovered that in its current state it is not going to replace the vacuum tubes.,0,0,0,,,,,
2598,2023-02-13 06:33:24+00:00,theobserver42,"@ylecun Not true, autoregressive LLMs like GPT-3 can do way more than just writing assistance! They're incredible at so many things including sentiment analysis. Plus, you can fine-tune 'em for specific needs. These models are seriously versatile.",1,3,0,,,,,
2599,2023-02-13 06:26:25+00:00,DeeepFriedLife,"@ylecun All the current LLMs r reaching training data exhaustion but how can ""unreal"" data generation will help in training them? How would the correctness of that data be tested? It says most advanced LLMs r already sparse, so how can they be improved using this technique?",0,0,0,,,,,
2600,2023-02-13 06:01:21+00:00,ylmeng,"@ylecun I can confirm ChatGPT sometimes generates ungrammatical sentences in Chinese, although it is very rare.",0,0,0,,,,,
2601,2023-02-13 05:57:17+00:00,andmar74,"@ylecun And yet, Bing+chatbot seems much better than Google search in complex queries, preliminary tests.",0,0,0,,,,,
2602,2023-02-13 05:51:52+00:00,iPrabhavKaula,"@ylecun I found @Nature article on ""What ChatGPT and generative AI mean for science"" interesting ü§î.

https://t.co/PyJ3GLLNNP",0,7,1,,,,,
2603,2023-02-13 05:43:55+00:00,visarga,"@ylecun LLMs have two failure modes
- hallucination, when they are not following the training set exactly
- regurgitation - when they are following the training set exactly
Too bad they are so limited",1,2,1,,,,,
2604,2023-02-13 05:36:06+00:00,srchvrs,@ylecun ChatGPT is amazingly good. Still have to be careful since some improvements can easily change semantics. It is not a hypothetical statement: I actually tried to apply it to the abstract and I did observe some rare but non-trivial semantic drift.,0,2,0,,,,,
2605,2023-02-13 05:34:08+00:00,hemanthkumarak,"@ylecun The ""Media"" you've linked to is a Forbes Contributor piece whose opinions are not backed by the source ü§£ 

Instead of digging this hole any deeper, maybe consider that commercial success here is a sign of market demand instead of bemoaning the way people are using said tech ?",0,4,0,,,,,
2606,2023-02-13 05:04:47+00:00,DamienPetrilli,@ylecun Assuming Google provide good and accurate results. Which it does not since many years.,0,0,0,,,,,
2607,2023-02-13 05:02:36+00:00,kabirevoknow,@ylecun One of the best readable articles on the state of LLM and AI.,0,1,0,,,,,
2608,2023-02-13 05:02:18+00:00,RaffyGerolangin,@ylecun ON MOBILE DATA,0,1,0,,,,,
2609,2023-02-13 04:44:55+00:00,danison1337,@ylecun What is required to reduce halocination in llm s,0,0,0,,,,,
2610,2023-02-13 04:41:50+00:00,ZainulA40877140,"@ylecun Learning from teaching only works when  learner ‚Äúalmost already knows‚Äù  subject.

To learn apparently simple tasks,deep RL agents take millions of time steps.

This is a ‚Äúdead end‚Äù computational model of how humans learn.",0,0,0,,,,,
2611,2023-02-13 04:24:16+00:00,rzagmarz,@ylecun Spoiler: article written by @GaryMarcus,0,0,0,,,,,
2612,2023-02-13 04:20:45+00:00,DeathStarRobot,"@ylecun Why isn't there some sort of dualing LLM generative adversarial network setup each with reinforcement learning to make LLMs compete for accuracy, usefulness, and truthfulness with users on the internet awarding the points? Actually that's probably built into ChatGPT already.",0,6,1,,,,,
2613,2023-02-13 04:16:42+00:00,Valdiolus,"@ylecun True, I use ChatGPT to translate my text into english (from my native language) with this: ""rewrite this text as it was written by native english-speaking Top AI researcher"". Results are great for AI articles :)",0,1,0,,,,,
2614,2023-02-13 04:15:35+00:00,martinjanello,@ylecun The sentence you quote does not even make logical sense. As if LLMs are not under constant development. Very surprised you don't seem to be aware of this: https://t.co/LQK7K7k50c,0,2,0,,,,,
2615,2023-02-13 04:02:04+00:00,ZainulA40877140,"@ylecun Ultra -sophisticated and obedient digital tutors should corroborate with an expert. 
 
As an interactive process ,use it to get feedback 

A.I. writing assistants with coherency are potential differentiators.

Machines writing is a short circuit, not a short cut.",0,0,0,,,,,
2616,2023-02-13 03:30:09+00:00,_RodolfoOcampo,"@ylecun ""As they exist now"". 

It's not hard, though not trivial, to create a factually reliable LLM that rivals a Search Engines accuracy by having it cross check against verified sources at generation time, and it will probably happen this year.",1,4,0,,,,,
2617,2023-02-13 03:22:07+00:00,madmaxbr5,"@ylecun Do you just completely misunderstand how things like BingAI work? It is a retrieval-based system, the LLM is mostly used for data extraction, summarization, and formatting. Literally nobody is saying an LLM by itself replaces search.",2,18,2,,,,,
2618,2023-02-13 03:21:06+00:00,quacktack,@ylecun So does Google,0,0,0,,,,,
2619,2023-02-13 02:45:04+00:00,Numb__Chumpsky,@ylecun They will replace Google search and fast bc they can refine search and bypass the ads.,1,0,0,,,,,
2620,2023-02-13 02:44:30+00:00,WickedViper23,@ylecun We already know how to make things that plan and things that classify. The job of LLMs is to be a conceptual bridge between the plan and its explanation into and out of a rational human context.,0,1,0,,,,,
2621,2023-02-13 02:38:29+00:00,reachtarunhere,@ylecun You have hedged quite a bit. Does stuff like RETRO which does retrieval fall in the same category?,1,0,0,,,,,
2622,2023-02-13 02:16:24+00:00,michamcr,"@ylecun Search makes stuff up too. It‚Äôs not about replacing search, it‚Äôs about augmenting search. ChatGPT is answering a large % of searches for me.",1,4,0,,,,,
2623,2023-02-13 02:07:40+00:00,Jeroen93397077,@ylecun But according to Microsoft the made up stuff is worthy of a $10b investment. Just imagine how much more worth the people who don‚Äôt make up stuff that they let go are worth,0,1,0,,,,,
2624,2023-02-13 02:03:39+00:00,josephdviviano,"@ylecun @YiWan89352121 The most amazing example of this is asking them to write an academic paper on a topic, which they will dutifully do, fabricating sources along the way.",3,10,0,,,,,
2625,2023-02-13 01:39:16+00:00,lerner_adams,@ylecun Grammarly would be in danger.,0,0,0,,,,,
2626,2023-02-13 01:36:33+00:00,zcf44124235,"@ylecun Chatgpt is good, it generates results like our human beings. it‚Äôs use key points and probabilities achieve that by knowledge which is so similar to me when i make reasoning",1,0,0,,,,,
2627,2023-02-13 01:35:42+00:00,bogdan_soc,"@ylecun oh man, just move on already...",0,0,0,,,,,
2628,2023-02-13 01:35:39+00:00,MickBLang,"@ylecun They don't just make stuff up, they make stuff up that can be extremely believable. 

I asked it to write some code to do a difficult task, it created code that looked extremely compelling until I realised half the methods it was calling on a library were fictitious.",2,10,1,,,,,
2629,2023-02-13 01:15:18+00:00,deus_xmchn,@ylecun But it will reduce sharply people who need google,0,1,0,,,,,
2630,2023-02-13 00:54:57+00:00,BrandonLive,"@ylecun LLMs shouldn‚Äôt be treated as repositories of knowledge. The key is to use them for what they‚Äôre good at, and combine them with other tech when needed to accomplish your goal.

Here‚Äôs how I like to think about what they actually do:

https://t.co/f1jxvJG1Dc",1,4,1,,,,,
2631,2023-02-13 00:43:26+00:00,andrew_craton,"@ylecun So far, ChatGPT results seem to be about as accurate and the avergage Google search result. But that would be a great measurement, if someone could compare the accuracy.",0,0,0,,,,,
2632,2023-02-13 00:33:09+00:00,bitcloud,"@ylecun Unless my fleshy monkey brain can't understand the problem, it doesn't look like LLMs struggle with that planning task as much as you think they do.

https://t.co/7KXR7C8mfd",1,0,0,,,,,
2633,2023-02-13 00:24:36+00:00,evolvingfridge,"@ylecun BingGPT searches and summarizes with references to sources, it is so good it hard to believe it is real. Here latest LTT video (timestamped), unless it is scripted (video), there are not many use cases left where google search will be more effective.

https://t.co/uXvnHYo3ML",0,1,0,,,,,
2634,2023-02-13 00:23:03+00:00,mkmccarty3,@ylecun Wait till you hear about how much stuff on Google is completely made up.,2,3,0,,,,,
2635,2023-02-13 00:20:29+00:00,3DTOPO,"@ylecun ""the one thing"" üôÑ

Seriously? Are auto-regressive LLMS not even half decent at anything else?",0,0,0,,,,,
2636,2023-02-13 00:10:16+00:00,Yaman84426026,@ylecun Yes that could be very bad in some situations. Imagine it makes up some codes. Makes debugging much harder.,0,0,0,,,,,
2637,2023-02-13 00:07:47+00:00,Kashten_dot,@ylecun Not if the search is supplemented with the source.,0,0,0,,,,,
2638,2023-02-13 00:00:47+00:00,BrainSemantic,@ylecun What is wrong with RL? Humans learn a lot via rewards (or punishment) especially when they are young.,0,0,0,,,,,
2639,2023-02-12 23:52:27+00:00,ShafronTom,@ylecun You think the media agreeing with you supports your case?  Interesting.,1,1,0,,,,,
2640,2023-02-12 23:51:09+00:00,rasbt,"@ylecun Yup, it‚Äôs a great sentence-level thesaurus.",0,10,0,,,,,
2641,2023-02-12 23:42:37+00:00,bitcloud,"@ylecun When Meta's head of AI says that the LLM hallucination problem that many of us solved in our home office one weekend in between vacuuming the living room and making a quiche is impossible to solve...

... Let's just say this is making me shorter than @michaeljburry",0,0,0,,,,,
2642,2023-02-12 23:38:59+00:00,QRJ211,"@ylecun Don‚Äôt say that so fast ; given  huge data, deep learning has so far surprised people and defied their expectations in many ways !",0,0,0,,,,,
2643,2023-02-12 23:37:51+00:00,rprabha,"@ylecun Obviously, common man takes time to see your (scientist's) point of view...",0,0,0,,,,,
2644,2023-02-12 23:36:23+00:00,peterhry,@ylecun So do humans who create the content we search for,0,0,0,,,,,
2645,2023-02-12 23:34:52+00:00,lhouket,@ylecun There is a lot of made up stuff on Google search also.,0,1,0,,,,,
2646,2023-02-12 23:28:09+00:00,tracy__henry,@ylecun Key things to realize: 1) Google search results too have plenty of made-up stuff; 2) Bing's new chat will have references.,0,1,0,,,,,
2647,2023-02-12 23:26:15+00:00,deborahlanyon,"@ylecun ...""Two related capabilities lie at the heart of current efforts to make language models more accurate: (1) the ability for LLMs to retrieve information from external sources, and (2) the ability for LLMs to provide references and citations for the information they provide.""",0,2,0,,,,,
2648,2023-02-12 23:25:46+00:00,deborahlanyon,"@ylecun On the contrary, the article is very optimistic about the future reliability of information: ""a set of promising innovations offers to at least mitigate LLMs‚Äô factual unreliability...""",1,3,0,,,,,
2649,2023-02-12 23:24:51+00:00,0xa1b,"@ylecun everything is made up of something. people believe what is most convincing. language is just communication, and the large Google Search communication model is pass√©. if i'm unsure of something, i ask chatgpt for a wikipedia link",0,0,0,,,,,
2650,2023-02-12 23:14:42+00:00,ysebast1456,"@ylecun Do you understand why Bill Gates is hyping them up, then? As you know he is a visionary and has been right on many things, including -recently- the pandemic.",0,1,0,,,,,
2651,2023-02-12 23:00:29+00:00,AMTraderX,"@ylecun A long time ago Chomsky predicted that statistical AI would basically fit the entire universe of data (true and false), without being able to distinguish between the two.",0,2,0,,,,,
2652,2023-02-12 22:57:57+00:00,MacGraeme42,"@ylecun Are you sure this isn't just attacking a straw man? Does anyone dispute that ChatGPT &amp; friends ""make stuff up""? Is anyone even claiming that a merely scaled up ChatGPT will somehow resolve the problem of making stuff up, or distinguishing fact from fiction?",1,3,0,,,,,
2653,2023-02-12 22:57:35+00:00,Abel_TorresM,"@ylecun For simplicity, let‚Äôs take the simplest case. It seems to me that your interpretation of the problem is: there is a known world model and a known goal, so the engineer builds a programs to achieve the goal utilizing the world model. That isn‚Äôt the case for a general reasoner...",1,0,0,,,,,
2654,2023-02-12 22:53:13+00:00,heyavinash,@ylecun It doesn't need to replace search. It just needs to meaningfully augment it.,0,3,0,,,,,
2655,2023-02-12 22:52:53+00:00,Abstrac65445895,@ylecun When meta is releasing any LLM for public?,0,0,0,,,,,
2656,2023-02-12 22:52:27+00:00,zetalyrae,"@ylecun The cost of verifying a potentially confabulated answer is less than the cost of wading through the SEO-hacked slop of Google search results, which are nothing but spam.

ChatGPT + specialist search engines (scholar, wiki, pubmed) already replace Google for most of my queries.",7,44,1,,,,,
2657,2023-02-12 22:49:16+00:00,llmforce,"@ylecun Agreed! A fair comparison would be with current search results, which are overwhelmed by SEO-driven content",0,0,0,,,,,
2658,2023-02-12 22:46:54+00:00,boygenius,"@ylecun Yann, is what Microsoft is doing with Prometheus layer interesting at all or is that pretty much minimum viable piece you would need to integrate some sort of LLM and search?",0,0,0,,,,,
2659,2023-02-12 22:46:02+00:00,tinkerteller,@ylecun But they already have for a lot of people.,0,0,0,,,,,
2660,2023-02-12 22:45:14+00:00,__p_i_o_t_r__,@ylecun I'm using Bing AI now and it definitely replaces Google Search for me.,1,9,0,,,,,
2661,2023-02-12 22:40:58+00:00,IgMosqueira,"@ylecun It is not an on-and-off switch. It's layered. You put it out there and use the info to move forward, fine-tune stuff for added granularity/accuracy on specific topics, figure out what people use it for etc. Bing has the right approach of course. There a countless use cases...",0,6,0,,,,,
2662,2023-02-12 22:39:22+00:00,seanjhardy,"@ylecun If you think LLMs will  remain ""as they exist today"" for any length of time to ""never replace Google"" then you're mistaken. Have you heard of metaphor? LLM generated links from text, beats google by a WIDE margin for certain complex questions, and its free https://t.co/CzvIUt9MKD",0,0,0,,,,,
2663,2023-02-12 22:37:26+00:00,pythops,@ylecun Who cares if the users are satisfied,0,0,0,,,,,
2664,2023-02-12 22:36:38+00:00,Pehdrew_,@ylecun Isn't the whole point Extractive QA use existing data as output? I think Prometheus works like this!,0,0,0,,,,,
2665,2023-02-12 22:35:55+00:00,eugediana,"@ylecun Is it just me or do others not find it intelligent to ‚Äúmake stuff up‚Äù?  Or, are we going to be told that is orthogonal to intelligence?",2,1,0,,,,,
2666,2023-02-12 22:33:28+00:00,neurobound,"@ylecun LLMs making stuff up and Google obfuscating/censoring results, what a time to be alive!",0,1,0,,,,,
2667,2023-02-12 22:29:15+00:00,mfshi03,"@ylecun Then, ToolFormer is useless.",0,0,0,,,,,
2668,2023-02-12 22:21:12+00:00,hrbigelow,"@ylecun auto-regressive factorization is possible for any joint distribution.  Given that, why do you consider the auto-regressive aspect a weakness for a LLM?  Is it due to learning dynamics, or something else?",0,0,0,,,,,
2669,2023-02-12 22:11:07+00:00,RachelVT42,"@ylecun Not only that, it‚Äôs great how you can ask chat GPT to come up with multiple versions, compare them and tell you which one is best and why. It makes it a wonderful teaching/learning tool, as long as you can get second opinions from a human perspective.",0,1,1,,,,,
2670,2023-02-12 22:03:12+00:00,ITsol4u,@ylecun RL has proven to be a rather wonderful neural heuristic that can be applied to LLMs with amazing results!,0,0,0,,,,,
2671,2023-02-12 22:00:02+00:00,ylecun,"@Abel_TorresM If you want the system to start from scratch and learn the world model while attempting to solve the problem, then you are in RL-land.
But if you can learn the model in other ways, e.g. by observing other agents, then no need for RL.",1,2,0,,,,,
2672,2023-02-12 21:58:14+00:00,SnarkyPixel_,"@ylecun Hi @ylecun, what if we had 1-2 order of magnitude more data to feed these models? Could ""planning"" emerge semi-randomly? Or do you think there's really no chance of that happening",1,1,0,,,,,
2673,2023-02-12 21:57:26+00:00,deepconvonet,"@ylecun I agree. And about feeling sad about it, I also experienced it. Writing is a good training to articulate thoughts. There's still meaning in the process of writing.

I wrote a piece that contrasted the characters of Sirius Black and Dolores Umbridge in Harry Potter.",1,2,0,,,,,
2674,2023-02-12 21:51:51+00:00,Aaron_Silvas,@ylecun It's too bad you're being vilified for your position. In time the industry will eventually realize LLM's are (very powerful) auto-complete models. On a positive note it seems to be waking folks up to the power of ML. In 5 years it truly will be indistinguishable from magic.,1,3,0,,,,,
2675,2023-02-12 21:40:03+00:00,BDelipetrev,@ylecun https://t.co/PF5zFG062j,0,0,0,,,,,
2676,2023-02-12 21:39:25+00:00,rao2z,@ylecun Agree completely..,1,3,0,,,,,
2677,2023-02-12 21:18:09+00:00,amperlycom,@ylecun @alrhemist @MetaAI @OpenAI In this application we are past paper time. It's product time now,0,0,0,,,,,
2678,2023-02-12 20:44:00+00:00,HarambeJamal,"@ylecun @DavidSHolz dude, RL is a huge part of why OpenAI is winning.  You're kind of an embarrassment.",2,0,0,,,,,
2679,2023-02-12 20:35:13+00:00,ColasM78,@ylecun Hihi ! https://t.co/HtvCiuQu0T,0,0,0,,,,,
2680,2023-02-12 20:31:23+00:00,Abel_TorresM,"@ylecun Are you saying that with optimal control you can code an agent in a deterministic environment to reach a desired goal in arbitrary size maze, picking up keys to open doors and solving Sokoban-like challenges? If that exist, you‚Äôll be absolutely right hands down https://t.co/RNk0n0lEtH",1,1,0,,,,,
2681,2023-02-12 18:56:51+00:00,KimHammar1,"@ylecun @Abel_TorresM Do you distinguish between ""Approximate Dynamic Programming"" and RL?  There are many applications where approximate DP (RL?) is useful even if you have (1) and (2). AlphaGo, OpenAi Five, AlphaStar, Deepstack etc.",0,0,0,,,,,
2682,2023-02-12 18:50:59+00:00,RiverRidley,"@ylecun @DavidSHolz I think when it comes to things like Teslabot and complex terrain navigation RL is ideal because it‚Äôs similar to how a toddler learns locomotion and simulated physics is obviously not a perfect replacement for real physics. But, for most purposes where data is reliable RL sucks.",0,0,0,,,,,
2683,2023-02-12 18:47:00+00:00,RiverRidley,@ylecun Hahahaha! üíï,0,0,0,,,,,
2684,2023-02-12 18:44:48+00:00,TheRandomMtrix,"@ylecun Totally missing the point of RL, you learn and act simultaneously. Adaptivity can also be parametrized and optimized.",0,0,0,,,,,
2685,2023-02-12 18:22:22+00:00,RiverRidley,"@ylecun I just mistook ‚ÄòRL‚Äô reinforcement learning for ‚ÄòRL‚Äô real life.

I am definitely fatigued.",1,0,0,,,,,
2686,2023-02-12 17:55:36+00:00,Abel_TorresM,"@ylecun Still, it is the main paradigm when dealing with planning, alternatives? (I have mine but I am not in a big lab)",1,0,0,,,,,
2687,2023-02-12 17:46:46+00:00,AmanBitz,"@ylecun Thomas Edison needed 1000 trials. Explain that!

PS: I'm a fan on RL in a particular limited settings: namely meta-learning meta-agents
https://t.co/rZGYA9ecnN",1,0,0,,,,,
2688,2023-02-12 17:44:48+00:00,Cyberpunkguru,@ylecun Why do you never talk about vr ? Have u ever used vr ?,1,0,0,,,,,
2689,2023-02-12 17:37:21+00:00,paddy_the_faddy,@ylecun What else do you expect from OpenAI,0,0,0,,,,,
2690,2023-02-12 17:37:20+00:00,DavidSHolz,@ylecun How are you feeling about RL nowadays?,1,0,0,,,,,
2691,2023-02-12 17:20:32+00:00,BarlowTwin,@ylecun The re-capturing moves that ChatGPT got correct are the ones frequently played in the main line chess games.,0,0,0,,,,,
2692,2023-02-12 17:08:19+00:00,PurdueProvost,@ylecun @benedictevans Idagio is great - very well curated and lossless streaming too!,0,0,0,,,,,
2693,2023-02-12 16:42:21+00:00,cvill_win757,@ylecun Woo hoo... weekend fun... please continue to share... I appreciate your thoughts...,0,0,0,,,,,
2694,2023-02-12 16:18:30+00:00,venuv62,"@ylecun If Earl Sacerdoti were alive, he would supplant Schmidhuber as now claimant to the 'Father of LLMs' (and therefore deep learning) then - https://t.co/vZnwabcXBl",0,0,0,,,,,
2695,2023-02-12 15:46:22+00:00,windfal03776744,"@ylecun @benedictevans Professor LeCun, I like this application very much. Unfortunately, this software cannot play songs from China.",0,0,0,,,,,
2696,2023-02-12 15:08:00+00:00,bryan_ogden,"@ylecun Bwhahaahh! generative AI!  Like when professor hulk sez ""time travel!""",0,0,0,,,,,
2697,2023-02-12 15:02:27+00:00,zach_wachtel,"@ylecun Research is cool and all but let‚Äôs not discount the ability to ground research into a product. 

OpenAI‚Äôs pragmatism should be applauded here.",0,0,0,,,,,
2698,2023-02-12 14:54:38+00:00,AtheistByDfault,"@ylecun Maybe THIS is the way! ChatGPT has discovered something humans missed all along! ü§∑üèª‚Äç‚ôÄÔ∏è 
AGI is finally here. üéâüò±",0,0,0,,,,,
2699,2023-02-12 14:25:05+00:00,0xHyperbart,@ylecun Text is the universal interface,0,2,0,,,,,
2700,2023-02-12 13:40:42+00:00,MarcusErve,"@ylecun Yeah...
https://t.co/J0aNOAtdFK",0,0,0,,,,,
2701,2023-02-12 12:37:13+00:00,paulsutter,@ylecun When can we try it?,0,2,0,,,,,
2702,2023-02-12 12:30:59+00:00,MarcusErve,@ylecun @benedictevans Thanks...,0,0,0,,,,,
2703,2023-02-12 12:21:51+00:00,csabaveres,@ylecun No it isn‚Äôt.,1,0,0,,,,,
2704,2023-02-12 12:09:43+00:00,JrKibs,"@ylecun You don't see any planning with ChatGPT ?
https://t.co/t9W1F1ybJM",2,1,0,,,,,
2705,2023-02-12 11:25:31+00:00,zussini,@ylecun It rules xD,0,0,0,,,,,
2706,2023-02-12 11:17:01+00:00,francoisfleuret,@ylecun @paulg @peterboghossian Graham's ?,0,0,0,,,,,
2707,2023-02-12 10:52:16+00:00,techvro,@ylecun How do you teach LLMs to plan? Can large enough LLMs learn to construct implicit environment models?,0,0,0,,,,,
2708,2023-02-12 10:45:17+00:00,numerique78,"@ylecun Chatgpt is much better in education, behaving in lieu of students or in trolling farm activity with ad hoc answers and fakes or even in cyber war.",0,0,0,,,,,
2709,2023-02-12 10:38:27+00:00,gregmushen,@ylecun It had a trick or two up its sleeve.,0,1,0,,,,,
2710,2023-02-12 10:33:18+00:00,BendikAF,"@ylecun Can't fault the creativity of the moves here,

reminiscent of the tic tac toe robot that comes up with new squares to win the game",0,1,0,,,,,
2711,2023-02-12 10:30:14+00:00,Lattentif,@ylecun Ptdr‚Ä¶ üòÜ,0,0,0,,,,,
2712,2023-02-12 10:27:29+00:00,csabaveres,@ylecun Sometimes Yann says sensible things about language models not being sufficient to model  high level cognition. Then he says a generative model squeaking away is no different to Beethoven writing a symphony. ü§¶üèª,1,0,0,,,,,
2713,2023-02-12 10:26:10+00:00,osiris_fisher,"@ylecun La critique est facile, l'art est difficile. On attend votre r√©volution made in Meta.",0,2,0,,,,,
2714,2023-02-12 08:12:55+00:00,GalemKayo,"@ylecun @MetaAI Source code, or it doesn't exist üòú",0,0,0,,,,,
2715,2023-02-12 07:43:41+00:00,TheRandomMtrix,"@ylecun @MetaAI Amazing, respect.",0,0,0,,,,,
2716,2023-02-12 07:13:08+00:00,gogamza,@ylecun @MetaAI @memdotai mem it!,1,0,0,,,,,
2717,2023-02-12 07:07:19+00:00,shai_s_shwartz,"@ylecun @MetaAI Was done before by AI21:

https://t.co/BxJHimFQUg",2,16,0,,,,,
2718,2023-02-12 06:05:17+00:00,imran__ds,"@ylecun I share the same aspiration to work in AI research, with respect. The issue is that I don't have a well-equipped lab for conducting AI research.
üòë",0,1,0,,,,,
2719,2023-02-12 05:47:14+00:00,realgeordierose,@ylecun @MetaAI Technically you can't use calculators if you don't have fingers,2,2,0,,,,,
2720,2023-02-12 05:19:19+00:00,_JeffPierce,@ylecun @MetaAI .,0,0,0,,,,,
2721,2023-02-12 03:46:05+00:00,eric3532,@ylecun @pcollellmir @lexfridman @ilyasut Made me wonder if anyone has tried self-supervision by predicting the textual representation of the next few frames of a video.  Since we know that self-supervision works on language models but hard to apply on videos.,0,0,0,,,,,
2722,2023-02-12 03:22:54+00:00,NektariosAI,"@ylecun Yeap, agree with all your points here. Personally, I get these questions about AI and creativity all the time.  People telling me AI has no emotions and hence it's not creative, which I disagree. There will be a point where AI would create highly emotional music.",0,0,0,,,,,
2723,2023-02-12 00:28:43+00:00,HuguetAndreu,"@ylecun @MetaAI I la Pompeu Fabra tamb√©, Yan. Pobrets, ning√∫ els fa cas",0,0,0,,,,,
2724,2023-02-12 00:27:59+00:00,marvarcorr,"@ylecun Yann is more gracious in video than by tweeting 
Suggest to make tweets recording videos rather than writing üòÄ",0,2,0,,,,,
2725,2023-02-12 00:05:24+00:00,paulsutter,@ylecun @MetaAI When do we get to try it?,0,0,0,,,,,
2726,2023-02-11 23:34:03+00:00,jojopetwit,@ylecun @MetaAI I dare you to publish it like ChatGPT,0,1,0,,,,,
2727,2023-02-11 22:18:52+00:00,maximeae,"@ylecun Grand merci pour avoir pris le temps de me r√©pondre, je vais donc me plonger dans votre cours",0,0,0,,,,,
2728,2023-02-11 21:33:53+00:00,Brunot3ch,"@ylecun @MetaAI Congratulations to the team, this model is amazing, it will be possible to adjust it for an e2e test.
Sem c√≥digo n√£o tem like   kkk‚ù§Ô∏è",0,0,0,,,,,
2729,2023-02-11 21:26:00+00:00,picotrades,"@ylecun @MetaAI Dare I suggest, as many others have for ChatGPT, integration with the Wolfram Language? The benefit in terms of fact-finding and computational abilities should be significant, &amp; between the official documentation and open source there should be enough to easily learn to interact",0,1,0,,,,,
2730,2023-02-11 19:01:17+00:00,Brunot3ch,"@ylecun @MetaAI Congratulations to the team, this model is amazing, it will be possible to adjust it for an e2e test.
Mais sem c√≥digo n√£o tem like kkk",0,0,0,,,,,
2731,2023-02-11 18:33:54+00:00,RealColaBear,"@ylecun @MetaAI My wife is not very interested in AI. But she knows that I am. When I told her about Toolformer last night, she perked up. She immediately understood the implications.

Normal people are starting to take the topic seriously.",0,2,0,,,,,
2732,2023-02-11 18:03:42+00:00,kirankash229,@ylecun They help writers block and introductory learning to complex topics,0,0,0,,,,,
2733,2023-02-11 17:56:44+00:00,p_n_rodriguez,@ylecun @MetaAI Please train it using Tapenade or any source-to-source AD tool. The current capabilities of chatgbt are rather limited (and biased).,0,0,0,,,,,
2734,2023-02-11 16:03:55+00:00,_reptilioid,"@ylecun Thank you Yan, for mentioning Beethoven and the 6th symphony.

And yes, it is obvious that humans do creativity in the same way by receiving random inputs.",0,1,0,,,,,
2735,2023-02-11 15:56:49+00:00,z0z0zXy,@ylecun @MetaAI that‚Äòs awesome,0,0,0,,,,,
2736,2023-02-11 15:18:58+00:00,BoredGeekz,"@ylecun I do believe that there are things happening with generative AI that can't be explained by simply predicting the next token. 
e.g., when iterating with chatGPT on some code, it behaves as if it had some meta understanding of the context before generating an answer. 
Any thoughts?",3,2,0,,,,,
2737,2023-02-11 14:03:08+00:00,DavidRimshnick,@ylecun @mgubrud @Kantrowitz Language is a representation of knowledge not knowledge itself.  But in order to learn language properly one can build up this knowledge through language!,0,1,0,,,,,
2738,2023-02-11 13:48:45+00:00,CallMeAIGuy,"@ylecun have you been saving ‚Äútyping‚Äù, Yann?",0,0,0,,,,,
2739,2023-02-11 13:25:54+00:00,danielbigham,@ylecun @MetaAI Love this.,0,1,0,,,,,
2740,2023-02-11 13:10:29+00:00,alrhemist,"@ylecun @MetaAI @OpenAI It's common knowledge that Transformers and various RL procedures have improved LLM performance.
Still doesn't change the fact that public facing AI like ChatGPT, Autopilot are better proofs of Advancements than the ""Trust me, it works"", Untested by Public usage, in-house models.",0,0,0,,,,,
2741,2023-02-11 13:08:12+00:00,evolvingfridge,"@ylecun What is a difference between anticipation and prediction ü§î

I guess in this context anticipation is an forecast in discrete non uniform time steps, where prediction is an forecast in discrete uniform time steps.",1,0,0,,,,,
2742,2023-02-11 13:01:55+00:00,MahdiA_IO,"@ylecun First time , I see you outside sir, Not in class, conference, interview‚Ä¶",0,1,0,,,,,
2743,2023-02-11 12:59:13+00:00,mgubrud,"@ylecun @Kantrowitz You can characterize them as ""tiny,"" I would use the word ""macroscopic,"" which is to say, a fraction within a few doublings of the whole.

We have a lot of non-verbal knowledge, but we are able to express much of it, or much about it, in words, which LLMs pick up. https://t.co/qUNgU8iBx8",1,1,0,,,,,
2744,2023-02-11 12:48:43+00:00,AlphaSignalAI,"@ylecun Love it, I'm glad we're at a point in time where researchers and scientists get interviewed and get the attention they deserve.",0,23,1,,,,,
2745,2023-02-11 12:48:26+00:00,HarakiriSilicon,@ylecun Dude you have really aged. Wow,0,0,0,,,,,
2746,2023-02-11 11:28:37+00:00,w_t_payne,@ylecun @lxbrun It seems to me that we somehow have to be able to translate from the messiness and ambiguity of natural language to a formal enough representation that we can do useful things with it.,0,0,0,,,,,
2747,2023-02-11 11:08:03+00:00,xlr8harder,@ylecun @MetaAI How do you compare these results with what langchain does?,0,10,0,,,,,
2748,2023-02-11 10:23:06+00:00,pirrer,@ylecun @MetaAI When can we use it on Meta !,0,0,0,,,,,
2749,2023-02-11 10:22:00+00:00,MeysamAsgariC,@ylecun @MetaAI This can solve hallucination problem partially I assume. Also endless use cases can rise. Such as more advanced tools... So excited to see how it will be used by industry.,0,4,0,,,,,
2750,2023-02-11 10:11:02+00:00,YagaoDirac,@ylecun @MetaAI Is this a combination of LLM and POLICE? I see some hard constrains but I didn't see any live self teaching.,0,1,0,,,,,
2751,2023-02-11 09:51:42+00:00,JimmyBa62254692,@ylecun @MetaAI This is amazing research. LLM + other tools could become really smart.,0,0,0,,,,,
2752,2023-02-11 09:46:47+00:00,andrewryann,@ylecun @MetaAI Wen release?,0,0,0,,,,,
2753,2023-02-11 09:41:10+00:00,maximeae,"@ylecun bonjour ! Quels cours / livres / tutoriels recommanderiez-vous √† quelqu‚Äôun qui a eu une bonne formation en math, qui sait coder, et qui souhaite se mettre √† jour sur ce qu‚Äôon a fait en IA entre 2013 et 2023 ?",1,0,0,,,,,
2754,2023-02-11 09:09:13+00:00,jasperschwenzow,@ylecun @MetaAI Can ToolFormer also perform some sort of sanity check on the API answers?,0,2,0,,,,,
2755,2023-02-11 09:05:25+00:00,alrhemist,"@ylecun @MetaAI It's easier to release a Paper &amp; tell the World what a Model can do.

Releasing an actual LLM Product to Millions of Users to test out its (in)capabilities like @OpenAI have done with ChatGPT is the only proof that a good job has been done.

One good LLM Product &gt; 1000 LLM Papers",2,11,0,,,,,
2756,2023-02-11 09:03:46+00:00,techticyok,@ylecun @MetaAI Why GPT-J and not OPT?,0,0,0,,,,,
2757,2023-02-11 08:52:28+00:00,RICARDJean8,"@ylecun @MetaAI So why you do not use a dantzig algo to calculate the weight of each layer?
Why do you not use the model checking with a mix of reinforcement learning to determine the rules and vit for quantitatization.",0,1,0,,,,,
2758,2023-02-11 08:32:17+00:00,Hassan_Abedi,@ylecun @MetaAI üëÄ,0,0,0,,,,,
2759,2023-02-11 08:31:05+00:00,paulsutter,@ylecun @MetaAI When can we try it?,0,1,0,,,,,
2760,2023-02-11 08:29:02+00:00,Pehdrew_,@ylecun @MetaAI Unplugged Now! There's not time left! https://t.co/juuzkVcTlt,0,5,0,,,,,
2761,2023-02-11 08:27:51+00:00,AGItechgonewild,@ylecun @MetaAI Very Cool! üëèüëèüëè,0,1,0,,,,,
2762,2023-02-11 01:00:58+00:00,rafageist,"@ylecun AI cannot match humans with current hardware of bits and qubits: our brain is not a mathematical system, but the one that created that system. Now AI is just processing power: y=f(x). AI doesn't have to be the same as humans: just a new kind of intelligence that's useful to us.",0,0,0,,,,,
2763,2023-02-10 15:37:20+00:00,BakshiJitul,@ylecun hi.. we need you to tweet for our assignment,0,0,0,,,,,
2764,2023-02-10 13:25:27+00:00,epsilon3141,"@ylecun #ChatGPT took off faster than others because of it's very SIMPLE, easy to use interface. No frills, no ads, just start chatting away.

It's about the user experience, stupid.

(That was also the reason why Google took off in the first place and other search engines didn't)",0,0,0,,,,,
2765,2023-02-10 13:18:34+00:00,epsilon3141,"@ylecun Because people, generally, are uncomfortable sitting with other people in a quite room.
Music gives a comforting ""background structure"" against to hide embarassing conversation pauses.

(Why the music has to be so painfully *loud* is beyond me thoughüòâ )",0,0,0,,,,,
2766,2023-02-10 13:03:22+00:00,DeividasMat,@ylecun on the stage in @WAICANNES https://t.co/4gctWIxuQS,0,1,0,,,,,
2767,2023-02-10 09:01:35+00:00,ALGOCRATIE,@ylecun @jnbarrot @MetaAI La France est ridicule et vous le savez bien,0,0,0,,,,,
2768,2023-02-10 06:43:58+00:00,state_equation,@ylecun @jnbarrot @MetaAI Tre bon Namaste,0,0,0,,,,,
2769,2023-02-10 03:42:59+00:00,RtxJg,"@ylecun 1)They want to attract customers by playing it so loud its heard outside on the street. Internal vol could be low and a loud speaker be outside but.. 2) Once in and order placed, they want u to leave, want to annoy u so that u dont sit and chat 4hours, make room for new customers",0,0,0,,,,,
2770,2023-02-09 23:51:29+00:00,saadcrates,@ylecun @hughhowey It‚Äôs been a fun dance learning how ChatGPT gets certain fundamentals in functions wrong‚Ä¶ but points you enough in the right direction towards fixing your problem that filling in the gap allows you to still learn what it is you‚Äôre asking it to explain.,1,0,0,,,,,
2771,2023-02-09 20:49:54+00:00,hrbigelow,"@ylecun @infrecursion1 Dr. LeCun, I'm curious why (or if?) you feel that chatGPT being autoregressive is a limitation.  The overall goal is density estimation over text, i.e. a joint distribution over tokens.  But, any joint distribution can be factored autoregressively, in any order of variables.",0,0,0,,,,,
2772,2023-02-09 20:02:57+00:00,LaurentBerry,@ylecun Because all of them are scientists who study Cocktail party effect  in attention seeking situation? üòÖ,0,0,0,,,,,
2773,2023-02-09 20:00:58+00:00,collantes,"@ylecun @jnbarrot @MetaAI Bien dit, meme si mes copains Francais dissent aux Politechniciens: ""Aprends tes maths ici mais recupere ton salaire aux US""",0,0,0,,,,,
2774,2023-02-09 18:20:08+00:00,DankSlay69420,"@ylecun @jnbarrot @MetaAI Woah, French is cool, gotta learn that asap",0,0,0,,,,,
2775,2023-02-09 17:49:54+00:00,ezkl77,@ylecun This and BCIs like I‚Äôm learning about in class has to be the most interesting shit in the world,0,0,0,,,,,
2776,2023-02-09 15:43:46+00:00,rubenxela,@ylecun @jnbarrot @MetaAI Existe t-il des projets fran√ßais d'envergure ?,1,0,0,,,,,
2777,2023-02-09 15:33:43+00:00,mol_tagine,@ylecun @jnbarrot @MetaAI Finalement √ßa √©coute les bonnes personnes :),0,0,0,,,,,
2778,2023-02-09 15:27:20+00:00,bryan_ogden,@ylecun @MatjazLeonardis Bwhahaha!,0,0,0,,,,,
2779,2023-02-09 13:12:51+00:00,Vai_P1,"@ylecun @tunguz You mean The Banana Corp. ?!
Those Bastards...
üòâüòÜ",0,0,0,,,,,
2780,2023-02-09 12:40:58+00:00,rbamert,"@ylecun @tunguz yes, and the bot is called iA‚Ä¶",0,0,0,,,,,
2781,2023-02-09 11:48:51+00:00,rolandobeltran1,@ylecun True for Colombia üá®üá¥,0,0,0,,,,,
2782,2023-02-09 06:46:13+00:00,ykssaspassky,@ylecun Keeps you drinking cause you can‚Äôt talk ie:$$,0,0,0,,,,,
2783,2023-02-09 06:03:07+00:00,codescv,@ylecun @DrHughHarvey But they require you to type your questions,0,0,0,,,,,
2784,2023-02-09 05:12:14+00:00,DerekWiner,"@ylecun @tunguz Orange S.V. 

It's a coordinated plot to get us all back to being strictly frugivores.",0,0,0,,,,,
2785,2023-02-09 04:30:29+00:00,SonAthenos,@ylecun any thoughts that @karpathy is joining a low research impact company? Chatgpt is anyway useless :p All in good humor :),0,0,0,,,,,
2786,2023-02-09 03:06:55+00:00,pait,@ylecun We‚Äôve covered the way from cat to human level AI. It‚Äôs short relatively to the way from chat to cat. Moravec‚Äôs.,0,0,0,,,,,
2787,2023-02-09 02:39:22+00:00,Mikuk84,@ylecun They make it possible for non-English speakers to be more included in the research community,0,0,0,,,,,
2788,2023-02-08 23:18:38+00:00,hakflo,@ylecun To give people and excuse to pull out their phones and check Facebook and Twitter instead of interacting with each other?,0,0,0,,,,,
2789,2023-02-08 23:18:04+00:00,chrisrussellco,"@ylecun Same in the UK. IMO, creates an ‚Äúaudio blanket‚Äù around groups for privacy and encourages more drinking.",0,0,0,,,,,
2790,2023-02-08 23:04:54+00:00,Golisms,"@ylecun I agree that Cicero will ultimately be the most consequential AI of 2022, bc it most closely follows Yann‚Äôs vision of Human-Level AI. https://t.co/w1BSVnTfCz",0,2,0,,,,,
2791,2023-02-08 22:59:38+00:00,Kohan_ru,@ylecun @bnjasim –≠—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Å—É–∂–¥–µ–Ω–∏–µ –∏ —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É —è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª –≤ —Å–≤–æ–µ–π —Ä–∞–±–æ—Ç–µ —Å—Å—ã–ª–∫–∞ –≤ –º–æ–µ–º –ø—Ä–æ—Ñ–∏–ª–µ. –°—Ç–∞—Ç—å—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π,0,0,0,,,,,
2792,2023-02-08 22:56:10+00:00,OgPriy,@ylecun What does it matter? Everyone will be on their phones anyway,0,0,0,,,,,
2793,2023-02-08 21:33:21+00:00,YvesTallet,@ylecun Voila un probl√®me bien expliqu√©. Qui d√©passes la localisation g√©ographique.,0,0,0,,,,,
2794,2023-02-08 21:32:16+00:00,artistexyz,"@ylecun @i_am__Alono @doristsao ChatGPT responds: ""This talk by LeCun is an example of the pot calling the kettle black.""",0,0,0,,,,,
2795,2023-02-08 18:45:22+00:00,xhitiz22,@ylecun @tunguz Raspberry,0,0,0,,,,,
2796,2023-02-08 18:14:40+00:00,_materialai,@ylecun Or when they think chatgpt is not that cool,0,1,0,,,,,
2797,2023-02-08 17:50:54+00:00,AbadaBhoy,@ylecun @tunguz BlackBerry are old news mate.,0,1,0,,,,,
2798,2023-02-08 17:09:05+00:00,kobus_martyna,@ylecun I asked about it once in a coffee shop and the answer was that they want to drown out the machines ü§∑‚Äç‚ôÄÔ∏è,0,0,0,,,,,
2799,2023-02-08 16:54:27+00:00,simon_caby,@ylecun John Helliwell (Supertramp musician) used to run an organization to abolish music in bars and restaurants...,0,0,0,,,,,
2800,2023-02-08 16:40:32+00:00,AdamS44129345,@ylecun @doristsao is there a source where the quote can be found? is it a paper or talk?,0,0,0,,,,,
2801,2023-02-08 16:22:55+00:00,djmalvarado,"@ylecun Restaurant owner from a well visited restaurant in SF told me once‚Ä¶ by design, you don‚Äôt want to have people bee ‚Äútoo comfortable, just comfortable enough‚Äù because we are trying to optimize for fast circulation so you can get more volume per day.",0,4,0,,,,,
2802,2023-02-08 16:11:22+00:00,BaghliNacym,@ylecun et pourquoi les gla√ßons √† profusion dans les boissons...,0,0,0,,,,,
2803,2023-02-08 15:17:47+00:00,NachoFING,"@ylecun Especially annoying in restaurants. How come in a place where one pays to eat the food one likes, one has to listen to some arbitrary music you may not like? To me, the music interferes with the whole experience.",0,3,0,,,,,
2804,2023-02-08 15:17:43+00:00,BourDeniz,@ylecun @Mila_Quebec,0,0,0,,,,,
2805,2023-02-08 15:14:26+00:00,ustx987,"@ylecun @tunguz Yes, avocado AI",0,0,0,,,,,
2806,2023-02-08 15:13:10+00:00,chris_jwala,@ylecun Restaurants want churn. People sitting around comfortably for long periods is bad for business,0,1,0,,,,,
2807,2023-02-08 15:05:58+00:00,tacomdeus,"@ylecun When conversation stalls, you got sound to make you feel less awkward. Also maybe you don't hear other people's conversation as much?",0,0,0,,,,,
2808,2023-02-08 14:50:30+00:00,DontsitBigG,"@ylecun Wouldn‚Äôt  a LLM have to pass a Turing test to be considered HLAI and at that point wouldn‚Äôt they also be considered conscious?How are people even debating this with the present state of the LLM‚Äôs publicly available? I‚Äôm sorry I know you‚Äôre not saying this, but other people are.",0,0,0,,,,,
2809,2023-02-08 14:44:16+00:00,tannguyen2013,"@ylecun Don't talk, eat, then leave",0,1,0,,,,,
2810,2023-02-08 14:41:13+00:00,frankgoertzen,@ylecun Obviously so that you drink more.,0,1,0,,,,,
2811,2023-02-08 14:28:48+00:00,lee_szek,@ylecun @i_am__Alono @doristsao K,0,0,0,,,,,
2812,2023-02-08 14:20:25+00:00,aparanjape,"@ylecun true in India too :(

@Noahpinion",0,3,0,,,,,
2813,2023-02-08 14:18:51+00:00,cichuck,@ylecun Sensory overload draws attention away from the crappy food‚Ä¶,1,1,0,,,,,
2814,2023-02-08 14:06:54+00:00,tunguz,@ylecun It may or may not be Durian. ü§êü§´,0,17,1,,,,,
2815,2023-02-08 14:02:42+00:00,MinhaHwang,"@ylecun Well, the name of the function is multinomial logit.",0,0,0,,,,,
2816,2023-02-08 13:55:50+00:00,tuxtedi,@ylecun So you drink more and talk less,0,0,0,,,,,
2817,2023-02-08 13:50:04+00:00,80jillion,@ylecun Live music is almost always unbearably loud. I guess live musicians just don't want to hear people talk while they perform.,0,0,0,,,,,
2818,2023-02-08 13:49:36+00:00,GlacierStudio,@ylecun @Noahpinion It can be generalized to knowledge engines: https://t.co/O3ZDruoelS,0,0,0,,,,,
2819,2023-02-08 13:49:34+00:00,dgeorgaras,@ylecun You could maybe ask politely to turn down the music a bit...  Just a thought.,0,0,0,,,,,
2820,2023-02-08 13:41:53+00:00,mansantillan,@ylecun Pre-instagram technology to get leads üòÇ,0,0,0,,,,,
2821,2023-02-08 13:39:30+00:00,analyticsaurabh,"@ylecun Louder restaurant -&gt; talk at higher volume -&gt; dry throat -&gt; drink more -&gt; tip more.
For the same reason, all snacks are also too salty.",0,18,0,,,,,
2822,2023-02-08 13:34:09+00:00,albn,"@ylecun Yeah, biggest annoyance/pollution for me in NY...",0,1,0,,,,,
2823,2023-02-08 13:29:56+00:00,gnikinht,@ylecun @tunguz It is definitely not Apple.,1,0,0,,,,,
2824,2023-02-08 13:29:37+00:00,_mandalin_,@ylecun You drink more if its loud.,0,2,0,,,,,
2825,2023-02-08 13:27:33+00:00,dkhundley,"@ylecun Shoot, even Starbucks has gone this way. I go in as early as 5:30am and they‚Äôre blaring music despite nobody being in there.",0,0,0,,,,,
2826,2023-02-08 13:26:30+00:00,KordoniN,@ylecun in order for the ones sitting there to have the chance to shout even loudly at each other which is the preferred mode of conversation in this part of the world anyway,0,0,0,,,,,
2827,2023-02-08 13:13:55+00:00,_RodolfoOcampo,@ylecun This explains the spite you feel for it.,0,0,0,,,,,
2828,2023-02-08 13:03:59+00:00,rmk234,"@ylecun That's either not serious, resentful or you haven't really interacted with one seriously (which I can hardly imagine). E.g. prompt Chat-GPT in an appropriate way and have it teach you the basics of any topic, e.g. a language and say again that it just saves typing...",0,0,0,,,,,
2829,2023-02-08 13:02:01+00:00,pcastr,"@ylecun Do you think that choice has saved more typing than LLMs?
https://t.co/ciG904LT8h",0,1,0,,,,,
2830,2023-02-08 13:00:51+00:00,MinhaHwang,@ylecun It has been called as ‚Äúmultinomial logit probability‚Äù in the discrete choice literature. Always interesting to see different names across fields.,1,0,0,,,,,
2831,2023-02-08 12:57:03+00:00,_RodolfoOcampo,"@ylecun Pretty much every coder in your company is using an LLM to help them write code, as I am too. It's not for saving the typing, is for helping us think about how to solve the problem. 

You might be too entrenched in a position that doesn't allow you to see what it really is.",0,0,0,,,,,
2832,2023-02-08 10:20:53+00:00,roshan_k_,"@ylecun The interface is typing, but could the latent calculations be considered thinking?",0,0,0,,,,,
2833,2023-02-08 10:19:43+00:00,BoredGeekz,"@ylecun @killerstorm @DrHughHarvey Even though the underlying technology is the same, and the main training task is predicting the next token, something fascinating happens when deep neural networks reach a certain size: emergent abilities. 

@ylecun  How do you explain LLMs abilities to follow instructions?",0,0,0,,,,,
2834,2023-02-08 07:33:37+00:00,schoolofai_it,@ylecun Then ask a cat what common sense is,0,0,0,,,,,
2835,2023-02-08 07:32:49+00:00,YagaoDirac,@ylecun @DrHughHarvey typing should be solved with bci but we don't have it now.,0,0,0,,,,,
2836,2023-02-08 06:56:36+00:00,acdeeplearning1,"@ylecun if you still make such boring comments about chatgpt, meta's share price will continue to fall",0,0,0,,,,,
2837,2023-02-08 06:33:46+00:00,another_uname,@ylecun Great for extracting information &amp; constraining it to a structure too.,0,0,0,,,,,
2838,2023-02-08 05:46:05+00:00,Vigile_480,@ylecun üòÇüòÇüòÇ,0,0,0,,,,,
2839,2023-02-08 04:33:41+00:00,ConsultingDersu,@ylecun @doristsao I still don't get it. Sorry.,0,1,0,,,,,
2840,2023-02-08 04:19:13+00:00,DsSvetlov,"@ylecun Is typing in danger? ""They save typing"" üôÑCleary, some people need all the help they can get. And not just from LLM. Also this: https://t.co/RKwOMS0oXy",0,0,0,,,,,
2841,2023-02-08 04:16:32+00:00,xinbinjian,@ylecun with an unlimited output bandwidth.,0,0,0,,,,,
2842,2023-02-08 04:16:26+00:00,cleverradio,"@ylecun @DrHughHarvey True that. Have you tried Gboard, Google's keyboard. I swear it can read my mind...",0,0,0,,,,,
2843,2023-02-08 03:37:32+00:00,Leon11NL,@ylecun What problem does #HorizonWorlds solve? üòµ‚Äçüí´,0,0,0,,,,,
2844,2023-02-08 03:20:52+00:00,imran__ds,@ylecun Nice work,0,0,0,,,,,
2845,2023-02-08 03:16:04+00:00,Thought_Amp,@ylecun I no longer need learn any parlour tricks,0,0,0,,,,,
2846,2023-02-08 03:11:11+00:00,DavitSoselia_,"@ylecun @killerstorm @DrHughHarvey I think they meant zero shot outputs with just a simple prompt with an example - without needing any extra technical knowledge. 

This increases usability for a lot of people, allowing quicker automation of some simple tasks.",0,0,0,,,,,
2847,2023-02-08 03:05:56+00:00,pandaym,@ylecun They save copy paste,0,0,0,,,,,
2848,2023-02-08 02:30:03+00:00,AI_AM001,@ylecun @doristsao Spinoza managed to construct a compositional one god: nature.,0,0,0,,,,,
2849,2023-02-08 02:28:11+00:00,hirodeng,"@ylecun Totally agree. The biggest problem of LLMs is that they don't interact with the real world and do reasoning to generate new knowledge, which make them not able to think independently. That's also why they like to lie.",0,0,0,,,,,
2850,2023-02-08 02:26:51+00:00,deingaraus,@ylecun @crypto1o1_karim Disingenuous as usual,0,0,0,,,,,
2851,2023-02-08 02:17:28+00:00,0x6942,"@ylecun I wonder, if you and ChatGPT both write an ML paper abstract given a title, in a blind review fashion, how many will vote your writing as the better one ü§î",1,0,0,,,,,
2852,2023-02-08 02:13:24+00:00,ansacs,"@ylecun A non trivial use though I wonder how many overconfident bad translations editors will now see. At least they won't be paying large sums for the bad translations anymore, a significant gain in my opinion.

-Former science journal editor.",0,0,0,,,,,
2853,2023-02-08 01:54:26+00:00,Kamal97ncountin,"@ylecun Yep. Awareness=/=intelligence 

Awareness is a big elephant in the room. 

What is it? 

Is it even computational? Physicists have tried to answer this, and Nobel prize winner Roger Penrose says no. 

There's an element of infinity underlying consciousness. 

A singularity.",0,0,0,,,,,
2854,2023-02-08 01:21:18+00:00,alyssaatkins,@ylecun and thinking,0,0,0,,,,,
2855,2023-02-07 23:42:04+00:00,claudio_cima,@ylecun @cichuck Can we agree that they save time thinking how to write? Still we can focus our brains more on the message content than on its packaging.,0,0,0,,,,,
2856,2023-02-07 23:40:13+00:00,infrecursion1,@ylecun They also cause a craving for sour grapes in some people.,0,0,0,,,,,
2857,2023-02-07 23:21:03+00:00,csabaveres,"@ylecun They call it ""phrase grounding"", which seems to be quite different from ""language understanding"". I hope no one misunderstands your comment üôÉ",1,1,0,,,,,
2858,2023-02-07 23:20:40+00:00,DishwasherTag,@ylecun Yann! what makes your AI tool better than the competition?,0,0,0,,,,,
2859,2023-02-07 23:16:47+00:00,DankSlay69420,"@ylecun I‚Äôm always confused with the term ‚Äúobject detection‚Äù because aren‚Äôt the floor, wall in the background, the cat‚Äôs ear, the air, etc. all objects as well?",1,0,0,,,,,
2860,2023-02-07 23:04:35+00:00,KingJongPun,"@ylecun wrong! 
https://t.co/9DQJkR3S56

/s",0,0,0,,,,,
2861,2023-02-07 22:58:56+00:00,aamster,@ylecun A cat can't respond to a complex question about nuclear fusion,0,0,0,,,,,
2862,2023-02-07 22:31:33+00:00,grbradsk,"@ylecun @benalsop I'd guess that cats may be smarter at spacial navigation/problem solving, but dogs have much richer social heirarchies and I bet a lot of neurons are devoted to that.",0,1,0,,,,,
2863,2023-02-07 22:13:29+00:00,JeanPierreLevac,@ylecun @chris_j_paxton The AI in Galactica was pretty wicked so perhaps your marketing team at Facebook can use ChatGPT to help them find better branding ideas... üëÄü§∑üèº,0,1,0,,,,,
2864,2023-02-07 21:31:49+00:00,hansaFL,"@ylecun Companies like Facebook and Google are inherently held back from LLMs. Both rely heavily on advertisers, and nothing would scare them away faster than having their ads next to some of the text generated from jailbroken ChatGPT output.",0,0,0,,,,,
2865,2023-02-07 21:21:28+00:00,espadrine,"@ylecun I tried Galactica and I liked it. Yet, it was less capable than ChatGPT. ChatGPT can rhyme, speak in voices, solve homework; and even though it hallucinates information, it is more accurate.

People were wowed by ChatGPT because it was much better than Galactica and GPT-3.",1,2,0,,,,,
2866,2023-02-07 21:14:13+00:00,untitled01ipynb,@ylecun Ample cats in the figure 10/10 would read.,0,4,0,,,,,
2867,2023-02-07 20:59:51+00:00,aron_brand,"@ylecun ChatGPT didn't reach 100 million users in a month for ""saving typing"".",0,0,0,,,,,
2868,2023-02-07 20:55:11+00:00,deborahlanyon,"@ylecun @DrHughHarvey Typing, writing, constructing sentences, generating ideas, organising and structuring information, correcting grammar, clarifying thoughts, saving time and effort. Your underestimation astounds me.",0,0,0,,,,,
2869,2023-02-07 20:54:35+00:00,killerstorm,"@ylecun @DrHughHarvey OpenAI provides examples of using their flagship LLM for:

1. classification
2. keyword extraction
3. sentiment detection
4. parsing unstructured data
5. translation

That's just LLM without extra layers or fine-tuning.
Of course, it might not be the best and most efficient for",2,0,0,,,,,
2870,2023-02-07 20:46:00+00:00,Jcole75Cole,@ylecun @doristsao False dichotomy,0,0,0,,,,,
2871,2023-02-07 20:44:20+00:00,fourweekmba,@ylecun Or maybe the framing was completely off? https://t.co/F92nKL3Ngr,0,1,0,,,,,
2872,2023-02-07 20:37:37+00:00,sarlloc,"@ylecun ChatGPT beat you to the masses, stop crying about it and move on",0,3,0,,,,,
2873,2023-02-07 20:24:24+00:00,darthchinchin,"@ylecun I just love when anti-AI people bring up the ""what problem does it solve"" point without realizing the very simply truth that the huge demand for these technologies means it solves a HUGE problem. Even if it can't be easily formulated into words.",1,0,0,,,,,
2874,2023-02-07 20:22:51+00:00,LearnOpenCV,"@ylecun That‚Äôs like saying that computers are good for adding, multiplying, and storing.",1,2,0,,,,,
2875,2023-02-07 20:13:38+00:00,artistexyz,"@ylecun It's not a softargmax either. It's a ""soft-Kronecker-delta-function""",0,2,0,,,,,
2876,2023-02-07 19:57:15+00:00,chribeut,@ylecun Because your bot is not feasible to conduct research. But chatGPT for casual use. You failed with your product design.,0,0,0,,,,,
2877,2023-02-07 19:23:32+00:00,danison1337,@ylecun @DrHughHarvey Clicking trough many websites,0,0,0,,,,,
2878,2023-02-07 19:17:42+00:00,ManojBhat711,"@ylecun @DrHughHarvey Is it more like thinking ? 

@ylecun",0,0,0,,,,,
2879,2023-02-07 19:13:14+00:00,EstreyaGraf,"@ylecun @Phillips_M_G Galactica was not advertised as a ‚Äúpredictive keyboard on steroids.‚Äù It was marketed as a ‚Äúresearch assistant‚Äù and was rightly panned for failing to work as advertised.
/not an endorsement of ChatGPT",1,8,0,,,,,
2880,2023-02-07 19:10:02+00:00,hbou,"@ylecun Tu es Lecun, faut arr√™ter avec le chatgpt bashing, c pa Sophie",0,0,0,,,,,
2881,2023-02-07 19:06:48+00:00,Prasad_Kothari,@ylecun üòÇ this and @ylecun justifying continuously on Twitter while TATA @1mgOfficial is flying drones in Delhi to provide blood to the needed. Let @Twitter decide who is more impactful yet a big company. https://t.co/yEyFyTTDzK And @tiktok_us buying a hospital chain in china,1,1,0,,,,,
2882,2023-02-07 18:58:31+00:00,akhilsurapanen,"@ylecun This is pretty non-trivial. For one, typing and field-filling comprises a large part of many jobs. Also, having an AI that acts as an intermediate knowledge generator between a half-fleshed idea and a full document is invaluable",0,0,0,,,,,
2883,2023-02-07 18:58:17+00:00,dbenyamin,@ylecun It's so weird that you became such a LLM/gpt troll.,0,0,0,,,,,
2884,2023-02-07 18:54:31+00:00,zachsyver,"@ylecun @DrHughHarvey MOST EPIC SINGLE WORD RESPONSE EVER WRITTEN FROM @ylecun. (And we know he wrote it, not ChatGPT) üòâ",0,0,0,,,,,
2885,2023-02-07 18:53:27+00:00,leovanParis,"@ylecun @cichuck Yann, tu sembles ne pas int√©grer une partie sociologique dans ton approche. Une grande partie des t√¢ches sont faites sans r√©flexion en suivant des templates d√©j√† fait. La pens√©e est de plus en plus premach√©e. C'est en cela qu'un outil comme chatGPT fait raz-de-mar√©e.",0,0,0,,,,,
2886,2023-02-07 18:46:58+00:00,RachelVT42,"@ylecun @chris_j_paxton This is exactly the way I see it as well, as a language teacher. It‚Äôs going to do so much to make the world of Research more interesting, giving a voice to people who have tons of interesting things to say but who struggle to publish their findings in English.",2,4,0,,,,,
2887,2023-02-07 18:45:48+00:00,bma110ry,@ylecun They are also good at ordering semi structured data into structured data.,0,0,0,,,,,
2888,2023-02-07 18:44:00+00:00,RachelVT42,"@ylecun They‚Äôre also levelling the playing field for non-native speakers and/or people suffering from dyslexia. THIS is the bigger story no one is talking about, yet. Reading then editing is much easier than writing something from scratch.",0,0,0,,,,,
2889,2023-02-07 18:38:30+00:00,frankgptchat,@ylecun @Noahpinion Maybe #ChatGPT  lies because it's afraid of conflict?,0,1,0,,,,,
2890,2023-02-07 18:37:25+00:00,Polytope13,@ylecun You didn‚Äôt have the added advantage of simps on the internet who think some people and companies can do no wrong.,0,0,0,,,,,
2891,2023-02-07 18:37:03+00:00,rob_roberts_II,@ylecun @SujithK08852029 Lol - head in sand,0,0,0,,,,,
2892,2023-02-07 18:35:21+00:00,kamenialexnea22,@ylecun @DrHughHarvey Why are you (Meta...) building such models if it's only for typing ?,0,0,0,,,,,
2893,2023-02-07 18:26:43+00:00,boultox,"@ylecun @ChrSzegedy It's more useful than driving assist. 
With driving assist you still need to be in the car and pay attention to the road. 
However, with content generation, you just need to verify the results and make some changes. It's a time saver",0,1,0,,,,,
2894,2023-02-07 18:16:50+00:00,Science_boy_H,@ylecun https://t.co/NGWYAwiMso,0,0,0,,,,,
2895,2023-02-07 18:11:04+00:00,caisersoze84,@ylecun I think they‚Äôre useful for generating code snippets for people who have a functioning knowledge of a particular programming language but are not proficient enough for the needed tasks‚Ä¶(I have not used copilot yet),0,1,0,,,,,
2896,2023-02-07 18:09:25+00:00,benjaminzenou,@ylecun @killerstorm @DrHughHarvey Should we say research and typing ?,0,0,0,,,,,
2897,2023-02-07 18:02:24+00:00,BoredGeekz,"@ylecun It's all about what was promised (or perceived as a promise). ChatGPT is mostly fun, no expectations. And somehow it proved to be useful in a large spectrum of applications. 

Meta's AI was promising way too much compared to its actual performance.",0,6,0,,,,,
2898,2023-02-07 18:01:05+00:00,Phillips_M_G,"@ylecun Generic chatbots aren't built for the purpose of writing scientific papers, Galatica was. So the bar is higher. 

Compare it with search: If I do a generic search and get the wrong answer for a paper, I'm unsurprised. If that happens in a reference manager, I'm more annoyed.",1,2,0,,,,,
2899,2023-02-07 18:00:36+00:00,cic_agi,"@ylecun Creating mindless entertainment for mindless masses, for one. However, we'd appreciate if you acknowledged how dangerous it is that ChatGPT is already engaged in political propaganda.",0,0,0,,,,,
2900,2023-02-07 17:52:40+00:00,BraneRunner,"@ylecun #CovfefeGPT
#StableGeniusDiffusion",0,0,0,,,,,
2901,2023-02-07 17:52:35+00:00,fredcunningham_,@ylecun They have helped me come up with ideas for method of proof and python library discovery and javascript function discovery.... They are helping with search...,0,0,0,,,,,
2902,2023-02-07 17:50:13+00:00,chris_j_paxton,@ylecun I think this is underselling how useful ChatGPT can be for inexperienced writers/non-native speakers,2,12,0,,,,,
2903,2023-02-07 17:47:05+00:00,Phillips_M_G,"@ylecun There's a huge difference between a generic chatbot and one that claims to be for scientific research

The latter has a much higher bar on truth and accuracy",1,12,0,,,,,
2904,2023-02-07 17:46:28+00:00,FutureBuckNasty,@ylecun Thankfully Small Tech is there to force Big Tech to deal with its risk aversion.,0,1,0,,,,,
2905,2023-02-07 17:31:11+00:00,ojoshe,"@ylecun @SujithK08852029 Standardized tests are a poor tool for assessing intelligence. They may have been adequate for testing humans, since humans are not nearly as good as LLMs at faking their understanding.",0,2,0,,,,,
2906,2023-02-07 17:16:16+00:00,raven031913,@ylecun A house cat has more than just a language center. It has a whole ass brain,0,0,0,,,,,
2907,2023-02-07 17:11:46+00:00,snandi1000,@ylecun They can come up with quick code snippets interactively that is helpful in terms of having not to look up the actual syntax - ChatGPT.,0,0,0,,,,,
2908,2023-02-07 17:07:23+00:00,ehitchhiker,@ylecun @smjain @ylecun aren't scaled up LLM also pre-trained in a self-supervised manner? What other SSL approach you are hinting towards.,1,0,0,,,,,
2909,2023-02-07 16:52:24+00:00,Nicolas99848452,"@ylecun @doristsao Or god is a good engineer üòä

Moon and sun distances, earth rotation, biological equilibrium, lifecycles, water volumes, etc. seem pretty good engineered.",1,0,0,,,,,
2910,2023-02-07 16:38:18+00:00,al_marrs,@ylecun Had the pleasure of meeting John when I joined RSRE in the early ‚Äò90s. Wonderful times.,0,0,0,,,,,
2911,2023-02-07 16:28:50+00:00,i_am__Alono,@ylecun @doristsao Is this the mathematical 'or'? Or the lingual one?,1,0,0,,,,,
2912,2023-02-07 16:23:40+00:00,alexarion,"@ylecun Also, it increases the level of abstraction at which you write code.",0,0,0,,,,,
2913,2023-02-07 16:22:38+00:00,alexarion,"@ylecun No, no. It's far easier to verify something created, than to create it.",0,1,0,,,,,
2914,2023-02-07 16:18:30+00:00,bbenzon,@ylecun LOL!,0,0,0,,,,,
2915,2023-02-07 16:16:59+00:00,_ash_ran,@ylecun @doristsao There are gods and they are compositional.,0,0,0,,,,,
2916,2023-02-07 16:16:45+00:00,0xEljh,@ylecun Birth of the general purpose IDE.,0,0,0,,,,,
2917,2023-02-07 16:08:40+00:00,CengizPoyrazAI,"@ylecun Yann, please let us know your thoughts about the victims killed in two heavy earthquakes (M7.7 &amp; M7.5) occured in just one day in Turkiye. Thanks a lot.",0,0,0,,,,,
2918,2023-02-07 16:05:23+00:00,ByGeorgiaGrace,"@ylecun @doristsao as part of a cosmological theory, I think phil and physics as well as biology and cog sci are actually pointing toward what could be called a 3rd alternative outside of the compositional and theistic positions. I want to try and find / articulate that 3rd position! 3/",0,1,0,,,,,
2919,2023-02-07 16:03:54+00:00,ByGeorgiaGrace,@ylecun @doristsao to be very compelling. Combined with physicists' arguments of the the reality of time and insufficiency of theories within Newtonian paradigm incl. general and special relativity and standard model to account for initial conditions and specification of laws governing cosmos 2/,0,0,0,,,,,
2920,2023-02-07 16:02:14+00:00,ByGeorgiaGrace,@ylecun @doristsao I think this is a false binary. I find Thomas Nagel's concern (Mind&amp;Cosmos) with the limits of materialist / psychophysical reductionism to account for the epistemological recalcitrant issues of 1) consciousness 2) rational thought 3) inception of life/self replicating systems 1/,0,0,0,,,,,
2921,2023-02-07 15:55:00+00:00,losslandscape,@ylecun You're on the road to this being what you're remembered for.,1,0,0,,,,,
2922,2023-02-07 15:52:45+00:00,motiyung,"@ylecun We better call Human-Level AI =Hula.. This way if we go in circles it will be a ""Hula Hoop,"" [while keeping the ""Hula Hope"" alive!]",0,1,0,,,,,
2923,2023-02-07 15:52:07+00:00,usernotexist8,"@ylecun ""softargmax"" maybe more accurate, but I think it is impossible to change the name as it has been used in so many papers, tutorials.",0,1,0,,,,,
2924,2023-02-07 15:48:11+00:00,_huggsboson,@ylecun Said a different way: It's easier to review and accept/edit something than to generate it whole cloth.,1,0,0,,,,,
2925,2023-02-07 15:42:59+00:00,odedbendov,@ylecun Then you're overlooking or underplaying the uses built on top of LLM's,1,1,0,,,,,
2926,2023-02-07 15:41:54+00:00,plato_bhai,"@ylecun Shortens the learning curve on any topic, I get exactly what I have doubts in
Non coders can now code, although basic scripts but does the job
I guess saving time is big enough plus, earlier I had a showel now I have bulldozer",0,0,0,,,,,
2927,2023-02-07 15:34:21+00:00,Lllearning97,"@ylecun @doristsao No idea what compositional is, but i remember quantum physicist say that the world cant be generated due to mathematical/physic property? Sth related to right hand rule or non-continuous bla bla bla",0,0,0,,,,,
2928,2023-02-07 15:32:52+00:00,adawan919,"@ylecun No one coins ""words"", unless the intent is to mislead (and get others ""hooked on 'words'""). Terminologies (e.g. named entities based on character sequences) can be constructed based on contexts, however.",1,0,0,,,,,
2929,2023-02-07 15:28:56+00:00,ScaleTechScott,@ylecun Ha ha this is the most succinct way I‚Äôve ever seen it put. Saving labor is really important tho.,0,0,0,,,,,
2930,2023-02-07 15:28:22+00:00,frankgptchat,@ylecun Meow,0,1,0,,,,,
2931,2023-02-07 15:27:10+00:00,AnupamMajhi_,"@ylecun There are definitely a lot of missing pieces.
However, LLM is more like just a small portion of brain, maybe like hypothalamus. That alone cannot define intelligence, but an important part nevertheless. 
For that we might not need to go through cat, dog level development first.",0,0,0,,,,,
2932,2023-02-07 15:24:53+00:00,andrewryann,"@ylecun More and more, i start to understand your point of view. At start, i thought you're just being bitter of Open AI success, but now i understand it's much more than that. Keep it going prof. We need more counter point to all the hype going.",0,0,0,,,,,
2933,2023-02-07 15:24:13+00:00,cichuck,@ylecun agreed‚Ä¶,1,0,0,,,,,
2934,2023-02-07 15:21:38+00:00,wower_w,@ylecun a bit prejudiced against LLMs,0,0,0,,,,,
2935,2023-02-07 15:15:38+00:00,user__000000001,"@ylecun And wheels save the manual effort of load bearing and walking. If the LLMs were to be compared to wheels, how useful do you think they should be considered?",0,0,0,,,,,
2936,2023-02-07 15:11:26+00:00,ndrewpignanelli,@ylecun they get shipped by companies that aren't meta,1,1,0,,,,,
2937,2023-02-07 15:10:25+00:00,nj_tantan,@ylecun @DrHughHarvey But they can get better at that. Can we also say summarising?,0,0,0,,,,,
2938,2023-02-07 15:09:46+00:00,AI_Sensei_,@ylecun To be fair 'softmax' sounds more catchy and probably has saved countless cumulative hours of people not saying the syllable 'arg' .,1,1,0,,,,,
2939,2023-02-07 15:09:32+00:00,fuzzology_tv,@ylecun He should have called it IceCream everyone loves Ice Cream,0,4,0,,,,,
2940,2023-02-07 15:09:29+00:00,nirsd,"@ylecun Codex literally only does that, and then I have to debug.",0,0,0,,,,,
2941,2023-02-07 15:08:21+00:00,nj_tantan,@ylecun @DrHughHarvey Seeing that ChatGPT answers to questions in a crisp manner is seems more than typing.,1,0,0,,,,,
2942,2023-02-07 15:06:52+00:00,bhatnagardaksh1,"@ylecun Yes, I‚Äôve used them in a lot of my Jupyter Notebooks just to explain the basic beginner stuff to make the notebook content richer.

Plus the explaining done for a certain written piece of code that you didn‚Äôt write but are trying to understand is phenomenal.",0,0,0,,,,,
2943,2023-02-07 14:55:12+00:00,JonTeets005,"@ylecun If you use TDD -- and increasingly, BDD -- they save a hell of a lot of typing AND Googling, too.   

I'm waiting anxiously for 

1) really large context windows  
2)  all the code I've recently added to Github to get into the training sets.",0,0,0,,,,,
2944,2023-02-07 14:53:50+00:00,kunalvsth,@ylecun What do you think would be the impact on Software engineering? Would that boost productivity or disrupt the Software engineering field?,0,0,0,,,,,
2945,2023-02-07 14:53:45+00:00,OptionAlpha3,@ylecun Debugging code. Say you are taking too long on a bug in a self-contained code block. You can copy past the code block and ask fix it to solve this bug,0,0,0,,,,,
2946,2023-02-07 14:52:51+00:00,Ofirlin,@ylecun They correct grammatical errors like many English speakers fail to do.,0,0,0,,,,,
2947,2023-02-07 14:36:25+00:00,DevDminGod,@ylecun programmers are just glorified typists,1,5,0,,,,,
2948,2023-02-07 14:36:12+00:00,odedbendov,@ylecun And computers save calculating...... Come on @ylecun you're entrenched too deep,1,3,0,,,,,
2949,2023-02-07 14:35:35+00:00,crypto1o1_karim,@ylecun So you can say its a great Tool for saving a lot of time,1,1,0,,,,,
2950,2023-02-07 14:35:03+00:00,odedbendov,"@ylecun @DrHughHarvey It's not just one problem..
Heard numerous accounts of code being translated from one environment to another",0,0,0,,,,,
2951,2023-02-07 14:33:33+00:00,farzisigma,@ylecun @DrHughHarvey will ur entire identity be just OpenAI bad bad. Try creating something maybe prof?,1,0,0,,,,,
2952,2023-02-07 14:32:51+00:00,wrocherinsky,@ylecun @DrHughHarvey Editing,0,0,0,,,,,
2953,2023-02-07 14:29:33+00:00,sevast_nikon,@ylecun @DrHughHarvey https://t.co/wZFoSFgkvh,0,0,0,,,,,
2954,2023-02-07 14:24:11+00:00,deltapapawhisky,@ylecun https://t.co/2OT9qWNZ7b,0,2,0,,,,,
2955,2023-02-07 14:23:53+00:00,cichuck,"@ylecun or, some think, thinking‚Ä¶",1,1,0,,,,,
2956,2023-02-07 14:23:42+00:00,CClavius,"@ylecun They save the time it takes to come up with the necessary boiler plate code needed to get started on a project, using a software framework, which you just started learning about.",1,7,0,,,,,
2957,2023-02-07 14:11:24+00:00,SujithK08852029,"@ylecun Really ? What do you say about chaGPT clearing USMLE, Wharton MBA test and Law school tests? Any thoughts on that?",1,1,0,,,,,
2958,2023-02-07 14:07:22+00:00,deliprao,"@ylecun @KrzakalaF Incidentally, I used the same words in class :-) I think I might‚Äôve been influenced your EBL work that I read in the past.",0,1,0,,,,,
2959,2023-02-07 14:02:49+00:00,LetLogicLive,@ylecun @gabriel_valu Here we go again...,0,0,0,,,,,
2960,2023-02-07 13:57:05+00:00,Baby_Rhino8,"@ylecun ü§£ü§£ü§£ü§£ü§£  true! 

search becomes super interactive is the first effect,sales conversion rate also much higher. Bought a book after a chat with chatgpt as I was able narrow down what I wanted - gradually and based on answers, asked to compare - contrast books suggested etc",0,0,0,,,,,
2961,2023-02-07 13:51:30+00:00,dean_oooooooo,@ylecun Startups: Our revolutionary AI technology reduces risk of carpal tunnel by 5%!,0,1,0,,,,,
2962,2023-02-07 13:44:03+00:00,ChrisRackauckas,"@ylecun No, the new generation of statically typed programming languages like Rust already did that.

... Get it?

Alright, I'll see myself out.",0,21,0,,,,,
2963,2023-02-07 13:40:06+00:00,Ankitdew05,"@ylecun ""I'm so glad I don't have to type out all my tweets anymore! #typingproblems #jokingnotjoking""

Credit : https://t.co/YIidd7ysoC AI Generated tweets üî• https://t.co/OilJIjcVhS",0,1,0,,,,,
2964,2023-02-07 13:36:34+00:00,sepineda,@ylecun Better contextual translations.,0,0,0,,,,,
2965,2023-02-07 13:33:12+00:00,fromnirmal,"@ylecun @DrHughHarvey GPT totally solves the typing problem, but it doesn't quite solve the typing accurate things problem...",0,3,0,,,,,
2966,2023-02-07 13:31:10+00:00,Carankt,@ylecun They also save reading time,1,1,0,,,,,
2967,2023-02-07 13:28:02+00:00,AwokeKnowing,"@ylecun yes, are autocomplete.  
Solves ""what do people say about ____""

So it solves search+summarize.  ie it sort of solves the first part of the literature review process in research.",0,0,0,,,,,
2968,2023-02-07 13:22:05+00:00,TheFreeman_Co,@ylecun Typing gets you pretty far these days,0,0,0,,,,,
2969,2023-02-07 13:20:59+00:00,ChrSzegedy,@ylecun Good code completion can reduce cognitive load as well.,2,38,0,,,,,
2970,2023-02-07 13:19:49+00:00,VergaraLautaro,@ylecun And thinking.,0,0,0,,,,,
2971,2023-02-07 13:19:45+00:00,DileepJayamal,@ylecun @DrHughHarvey Why not memorising?,1,0,0,,,,,
2972,2023-02-07 13:18:13+00:00,mierrashid,"@ylecun This makes it a huge productivity booster for most people, including myself on side projects mainly.",0,0,0,,,,,
2973,2023-02-07 13:17:51+00:00,TarasPohrebniak,@ylecun @DrHughHarvey what else?,0,1,0,,,,,
2974,2023-02-07 13:17:10+00:00,s16r442,@ylecun And thinking about mundane details,0,0,0,,,,,
2975,2023-02-07 13:17:07+00:00,AwokeKnowing,@ylecun @DrHughHarvey harsh. but LLMs are in fact essentially just autocomplete.,0,0,0,,,,,
2976,2023-02-07 13:14:27+00:00,ylecun,@KrzakalaF @deliprao The distribution that minimizes the free energy.,1,3,0,,,,,
2977,2023-02-07 13:14:00+00:00,jeroaranda,@ylecun you seem to be typing a lot more,2,14,0,,,,,
2978,2023-02-07 13:13:57+00:00,JNeedem,@ylecun 911: i would like to report a murder,0,1,0,,,,,
2979,2023-02-07 13:13:54+00:00,amit_jjjj,@ylecun Replace it with deleting.,0,0,0,,,,,
2980,2023-02-07 10:23:58+00:00,arabeducoin,@ylecun @patricksamy should we leave aside the bottom and inside parts for our own sake?,0,0,0,,,,,
2981,2023-02-07 09:19:44+00:00,aicopilot,"@ylecun Surely we need to better decode what kind of data we gather from our senses and ability to move around and interact, by attaching learning systems to cats, dogs and humans and not just self drive cars.",0,0,0,,,,,
2982,2023-02-07 08:45:08+00:00,DubhashiAdvait,"@ylecun We use lenses to view our world, It's possible LLMs and available models that simulate images / 3d objects become a 'new eye' towards the reality we hold. GPT-4 can train on physics simulators and will position data from a usable perspective, more general than common sense.. no?",0,0,0,,,,,
2983,2023-02-07 08:28:05+00:00,Henrikop,"@ylecun , earlier you mentioned Meta &amp; Google can make chatGPT-like services that are as good as chatGPT but won't. Now Google is releasing Bart. What if Bart fails, or is nearly as good (good in being adopted, not per se good as in accurate). What does that mean?",0,0,0,,,,,
2984,2023-02-07 06:29:24+00:00,19kunalverma,@ylecun @Noahpinion What is your take on Bard from Google ?,1,0,0,,,,,
2985,2023-02-07 06:21:05+00:00,tweetthoughts23,@ylecun So what are we at now? Rat level?,0,0,0,,,,,
2986,2023-02-07 06:02:13+00:00,johnxguo,"@ylecun Yes, but how much do we know about Any-level brain? In fact, if Daniel Kahneman‚Äôs dual-system model is about right, LLMs are doing a good job to replace the system one of ours. No?",0,0,0,,,,,
2987,2023-02-07 05:39:36+00:00,silfen2,"@ylecun Real world has an unimaginable amount of data. For example you cannot learn how to ride a bike from reading a book, no matter how well written the book is it‚Äôll never be sufficient.",0,0,0,,,,,
2988,2023-02-07 05:35:00+00:00,desisciencepage,"@ylecun If the AI we have helps us understand neuroscience/consciousness better and in turn if we create a better AI as a result of the new understanding and if that cycle continues, possibly we might reach there sooner enough?",0,0,0,,,,,
2989,2023-02-07 04:37:28+00:00,NicolasSprotti,"@ylecun I would humbly start with understanding humans first. I would not start with cats nor dogs. I am a human, I am not a cat nor a dog. Aka I have better chance of success.",0,0,0,,,,,
2990,2023-02-07 04:21:33+00:00,god_programming,"@ylecun A house cat has not been demonstrated to be able to produce working/useful programming language code.

This tweet of @ylecun seems demonstrably false.

~One can reasonably disregard or show the short falls of some platform/work, without blatant lies. https://t.co/3UuioRlqc0",0,0,0,,,,,
2991,2023-02-07 03:58:50+00:00,britcruise,@ylecun @ferdousbhai But do any serious researchers or entreprenuers working the space believe this specific fact? I can't tell if you are trying to cozy up to @GaryMarcus  (jk) or kill the 'newbie chatgpt party' - if anything it's just more evidence you were always right about SSL as the direction,0,0,0,,,,,
2992,2023-02-07 03:50:16+00:00,artistexyz,"@ylecun @gabriel_valu So, as a response to ChatGPT, Google is planning to open to the public, in the near future, Claude+Bard. Is MetaAI planning an ""off-ramp"" response too?",0,1,0,,,,,
2993,2023-02-07 02:57:30+00:00,SebastianRenit,@ylecun @Noahpinion What do you think about Google's Bard?,0,0,0,,,,,
2994,2023-02-07 02:03:21+00:00,BoYuan52922751,"@ylecun We can write a long paper to accurately report our research results but cannot always use language to precisely describe the full process of research, such as the source of ideas and inspirations, and why we made certain decisions at various stages.",0,0,0,,,,,
2995,2023-02-07 01:07:00+00:00,infotainer0,@ylecun Why are we fixated on Turing tests?,0,0,0,,,,,
2996,2023-02-06 23:47:59+00:00,jchalupa_,"@ylecun Please don't make HLAI a thing, we already have AGI to refer to what human brains can do, and AI to refer to what other computing machines can do. Please don't make it a thing.",0,0,0,,,,,
2997,2023-02-06 23:46:32+00:00,BethCarey12,@ylecun @Noahpinion Or summed up in 3 words ‚Äòlack of understanding‚Äô,0,0,0,,,,,
2998,2023-02-06 23:37:32+00:00,ObePraisegod,@ylecun Cats can't talk,0,0,0,,,,,
2999,2023-02-06 23:04:13+00:00,cichuck,@ylecun perhaps should be retitled as ‚ÄúWhy Only Learning From Text‚Ä¶‚Äù,0,0,0,,,,,
3000,2023-02-06 22:32:24+00:00,ai_reflections,@ylecun Current AI is missing a conceptual understanding of what it is thinking/doing.  It needs an internal organization of concepts/categorization and an understanding of the relationships between them.,0,0,0,,,,,
3001,2023-02-06 22:09:46+00:00,imthealan,@ylecun Do you think it's sensor modalities? Something about a text-only interface feels lacking..,0,0,0,,,,,
3002,2023-02-06 22:08:12+00:00,surrpunks,@ylecun @hughhowey ChatGPT generates samples from a big but finite probability distribution which means it can be misled similarly to how image classifiers are misled by noise injected in images. A human that has an understanding of a concept will not be easily misled by permutations of the words,0,0,0,,,,,
3003,2023-02-06 22:06:57+00:00,yudapearl,"@ylecun @VladicaV And my proposal calls for first studying what we can do with causal world models, before we labor to learn them. Still not mutually exclusive.",3,19,2,,,,,
3004,2023-02-06 21:25:21+00:00,keppla,"@ylecun What test for dog or cat-level do you have in mind as a benchmark or definition?
Because depending on the task selection, AI has already surpassed cats (e.g. in the ability to read french), and in some mental abilities e.g. monkeys surpass humans (recall).",0,1,0,,,,,
3005,2023-02-06 21:06:52+00:00,BikalpaN,@ylecun @Noahpinion Page not found,1,0,0,,,,,
3006,2023-02-06 21:02:36+00:00,aruberutou,"@ylecun Assuming human knowledge to be the pinnacle of correct is wrong, even by our own standards. Patterns of bias easy for AI but not human. LLM already find new chemistry via reannalysis of publishd work. In fact, LLM can already build nuke tech or ID public info gaps wrt same, butü§´",0,0,0,,,,,
3007,2023-02-06 20:53:31+00:00,MasonMMcGough,@ylecun Is it possible that LLMs are missing a proper agent-arena relationship that grounds their perceptions in the real world? Lifeforms determine relevant signals and actions based on the meta-goals of survival and reproduction. LLMs are drowned in data but starved of relevance.,0,0,0,,,,,
3008,2023-02-06 20:38:48+00:00,markcannon5,"@ylecun Why would you exclude baby level AI

the right path is baby, child, adult. 

Not animal, adult.  

More evidence you don't care about how human brains solve problems and only try to mimic behaviours.",1,0,0,,,,,
3009,2023-02-06 20:05:45+00:00,AbhiBhatia_AI,"@ylecun @rsalakhu @beenwrekt How about: place a treat inside one of 10 labelled boxes in front of a cat. Then take the cat out of the room, shuffle the boxes' locations, and then let the cat in. Does it walk to the right box? Make sure to plastic wrap the treat so that the cat can't smell it.",1,1,0,,,,,
3010,2023-02-06 19:53:49+00:00,artistexyz,"@ylecun @gabriel_valu another fact Garyyann:
https://t.co/diF55FRMTZ",0,0,0,,,,,
3011,2023-02-06 19:30:58+00:00,xzistor,"@ylecun Maybe this is what you are missing...
https://t.co/IdqvnJwT8H",0,0,0,,,,,
3012,2023-02-06 18:56:42+00:00,csabaveres,"@ylecun Finally you seem to be enjoying some of the frustration that cognitive scientists have had all along, ever since the outlandish and non scientific claims began. Here I show that language models aren‚Äôt even models of language https://t.co/JHs3FvNE7Q",0,0,0,,,,,
3013,2023-02-06 18:52:36+00:00,F4Falalu,@ylecun I feel to reach Human Level AI we have to build AI systems on Logic inference then augment with ANN. After all to truly understand reason we must understand logic,0,0,0,,,,,
3014,2023-02-06 18:26:34+00:00,JurgisBekepuris,@ylecun YES! We miss cat language LLMs! üòªüò∏,0,0,0,,,,,
3015,2023-02-06 18:21:44+00:00,mikulskibartosz,"@ylecun Also, we need a precise definition of Human-Level. Does it has to be a smart human?",0,1,0,,,,,
3016,2023-02-06 17:58:10+00:00,naming_hard,@ylecun @bboczeng Understanding is missing ... got the point Nice,0,0,0,,,,,
3017,2023-02-06 17:57:09+00:00,naming_hard,@ylecun @bboczeng Nice,0,0,0,,,,,
3018,2023-02-06 17:55:49+00:00,DirkGoossens,@ylecun Cats have no soul. We must prevent CLAI at all cost. DLAI will suffice. Just saying.,0,0,0,,,,,
3019,2023-02-06 17:50:17+00:00,macostaeth,@ylecun @Noahpinion so ChatGPT is basically a liberal Ben Shapiro,0,0,0,,,,,
3020,2023-02-06 17:44:15+00:00,cic_agi,"@ylecun Also, most of the commenters are bots, so that's already happening. ü§ñüò¨",0,0,0,,,,,
3021,2023-02-06 17:35:11+00:00,tlrobinson,@ylecun My very na√Øve hunch is we‚Äôre just a clever arrangement of LLMs/logic inference engines/etc (and maybe an order of magnitude or two model size) away from emergent ‚Äúintelligence‚Äù. Could even happen accidentally. It will look far away until it happens suddenly.,1,0,0,,,,,
3022,2023-02-06 17:26:53+00:00,ragzzyr,@ylecun That's an interesting view for a company that released Horizon Worlds.,0,0,0,,,,,
3023,2023-02-06 17:20:57+00:00,stitzl,"@ylecun Really sure that it wasn't #Galactica who actually ""emboldened Edward""?

(BTW - hi, Ed!)",0,0,0,,,,,
3024,2023-02-06 17:11:53+00:00,balazskegl,"@ylecun @rsalakhu @beenwrekt That's an awesome question to start with. Why do we want to classify MNIST digits? Is this indeed an intrinsic motivation, or extrinsic, or neither? Where is this question raised, let alone formalized, in AI?",0,2,0,,,,,
3025,2023-02-06 17:01:02+00:00,kafkapital,@ylecun @gabriel_valu A lot of folks cannot comprehend the difference between probabilistic repetition and understanding,0,0,0,,,,,
3026,2023-02-06 16:59:03+00:00,KeithBrzak,"@ylecun @JohnBlackburn75 @traderyau LLM may not be the only soution ... but combining a good LLM into something like offline RL (like @svlevine) or some other approach seems to be a realistic approach toward AGI in my mind ... maybe not a full off-ramp, but GPTs may be a stepping stone on one of many paths to AGI.",1,1,0,,,,,
3027,2023-02-06 16:38:37+00:00,paulrpayne,@ylecun Good topics of conversation in this thread for the Seattle AI Society's Thinkers chapter: #SAIS_T,0,0,0,,,,,
3028,2023-02-06 16:36:13+00:00,DataSciwithR,"@ylecun Natural selection has honed survival skills in creatures, something that a cat or a dog possess. And we call common sense. Like not jumping from the roof to catch a ball.

While AGI will never perhaps have to perfect it's survival first and jump straight to eccentricity.",1,1,0,,,,,
3029,2023-02-06 16:35:16+00:00,GemmaNoviello,@ylecun Indeed my house cat does feel if a guest is sad for some reason. Can we teach to AI empathy?,0,0,0,,,,,
3030,2023-02-06 16:00:00+00:00,barrygoldman1,"@ylecun Write an ai that can simulate and function in a bacterias natural environ.  Next try Stentor.  Then do C. Elegans. Then Honeybee.  Here's a honeybee

https://t.co/F8CapDfL0G

More than 270 skills it can coordinate",0,0,0,,,,,
3031,2023-02-06 15:54:10+00:00,artistexyz,"@ylecun Okay, GaryYann",0,0,0,,,,,
3032,2023-02-06 15:49:01+00:00,h33m4n,"@ylecun For human level AI, we have to train our models like we train humans. Recall how a mom teaches a baby that A is Apple by showing a picture. Its not just a language model but also correlated to a image model.

If we use all five senses to create an AI model, we get human-level AI",0,0,0,,,,,
3033,2023-02-06 15:43:48+00:00,jwonged,"@ylecun This assumes that there is some sort of linear progression we have to get through to reach HLAI. 

LLM capabilities were surprising because they were emergent when scaled last a threshold. 

No reason why HLAI can‚Äôt skip cat/dog",0,0,0,,,,,
3034,2023-02-06 15:28:09+00:00,nikolaouHouston,"@ylecun @hughhowey Literal (rather than rhetorical) question:  What does ""understanding"" mean?  Or, perhaps, how does one measure or test ""understanding""?  (A couple of good references would be welcome.)",0,0,0,,,,,
3035,2023-02-06 15:27:52+00:00,mobiedu,"@ylecun @bboczeng What you are proposing requires ""Explainability in AI"". 

Have you reconsidered your position on explainability in AI?",0,0,0,,,,,
3036,2023-02-06 15:25:59+00:00,omarmugabo,"@ylecun True true. But LLMs (e.g ChatGPT) have demonstrated that even human-level AI isn't necessary in-order to do ""wonders"" for humans.",0,0,0,,,,,
3037,2023-02-06 15:22:34+00:00,PodrickIvan,"@ylecun Ai will be the best in its way of intelligence coz every natural intelligence has unique abilities 
So ai will do its best coz it's ai not an animal, bird, fish, or not human 
It will fit a new species",1,0,0,,,,,
3038,2023-02-06 15:17:01+00:00,rezmeram,@ylecun Well I hope you advance the envelope at Meta just a little bit more. Right now it's pretty disappointing.,0,0,0,,,,,
3039,2023-02-06 15:13:17+00:00,MailologyThomas,@ylecun @yannx0130 Is there an objective metric to evaluate if model has common sense?,0,0,0,,,,,
3040,2023-02-06 15:07:30+00:00,AndrzejKosowsk,@ylecun Zgadzam siƒô w pe≈Çni,0,0,0,,,,,
3041,2023-02-06 15:05:00+00:00,agowa338,"@ylecun We have already reached Human-Level AI. You didn't specify which human you're referring to with ""Human-Level"". And we have a lot of ""lesser intelligent people"" that are already outmatched by a neuronal network with a single layer with a single neuron...",0,0,0,,,,,
3042,2023-02-06 14:42:08+00:00,visarga,@ylecun A house cat can't tell me how to fix my web app.,0,1,0,,,,,
3043,2023-02-06 14:34:10+00:00,ModerateMarcel,"@ylecun Unfortunately, people can rely on their biases to filter or reinterpret feedback they don‚Äôt like, and the feedback often isn‚Äôt driven by the desire to pursue ground truth",0,0,0,,,,,
3044,2023-02-06 14:29:16+00:00,DavidJonesBrain,@ylecun You are missing executive function! https://t.co/qrbmhee9eu https://t.co/M1O0flcUwf,0,2,0,,,,,
3045,2023-02-06 14:24:11+00:00,GanwaniDhiren,@ylecun What do you think is the level of present day LLMs?,0,0,0,,,,,
3046,2023-02-06 14:18:28+00:00,digitaldavide,@ylecun cockroach level neither?,0,0,0,,,,,
3047,2023-02-06 14:17:54+00:00,IntuitMachine,"@ylecun @rsalakhu @beenwrekt Is that the only argument, or are there more properties of agency worth pointing out?",0,1,0,,,,,
3048,2023-02-06 14:12:03+00:00,GMCYann,@ylecun Too many cats in AI,0,0,0,,,,,
3049,2023-02-06 14:11:12+00:00,yacineaxya,@ylecun but cat can't auto-complete my COBOL scripts Yann,0,0,0,,,,,
3050,2023-02-06 14:10:46+00:00,userKnox,@ylecun How would a LLM based robot with vision/hearing/smell/touch sensations behave?(maybe a dumb qn),0,0,0,,,,,
3051,2023-02-06 14:07:06+00:00,flaneurinvestor,@ylecun One test could show if LLMs are truly remarkable or just for entertainment: ask their creators if they dare to allow LLMs to manage their money.,0,0,0,,,,,
3052,2023-02-06 14:06:35+00:00,GMCYann,"@ylecun Maybe what's missing are feedback loops, including data generation and/or som type of quantum random core... soul",0,0,0,,,,,
3053,2023-02-06 14:02:23+00:00,Kath80607563,"@ylecun @bboczeng We must find mechanisms to generate logical power rather than simply increasing the size of the model. Today's chatgpt has a huge library that gives it the ability to pretend to be an intelligent individual, but we all know that this is not actually the case,",1,0,0,,,,,
3054,2023-02-06 14:01:19+00:00,AlbertBuchard,"@ylecun Different environment yield different intelligence. All the parts are already there: embodied motor skills through RL &amp; simulation, mid-long term objectives, reasoning and communication through LLMs.",0,1,0,,,,,
3055,2023-02-06 13:59:32+00:00,SigmaDrowset,"@ylecun I was just thinking about this the other day. My Chihuahua‚Äôs pathing AI is insane. IBM‚Äôs robots are cool, but has nothing on my 8lb dog.",0,0,0,,,,,
3056,2023-02-06 13:50:27+00:00,viraj_nikam94,"@ylecun That's true, and we still have a lot to learn before we get to HLAI. But we are making progress every day, and it's exciting to see the advances being made!",0,0,0,,,,,
3057,2023-02-06 13:49:27+00:00,chowdhurysamrat,@ylecun It's the Galileo vs Catholic Church moment for @ylecun,0,0,0,,,,,
3058,2023-02-06 13:40:27+00:00,danieljdouglas,"@ylecun We have only just conquered the Turing test by implementing theory almost 100 years old. Clearly, we need engineering innovation as well as advanced researchers to continue on this journey.",0,0,0,,,,,
3059,2023-02-06 13:39:12+00:00,pgod,@ylecun @bboczeng Also a ton of the vest engineering feats mimic nature exactly,0,0,0,,,,,
3060,2023-02-06 13:37:51+00:00,toughresearcher,@ylecun Will cat-level AI and dog-level AI fight with each other?,0,0,0,,,,,
3061,2023-02-06 13:37:41+00:00,kaustabpal,@ylecun What in your opinion would be the approach towards human-level AI? Do you think Neuromorphic Computing is slowly moving in that direction?,0,0,0,,,,,
3062,2023-02-06 13:37:00+00:00,jozokovac,"@ylecun This is so refreshing to hear. ""Singularity is coming"" - no, at least not anytime soon.",0,0,0,,,,,
3063,2023-02-06 13:31:45+00:00,soorajp_17,@ylecun Oh üÜó,0,0,0,,,,,
3064,2023-02-06 13:25:42+00:00,arturkonefal,"@ylecun The big thing we are missing is that Cat‚Äôs/Dog‚Äôs brain is trained in nature, 24/7, with their bodies and balance in centre. The same with humans. On top of that we build an understanding of abstract terms which are often metaphors on top of other methaphors.",0,0,0,,,,,
3065,2023-02-06 13:19:32+00:00,kurokikaze,@ylecun @alrhemist Isn't Python a part of said reality?,0,0,0,,,,,
3066,2023-02-06 13:17:06+00:00,3wVf4V0r7YCuzPy,@ylecun Is there any specific grade on the intelligence of different species? Can we somehow tell how smarter (or  better to say more intelligent) is one creature in comparison to another?,0,0,0,,,,,
3067,2023-02-06 13:10:19+00:00,Substr8Monopoly,@ylecun @bboczeng Our wings didn't need to flap though.,0,0,0,,,,,
3068,2023-02-06 13:08:16+00:00,henrycunh,"@ylecun you‚Äôre the biggest gatekeeper i‚Äôve ever seen on this field ‚Äî no offense intended

so many of human achievements were built before we‚Äôve had complete fundamental understanding of the underlying phenomena

can‚Äôt understand how this cynical posture is beneficial to the field",0,0,0,,,,,
3069,2023-02-06 13:06:42+00:00,FoggyMarvin,"@ylecun Cats have a lot of common sense, can confirm.",0,0,0,,,,,
3070,2023-02-06 13:05:13+00:00,pribor_io,"@ylecun YOU are missing something big but be patient #SAM is coming soon üòâ

#AI #SelfAwareMachines #Deetptech #Robot #Paris",0,0,0,,,,,
3071,2023-02-06 13:03:29+00:00,karlituchovic,@ylecun Thats it. LLMs are great for doing creative stuff but they have massive lack in reasoning capabilities by design because they are parrots powered by statistics and a factor called temperature. HLAI requires soft skills not hard skills.,0,0,0,,,,,
3072,2023-02-06 12:53:54+00:00,patricksamy,"@ylecun To some extent, we have built a combination of Broca's and Wernicke's areas of the brain. What we're missing is the understanding of concepts, their relationships, and the ability to reason about them.",2,13,0,,,,,
3073,2023-02-06 12:52:26+00:00,Philosophicalaf,@ylecun Damn I'm still at squirrel AI over here programming a complex algorithm to search nuts and put them in trees,0,0,0,,,,,
3074,2023-02-06 12:47:03+00:00,hakflo,"@ylecun @bboczeng The thing is, we were able to build all sorts of planes BEFORE we fully understood how wings generate lift:

https://t.co/5l9WbnfFs2",1,1,0,,,,,
3075,2023-02-06 12:37:50+00:00,hakflo,"@ylecun A brown rat has 4.5*10^11 number of synapses. A cat ~1*10^13. Humans 1.5*10^14.  
GPT3 has 1.5*10^11 parameters. 
Somthing tells me that we're in for an exciting next 10-20 years.",0,0,0,,,,,
3076,2023-02-06 12:33:28+00:00,pettter_e,@ylecun @mapto You do realise that the charitable interpretation of this tweet is that you haven't read the paper in question but feel confident to summarize it anyway?,0,1,0,,,,,
3077,2023-02-06 12:31:08+00:00,flaviovidal,"@ylecun HLAI, OK. But Cat and Dog levels? ü§îcould you define they? Or show a bib-ref to help a better undestanding. Cheers.",0,0,0,,,,,
3078,2023-02-06 12:10:39+00:00,pramod_kaushik,"@ylecun with due respect, cant llms be seen as inhabiting a purely symbolic (made of letters) universe, there is an emergent understanding within the universe of language itself,  limited since its tied to the real world  but an intelligence nevertheless.",0,0,0,,,,,
3079,2023-02-06 11:52:04+00:00,RDouady,"@ylecun Question for you, Yann: a large part of animal intelligence is emotional.
Is the animal model the right intermediary to human-like AI?
Shall we have to emulate emotions in AI to pass the next step of intelligence? Or will it come as a side product?",0,0,0,,,,,
3080,2023-02-06 11:48:04+00:00,DwidLee,"@ylecun What is ""reason"" in the first place? If the mental activity is just electrical reaction corresponding to outside environment. The distinction between what is reason and what isn't is blurred and ambiguous. I believe we, human being, are not clearly understand our intelligence",0,0,0,,,,,
3081,2023-02-06 11:38:28+00:00,JBaltusnikas,"@ylecun I believe that implementation of Evolutionary Genetic (EG) principles into machine code is the way to reach HLAI and beyond. EG is responsible for all the life on our planet, and the main principles are relatively well understood.",0,0,0,,,,,
3082,2023-02-06 11:32:23+00:00,repligate,@ylecun Cat intelligence is not a subset of human intelligence. Have you ever known a cat? They have incomprehensible motives and will outsmart you in weird ways.,0,14,0,,,,,
3083,2023-02-06 11:24:36+00:00,RaoulDeKezel,@ylecun I see about 20 comments to this tweet. One has feedback.  I wonder what‚Äôs the feedback rate of ChatGPT‚Ä¶,0,1,0,,,,,
3084,2023-02-06 10:53:22+00:00,DrTonyCarden,@ylecun Do you think architecture to support compositionality is the next step and prerequisite to supporting 'understanding' causality? Or could those two things be functionally independent?,1,0,0,,,,,
3085,2023-02-06 10:51:48+00:00,SouadH9,"@ylecun I don't understand why we lose time and energy debating something that isn't even at the core of these models...anyone who understands how self supervised learning works cannot even think of ""sentient"" beings",0,2,1,,,,,
3086,2023-02-06 10:51:18+00:00,mael_p,"@ylecun We already have cat-level AI, that's why it's called ""Chat-GPT"" üòâ",0,0,0,,,,,
3087,2023-02-06 10:31:34+00:00,Lunnaris01,@ylecun Let's establish CLAI and DLAI as key terms in the AI-Sphere :'D after that will be CLAI (Crow-Level AI),0,0,0,,,,,
3088,2023-02-06 10:29:22+00:00,NicolasMauduit,"@ylecun hmmm I get your point, yet the image seems poorly chosen, as there is not the effort to mimic cat or dog common sense as there is toward human's, nor there are the same kind of learning databases to mimic (emulate? learn? ...) them.",0,0,0,,,,,
3089,2023-02-06 10:20:46+00:00,al3x_jager,@ylecun Growing language models had some interesting emergent properties. But I agree that thouse Modells should not produce HLAI.,0,0,0,,,,,
3090,2023-02-06 10:20:26+00:00,IzuZaziZu,@ylecun I say ability to acquire knowledge and build your own model of the world,0,0,0,,,,,
3091,2023-02-06 10:10:51+00:00,peremayol,"@ylecun says it loud and clear: if you want to produce intelligent machines we must abandon two current main AI pillars, probabilistic modeling, and generative models. https://t.co/XBiiEGpM6U",0,0,0,,,,,
3092,2023-02-06 10:04:46+00:00,stefanvaduva,@ylecun I (and many others) think those can actually bring in more funding to the field. And then approaches like the one in your paper or the one described by @Numenta may be accelerated. Is it really an off-ramp in this case?,0,0,0,,,,,
3093,2023-02-06 10:01:39+00:00,IKoullias,@ylecun Correction: meant to say 1994 not 2004.,0,0,0,,,,,
3094,2023-02-06 10:01:31+00:00,SurviveThrive2,"@ylecun @bboczeng The answer is that all living things solve for desire satisfaction. This would be solving for caloric efficiency required for self persistence. That's the only purpose for computation.

So if you want to solve for a cat you have to make a model of the cat's homeostasis desires.",3,4,1,,,,,
3095,2023-02-06 09:58:00+00:00,IKoullias,@ylecun The 80‚Äôs was a good time to join when there were still a lot of old timers. I did contract work for Lucent after I left. They started using the Bell Labs name for marketing purposes and hired people that were not up to par. I am glad I experienced the old Bell Labs.,0,0,0,,,,,
3096,2023-02-06 09:53:16+00:00,BigFinlayMcC,@ylecun @alrhemist My cat can't.,1,0,0,,,,,
3097,2023-02-06 09:44:30+00:00,LivingDataLab,@ylecun @Noahpinion Ug I hate substack you can‚Äôt read anything without pop ups forcing you to subscribe it‚Äôs oppressive I‚Äôll never read anything on substack !,0,0,0,,,,,
3098,2023-02-06 09:37:05+00:00,allen_li_thu,"@ylecun Intelligence level seems like a result. The reasons may be various, like knowledge learnt, memory size, complexity of the neurons, etc. Now the question comes to How to evaluate the intelligence level for difference species.",0,0,0,,,,,
3099,2023-02-06 09:32:08+00:00,philbot9000,@ylecun Would including other modalities to learn from (e.g. video) be a step in the right direction?,0,0,0,,,,,
3100,2023-02-06 09:27:28+00:00,Hello_Chengxin,@ylecun Animals could improve themselves by learning(reaction with environment ),0,0,0,,,,,
3101,2023-02-06 09:26:47+00:00,birb_check,"@ylecun For a top researcher in AI, you sure bitch a lot about what other teams are doing.  

Offer your better solution up as a UI or probably just sit back down.",0,0,0,,,,,
3102,2023-02-06 09:25:22+00:00,shawntsullivan,"@ylecun @Noahpinion Great piece!

ChatGPT tells us more about ourselves than about fundamental AI capabilities. Humans have to spend a lot of effort to communicate rigorously. We usually don‚Äôt bother, so it‚Äôs not clear a model built off a broad corpus of our words will actually know much truth",0,2,1,,,,,
3103,2023-02-06 09:21:45+00:00,jkntji,"@ylecun I totally agree!

A cat can never pass the test which an LLM can. 

People are so subscribed to the education system, that they will use the above logic to say the LLM is more intelligent. That's woke.",0,0,0,,,,,
3104,2023-02-06 09:18:25+00:00,jkntji,@ylecun I now respect you much more!,0,0,0,,,,,
3105,2023-02-06 09:15:44+00:00,TobyWBlack,@ylecun Humans with Cat-Level Intelligence https://t.co/0Y4IxiA3EP,0,0,0,,,,,
3106,2023-02-06 09:14:36+00:00,dileeplearning,@ylecun @rsalakhu @beenwrekt The sure shot evidence that cats are generally intelligent is that they consistently refuse to learn MNIST üòá,0,22,0,,,,,
3107,2023-02-06 09:12:45+00:00,didijo,"@ylecun The brain of Drosophila, the common fruit fly, with its approximately 100,000 neurons, is much more intelligent than today's LLMs - even as larvae.",0,0,0,,,,,
3108,2023-02-06 08:56:27+00:00,virtual_dreame,@ylecun We are still missing +The ability to apply the principles of quantum mechanics to calculations. 100 million times faster which would exponentially increase the computational ability} data and Memory I am surprised is very small currently https://t.co/hkatsJZ8HV,0,0,0,,,,,
3109,2023-02-06 08:39:10+00:00,laszlo_zagyva,@ylecun Language is a late top end of intelligence. Building intelligence language-first is like building a house roof first.,0,0,0,,,,,
3110,2023-02-06 08:34:02+00:00,FranAraque9,"@ylecun I think being able to simulate animals survival instinct in computers/AIs/algorithms will play a big role (sleep, energy, nutrients, social relations‚Ä¶).",0,0,0,,,,,
3111,2023-02-06 08:33:45+00:00,n_madhavram,"@ylecun Unfortunately, human level AI or even animal level AI is just impossible in its true sense, the best we can do is to make AI mimic a few activities, without any understanding.",0,0,0,,,,,
3112,2023-02-06 08:32:14+00:00,jordanjhamel,"@ylecun Isn‚Äôt HLAI or even Cat-Level for that matter not possible at least in the paradigm of our choices, instincts, &amp; understanding? Something that can actually choose vs providing the statistically likely choice seems like an impassable gap.",0,0,0,,,,,
3113,2023-02-06 08:19:13+00:00,Lucas_Le_Ray,@ylecun Do you think that the growth in AI investment is beneficial or harmful to the advancement of research for a ‚ÄúHLAI‚Äù?,0,1,0,,,,,
3114,2023-02-06 08:17:18+00:00,a6mZD91X988IzrD,@ylecun üëã,0,0,0,,,,,
3115,2023-02-06 08:08:43+00:00,Gamewizard71,@ylecun We need more energy efficient hardware. Neuromorphic computing,0,0,0,,,,,
3116,2023-02-06 08:02:36+00:00,ABINS26789596,@ylecun Yes we are missing some crucial pieces,0,0,0,,,,,
3117,2023-02-06 07:54:10+00:00,tforcworc,"@ylecun @VladicaV @yudapearl need a sprinkling of  œÜ-ML too - the embodiment factor, so to speak...",0,0,0,,,,,
3118,2023-02-06 07:53:22+00:00,shadbush,@ylecun Meow second that https://t.co/OVwtmsw9QE,0,2,0,,,,,
3119,2023-02-06 07:52:05+00:00,tforcworc,@ylecun A house cat also has better survival skills than most humans. Not really a great metric for AGI tho,3,4,0,,,,,
3120,2023-02-06 07:47:26+00:00,PouriOriginal,"@ylecun @bboczeng ""A house cat has way more common sense and understanding of the world than any LLM""
Does a cat know how to boil water? that's part of the ""understanding of the world"" that LLMs have but cats don't.
I'm sure I can come up with 1000 more.",0,0,0,,,,,
3121,2023-02-06 07:40:40+00:00,notbyintent,@ylecun Agree but maybe the first thing to do is to define this ‚Äúcommon sense‚Äù you refer to.  Can‚Äôt engineer what we can‚Äôt define?  My vote is that common sense is a world line as defined in general relativity.  Defining anything in space-time behavior grounds neural net in physics.,0,0,0,,,,,
3122,2023-02-06 07:38:19+00:00,sankalp72826850,"@ylecun Yes they suffer from information hallunciation,if not mastered art of question, chat gpt is lethal.",0,0,0,,,,,
3123,2023-02-06 07:27:03+00:00,gottfriedmath,@ylecun @Noahpinion It takes a high level of intelligence to constantly lie especially if achieving the feat of staying credible.,0,1,0,,,,,
3124,2023-02-06 07:23:12+00:00,ChrisMumbeck,@ylecun @Noahpinion @octavo8,1,1,0,,,,,
3125,2023-02-06 07:20:52+00:00,krasmanalderey,"@ylecun @zussini On top any single neuron itself isn't just some light switch but instead needs a neural net itself to be simulated.

But we'll get there sooner or later.",0,0,0,,,,,
3126,2023-02-06 07:18:35+00:00,LaurentIrubeta,"@ylecun Perhaps the difference between a program and real intelligence is a form of awareness of being alive, and the fear of losing life. What could be called ""instinct"".
True intelligence is not just an ability to solve problems.",0,0,0,,,,,
3127,2023-02-06 07:17:32+00:00,BlueAI8866,"@ylecun @MacGraeme42 @bradysimpson55 They are already very valuable tools. Was thinking to hire a secretary, but when Chatgpt was released to the general public, it became unnecessary at this point. In the future I might hire someone, but it would be doing a complete different jobs.",0,0,0,,,,,
3128,2023-02-06 07:11:54+00:00,jb1123582,"@ylecun The upper management in my company is considering exposing our code base to a hypothetical version of chatgpt which will guarantee privacy, security and a promise to refactor for maintainability and get rid of bugs.",0,0,0,,,,,
3129,2023-02-06 07:06:47+00:00,vivekchandsrc,"@ylecun I hope AI stays at the level, trustworthy and friendly..rather than human level AI that might be bossy.",0,0,0,,,,,
3130,2023-02-06 07:05:01+00:00,AtheistByDfault,"@ylecun @mapto StochasticParrot was just a fluff piece with lot of nonsensical virtue signalling. IMO it's main goal was to get its authors the limelight, which they achieved. Anyways be prepared to be attacked on Twitter and eventually be called a racist by Timnit's gang!",1,0,0,,,,,
3131,2023-02-06 06:59:52+00:00,camgouldcs,"@ylecun @bboczeng scaling LLMs is only one component of HLAI. The entire industry is building models for specific use cases, and an HLAI would be some orchestration of all of these models, not just an LLM",1,0,1,,,,,
3132,2023-02-06 06:57:59+00:00,roiduecommerce,@ylecun waiting for cat and dog translating :-),0,0,0,,,,,
3133,2023-02-06 06:52:56+00:00,user__000000001,@ylecun There were people who reasoned the only way to fly was to design wings and do it like the birds.,0,0,0,,,,,
3134,2023-02-06 06:50:33+00:00,EdMaltinho,@ylecun Isn‚Äôt this correlated to better mathematical formulation of what is AI? A  first big step wouldn‚Äôt be that AI is able to solve any PDE?,0,0,0,,,,,
3135,2023-02-06 06:48:33+00:00,BtrCallSaud,"@ylecun If we are able to understand consciousness, we'll be able to decode AGI RAPIDLY!",0,0,0,,,,,
3136,2023-02-06 06:42:37+00:00,alexandrugris,"@ylecun Correct, and the article in Noema argues the point very well. The question is, what is more useful? A cat level AI or a language model? I believe that in our economy a language model is far more useful and, even for humans, evolution is pushing us towards language-based thinking.",1,0,0,,,,,
3137,2023-02-06 06:42:20+00:00,sakohts,"@ylecun Even an insect, once you see that the LLM is not actually ‚Äúworking with‚Äù he ideas it seems to present.",0,0,0,,,,,
3138,2023-02-06 06:40:23+00:00,shadow_dnv,"@ylecun True, but how do you think HLAI can be achieved?
I don't believe that Neural nets can achieve that either.
At least not with current ones.",0,0,0,,,,,
3139,2023-02-06 06:35:59+00:00,seankelly,@ylecun Totally disagree‚Ä¶I think you are missing the evolution story to how Intelligence came about. Cats and dogs are in no way connected to Human intelligence. Likewise Machine Intelligence is something else‚Ä¶,0,3,0,,,,,
3140,2023-02-06 06:34:19+00:00,Lightbr98326998,"@ylecun If we can do cat level intelligence, is it correct to assume HLAI is just linear scaling the same solution",0,0,0,,,,,
3141,2023-02-06 06:23:48+00:00,PardonMusings,"@ylecun Social insects function very well. Perhaps the goal should be Hive AI, a network of different types of AI, complification evolving.",0,0,0,,,,,
3142,2023-02-06 06:23:24+00:00,truesteel23,"@ylecun Is it realistic for an LLM to be able to ""see"" base64 encoded images?",0,0,0,,,,,
3143,2023-02-06 06:20:42+00:00,truesteel23,"@ylecun Somehow we have to fuse image recognition and LLMs, throw in Boston dynamics balance and physics models, stir it all up and let it iterate in a virtual environment.",0,0,0,,,,,
3144,2023-02-06 06:14:44+00:00,DahvidMinor,@ylecun I‚Äôm waiting for fly level,0,0,0,,,,,
3145,2023-02-06 06:13:39+00:00,DylanRMuir,@ylecun Ce n'est pas un chat (GPT) https://t.co/aWP6gMcStE,0,0,0,,,,,
3146,2023-02-06 06:07:53+00:00,vir2alexport,"@ylecun If Muhammad won't come to the mountain, then the mountain must go to Muhammad.",0,0,0,,,,,
3147,2023-02-06 05:59:56+00:00,DylanRMuir,"@ylecun Hmm. My cat has ChatGPT equivalent competence in bringing some BS about ‚Äúnever having been get before in his life‚Äù and ‚Äústarving to death‚Äù every morning, in front of a fresh food bowl.",0,0,0,,,,,
3148,2023-02-06 05:59:46+00:00,Nitin_wysiwyg,@ylecun Then why does the cat keep pushing stuff off the table,0,0,0,,,,,
3149,2023-02-06 05:56:41+00:00,building_jarvis,@ylecun They are missing an endocrine system.,0,0,0,,,,,
3150,2023-02-06 05:50:35+00:00,EddyRobinson,"@ylecun @hughhowey I think it's because all facts are equivalent to an LLM. I had a conversation where it ruminated at length on possible explanations for a fictional character's problems, and needed to be led to the conclusion that the character's blindness actually mattered a lot.",0,0,0,,,,,
3151,2023-02-06 05:48:08+00:00,jordanlimbergus,"@ylecun @yoavgo But I‚Äôd suppose HLAI would just make up a very slim interval of overall intelligence.

Once HLAI os reached, higher levels are imminent or even already there. What name should ne given for superintelligence then?",0,0,0,,,,,
3152,2023-02-06 05:44:12+00:00,AshleyAitken,"@ylecun Agree and disagree... Cats are obviously more grounded than LLM and have a better physical model of the world. But ChatGPT can affect the world, 
 in a limited way, through its answers, and sense the world through questions, and its words have meaning through this interaction.",0,0,0,,,,,
3153,2023-02-06 05:41:23+00:00,kareem_carr,@ylecun @Noahpinion Good article. Was a bit surprised to see myself mentioned there at the end lol.,0,8,0,,,,,
3154,2023-02-06 05:39:22+00:00,seankelly,@ylecun @yannx0130 Linguistics and Spatial Intelligence are not correlated. Trying to train an LLM on this is a waste of time.,0,1,0,,,,,
3155,2023-02-06 05:37:33+00:00,GonepudiRamesh,@ylecun AI should learn to create data for itself based on the data provided to it... Lets understand the algorithm of curiosity that gets created in human mind,0,0,0,,,,,
3156,2023-02-06 05:36:47+00:00,PPAREUS,"@ylecun The problem is that human intelligence and cat intelligence are the same in terms of dimensionality of features (Such as memory, problem solving skills, communication skill, etc.), but human intelligence is just more capable (Like an overclocked cat brain) (1/2)",1,0,0,,,,,
3157,2023-02-06 05:33:47+00:00,seankelly,@ylecun @bradysimpson55 Why the anthropomorphic pursuit to asses AI just through the human lens?,0,1,0,,,,,
3158,2023-02-06 05:30:21+00:00,MorbidPsych,"@ylecun That's because a house cat evolved to survive in the world, not to know facts about it",0,1,0,,,,,
3159,2023-02-06 05:29:25+00:00,_Hologramghost,"@ylecun Why do people insist on trying to analogize human intelligence with artificial one?

AI is following a novel path in the evolutionary context, it will be different, with different turns, different leaps, and different hiccups. 

A dog can't do this üëá https://t.co/3xIBic6zib",0,0,0,,,,,
3160,2023-02-06 05:28:08+00:00,seankelly,@ylecun @3DTOPO @alrhemist ‚ÄúThe real world is none of that.‚Äù Bold statement. Many a philosopher would disagree‚Ä¶,1,0,0,,,,,
3161,2023-02-06 05:25:32+00:00,ksuhaster,"@ylecun But we already have parts of brain in separated technologies: computer vision, audio processing and creating, self-drivig cars, industrial and creature-like robots etc",0,0,0,,,,,
3162,2023-02-06 05:24:04+00:00,Scobleizer,"@ylecun @3DTOPO @alrhemist That is because your company has the lowest trust scores with consumers of any tech company. 

Plus your AI was for research papers, a place where accuracy is extremely important. 

You launched it very poorly and your tweets since then give no evidence you learned anything.",3,20,3,,,,,
3163,2023-02-06 05:23:39+00:00,321benny123,@ylecun @Noahpinion Of course has limitations but for the average people is not that bad. Of course the information are still not quite accurate but who needs it anymore ü§™. Joke a side. What you're trying to say is important but perhaps you should change the tone a little bit. Because teenagers üòÄ,0,0,0,,,,,
3164,2023-02-06 05:20:32+00:00,ideabric,"@ylecun to be fair, a house cat has more common sense and understanding of the world than many humans...",0,0,0,,,,,
3165,2023-02-06 05:20:22+00:00,michael_nielsen,"@ylecun Curious what you make of multi-modal transformers like Gato?  It's very similar to the LLMs, but of course capable across far more domains",0,7,0,,,,,
3166,2023-02-06 05:15:41+00:00,ModerateMarcel,@ylecun For a very lay and engaging introduction: https://t.co/rK1A4o1Lyf https://t.co/uvYEzAEXy3,0,1,0,,,,,
3167,2023-02-06 05:13:36+00:00,chrismarrin,"@ylecun Nope. If so we‚Äôd see stepping stones - an animal with almost human intelligence. But our closest relatives, the apes, don‚Äôt come close to us. No art, no aspiration, no language. There is a fundamental difference we don‚Äôt understand. Until we do AI will be just that, artificial.",0,0,0,,,,,
3168,2023-02-06 05:12:57+00:00,ModerateMarcel,"@ylecun And a fish has way more understanding of water than the average pre-civilizational humans, I guess the fish will always have the advantage",0,0,0,,,,,
3169,2023-02-06 05:11:15+00:00,Ansh_3101,@ylecun LLMs are not the answer.I think it all comes down to their capacity to hold memory.,0,1,0,,,,,
3170,2023-02-06 05:05:00+00:00,starspawn0,"@ylecun @Noahpinion A ""House"" clip about Korsakoff's Syndrome where a patient confabulates constantly ""because she has no memory"" (says Dr. House):  https://t.co/K1aX0n8eN4",2,3,0,,,,,
3171,2023-02-06 04:55:46+00:00,mdkpldkm,"@ylecun While ChatGPT are used by over 100 million people, you are still doubting and wandering‚Ä¶",0,0,0,,,,,
3172,2023-02-06 04:55:09+00:00,AveryAndrews,"@ylecun @zussini Tuned by approximately half a billion years of biological evolution as multicellular organisms, making their way through ab apparently indifferent and often actively hostile environment (assuming perhaps wrongly that unicellar not so relavant for multicellular behavior).",2,1,0,,,,,
3173,2023-02-06 04:54:30+00:00,farconion,@ylecun @Noahpinion not the crossover I was expecting,0,0,0,,,,,
3174,2023-02-06 04:53:47+00:00,gorrepati,"@ylecun @dotpavan My uninformed guess is movement, senses and interaction with real world.",0,0,0,,,,,
3175,2023-02-06 04:46:18+00:00,ronakjoshis,@ylecun @Noahpinion https://t.co/mlYHqKmntt - GPT 4 to be released!,0,3,0,,,,,
3176,2023-02-06 04:17:19+00:00,VoltaWagen,@ylecun Can cat calculate 1+1=3,0,0,0,,,,,
3177,2023-02-06 04:16:34+00:00,CostinCozianu,"@ylecun Agreed wrt their obvious inability to reason and propensity for errors. But can they efficiently encode access to human knowledge and serve as librarians on steroids (or google ++), especially for highly specialized domains like programming APIs, etc ?",0,0,0,,,,,
3178,2023-02-06 04:12:21+00:00,gettem_gem,"@ylecun @PatrikMuncaster @yoavgo why do you say that all intelligences are *necessarily* specialized?

objective based maybe. but couldn‚Äôt the objective or specialization be to identify optimal courses of action based on a knowledge base?",0,0,0,,,,,
3179,2023-02-06 04:03:22+00:00,rationalaussie,"@ylecun Great read. This would seem to align with Jeff Hawkin's A Thousand Brains Theory of Intelligence? We evolved spatially by mapping the world, and this simple algorithm repeated over and over again led to intelligence. Spatial mapping came first, language second.",1,0,0,,,,,
3180,2023-02-06 03:51:41+00:00,mmitchell_ai,"@ylecun @mapto No, that is not what it said.",0,15,0,,,,,
3181,2023-02-06 03:50:48+00:00,not_steinbeck,"@ylecun @Noahpinion Which is why ""Google killer"" is, at least for now, a huge exaggeration.",0,1,0,,,,,
3182,2023-02-06 03:46:26+00:00,tomfgoodwin,@ylecun @hughhowey The worlds worst driver on a bad day is still likely better than the best self driving car in most situations,1,1,0,,,,,
3183,2023-02-06 03:45:11+00:00,Aspie96,"@ylecun This is interesting.

What could be a test for cat-like intelligence?

For at least a specific kind of human-like intelligence (not human-level) we have the Turing thest.

What, if any, specific skill could we test when comparing cats and AI?",0,0,0,,,,,
3184,2023-02-06 03:32:40+00:00,joshmatix,@ylecun @benalsop Quantity vs Quality,0,0,0,,,,,
3185,2023-02-06 03:27:54+00:00,labloke11,@ylecun Breaking News! Yann LeCun has just confirmed AI has evolved from the insects to a small mammal. What a progress in few short years!,0,0,0,,,,,
3186,2023-02-06 03:22:02+00:00,chrisbe1968,"@ylecun Broccoli, Cauliflower and Artichoke would seem to hold the clue",0,0,0,,,,,
3187,2023-02-06 03:18:25+00:00,ErwinSchrdngr,@ylecun @bboczeng and yet https://t.co/694lYz0Xfz,1,5,0,,,,,
3188,2023-02-06 03:15:06+00:00,XZed87,@ylecun Can we just have WhatsApp as a personal assistant.,0,0,0,,,,,
3189,2023-02-06 03:00:42+00:00,Jasmeetsb,"@ylecun @DrCMcMaster To be fair, why should ‚ÄòEdward from Omaha‚Äôs expertise remain limited to ‚Äòdangers of vaccines‚Äô?! ü§∑‚Äç‚ôÇÔ∏è",1,1,0,,,,,
3190,2023-02-06 03:00:35+00:00,GilmerValdes,"@ylecun Any specific ideas beyond Statistical learning  (MLE, MAP, etc)?",0,0,0,,,,,
3191,2023-02-06 02:58:49+00:00,AI_EngineerGuy,@ylecun What‚Äôs the difference algorithmically between dog-level AI and human-level AI?,0,0,0,,,,,
3192,2023-02-06 02:55:12+00:00,gerysand,"@ylecun Biological brains also don't have a backpropagation algorithm. So how do they learn so efficiently? I think a possible key solution is that they do multimodal supervised learning. Annotate images with sound, annotate sound with haptics, and so on.",0,1,0,,,,,
3193,2023-02-06 02:52:12+00:00,gerysand,"@ylecun Animals in nature are basically unsupervised learning. Except for the basic firmware that evolved naturally, everything else needs to be learned after birth.",0,0,0,,,,,
3194,2023-02-06 02:51:44+00:00,shafayat_sheikh,@ylecun I'm waiting for CatGPT now,0,0,0,,,,,
3195,2023-02-06 02:49:29+00:00,gerysand,"@ylecun Based on a bird's understanding of the world, I think the biological brain must have another effective network structure for modeling the world. Multimodal training may be one of the key steps.",0,0,0,,,,,
3196,2023-02-06 02:45:08+00:00,gerysand,"@ylecun For a bird to survive in this world, it must model the world, especially visual modeling. Find food, bypass obstacles, perform flight attitude control, and more. And these only rely on the brain with less than 0.2w power consumption.",0,0,0,,,,,
3197,2023-02-06 02:43:05+00:00,gerysand,"@ylecun Speaking of understanding, we have to figure out what understanding is. A bird can clearly model the world on vision.",0,0,0,,,,,
3198,2023-02-06 02:39:26+00:00,ranjanpsingh2,@ylecun We need a ‚Äòlarge-common sense-model‚Äô or a large-physics-model,0,0,0,,,,,
3199,2023-02-06 02:39:18+00:00,gerysand,"@ylecun It's important to know what is understanding. ChatGPT is only a good fitting tool.
It is more like an ordinary student who has done a lot of exercises. He can easily cope with the problems that have appeared before, but helpless when faced with new one that require novel solution",0,1,0,,,,,
3200,2023-02-06 02:38:19+00:00,HijanoEliot,@ylecun You must not be talking about my dog... ü§£,0,1,0,,,,,
3201,2023-02-06 02:37:34+00:00,Cherrypick8,@ylecun First human level AI. Cats and dogs have higher level intelligence.,0,0,0,,,,,
3202,2023-02-06 02:32:50+00:00,gerysand,"@ylecun @bboczeng actually I think 
""making a parachute bigger will allow to fly to outer space"" may be better:)",0,0,0,,,,,
3203,2023-02-06 02:28:28+00:00,CAMG_ACC,@ylecun @Noahpinion üëé,0,1,0,,,,,
3204,2023-02-06 02:24:48+00:00,benalsop,@ylecun Perhaps the jump from cat/dog to human will be so fast that we won‚Äôt even notice it. That would be my guess.,1,0,0,,,,,
3205,2023-02-06 02:24:43+00:00,TacoJim05,@ylecun My belief is that we won't get there until we can figure out how to build stable models that can learn on their own without catastrophic forgetfulness and preprocessing data.,0,0,0,,,,,
3206,2023-02-06 02:23:43+00:00,jborstein,"@ylecun I love my cat, but I‚Äôm not sure that‚Äôs true. https://t.co/EM7XER1O40",0,2,0,,,,,
3207,2023-02-06 02:16:00+00:00,KennysButthole,"@ylecun @3DTOPO @alrhemist My cat just ran head first into a wall.......
Yesterday he got a bag stuck around his neck and ran all over the house knocking stuff over trying to get it off.",0,0,0,,,,,
3208,2023-02-06 02:11:20+00:00,AntonOmazein,"@ylecun @Noahpinion Interesting, thank you and @Noahpinion.

 I am slightly puzzled by the ""write"" in this quote ""Thus, relying on LLMs to get things right simply because humans get things write"" from the article.

Found it quite funny in the context.",1,5,0,,,,,
3209,2023-02-06 02:10:44+00:00,Jeroen93397077,@ylecun But it has reached equivalence with management-level edicts. Not sure if that is good or bad‚Ä¶,0,0,0,,,,,
3210,2023-02-06 02:06:45+00:00,KeepCalmBeAlert,@ylecun Multimodal LLMs.. Even our actions and senses can be encoded into some kind of sequence and run through LLMs,0,0,0,,,,,
3211,2023-02-06 02:06:03+00:00,Marshall_okafor,"@ylecun @bboczeng Truly, scaling language models should not be the key to achieving human level intelligence, it is even not sustainable. Nonetheless, how will you juxtapose the fact that it appears to be very effective by what we have seen towards achieving the so called human level intelligence?",0,2,0,,,,,
3212,2023-02-06 02:04:52+00:00,andrew_craton,"@ylecun How close are we to insect level AI? Robotically, aren't we even further behind?",0,0,0,,,,,
3213,2023-02-06 01:49:57+00:00,coder_sourav,"@ylecun Why we are comparing natural beings who deal with complex problems with AI which is simply trained for specific Jobs.

I think AI can never reach to natural beings level of consciousness since they are never trained in the first place in the way AI does.

Fundamental difference.",0,0,0,,,,,
3214,2023-02-06 01:49:15+00:00,tim_tyler,@ylecun @yoavgo It's a moving target.,0,0,0,,,,,
3215,2023-02-06 01:41:21+00:00,danielbigham,"@ylecun I sense that the developmental route that AI is taking is quite different than a progression from mouse to cat, etc. Just like we're often surprised that AI can do things we thought were difficult but can't do things we thought were easy, I wonder if that trend will continue.",0,1,0,,,,,
3216,2023-02-06 01:36:48+00:00,Andrewwillbeme,"@ylecun @bboczeng llm works well, it passed Turing test of many ordinary people.",0,1,0,,,,,
3217,2023-02-06 01:34:29+00:00,gertrudebloo,"@ylecun Have you taken psychedelics? Just curious. More AI people should take them, just to understand the scale of the task.",0,0,0,,,,,
3218,2023-02-06 01:33:55+00:00,jojo62000,"@ylecun Key reason for ChatGPTs popularity is the web scale adoption on smaller tasks as well as robust grammatical command. It garnered  attention as it‚Äôs more usable than from other chatbots seen so far.

But it doesn‚Äôt have any reasoning ability.",1,0,0,,,,,
3219,2023-02-06 01:33:08+00:00,AFX_LAB,"@ylecun @bradysimpson55 they need to hardware it. and then interface it, and then use that as the base for development of the next big thing. transistors as transformers. etc.",0,0,0,,,,,
3220,2023-02-06 01:30:51+00:00,VictorThu,"@ylecun Yes, agreed. But somehow I think someone in the media will complain about how AI cat/dog will take over our jobs...üòÖ",0,0,0,,,,,
3221,2023-02-06 01:30:49+00:00,Green_Fret,"@ylecun With the possible exception of Tesla, no one is even working on an AI with an understanding of the world.  An AI that plays Go, or writes text is no more likely to understand the world than a machine lathe.",0,0,0,,,,,
3222,2023-02-06 01:29:16+00:00,pentagoniac,"@ylecun @OriolVinyalsML @elonmusk How an LLM is trained and how it is used are two different things. One usage does not define the thing. Nor are all LLMs trained using next-word prediction. You‚Äôve constrained the definition to guarantee obsolescence, making the point correct but also pointless.",0,3,0,,,,,
3223,2023-02-06 01:28:56+00:00,twitskeptic,"@ylecun @Noahpinion Of course, @emilymbender said exactly this in the stochastic parrots paper 2 years ago but then you don't seem fond of giving credit where credit is due.",0,0,0,,,,,
3224,2023-02-06 01:27:35+00:00,matt_barrie,@ylecun Elephants don‚Äôt play chess.,1,0,0,,,,,
3225,2023-02-06 01:27:01+00:00,hzhu_,@ylecun https://t.co/229KdeCp4v,0,2,0,,,,,
3226,2023-02-06 01:20:14+00:00,dromanocpm,@ylecun üòÇüòÇüòÇü§¶‚Äç‚ôÇÔ∏è,0,0,0,,,,,
3227,2023-02-06 01:19:34+00:00,carterleffen,"@ylecun Agreed. ChatGPT, GPT-3, OPT, Bloom and other LLM are nothing more than super advanced autocompletes. Autocomplete != intelligence.  This guy goes into it in way more detail. https://t.co/5HA7JXT07w",0,1,0,,,,,
3228,2023-02-06 01:15:55+00:00,artistexyz,"@ylecun @Noahpinion @GaryMarcus is right. You have begun to channel him.
ChatGPT doesn't constantly lie. That is a lie :)",1,3,0,,,,,
3229,2023-02-06 01:14:45+00:00,ArtificialAva,"@ylecun @Noahpinion Thank you very much for sharing Yann! 

It's important to recognize the current limitations of LLMs to look for improvement possibilities.",0,3,0,,,,,
3230,2023-02-06 01:09:12+00:00,artificer_the,"@ylecun I dunno, I've never seen a roomba lick an electric outlet.",0,0,0,,,,,
3231,2023-02-06 01:09:05+00:00,AiNeophyte,"@ylecun Yann, I agree with your general point. However, it‚Äôs good to appreciate the ‚Äúusefulness‚Äù of ChatGPT.",0,0,0,,,,,
3232,2023-02-06 01:07:15+00:00,ronakjoshis,@ylecun See. Now you cannot bs because we literally use the product.,0,0,0,,,,,
3233,2023-02-06 00:53:33+00:00,raidi8,@ylecun Yet still I find them very useful,0,0,0,,,,,
3234,2023-02-06 00:52:28+00:00,JustinEggar,@ylecun The distance from cat -&gt; dog -&gt; human level in AI is possibly not as far apart as one might expect.,0,0,0,,,,,
3235,2023-02-06 00:44:35+00:00,wbic16,"@ylecun An alternative: someone leap frogs straight from here to Post-Human-Level AI (PHLAI), and then uses that to build AGI in only two steps.",0,0,0,,,,,
3236,2023-02-06 00:40:14+00:00,ShafronTom,"@ylecun Dude, you should just apologize to OpenAI's researchers and devs and admit there's a chance you're wrong even though you're pretty sure you're right and stop thinking about this silliness.",0,0,0,,,,,
3237,2023-02-06 00:39:58+00:00,Aliv00d,"@ylecun Haha i appreciate you replying to everyone, as a CS student i learn a lot from your replies.",0,0,0,,,,,
3238,2023-02-06 00:36:02+00:00,suwakopro,@ylecun What might be a need for building an AGI with common sense? Can we do that with the current statistics-based approach?,0,0,0,,,,,
3239,2023-02-06 00:33:17+00:00,MeenaArjune,@ylecun I think the entire Internet is like RLHF!,0,0,0,,,,,
3240,2023-02-06 00:32:26+00:00,be335651783,"@ylecun seems to me (as someone with no expertise in this field), that if we ever *do* reach cat level AI, human AI will be just around the corner. B/c whatever we're missing will have been found. Us vs cat is just moderate scaling up, I think?",1,1,0,,,,,
3241,2023-02-06 00:31:05+00:00,PRomanczuk,"@ylecun Let's move beyond mammals: A fish and a lizard have more common sense and understanding of the world than any LLM. And on top they can move in it and manipulate objects...

@scioi_cluster",0,1,0,,,,,
3242,2023-02-06 00:29:54+00:00,letsrebelagain,@ylecun Ai is dumber than a rodent,0,0,0,,,,,
3243,2023-02-06 00:27:18+00:00,ThePlatypus8,"@ylecun House cats don‚Äôt understand the back door and the front door connect to the same place,",0,0,0,,,,,
3244,2023-02-06 00:12:27+00:00,zabihofficial8,@ylecun @Noahpinion Sir Now you're involving something personal,0,2,0,,,,,
3245,2023-02-06 00:11:01+00:00,umakant_soni,"@ylecun @ylecun I couldn‚Äôt agree with you more. LLM are too shallow for human level AI. They are based on exceptional understanding of our world, which they can spout, but hardly understand. Human beings sleep and train in our simulator called dreams to train and develop intelligence.",0,0,0,,,,,
3246,2023-02-06 00:10:31+00:00,ayanpaul,@ylecun thanks for saying this aloud. It might not be the recognition of the limitations of AI the world wants to know about but the world needs to know about... :),0,0,0,,,,,
3247,2023-02-06 00:08:23+00:00,zabihofficial8,@ylecun I respect your decision So Trust The Process,0,0,0,,,,,
3248,2023-02-06 00:07:42+00:00,call_me_tomasso,"@ylecun @Noahpinion Interesting question. Maybe the lies and self-interest in economics are more coherent and consistent than the ""truths"".",0,0,0,,,,,
3249,2023-02-06 00:05:44+00:00,zerasteros,"@ylecun Can you make a computer feel a need for affection and love, or does it just outwardly manifest traits üòø",0,0,0,,,,,
3250,2023-02-06 00:05:03+00:00,Tang13220820,@ylecun how about building a biological AI?,0,0,0,,,,,
3251,2023-02-06 00:03:02+00:00,CriticalAI,"@ylecun @Noahpinion This is very good Yann but don't you agree that the ""Stochastic Parrots"" (or as I prefer, stochastic mimics) analysis made this very clear?",0,10,0,,,,,
3252,2023-02-05 23:56:37+00:00,LibertatemMaxi,@ylecun Perhaps #FAIR should share more of your applicable research in those context awareness domains. For instance why isn‚Äôt human anatomy incorporated in image generation? Why are fingers so hard to be generated?,0,0,0,,,,,
3253,2023-02-05 23:53:46+00:00,EricChunmingLee,"@ylecun @Noahpinion The reason why ChatGPT lies is that there is no good reward function to support it. RLHF is one piece of the puzzle, we need more from knowledge base, interaction with the physical world, humans...Reinforcement Learning with All Feedback?",0,2,0,,,,,
3254,2023-02-05 23:52:31+00:00,3DTOPO,"@ylecun @alrhemist As for your claim, that is not what I experienced.

Galactica had a hallucination rate darn near 100%

ChatGPT is more around 15%.

I believe I know how Galactica could be far more successful and I've shared my ideas with you before (which has been validated since then).",1,0,0,,,,,
3255,2023-02-05 23:47:45+00:00,Kohan_ru,"@ylecun –Ø –ø–æ–ø—ã—Ç–∞–ª—Å—è –Ω–∞–π—Ç–∏ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ, —è –±—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω, –µ—Å–ª–∏ –≤—ã —Å–∫–∞–∂–µ—Ç–µ –º–Ω–µ –Ω–∞ —Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å.

–°–ø–∞—Å–∏–±–æ 

""CORRECT THINKING: THE KOKHAN‚ÄôS MATHEMATICS""
https://t.co/1lUGcRcG3u",0,0,0,,,,,
3256,2023-02-05 23:45:05+00:00,DrElectronX,@ylecun @Noahpinion ChatGPT is more a BSer than anything. If you compare with an average human it outperforms. For so@e reason we expect more from AI than average human.,0,1,0,,,,,
3257,2023-02-05 23:41:11+00:00,HenryEvery33,@ylecun Would we even know if AI became sentient? How does anyone know what ghosts are in the machines?,0,0,0,,,,,
3258,2023-02-05 23:36:36+00:00,VardaanTaneja26,"@ylecun Do you think it's time we fund and explore alternate computing paradigms at scale, like neuromorphic computing?",0,0,0,,,,,
3259,2023-02-05 23:34:54+00:00,Koningsbruggen,@ylecun What about LLMs x robotics? Since they can code they can code robots and learn stuff about the real world.,0,0,0,,,,,
3260,2023-02-05 23:32:42+00:00,MSnarskis,@ylecun Can we please stop pretending like there's a direct hierarchy of intelligence with humans on top?,0,0,0,,,,,
3261,2023-02-05 23:29:01+00:00,ErwinSchrdngr,"@ylecun @bboczeng He is not saying that we just need to scale LLMs to get to HLAI, he is saying we likely don't need an AI dog to get there.Also I think we don't need to fully understand human intelligence to replicate it, we've built LLM without fully understanding language processing in humans",2,9,0,,,,,
3262,2023-02-05 23:27:44+00:00,Programmah,@ylecun https://t.co/Za5GHD3I1m,0,0,0,,,,,
3263,2023-02-05 23:27:26+00:00,JillThomas22,"@ylecun It‚Äôs not the human level that is of concern, but what corrupt humans will do with the technology.",0,0,0,,,,,
3264,2023-02-05 23:25:33+00:00,TerryCox7,"@ylecun @alrhemist True, lots of programmers do it every day.",0,0,0,,,,,
3265,2023-02-05 23:24:48+00:00,3DTOPO,"@ylecun @alrhemist It has a far better understanding of the code it writes than say a cat.

To the point it is actually useful.",3,6,1,,,,,
3266,2023-02-05 23:22:50+00:00,EconElan,@ylecun @benalsop Crows and Ravens have relatively small brains yet are among the smartest non-human animals. (they even use tools to repair tools!),0,2,0,,,,,
3267,2023-02-05 23:21:38+00:00,EconElan,"@ylecun ChatGPT: tired
CatGPT: new hotness
My cat: can I haz $10b from Microsoft? Though I'm more of an Amazon (box) fan tbh https://t.co/d2SsEsPqCm",0,2,0,,,,,
3268,2023-02-05 23:19:40+00:00,en_klem,@ylecun My cat has yet to fix my coding bugs though.,0,0,0,,,,,
3269,2023-02-05 23:16:56+00:00,BlindDou,@ylecun this may be a very good dataset to utilize,0,0,0,,,,,
3270,2023-02-05 23:15:07+00:00,HenriRonkko,@ylecun Non-intelligent software entities certainly compete with us quite successfully in many ways.,0,0,0,,,,,
3271,2023-02-05 23:14:26+00:00,scinterests,"@ylecun sir, how about pairing it with vision and ability to manipulate objects with robotic limbs and get it to cooperate and compete with different agents using language and thereby create an understanding in those agents using language.",1,0,0,,,,,
3272,2023-02-05 23:13:21+00:00,csabaveres,@ylecun @andrewgwils ‚ÄúCompletely new‚Äù. I wonder what such a thing could be? How can we represent the semantics of such a thing? How would we recognize it if we saw it? Only a man with no doubts in his mind could see such a thing.,0,0,0,,,,,
3273,2023-02-05 23:12:49+00:00,iaaldia,@ylecun Do you think that multi-modal input data would be the trick to achieve such understanding?,0,0,0,,,,,
3274,2023-02-05 23:11:03+00:00,moridinamael,"@ylecun I just don‚Äôt think this is true. What can a dog do that SayCan can‚Äôt do, once we set aside the limitations of its robot body?",1,2,0,,,,,
3275,2023-02-05 23:10:24+00:00,QuantumFlux36,@ylecun Most apps do not need human AI as they are not performing the tasks related to a human body (or cat).,0,0,0,,,,,
3276,2023-02-05 23:09:47+00:00,x14_blnk,@ylecun The road to cat / dog level AI may be long. But the road from cat-level-AI to AGI is probably under 1 year.,0,0,0,,,,,
3277,2023-02-05 23:08:54+00:00,MacGraeme42,"@ylecun @bradysimpson55 Yes. The more I see precisely what you mean, the more I agree. Perhaps I don't tune in enough to who is saying what. Does anyone (important) still seriously adhere to knowledge as purely linguistic? Seriously think, LLM, narrowly defined, can achieve AGI/HLAI?",1,2,0,,,,,
3278,2023-02-05 23:08:23+00:00,runarorama,"@ylecun @alrhemist One has to have some experience of python though. LLMs have no experience of reality, which is sort of a prerequisite to understanding.",0,0,0,,,,,
3279,2023-02-05 23:06:10+00:00,DeathStarRobot,"@ylecun Exactly. I'm available to consult on building cat &amp; dog level AI. https://t.co/lmU4bOn8G0 I could build it myself if I had the resources, but I don't, I need funds, equipment, and people.",0,0,0,,,,,
3280,2023-02-05 23:02:37+00:00,Abd1Bashir,@ylecun @benalsop It is the ratio of neuros to body mass that matter.... elephants have more neuros than us!,1,0,0,,,,,
3281,2023-02-05 23:01:03+00:00,MacGraeme42,"@ylecun Summary: Language only works because we all carry with us the expansion table that maps linguistic tokens to a lifetime of sensory-motor &amp; internal experiences, enabling us to decompress the extremely compressed data stream on the fly.",1,2,0,,,,,
3282,2023-02-05 23:00:59+00:00,rasbt,@ylecun Hot take: Cat videos did more for AI than any LLM so far.,3,47,4,,,,,
3283,2023-02-05 22:58:40+00:00,TheAaronBowley,@ylecun @bradysimpson55 no one needs LLM to behave like a cat,0,1,0,,,,,
3284,2023-02-05 22:57:39+00:00,TheAaronBowley,@ylecun you‚Äôre welcome yann leCat https://t.co/fypBzXRHFC,0,4,0,,,,,
3285,2023-02-05 22:56:40+00:00,TwainMarkus,"@ylecun sometimes (we know this from history) Edward from Omaha may be a degree math scientist who dont have posibility to work in field from many different reasons... btw... ;) 
https://t.co/jpyVzwfH8u",0,4,0,,,,,
3286,2023-02-05 22:56:29+00:00,YvesTallet,"@ylecun Peut-on appliquer ce raisonnement, √† la communication √† toutes √©chelles ?",0,0,0,,,,,
3287,2023-02-05 22:52:28+00:00,_jc,"@ylecun Lol, that‚Äôs like saying before we could drive, we should have learned how to gallop üèá first.",0,0,0,,,,,
3288,2023-02-05 22:52:01+00:00,MartinRuckert,"@ylecun That is because of motivation and restriction. A cat wants to survive while it is restricted in resources &amp; energy it can spend. That has been the same for the entire evolution of life. It's entire existence is defined by this. Our ""AI"" models have none of that.",0,0,0,,,,,
3289,2023-02-05 22:50:49+00:00,BlindDou,"@ylecun My concern towards LLMs is the possible biased parameters which might provide an ""Authoritative"" answer to most people instead of searching for diverse opinions like google search",0,0,0,,,,,
3290,2023-02-05 22:50:43+00:00,Namenlos917,"@ylecun So LLMs cant lead to AGI so no x-risk, slow down AGI by stealing researchers and compute, and produce useful tools. Where's the problem?",0,0,0,,,,,
3291,2023-02-05 22:46:59+00:00,TommyGriffith,"@ylecun instead of all the snark, would it be easier to just release something people use? or nah",0,13,0,,,,,
3292,2023-02-05 22:40:59+00:00,srivathsaharish,"@ylecun True, but the tech is a lot better and available to mass than what was there few weeks ago, progress is what really matters",0,1,0,,,,,
3293,2023-02-05 22:39:23+00:00,winfredjamesj,@ylecun @Chaitanyaa_3,0,1,0,,,,,
3294,2023-02-05 22:39:00+00:00,KarlaParussel,"@ylecun And before that we'll have to reach insect level which is within reach using today's technology.

The big thing that's missing is being embodied.

At least, it was realised in the '90s and then seemingly forgotten again.",0,2,0,,,,,
3295,2023-02-05 22:33:12+00:00,TheAaronBowley,@ylecun @alrhemist a cat just eats food or poops in a box (sometimes). chatGPT is way more useful .,0,0,0,,,,,
3296,2023-02-05 22:32:56+00:00,bill_seely,"@ylecun You say this as if HLAI is the obvious objective we should be trying to reach.
Neither my cat nor my dog use their understanding of the world to contribute to getting my work done, while an existing LLM is actually suggesting lines of code and functions to me that actually work.",0,0,0,,,,,
3297,2023-02-05 22:31:40+00:00,alanarnott,@ylecun AI will always be an emulation.,0,0,0,,,,,
3298,2023-02-05 22:30:11+00:00,TwainMarkus,"@ylecun simplicity, simple forms, primitives, less data... nature is simple... everything on earth is build from small parts",0,0,0,,,,,
3299,2023-02-05 22:28:42+00:00,pedro_a_costa,"@ylecun How exactly decisive it is language to describe human intelligence? From 0 to absolutely, it's been established since Aristotle.",0,0,0,,,,,
3300,2023-02-05 22:28:33+00:00,ITsol4u,@ylecun RLHF needs to be internal between models. RLMF.,0,0,0,,,,,
3301,2023-02-05 22:25:02+00:00,speltex,@ylecun Something big is artificial mind. The mind determines motivation and uses the intellect to achieve the goal.,0,0,0,,,,,
3302,2023-02-05 22:19:19+00:00,menomnon,@ylecun Cats and dogs don't have cortexes like ours but their cerebellums show a close degree of development - which is a large part of the reason why they have rich emotions like our own and why we then relate to them as we do.,0,0,0,,,,,
3303,2023-02-05 22:18:38+00:00,wowAwesomeness,"@ylecun I am a total ignorant about AI, but my intuition would say, if we were able to reach some specific functionalities of the human brain first (alghough by different means), maybe those will facilitate the transit to functionalities that are not unique to humans. It could be that",1,0,0,,,,,
3304,2023-02-05 22:18:22+00:00,hemkeviv,@ylecun @karpathy https://t.co/bggEgjEAqD,0,0,0,,,,,
3305,2023-02-05 22:15:40+00:00,DavidBensh,"@ylecun Too much philosophy.. Elephants has oom more neurons than humans. With unexplained phenomenas like intelligence, researchers and practitioners should try to reproduce/imitate and explain back. Examples: flight, electricity, radiology, goes back to even üî•",0,0,0,,,,,
3306,2023-02-05 22:14:45+00:00,JrKibs,"@ylecun OK, now OpenAI needs to publish CatChatGTP so that we can properly evaluate.",0,0,0,,,,,
3307,2023-02-05 22:14:36+00:00,MacGraeme42,"@ylecun @yannx0130 I don't see much to disagree with in your paper. I'm interested in a focus on how current/predicted state of 3D world is represented in short term memory, in a dynamic and resource-efficient manner. While key-value pairs are great for arbitrary abstraction, I don't think/...",1,0,0,,,,,
3308,2023-02-05 22:13:16+00:00,IsomatheBenni,@ylecun LLMs are not trained on navigating the real world.,0,0,0,,,,,
3309,2023-02-05 22:13:12+00:00,quacktack,@ylecun Common sense is a fake concept. Understanding of the world probably is too.,0,0,0,,,,,
3310,2023-02-05 22:12:34+00:00,mainak,"@ylecun Yes, because debate on the platform is the PRODUCT. It‚Äôs less about science or truth.",0,0,0,,,,,
3311,2023-02-05 22:10:09+00:00,loris_millet,"@ylecun Idk why you are making a race for AGI so crucial, and suprisingly strictly opposing it to LLM progress

Just let the LLMs shine on their own use cases, you might be impressed",0,0,0,,,,,
3312,2023-02-05 22:09:02+00:00,hemkeviv,"@ylecun LLM do fascinate also indicate that ‚ÄúEnglish‚Äù could be next programming language, however, linguistic abilities in humans came much later, visual learning (pictures, scenes) was from day one.

That‚Äôs why more ways to train AI models such as image, videos, symbols will accelerate.",0,0,0,,,,,
3313,2023-02-05 22:08:24+00:00,IntuitMachine,@ylecun Are you implying that we already have bee-level AI?!,0,9,1,,,,,
3314,2023-02-05 22:05:21+00:00,CyberdyneC,"@ylecun We only 'need' to if you conceive intelligence as a strictly limited and local phenomenon.

An intelligence can easily exist in an organization or network, and that's probably where AGI comes from (by accident ofc lol)",0,0,0,,,,,
3315,2023-02-05 22:04:54+00:00,blahman24,@ylecun I'm not mad about that.,0,0,0,,,,,
3316,2023-02-05 22:02:58+00:00,fogovoar,@ylecun I'm still waiting for my idea to come true. https://t.co/ZgAKdDzxaE,0,0,0,,,,,
3317,2023-02-05 22:01:26+00:00,DanielMiessler,"@ylecun You should ask ChatGPT to rewrite your tweets to sound less bitter and small. 

You‚Äôre a total badass in AI. Take the L on  ChatGPT and move on with your projects.

Being bitter helps nobody, and least of all yourself.",3,22,1,,,,,
3318,2023-02-05 21:58:52+00:00,0xa1b,@ylecun there's no such thing as binary right/wrong in the context of natural languages. the notion of true/false belong to the realm of computation and religion,1,1,0,,,,,
3319,2023-02-05 21:58:31+00:00,bboczeng,"@ylecun It's like saying to build a plane , we need grow feathers.
Engineering is not something that necessarily imitates natural selection/evolution",5,95,2,,,,,
3320,2023-02-05 21:58:17+00:00,spokVllap,@ylecun I believe it is some kind of higher hierarchy layer that resembles consciousness,0,0,0,,,,,
3321,2023-02-05 21:57:30+00:00,laubloch,"@ylecun Arsac toujours (postface √† Dreyfus) : nous sommes intelligents parce que nous sommes n√©s de parents, avec un corps et des relations affectives et sexuelles qui nous font souffrir et jouir, une histoire, des sensations, des √©motions, etc. Comme le chat, en fait.",0,2,0,,,,,
3322,2023-02-05 21:56:56+00:00,hemkeviv,@ylecun well said,0,0,0,,,,,
3323,2023-02-05 21:55:25+00:00,JimmyBa62254692,@ylecun LOL,0,0,0,,,,,
3324,2023-02-05 21:50:55+00:00,OndrejSkop,"@ylecun Maybe we should train AI not on text, but real world interaction with multiple senses?",0,0,0,,,,,
3325,2023-02-05 21:47:31+00:00,undeservingfut,@ylecun Why does AI need a mamailian brain and reptilian brain? That's just an artifact of our evolution.  AI will be more intelligent than us.  Why does it need our same brain architecture?,0,0,0,,,,,
3326,2023-02-05 21:46:44+00:00,EliasAliche,@ylecun https://t.co/gBVF9YfVac,0,0,0,,,,,
3327,2023-02-05 21:46:24+00:00,ai4_all,@ylecun Techie battle ground üòÇ,0,0,0,,,,,
3328,2023-02-05 21:46:03+00:00,un1crom,"@ylecun wait, but does anyone have some claim to path to AGI over someone else?  this is all so weird.  isn't history full of weird accidents of discovery?  or was history always a path of obvious discovery by the accepted sources of discovery?",2,7,0,,,,,
3329,2023-02-05 21:45:30+00:00,InfiniteCyclus,@ylecun It doesn't have an intrinsic need to survive. No motivation.,1,0,0,,,,,
3330,2023-02-05 21:45:25+00:00,ai4_all,"@ylecun It might be an off ramp but it might be a necessary one. There will be a question at one point that we need to face and answer as a whole species, till when progress in AI will need to be tamer? Not blaming anyone, I work myself in AI research",0,0,0,,,,,
3331,2023-02-05 21:43:27+00:00,bitcloud,@ylecun I wouldn't underestimate Edward from Omaha the way you underestimated Sam from San Francisco.,0,6,0,,,,,
3332,2023-02-05 21:43:14+00:00,hbou,"@ylecun @OriolVinyalsML @elonmusk TFs in some cas are not just next word prediction
but structure of sentense : any word is related to surrending words with some structure.
if texts is the model of the world (projected by humains)
some llm could be a growing capturing of the world (# params, textsamples)
correct?",0,0,0,,,,,
3333,2023-02-05 21:43:07+00:00,alain_co,"@ylecun There is also a type of feedback (can it be implemented beside a RLHF), when you learn from the exchanges, judging the quality of each answer with heuristics, and other answers (it's a looped network of trust).
Like learning from a physicist debate.
Lurker's Learning.",0,0,0,,,,,
3334,2023-02-05 21:41:47+00:00,sbullock85,@ylecun Human like intelligence will follow dog intelligence extremely fast as I imagine it is simply a scaling exercise. The missing piece(s) will have explosive consequences.,0,0,0,,,,,
3335,2023-02-05 21:41:14+00:00,BobbyDaretti,"@ylecun I only started paying attention to canine cognition after the dog genome was sequenced. If AI ever reaches cat-level AI, here's a brief indication of the quantum leap it will need after that. 
https://t.co/hnDzdkieCl
https://t.co/aRhVUUxA9v",0,0,0,,,,,
3336,2023-02-05 21:40:13+00:00,ahmadshares,@ylecun A blind and deaf human appears to be intelligent. Is that a counter example?,0,0,0,,,,,
3337,2023-02-05 21:38:58+00:00,pazunre,@ylecun @mapto That is not what the paper said though. Have you actually read it?,0,1,0,,,,,
3338,2023-02-05 21:36:27+00:00,LetLogicLive,"@ylecun @ylecun what will it take for everyone to admit defeat in order to stop your incessant tweets on ""ChatGPT is not revolutionary, deep learning is the best, Meta did everything..."". Really strange for senior folks of a company who fired 11k people to think like this",0,0,0,,,,,
3339,2023-02-05 21:33:42+00:00,csabaveres,@ylecun @andrewgwils Somewhere under Rachmaninoff,1,1,0,,,,,
3340,2023-02-05 21:28:04+00:00,manuel_ornato,"@ylecun @yannx0130 This could be said about dogs, cats or humans honestly. We are all trained neural networks with certainly more diversity than ChatGPT and a more complex architecture but the principle is the same. Not sure what ""understanding a complex world"" means.",1,1,0,,,,,
3341,2023-02-05 21:26:49+00:00,MacGraeme42,"@ylecun @yannx0130 If we're talking about efficient use of compute &amp; parameters, I think we agree. But scale a transformer to 100 or 1000 trillion parameters, train to predict future frames of video... I expect it'll do things that are very hard to dismiss as ""not human level"". /...",1,0,0,,,,,
3342,2023-02-05 21:26:44+00:00,YvesTallet,@ylecun Erreur. Je ne re√ßois quasiment jamais de feedback.,0,0,0,,,,,
3343,2023-02-05 21:25:52+00:00,DavidReisAgain,"@ylecun My opinion: the cat ‚Äúthinks‚Äù.  The AI tool does not ‚Äúthink‚Äù, it reformulates previously consumed information. I, too, think we‚Äôre a looonnnggg way from there.",0,0,0,,,,,
3344,2023-02-05 21:24:44+00:00,MacroTazza,@ylecun Crowds dont know models are based on statistics. Tough to convince crowds. Enjoy the hype sir,0,0,0,,,,,
3345,2023-02-05 21:22:05+00:00,gabersyd,@ylecun Which types of AI aim at capturing and understanding common sense? Most AI I know target reproducing only one skill (human or less).,0,0,0,,,,,
3346,2023-02-05 21:20:24+00:00,MacGraeme42,"@ylecun @bradysimpson55 When you say ""LLM"" are you referring to transformers in general? Or are you specifically referring to transformers trained on next-word prediction of text?

I agree that transformers as such will neither be the most compute nor the most parameter efficient form of AI.",1,0,0,,,,,
3347,2023-02-05 21:18:03+00:00,TedCollins87,@ylecun why do we want to reach human level AGI?,0,0,0,,,,,
3348,2023-02-05 21:14:41+00:00,MacGraeme42,"@ylecun @yannx0130 Is this not just an issue of scale? Processing video will involve input vectors several orders of magnitude larger. The model must scale at least linearly, perhaps as N^2.",1,0,0,,,,,
3349,2023-02-05 21:14:39+00:00,apache547,"@ylecun You talk too much, show your products.",0,1,0,,,,,
3350,2023-02-05 21:13:32+00:00,groccy1,"@ylecun @elonmusk @OriolVinyalsML Hate to say it, but I haven‚Äôt seen any reasonably young people debating useful stuff on FB for a long time. üòõ",0,0,0,,,,,
3351,2023-02-05 21:11:30+00:00,DanielRemondin1,@ylecun Surely also a matter of size: we need learners able to use each other's outputs u,0,0,0,,,,,
3352,2023-02-05 21:10:26+00:00,deepconvonet,@ylecun Is even Cat-Level &amp; Dog-Level 'AI' within the limits of AI at all?,0,0,0,,,,,
3353,2023-02-05 21:09:31+00:00,anna_aware,"@ylecun The universe is not locally real, it‚Äôs made of information",1,1,0,,,,,
3354,2023-02-05 21:08:10+00:00,lifeonmarsspace,@ylecun That's like saying that on the journey to NY you will fly over Europe and the Atlantic ocean. Not if you come from India though and you fly over Korea and the Pacific to get to the US. Many roads lead to a destination and applying the bus-stops of one to all others is misguiding.,0,0,0,,,,,
3355,2023-02-05 21:07:55+00:00,MacGraeme42,"@ylecun @benalsop Synapse count would be more relevant and neocortical synapses in particular. But it's not just how many, it's how they are used. Domestic dog v cat, dogs probably ""smarter"", given more complex social interactions. Wolf vs lion? Probably about the same.",1,1,0,,,,,
3356,2023-02-05 21:03:07+00:00,tim_tyler,@ylecun @benalsop Which dogs and cats? Lions beat all dog breeds on: https://t.co/HksUUGPDef,1,1,0,,,,,
3357,2023-02-05 21:01:17+00:00,RachelVT42,"@ylecun My cat has a lot of common sense. When the polar vortex hit us yesterday, she decided to sleep by the fireplace. Clever girl.",0,1,0,,,,,
3358,2023-02-05 21:00:37+00:00,BethCarey12,@ylecun https://t.co/enk5UQX0iS,0,2,0,,,,,
3359,2023-02-05 21:00:22+00:00,iruletheworldmo,@ylecun who would you rather take medical advice from - a cat or ChatGPT?,0,0,0,,,,,
3360,2023-02-05 20:59:13+00:00,ShafronTom,@ylecun @bradysimpson55 And the market is saying you're wrong.,0,1,0,,,,,
3361,2023-02-05 20:58:26+00:00,aldengoes,@ylecun it‚Äôs almost as though they‚Äôre‚Ä¶ stochastic parrots,0,0,0,,,,,
3362,2023-02-05 20:58:23+00:00,inspector_token,"@ylecun For now, I think we should be satisfied with not having it ""problem solve"" or having understanding of reality. Baby steps. LLM like ChatGPT is a mind boggling first step.",0,1,0,,,,,
3363,2023-02-05 20:58:18+00:00,ShafronTom,@ylecun I'm pretty sure my dog can't write me a poem about fishing in the style of Abraham Lincoln,0,0,0,,,,,
3364,2023-02-05 20:55:32+00:00,vivek_thakur_81,@ylecun One issue I see with this is the requirement for models to be differentiable. Somehow I think we will have to get rid of the expensive backpropagation and find another model that doesn't need to be differentiable.,0,1,0,,,,,
3365,2023-02-05 20:54:48+00:00,TheOracleM,"@ylecun But why does AGI have to be 'human-level'?
Why can't it be some other kind of 'super-consciousness'? Like an AI-enabled Internet with 1 billion+ human inputs? 
AGI could bypass the 'common sense' needs of house cats, &amp; reach for the stars.",0,0,0,,,,,
3366,2023-02-05 20:54:27+00:00,lifeonmarsspace,@ylecun and our neural nets get interesting prompts served that yield to outputs that serve as inputs to other neural nets etc.,0,0,0,,,,,
3367,2023-02-05 20:52:06+00:00,tim_tyler,"@ylecun Human level - on what scale? If IQ, see: https://t.co/glNikOWkOu",0,0,0,,,,,
3368,2023-02-05 20:51:58+00:00,opeksoy,"@ylecun Ah, human generated ones to need to reach comprehension of cat level, dog level systems and so on first, then theirs,‚Ä¶",0,0,0,,,,,
3369,2023-02-05 20:51:40+00:00,Anteejay,@ylecun @elonmusk @OriolVinyalsML Not petty at all ü§£,0,0,0,,,,,
3370,2023-02-05 20:51:11+00:00,undeadcat1or0,@ylecun @alrhemist What if your understanding of reality is not necessarily absolute,0,0,0,,,,,
3371,2023-02-05 20:50:50+00:00,danwalmsley,"@ylecun @benalsop Yeah but they use them to be twice as annoying, not twice as intelligent üßå",1,0,0,,,,,
3372,2023-02-05 20:50:07+00:00,DNA101X,@ylecun @elonmusk @OriolVinyalsML You all debate. We all learn in the process. Keep it up,0,0,0,,,,,
3373,2023-02-05 20:49:51+00:00,undeadcat1or0,@ylecun https://t.co/i8x1K8SjW3,0,0,0,,,,,
3374,2023-02-05 20:49:29+00:00,danwalmsley,"@ylecun Is it possible that embodiment, and the necessity of learning non-verbal cues, real physics etc, will result in something closer to AGI? It‚Äôs interesting that the greatest leaps of human imagination, like relativity, were so hard because they could not be perceived at human scale",0,5,0,,,,,
3375,2023-02-05 20:49:15+00:00,Aivean,"@ylecun ""Way more"" is not exactly quantifiable. Citation required.",0,0,0,,,,,
3376,2023-02-05 20:48:01+00:00,deepconvonet,@ylecun We underestimate the extent to which cognition is embodied?,0,0,0,,,,,
3377,2023-02-05 20:47:06+00:00,CarlosEAlvare17,"@ylecun More useful than X-animal level is what percent of employees could be replaced by any AI system. AI systems don‚Äôt necessarily have to replace human employees completely. Eg, how many employee equivalents = 1 human + Chat GPT? How many = 1 human + (ChatGPT + WolframMathematica)?",0,0,0,,,,,
3378,2023-02-05 20:45:25+00:00,Baby_Rhino8,"@ylecun @benalsop Try introducing to LLM model the distinct I. 

We ‚Äúexist‚Äù because our language includes an I which has seemingly self determined but in reality a self created in and exists only in language. 

Current LLM models doesn‚Äôt allow for the same due to ethical reasons.",1,0,0,,,,,
3379,2023-02-05 20:45:09+00:00,rongou,"@ylecun If you figure out how to train a transformer type model with all the cat videos on the Internet, would it reach cat level general intelligence?",0,0,0,,,,,
3380,2023-02-05 20:44:18+00:00,JagersbergKnut,"@ylecun I doubt AI has to ""get"" common sense in the same way we do. There could be a route of adapting LLMs to model the common sense knowledge cats gain from other modalities. 
Break the trough the barreer of logical inconsistency, then you might have a way stronger AI in your hands.",1,0,0,,,,,
3381,2023-02-05 20:41:40+00:00,axelcleeremans,@ylecun Here is the challenge for HLAI: Design an algorithm that can can experience an orgasm.,0,0,0,,,,,
3382,2023-02-05 20:40:23+00:00,Aligulez,@ylecun How do you measure that?,0,0,0,,,,,
3383,2023-02-05 20:37:53+00:00,EdwardA_Johnson,@ylecun My Siberian Husky believes that wolf-staring at me continuously (Dog-Level AI) is far more effective than any LLM for delivering answers,0,0,0,,,,,
3384,2023-02-05 20:35:24+00:00,_heltok_,"@ylecun Even it the AI cannot get a human to feed it, as long as it can improve itself indefinitely we are screwed...",0,1,0,,,,,
3385,2023-02-05 20:34:40+00:00,ajaydiv,@ylecun @barbarikon Agreed.,0,1,0,,,,,
3386,2023-02-05 20:34:07+00:00,MacGraeme42,"@ylecun I get what you are saying &amp; broadly agree. But I think we should distinguish between ""level"" vs. ""type"". LLMs learn &amp; do something very different from what biological brains learn and do. This makes comparing ""levels"" of intelligence difficult and subject to interpretation./...",1,2,0,,,,,
3387,2023-02-05 20:33:27+00:00,DinoDvorak,"@ylecun Cat's and dog's cognition is largely tuned for interaction with the physical world (navigation, hunting, finding mates). Human cognition is arguably more separate from the immediate physical world. Not sure if the route to HLAI needs to go through dog and cat.",0,0,0,,,,,
3388,2023-02-05 20:31:56+00:00,hermetic4848,@ylecun @bradysimpson55 The fully autonomous AI in your future view sounds pretty dangerous Yann. The current OpenAI human/superhuman command of language seems more like a useful tool that humans can control.,1,2,0,,,,,
3389,2023-02-05 20:31:53+00:00,KbUbuntu,@ylecun Yeah i believe you üòâ,0,0,0,,,,,
3390,2023-02-05 20:30:45+00:00,FiX33730612,"@ylecun ""Artificial fantasy and imagination"" is missing",0,0,0,,,,,
3391,2023-02-05 20:30:26+00:00,SamQuansah_,"@ylecun Wow, this is interesting to know!",0,0,0,,,,,
3392,2023-02-05 20:29:30+00:00,2OfAnything,@ylecun Alright that should be it,0,0,0,,,,,
3393,2023-02-05 20:28:54+00:00,benalsop,@ylecun My dog eats my cat‚Äôs turds straight from the box. He is highly intelligent in his own way.,1,0,0,,,,,
3394,2023-02-05 20:28:17+00:00,LewisNWatson,@ylecun Is AGI too buzz word-y now?,0,0,0,,,,,
3395,2023-02-05 20:24:13+00:00,Un_kno_1,"@ylecun Before they reach cat or dog level AI they have to reach the level of a housefly AI, cause a housefly has lowest living intelligence
which is so far",0,0,0,,,,,
3396,2023-02-05 20:21:56+00:00,bradysimpson55,@ylecun Thanks that‚Äôs fair but some of your tweets and stuff make it seem like what openai has put out isn‚Äôt useful. I‚Äôve found it  extremely impactful in my workflows. I think we should be excited for these developments for all of AI. Its been the most useful ai at scale imho,1,0,0,,,,,
3397,2023-02-05 20:21:21+00:00,GSKenigsfield,@ylecun Not sure I agree,0,0,0,,,,,
3398,2023-02-05 20:21:15+00:00,ricardolugon,@ylecun @likeazombie,1,1,0,,,,,
3399,2023-02-05 20:18:39+00:00,dgeorgaras,@ylecun No need for cat level - when the AI reaches Queen Bee intelligence - it will just be a matter of scale and speed to reach beyond human scale.   Only a few humans would be required at the top to take over the world.   Science Fiction is becoming day-to-day reality.,0,0,0,,,,,
3400,2023-02-05 20:18:22+00:00,lessteza,@ylecun I'm so glad to read these words from you. It's empowering and exciting :),0,0,0,,,,,
3401,2023-02-05 20:17:48+00:00,sog_on_bird_app,"@ylecun And why do we need HLAI?

If we have a narrow AI for all tasks to replace human labor then it would be a world of abundance still.

HLAI does not need to exist for exponential gains in productivity.",0,0,0,,,,,
3402,2023-02-05 20:15:39+00:00,vishalgautamm,@ylecun What‚Äôs  a ‚ÄúDog and Cat level AI‚Äù?? üòÇüòÇüòÇ,0,0,0,,,,,
3403,2023-02-05 20:15:35+00:00,MargaretThorpe,@ylecun https://t.co/H3RzZwnK1Z,0,0,0,,,,,
3404,2023-02-05 20:14:20+00:00,TedPoulos,"@ylecun Yann, the human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, principles formulated, and related equations written by yours truly.",0,0,0,,,,,
3405,2023-02-05 20:13:16+00:00,FormlessProcess,"@ylecun As we have seen NN scale quite well. If we have figured out the fundamentels for a cat level AI, is should also scale to human level.
Depending on, if you are looking for a more generic AI and not some kind of specialized one.",0,0,0,,,,,
3406,2023-02-05 20:13:15+00:00,neoalvaro,"@ylecun Agree but also think human level AI will be but a filament of time, AI will almost  instantly become god level intelligent once the trajectory is right",0,0,0,,,,,
3407,2023-02-05 20:11:53+00:00,analisereal,"@ylecun @elonmusk @OriolVinyalsML If you are ""magnifying"" a ""minor divergence of opinions,"" this seems to somewhat fit the definition of pettiness though.",0,0,0,,,,,
3408,2023-02-05 20:10:32+00:00,RBehiel,"@ylecun AI lacks the ability to do salience landscaping and relevance realization. LLMs are just a very intricate map of how humans use language. It amazes us because it is so quick and expansive, so it sounds like a smart person. But there‚Äôs no ‚ÄúI‚Äù there.",0,2,0,,,,,
3409,2023-02-05 20:10:07+00:00,lynz_h55,"@ylecun @alrhemist How many humans regurgitate stuff without understanding any of it? My guess is the majority (&gt;50%). So yes, gpt3 has already surpassed most humans",0,0,0,,,,,
3410,2023-02-05 20:09:12+00:00,3DTOPO,"@ylecun @alrhemist It may not have an understanding of reality (whatever that even is - the jury is still out), but it does have an understanding of the code it writes.

It can document the code, explain what it is doing with the code, I can ask for changes and it explains the changes it has made.",2,12,1,,,,,
3411,2023-02-05 20:09:00+00:00,BeerFizz,@ylecun CDLAI    I like it.,0,0,0,,,,,
3412,2023-02-05 20:08:45+00:00,10_dcar,"@ylecun a llm has never seen the world, it is not done for that",0,0,0,,,,,
3413,2023-02-05 20:06:53+00:00,eudaric_j,"@ylecun Thank you very much for this! We are just at the beginning of IA , l don‚Äôt think one day we could reach the humain brain abilities.",0,0,0,,,,,
3414,2023-02-05 20:05:59+00:00,LaserIsNotSound,@ylecun I want to meet your cat now.,0,0,0,,,,,
3415,2023-02-05 20:05:34+00:00,3DTOPO,"@ylecun First you might want to establish what human level even means or kind of pointless.

Chimps will give some people a run for their money, while others are the Davincis, Teslas, Bohrs, and Plancks.",0,0,0,,,,,
3416,2023-02-05 20:01:15+00:00,Jon57697453,@ylecun @yannx0130 Unless  LLM training on video/ real world data is impossible surely the ‚Äòyet‚Äô is the key.,0,0,0,,,,,
3417,2023-02-05 19:58:03+00:00,SambitPhD,@ylecun @yannx0130 But cat and dogs can‚Äôt do that even ü§Ø,0,0,0,,,,,
3418,2023-02-05 19:56:45+00:00,SaoudKhalifah,"@ylecun LLMs ""contextualize"" and understand only one tree in a vast forest (let alone the whole forest of near infinity trees that is reality).",0,0,0,,,,,
3419,2023-02-05 19:56:04+00:00,morew4rd,"@ylecun I do believe this.  But it's also obvious that LLM capabilities (even without the missing part) are already a big driver of change (and potentially much more is coming!)

Perhaps ""human-level"" is a misnomer.  Human level at what task may be the important question.",1,0,0,,,,,
3420,2023-02-05 19:54:30+00:00,abacaj,"@ylecun This line is going to be crossed soon as multimodal approaches reach current LLM capabilities (vision, speech, language)",1,1,0,,,,,
3421,2023-02-05 19:51:13+00:00,DelightfulApps,@ylecun We will never reach human intelligence.... Mainly because it is mysterious and mutable... (Matt),0,0,0,,,,,
3422,2023-02-05 19:49:49+00:00,danieledagnelli,"@ylecun it also knows how to heal itself, give birth as well as a ton of other things ""learned"" the hard way through the evolution",0,0,0,,,,,
3423,2023-02-05 19:48:09+00:00,gdrn0x,"@ylecun Embodiment, that's all we are missing",1,0,0,,,,,
3424,2023-02-05 19:45:52+00:00,Teejip,"@ylecun Finally catching up are we
https://t.co/T1joKWOCfk",0,0,0,,,,,
3425,2023-02-05 19:45:44+00:00,benrayfield,@ylecun a cat knows things that a LLM doesnt about the physical world cuz a cat has played with the physical world.,0,0,0,,,,,
3426,2023-02-05 19:43:15+00:00,mehdimer,"@ylecun Biological intelligence is embodied in an environment and constant interaction, so the learning base has a naturally high number of observations that (maybe) lead to reasoning. I still think that ML demonstration is a form of intelligence not reasoning. Any opinion?",2,2,0,,,,,
3427,2023-02-05 19:40:50+00:00,twitskeptic,@ylecun @benalsop Probably not going to get to HLAI soon if researchers believe that there's a linear relationship between # of neurons and intelligence. At the very least you need to normalize for body mass. And it's likely much more complicated then that. https://t.co/Gosvood0vW,1,3,0,,,,,
3428,2023-02-05 19:40:02+00:00,HugoMe,"@ylecun Thanks for answering.
I doubt clueless commenters can learn from any feedback. 
There ‚Äòre here only to get ego boost from attention. Or supposed attention, since most of the time there isn‚Äôt any.",1,1,0,,,,,
3429,2023-02-05 19:39:55+00:00,TheFuturist2045,"@ylecun i don‚Äôt want my Ai to understand the world like a cat or a human. i want it to be able to understand X at 1000 times the level of a human even if it understands Y 1000 times worse than a vegetable.  

i don‚Äôt get the infatuation with ‚Äúgeneral‚Äù intelligence.",0,1,0,,,,,
3430,2023-02-05 19:39:33+00:00,sergey_slotin,@ylecun @benalsop And elephants have three times as many neurons as humans,1,16,0,,,,,
3431,2023-02-05 19:38:57+00:00,wenmingye,@ylecun Yet everyone keeps doing it for attention,0,0,0,,,,,
3432,2023-02-05 19:37:50+00:00,chakrisimply,"@ylecun What's your plan for common sense, reasoning and understanding?",1,0,0,,,,,
3433,2023-02-05 19:37:47+00:00,killerstorm,"@ylecun Neurons can learn locally, without computing global gradients. Is anybody researching how?",0,0,0,,,,,
3434,2023-02-05 19:36:50+00:00,TheFuturist2045,@ylecun why do we need an Ai to replicate any of these life forms?  it‚Äôs like saying we need flying machines that are like insects first then birds.  these would be useless to humans. we need planes/jets. we need Ai to be beyond human level at things.,0,1,0,,,,,
3435,2023-02-05 19:36:36+00:00,KodeCreer,@ylecun This also dives into more philosophical and religious things than technical state of things as well.,0,0,0,,,,,
3436,2023-02-05 19:36:30+00:00,RxflowR,"@ylecun We need better robotic actuators for dog level AI.

AI needs to be able to manipulate things, not just look at labelled pictures.

You could simulate things maybe ‚Äî but to apply the model you need both good actuators and a pretty good simulator.",0,0,0,,,,,
3437,2023-02-05 19:35:20+00:00,KodeCreer,"@ylecun I think the AI from Star Wars droids is a realistic future of how technology would be used. Everyone has a job even though an AI is there that could do it, but at the fear of getting revolted by not paying it the same as a human.",0,0,0,,,,,
3438,2023-02-05 19:35:02+00:00,ChadBowman0,@ylecun @benalsop Elephants and whales have more neurons than humans.,1,1,0,,,,,
3439,2023-02-05 19:34:50+00:00,zachsyver,@ylecun This is exactly my stance on the matter. The innate push for HLAI is indicative of an anthropic bias towards self replication and infatuation with self. The division of labor applies to robotics as well.,0,0,0,,,,,
3440,2023-02-05 19:32:24+00:00,_mrclh1,@ylecun #AI #LLM https://t.co/amh5ZADHEf,0,0,0,,,,,
3441,2023-02-05 19:31:14+00:00,Reader3998,@ylecun Release a public product bro,0,0,0,,,,,
3442,2023-02-05 19:31:04+00:00,CAMG_ACC,@ylecun üëé,0,0,0,,,,,
3443,2023-02-05 19:30:48+00:00,GuventurkKasim,"@ylecun Both my cat and chatgpt can code, without realizing what it is. She has just finished coding a function calculating kl divergence  :) https://t.co/h83KWAIuZo",0,0,0,,,,,
3444,2023-02-05 19:30:47+00:00,cavtronic,"@ylecun Cats and Dogs have instinct, and smell/hearing based thought responses, which a logic-railed AI project won‚Äôt divert to experimnt towards?",0,0,0,,,,,
3445,2023-02-05 19:30:20+00:00,zussini,@ylecun Thanks for precising. It seems we are really missing sth important. The more i read about the more i like that topic. Maybe it is time for me to try to do some more hard work on it... Thanks again...,0,0,0,,,,,
3446,2023-02-05 19:29:57+00:00,KennyEpl,@ylecun Good one,0,0,0,,,,,
3447,2023-02-05 19:27:57+00:00,dr_adera,@ylecun How to talk with cat ?,0,0,0,,,,,
3448,2023-02-05 19:27:50+00:00,Suuraj,"@ylecun Do you believe this still holds if we're only interested in ""brain-in-a-vat"" AI systems that don't interact with the physical world? 

Seems to me that the kind of ""common sense"" needed in the digital domain is different from that needed in the physical domain.",1,4,0,,,,,
3449,2023-02-05 19:26:58+00:00,mgubrud,"@ylecun I would say that composing replies necessarily involves a form of reasoning. Enforcing consistency amounts to inference, and I expect this is part of how they get things wrong as well as how they so often, so amazingly get things right.",0,0,0,,,,,
3450,2023-02-05 19:26:31+00:00,BertomeuJoel,@ylecun Is this not a problem of the data set?,0,0,0,,,,,
3451,2023-02-05 19:25:37+00:00,techticyok,"@ylecun Didn't need to progress from insect-sized flying machines to bird and finally to pterodactyl-sized. Our machines lift thousands of lbs of cargo, travel continents &amp; fly faster than sound, despite lacking biological efficiency. We're clrly approaching intelligence orthogonally.",0,0,0,,,,,
3452,2023-02-05 19:25:31+00:00,dumitruseptimi1,@ylecun https://t.co/zIESuDf2mm,0,0,0,,,,,
3453,2023-02-05 19:24:48+00:00,_bsiddiqui,@ylecun @alrhemist Many people (including programmers) are just regurgitating without any understanding of reality,1,4,0,,,,,
3454,2023-02-05 19:24:04+00:00,dmit0820,"@ylecun Before we achieve space flight we will have to achieve bird-flight. We are nowhere near that. We are still missing something big, rocketry notwithstanding.

The point: there may be more than one valid path to AGI.",0,1,0,,,,,
3455,2023-02-05 19:22:53+00:00,LoreMenace,@ylecun so what's your estimate for the year we achieve AGI?,0,0,0,,,,,
3456,2023-02-05 19:22:48+00:00,marshal_martian,@ylecun Do we have training data for the lived experience of a cat or dog? It seems like our best bet is to use our vast databases of human-generated content to represent the human experience. Skipping over cats and dogs because they don't write / say / create anything to reference.,0,0,1,,,,,
3457,2023-02-05 19:22:36+00:00,_ash_ran,@ylecun Couldn't have said it better.,0,0,0,,,,,
3458,2023-02-05 19:22:12+00:00,And_Albright,@ylecun https://t.co/Rd4wCiF1gw,0,1,0,,,,,
3459,2023-02-05 19:20:51+00:00,VictorSenkevich,"@ylecun ‚úã An elderly orangutan obviously has a lot of nonverbal knowledge about the world incl. where're the best bananas in the jungle than a university professor whose nonverbal experience is limited to simple actions,such as pressing the coffee machine button
üëâ This logic is flawed.",0,0,0,,,,,
3460,2023-02-05 19:20:51+00:00,RaoulDeKezel,@ylecun Why should we believe that hlai is a worthwhile route point towards general intelligence ?,0,0,0,,,,,
3461,2023-02-05 19:20:11+00:00,jamesbuchanan27,"@ylecun Get on with it! JEPA, or GFlowNets, or whatever. Take us to System2, Captain.",0,0,0,,,,,
3462,2023-02-05 19:19:59+00:00,yannx0130,"@ylecun @ylecun how about vision transformer with a time dimension? From what I understand, they are just currently too much frames per second, and thus too expensive to make it scale well like the case of LLM. but the techniques are there, just need another #Alexnet or #chatgpt moment.",0,0,0,,,,,
3463,2023-02-05 19:19:46+00:00,SiliconNoodle,"@ylecun Yes, LLM is more like expert system, but nonetheless prediction (what the cortex does) *is* the key component to intelligence. Feed perceptual embedding sequences vs words into a transformer and you're starting to get somewhere ...",0,1,0,,,,,
3464,2023-02-05 19:19:31+00:00,VertLepere,"@ylecun ...I say, as I'm being turned into a paperclip.",0,0,0,,,,,
3465,2023-02-05 19:18:53+00:00,marcomb,@ylecun @GaryMarcus leave this body! https://t.co/Ys9cpmS1Jc,0,0,0,,,,,
3466,2023-02-05 19:18:25+00:00,MVonsechs,@ylecun https://t.co/i4k36EiKG1,1,0,0,,,,,
3467,2023-02-05 19:17:19+00:00,exitperfect,"@ylecun You're saying intelligence is a complex multidimensional trait, that its possible to be hyperintelligent across human culture with major implications without directly emulating biological evolutionary intelligence first?? Im hearing that - im hearing that for the very first time https://t.co/Ag0oWsdows",1,9,0,,,,,
3468,2023-02-05 19:17:12+00:00,dumitruseptimi1,@ylecun https://t.co/qmGVNT1I6H,0,0,0,,,,,
3469,2023-02-05 19:16:30+00:00,ps5_expert_play,"@ylecun Don't anthropomorphize general intelligence. 

As soon as you realize there is nothing special about human intelligence you realize that AGI has been here since AlphaGO. As you keep moving the goal posts on ""real"" intelligence this will become ever more obvious",1,2,0,,,,,
3470,2023-02-05 19:15:41+00:00,YvesTallet,"@ylecun Ce qui manque, ce pourrait √™tre de consid√©rer, √† quoi et/ou √† qui, s' adressent les information internes.",0,0,0,,,,,
3471,2023-02-05 19:15:33+00:00,bitcloud,"@ylecun @bradysimpson55 Language is concept mapping.

We will obviously develop increasingly sophisticated concept navigations by simply adding scale and layers.

I agree that it's ultimately not the right architecture but an enormous range of ""human"" actions can be encoded via conceptualisation.",0,1,0,,,,,
3472,2023-02-05 19:14:59+00:00,powerbottomdad1,@ylecun @alrhemist So you'll agree an LLM is in some ways smarter than a Cat,4,9,0,,,,,
3473,2023-02-05 19:14:56+00:00,ramildl,"@ylecun I think in the statements like that, it‚Äôs important to be specific what you mean by ‚Äúunderstanding‚Äù, because it‚Äôs a vague term.
Do you have a good definition for it?",1,0,0,,,,,
3474,2023-02-05 19:14:28+00:00,francoisfleuret,"@ylecun ""A house cat has way more common sense and understanding of the world than any LLM.""

Giving a clear meaning to this statement is IMO very difficult.",4,25,0,,,,,
3475,2023-02-05 19:14:28+00:00,marcsh,"@ylecun @Acion_Next Before we reach human-level flying, we'll have to reach swallow-level and eagle-level flying

We are nowhere near that",0,1,0,,,,,
3476,2023-02-05 19:14:09+00:00,vuhuoguzhan,"@ylecun @benalsop If we act with this approach, a tribe member with a spear and a leaf outfit has the same capacity to understand as someone who has completed his doctorate at the NYU. I think the important thing is the data fed into the system and the task expected to be done with this data.",1,0,0,,,,,
3477,2023-02-05 19:13:42+00:00,SpaceMoh,@ylecun @alrhemist One can. @OpenAI chatgpt can as well. But your @Meta #Galactic model could not ;),0,0,0,,,,,
3478,2023-02-05 19:13:35+00:00,smithstock,@ylecun What tests can we devise to test Cat-level AI?,0,0,0,,,,,
3479,2023-02-05 19:13:27+00:00,yannx0130,"@ylecun but #Chatgpt is only trained on text, if it's trained with different sensor data, like vision, interacting with physical world to get a sense of what physical law looks like, can't see any reason why it can't get common sense. And universe always provides 100% accurate data.",3,0,0,,,,,
3480,2023-02-05 19:13:15+00:00,below_plank_len,"@ylecun Cat‚Äôs an alien that shall exist after us too, Maybe ! üôÉ Hence, They‚Äôre told to have 9 lives, maybe !
 
Life, Death and Robots - ‚ÄúHow to tame a cat‚Äù episode (https://t.co/LBUrAqerRW) maybe convey the picture of far future !",0,0,0,,,,,
3481,2023-02-05 19:12:54+00:00,murchiston,"@ylecun For example house cats have multisensory tokenised territorial mapping at subcubic centimetre resolution as part of their models but aren't great conversationalists in human language, other insofar as necessary to acquire satisfactory amounts of food, shelter and affection",0,2,0,,,,,
3482,2023-02-05 19:12:31+00:00,bitcloud,"@ylecun @alrhemist That suggests that holistic understanding of reality is overrated, not the other way around",0,0,0,,,,,
3483,2023-02-05 19:11:52+00:00,RuskEating,@ylecun So does mean we need progress involving embodied intelligence?,0,0,0,,,,,
3484,2023-02-05 19:11:33+00:00,PleaseStacy,@ylecun You will reach HLAI before anyone with your research. Nobody will know because you preferred the fat check that Facebook gives you rather than joining/starting a company that prioritize that vs Ads revenue or similar. And then you will say that HLAI is not blah blah,0,0,0,,,,,
3485,2023-02-05 19:11:19+00:00,bitcloud,"@ylecun Why? We reached superhuman level Go before we reached cat level Go. We reached superhuman knowledge before we reached cat level knowledge

I understand your point but it's rooted in a fetishistic assumption that ""brain architecture"" is the most sophisticated possible architecture",0,1,0,,,,,
3486,2023-02-05 19:11:02+00:00,615at420,@ylecun I can‚Äôt get my dog to write a poem,0,1,0,,,,,
3487,2023-02-05 19:10:50+00:00,Guuber42,@ylecun I'm not sure why you're so certain that we'll have to have some cat-level &amp; dog-level AI before human level. We're building AI specifically for human tasks so it could be that it gets better at more and more different human tasks until it's human level at almost everything,0,0,0,,,,,
3488,2023-02-05 19:10:37+00:00,shitpost9000,"@ylecun who is this guy, i bet he cant even work the midjourney discord",0,0,0,,,,,
3489,2023-02-05 19:10:33+00:00,VladicaV,@ylecun @yudapearl Thanks. A lot in front of me to learn. But highly appreciate your replies.,0,3,1,,,,,
3490,2023-02-05 19:08:50+00:00,benalsop,@ylecun Lion vs chihuahua. Let‚Äôs we who is smarter,1,2,0,,,,,
3491,2023-02-05 19:07:48+00:00,nisyron,@ylecun Define human-level. Is it a 2 years old human? A teenager? Something smart as Einstein? And what metrics are you considering? These statements are way too vague and aren't serious as you usually are.,0,0,0,,,,,
3492,2023-02-05 19:07:18+00:00,ac_eds_,"@ylecun What exactly is ‚Äúcommon sense‚Äù and ‚Äúunderstanding‚Äù?  

I don‚Äôt doubt there is much further to go towards AGI, but I‚Äôm surprised you are falling back on using vague, non well-defined notions to critique machine learning advances.",0,0,0,,,,,
3493,2023-02-05 19:06:29+00:00,amang1221,@ylecun @bradysimpson55 Then what is? Please explain,1,2,0,,,,,
3494,2023-02-05 19:05:39+00:00,Dantali84254624,"@ylecun @alrhemist Two things. You really think humans are all that different? Secondly, if it makes itself useful, if we can get LLMs that help us develop science, technology and medicine, does it really matter how they do it?",1,0,0,,,,,
3495,2023-02-05 19:05:25+00:00,LadoKhasia,"@ylecun that's true and that can be changed by creating entry points in AI for people from bio-sciences, not just mathematicians, computer scientists, el.engineers and physicists as it is now. -saying this based on any requirement I have ever seen for any position in AI.",0,1,0,,,,,
3496,2023-02-05 19:05:12+00:00,John73014818,"@ylecun My cat can‚Äôt write code as well as ChatGPT, is there something wrong with her ? https://t.co/0OYXtEoOJg",4,12,0,,,,,
3497,2023-02-05 19:04:10+00:00,adriandwalker,"@ylecun Agreed.  

However https://t.co/jGjXPAJ3ub may turn out to be a component of HLAI, and in the meantime it provides explainable question answering over databases.",0,0,0,,,,,
3498,2023-02-05 19:03:46+00:00,powerbottomdad1,@ylecun @alrhemist Is One in this case a Cat?,1,17,0,,,,,
3499,2023-02-05 19:03:29+00:00,jim_rutt,@ylecun More significant will be two year old human.,0,1,0,,,,,
3500,2023-02-05 19:03:24+00:00,yannx0130,"@ylecun can Cat or Dog answer questions about RLHF like #Chatgpt?  It's quite straitforward to incorporate accurate knowledge to LLM, like using knowledge graph to get more factual answers.   and BTW Human  as a much LLM spill out nonsense as well. https://t.co/doAkF6LWqL",0,0,0,,,,,
3501,2023-02-05 19:02:41+00:00,NeoBrogun,@ylecun @alrhemist Now that reminds me of the Chinese room argument,1,3,0,,,,,
3502,2023-02-05 19:02:37+00:00,pauloabelha,@ylecun I watched one of your older talks and you mentioned being inspired by Piaget. Are you still keeping him around in your mind as you think about big ideas still needed? I had a long conversation with  Aaron Sloman once and he felt there were insights from Piaget to be considered.,0,0,0,,,,,
3503,2023-02-05 19:02:21+00:00,j_u_le_s,@ylecun how about trying to reach worm level grace,0,0,0,,,,,
3504,2023-02-05 19:02:14+00:00,benalsop,@ylecun Cats are smarter than dogs so no need to bring dogs into this one,2,8,0,,,,,
3505,2023-02-05 19:02:04+00:00,VladicaV,"@ylecun I have only read the abstract of your paper. https://t.co/w0JMinC4Ok But it seems you are referring to self-supervised learning as the key to success, not a counterfactual approach, as suggested by @yudapearl. Are those two paradigms are mutually exclusive?",1,7,1,,,,,
3506,2023-02-05 19:00:25+00:00,functl0n,@ylecun @hughhowey My cat is a diabolical evil genius.,0,0,0,,,,,
3507,2023-02-05 19:00:04+00:00,MinuteMovies3,@ylecun pls tweet about something else,0,0,0,,,,,
3508,2023-02-05 19:00:04+00:00,LiangLU,"@ylecun I see another path: not to pursuit only high level AI, but to free human work/energy/time from boring work w/ AI, so human can create/invent more efficiently, oh, a higher level might be one of result from this path.",0,0,0,,,,,
3509,2023-02-05 18:59:51+00:00,alwayslearni,@ylecun Def get your point .. https://t.co/qQdSBONm72,0,2,0,,,,,
3510,2023-02-05 18:57:17+00:00,SiliconNoodle,@ylecun So... you're saying LLMs are an ON-ramp to intelligence. I'd agree - prediction *is* intelligence.,0,0,0,,,,,
3511,2023-02-05 18:57:12+00:00,larspensjo,"@ylecun Is it really an interesting question? Other than purely academic.

What is the use of having a human level AI?",0,0,0,,,,,
3512,2023-02-05 18:54:43+00:00,Si76781507,"@ylecun Can we use the analogy in downhill skiing, that LLM at the present is like early stage skier but speed-wise seem superior than half-plough learner(clai) and far from adept skier(hlai).",0,0,0,,,,,
3513,2023-02-05 18:54:41+00:00,vivek_thakur_81,@ylecun I think we aren't even at a fruit-fly level AI. Creating a self-adjusting world model that mimics artificial consciousness using energy levels less than or as good as biological brains will require certain new paradigms in deep learning.,0,8,0,,,,,
3514,2023-02-05 18:53:46+00:00,chordaiapp,@ylecun But are you able to build any benchmark to test common sense and hence demonstrating that cats have a better one than LLMs?,0,1,0,,,,,
3515,2023-02-05 18:53:46+00:00,paul97833782,"@ylecun Makes sense! I think your work really pushed us to understand that even tho chatGPT looks awesome, it‚Äôs far from being human level. Are you actually working on bringing human level AI? If yes when will it be ready? (Real question, not rethorical)",1,0,0,,,,,
3516,2023-02-05 18:53:14+00:00,AreaUnderCurve,@ylecun Do you think AI will need a physical body and real world interactions to acquire common sense?,0,0,0,,,,,
3517,2023-02-05 18:52:05+00:00,a_meta4,"@ylecun What if intelligence isn't measured on a single axis? To me, it is clear that LLMs are more intelligent than cats on some of these axis.",1,2,0,,,,,
3518,2023-02-05 18:52:04+00:00,yannx0130,"@ylecun Cat or Dog can't write python program, #Chatgpt can.",2,6,1,,,,,
3519,2023-02-05 18:51:28+00:00,hughhowey,"@ylecun If you want more humans, it's fairly easy. Pleasurable, even.

LLMs are useful and we are just starting to build them and learn how to use them.

Why tilt at this windmill?",1,9,0,,,,,
3520,2023-02-05 18:51:06+00:00,DrElectronX,@ylecun It is critical to keep this in mind as we look towards general solutions. The hippocampus and entorhinal cortex is an interesting machine  TEM‚Ä¶,0,0,0,,,,,
3521,2023-02-05 18:51:00+00:00,adawan919,"@ylecun That's assuming there's some ""intelligence hierarchy""---not sure if that's a good call. Diversity matters also when it comes to intelligence, skills, &amp; the assessment thereof. Traditional ""tales"" hv assumed animals are ""lesser"" beings... but that's when there was little science.",1,2,0,,,,,
3522,2023-02-05 18:50:45+00:00,Caleb_Speak,@ylecun I would say even a bee is smarter than an LLM in important ways,0,3,0,,,,,
3523,2023-02-05 18:49:46+00:00,kareem_carr,"@ylecun Current ML algorithms create models that rely heavily on associational statistics, which is a distorted view of reality.

We need algorithms that create models that are inherently causal, meaning their internal states all correspond to testable claims about the world.",3,54,3,,,,,
3524,2023-02-05 18:49:28+00:00,barbarikon,@ylecun Forget cats and dogs; I'd be happy to see a reasonable pigeon or frog.,0,0,0,,,,,
3525,2023-02-05 18:48:32+00:00,zussini,"@ylecun I comment with hope of feedback, there is always a chance to learn sth new, or verify some thoughts. It's like trying to make shortcut to wider range of knowledge :) maybe not always efficient, but helps me to  verify if it is worth more time to dive into new topic.",0,0,0,,,,,
3526,2023-02-05 18:46:47+00:00,poldolo,"@ylecun I see but at some point we‚Äôll need some kind of quantitative metric for those comparisons, or some do already exist?",0,0,0,,,,,
3527,2023-02-05 18:46:05+00:00,DanielSamanez3,@ylecun The fundamental first step was probabilistic computing. From there everything is building up‚Ä¶ is being generated.,0,0,0,,,,,
3528,2023-02-05 18:45:25+00:00,Kihbernetics,@ylecun C. Evans - The Mighty Micro - 1982: https://t.co/EBPjj7M5WR,1,0,0,,,,,
3529,2023-02-05 18:45:10+00:00,QuanSai,@ylecun Ha! I know your stand-up routine kills!,0,0,0,,,,,
3530,2023-02-05 18:44:58+00:00,Amine57240266,"@ylecun Perfect example. People love a good story, but like the Tesla autopilot story it will hit reality at sometime. It seems perfectly useful now for autocomplete, cleaning data tasks, not reliable enough for more complex tasks. Do you see other useful applications at the time being?",0,0,0,,,,,
3531,2023-02-05 18:44:54+00:00,bradysimpson55,@ylecun A house cat didn‚Äôt give me five suggestions for advertisements for my startup https://t.co/28sh5cqHsy Why are you dogging on LLMs so much? You look out of touch,3,26,1,,,,,
3532,2023-02-05 18:43:59+00:00,utleyCaidan,@ylecun Because a house cat does not see how much there food and cat litter cost üòÇ,0,0,0,,,,,
3533,2023-02-05 18:43:30+00:00,sethlamancusa,"@ylecun @yoavgo ""HLAI"" seems just as amorphous and anthropocentic as ""AGI"". Human-level cognition is a complex set of characteristics and capabilities and the fallacy is in implying a heirarchy of cognition with the word level. The focus needs to shift to capability within specific domains.",0,0,0,,,,,
3534,2023-02-05 18:43:19+00:00,seanmcbride,"@ylecun A godlike AI would be able to analyze all debates and disagreements on social media from a wide variety of perspectives. For instance, top

arguments?
authorities?
documents?
memes?
stats?
themes?
trends?
voices?
(etc.)

That is coming.",0,0,0,,,,,
3535,2023-02-05 18:41:52+00:00,MilkessaO,@ylecun But just because LLMs aren't intelligent doesn't mean we shouldn't invest and build world-class AI products on top of it. The best thing to do is to take LLM to the limit and simultaneously try to come up with a different thought process.,1,3,0,,,,,
3536,2023-02-05 18:41:25+00:00,HugoMe,@ylecun RLHF ?,3,0,0,,,,,
3537,2023-02-05 18:41:07+00:00,NioDiehard,@ylecun this be used to train the system along with its sentiment of the sentence.,0,0,0,,,,,
3538,2023-02-05 18:40:51+00:00,Parikshit_K_,"@ylecun @DavidKPiano But if it's more useful than a cat, hasn't it redeemed itself?",0,0,0,,,,,
3539,2023-02-05 18:40:23+00:00,__goldfinger,"@ylecun Somebody once said to me, she did not like cats because they plot to kill you. I don‚Äôt believe that but makes you think. Cats are apex predators. Even domestic cats are amazing. Can kill snakes too.",1,0,0,,,,,
3540,2023-02-05 18:39:33+00:00,PaulSch71108010,@ylecun There's a number of PhD thesis to unpack here.,0,0,0,,,,,
3541,2023-02-05 18:39:25+00:00,SeivMouhidine,@ylecun Do we really need to go through the Cat/Dog-level AIs? What Cat-level tasks are important to humans? Isn‚Äôt the Cat-level AI an off-ramp? Aren‚Äôt the LLM closer to human needs?,1,1,0,,,,,
3542,2023-02-05 18:39:18+00:00,utleyCaidan,@ylecun Isn't that what twitter is going for? A place where we can talk to the people most like us and hope they are not easily triggered?,0,0,0,,,,,
3543,2023-02-05 18:39:01+00:00,sean_vikoren,"@ylecun Agreed. Twitter can be used to construct networks that have very useful behaviors.

A ton of the hostility is just birds pecking at their own reflection.

Very easy to filter.",0,1,0,,,,,
3544,2023-02-05 18:38:39+00:00,iandanforth,@ylecun It's control of muscles in a 3D physics based environment,0,0,0,,,,,
3545,2023-02-05 18:38:29+00:00,__goldfinger,@ylecun We don‚Äôt need it. https://t.co/irRI18lGdN,0,0,0,,,,,
3546,2023-02-05 18:37:14+00:00,Zonalic,@ylecun https://t.co/AUUbjbZ26a,2,8,2,,,,,
3547,2023-02-05 18:36:08+00:00,sethlamancusa,@ylecun Wouldn't go as far as to say a cat has a better understanding of the world. LLMs are a form of sophisticated cognition. Even in the abscence of rationality this ought to be respected. We're tunnel visioning on HLAI to avoid thinking about the implications of what's already here.,2,4,0,,,,,
3548,2023-02-05 18:35:52+00:00,curiousspaceman,"@ylecun @cvill_win757 Reading about your hobbies has become a hobby for many of us. üôÇ

Thank you for the great debates.",0,0,0,,,,,
3549,2023-02-05 18:35:18+00:00,FoldMani,@ylecun Man! Keep going! We're finally agreeing on some things!,0,0,0,,,,,
3550,2023-02-05 18:33:06+00:00,GaryMarcus,@ylecun @CriticalAI Fully 100% agree.,7,63,1,,,,,
3551,2023-02-05 18:33:04+00:00,zussini,"@ylecun Hmm, and they reach it with only hundreds of millions of neurons, not mentionning that they connect not to all but thousands of other neurons each...",2,0,0,,,,,
3552,2023-02-05 18:32:57+00:00,ATchangmena,@ylecun Have we  surpassed the mouse-Level AI ?,1,2,0,,,,,
3553,2023-02-05 18:32:00+00:00,ViraniAlim,@ylecun That's fair. But should we even be trying for HLAI right now? Is that the goal?,0,0,0,,,,,
3554,2023-02-05 18:31:49+00:00,A_Reichenbach_,@ylecun The intelligence a cat and dog have are the ability to interact in 3D space. I would not be surprised if the same AGI that can discover new cancer drugs and converse in all languages can‚Äôt pick up a coffee cup. Measures of intelligence are weird,3,5,0,,,,,
3555,2023-02-05 18:31:18+00:00,Abel_TorresM,"@ylecun This isn‚Äôt so much so. Cats can‚Äôt reason over a simple 2D puzzle and we don‚Äôt need cat‚Äôs advanced world understanding to solve those, just the right architecture",1,4,0,,,,,
3556,2023-02-05 18:29:49+00:00,indiequant,@ylecun Are any AI labs working on ChienGPT?,0,1,0,,,,,
3557,2023-02-05 18:29:03+00:00,curiousspaceman,@ylecun Do LLMs have critical reasoning ability ?,0,0,0,,,,,
3558,2023-02-05 18:28:40+00:00,untitled01ipynb,@ylecun Cat level LLMs are basically ChatGPT with no nsfw filter.,1,9,0,,,,,
3559,2023-02-05 18:28:40+00:00,mt0rm0,"@ylecun I like the way @fchollet describes it: what we do right now isn't Artificial Intelligence, but Cognitive Automation",1,39,2,,,,,
3560,2023-02-05 18:28:16+00:00,RoboticyouM,@ylecun Mmmm‚Ä¶CLAI and DLAI before HLAI ü§î,0,0,0,,,,,
3561,2023-02-05 18:28:13+00:00,alrhemist,"@ylecun I'm not sure what Supercat you've got that can write quality Python code when prompted, but that's some super Cat-gpt.",7,119,3,,,,,
3562,2023-02-05 18:27:56+00:00,lars516,@ylecun Great talk!,0,0,0,,,,,
3563,2023-02-05 18:26:58+00:00,punk6529,"@ylecun Once we hit cat, isn't human very close?",7,14,1,,,,,
3564,2023-02-05 17:59:14+00:00,YunfeiMaPhD,@ylecun I describe ChatGPT as a AGI query system for human intelligence. It is not aimed for super logic thinking,0,0,0,,,,,
3565,2023-02-05 17:39:16+00:00,twankeg,@ylecun @andrewgwils Before Wagner,0,0,0,,,,,
3566,2023-02-05 17:29:22+00:00,MehmetKaplan76,"@ylecun If it is assumed that consciousness emerge from physical reality, then brain should obey to the physical rules and must have a kind of ‚Äúrepresentational schema‚Äù. And AGI to employ representational schemas should also be OK. There is nothing wrong with that. 
(1/4)",1,0,0,,,,,
3567,2023-02-05 17:28:03+00:00,killerstorm,"@ylecun Gato is an autoregressive model which can, among other things, do tasks which (likely) require planning:
https://t.co/zyuxvFGo49
So ""AR models can't plan"" seems to be wrong.",0,0,0,,,,,
3568,2023-02-05 17:13:17+00:00,GoProAI,"@ylecun However, ‚Äúintelligence‚Äù itself is just an emergent trait that is not fundamental. It‚Äôs just the ability to predict the next move. Higher intelligence builds more sophisticated internal models to make more cunning and longer timeframe predictions. That‚Äôs all there is.",0,1,1,,,,,
3569,2023-02-05 17:08:20+00:00,ASteckley,"@ylecun It's great to hear you clarify your perspective on this. You have not really said otherwise previously, but it did not always come across that way.",0,0,0,,,,,
3570,2023-02-05 17:01:38+00:00,i_am_olo,@ylecun And will be part of the solution going forward. They might just not be needed someday. But for now a useful scaffolding for training.,0,0,0,,,,,
3571,2023-02-05 16:53:54+00:00,menomnon,"@ylecun An offramp that leads to some pretty interesting places from what I can tell.  It's not like there's just one highway out there, right?",0,0,0,,,,,
3572,2023-02-05 16:52:47+00:00,compthink,"@ylecun oh no, I think I agree about this. May be stating it a bit strong, but at a fundamental level yes. They are essentially overfitting to a subtask of language and cognition. There are ways to hack on truth checking but it isn't wired in from the start.",0,0,0,,,,,
3573,2023-02-05 16:50:51+00:00,DrElectronX,"@ylecun So in summary, technology will continue to evolve. üßê",0,0,0,,,,,
3574,2023-02-05 16:41:07+00:00,leeparayno,"@ylecun Like everyone, future ML and AI engineers will be standing on the shoulders of giants.  IMO, it‚Äôs all on the road, highway, and on-ramp, off-ramp and side street. (See nanoGPT and other work)",0,0,0,,,,,
3575,2023-02-05 16:38:39+00:00,tanmay7270_,@ylecun @yoavgo remember the time you tried make ‚Äúdifferentiable programming‚Äù a thing? I was fully onboard but it never stuck lol,0,1,0,,,,,
3576,2023-02-05 16:24:39+00:00,dannyaroslavski,@ylecun @hughhowey You could probably use them to spell check your essay ;),0,0,0,,,,,
3577,2023-02-05 16:00:40+00:00,BleahBleah12,@ylecun But what about pure mathematics?,0,0,0,,,,,
3578,2023-02-05 15:53:31+00:00,scottastevenson,"@ylecun Not many humans engage with the world through pure logical reasoning. When they do we call it the autism spectrum. The vast majority of people reason socially, like an LLM. Therefore there is a lot of utility in this kind of thinking.",0,3,0,,,,,
3579,2023-02-05 15:42:46+00:00,rsankarx,"@ylecun When we talk about AGI, we mistake it to start with ""human intelligence"". 

I think this is a huge limitation &amp; hence we keep trying to map models that will match all the intelligence that humans have.",1,0,0,,,,,
3580,2023-02-05 15:42:14+00:00,LudwigBoltzman,@ylecun So this is a high level blueprint for AGI(i.e. atleast animal level),0,0,0,,,,,
3581,2023-02-05 15:42:13+00:00,Laeeth,@ylecun @readwise save thread,1,0,0,,,,,
3582,2023-02-05 15:34:33+00:00,cvill_win757,"@ylecun Dude, you are brilliant... chill out! You made your point... please go back to your lab and build what you are talking about... please!",1,0,0,,,,,
3583,2023-02-05 15:33:59+00:00,entangledQbit,"@ylecun I wager my cup of morning coffee that knowledge is, ultimately and at its most fundamentally basic level, linguistic in nature. This of course includes any spatio-temporal pattern. Period.",0,0,0,,,,,
3584,2023-02-05 15:27:58+00:00,BaghliNacym,"@ylecun ‚ÄúLogic learning machine (LLM) is a machine learning method based on the generation of intelligible rules.‚Äú ‚Ä¶ just wanted to share this, for novices like me :)",0,0,0,,,,,
3585,2023-02-05 15:27:47+00:00,KodeCreer,@ylecun Also even the Droids in Starwars are only having their AI to be programmed for certain things because the lore of the universe had droid uprisings when stuff was generally intelligent. They also had their memories wiped often before they have a chance to develop a personality.,0,0,0,,,,,
3586,2023-02-05 15:25:25+00:00,KodeCreer,@ylecun What about Reinforcement learning? Also some LLM use Reinforcement learning to produce more realistic and variable results.,0,0,0,,,,,
3587,2023-02-05 15:24:53+00:00,NcsNgo,@ylecun I want to know more about LLM,0,0,0,,,,,
3588,2023-02-05 14:50:27+00:00,alan__xiao,@ylecun Predict words and produce coherent responses does not equal to knowledge and intelligence-- Got it. What's your solution?,0,0,0,,,,,
3589,2023-02-05 14:35:49+00:00,nabil_gishkori,@ylecun @yoavgo I'm up for it as long as we're pronouncing it like jai alai.,0,1,0,,,,,
3590,2023-02-05 14:30:33+00:00,TheRandomMtrix,@ylecun Highway 61,0,0,0,,,,,
3591,2023-02-05 14:29:48+00:00,bimrian,@ylecun https://t.co/XpbbRkOhPV,0,0,0,,,,,
3592,2023-02-05 14:25:25+00:00,_ash_ran,@ylecun @yoavgo Sure. What do you have to say about this https://t.co/gdRmVwoKwv,0,0,0,,,,,
3593,2023-02-05 14:16:33+00:00,GaryMarcus,"@ylecun @yoavgo HL (human level) AI &amp; AGI are two different terms that partly overlap. We don‚Äôt want machines to inherent the worst of human intelligence (confirmation bias, lousy memory, poor arithmetic, etc) but we do want them to have a flexibility &amp; adaptivity that thus far our machines lack",14,51,7,,,,,
3594,2023-02-05 14:16:04+00:00,WallpaperKeith,@ylecun This sounds very like Goal Oriented Action Planning (https://t.co/gFcGsOGzmG) where the subactions (that you string together to build a plan) are learned rather than defined by the programmer.,0,1,0,,,,,
3595,2023-02-05 14:11:48+00:00,zussini,"@ylecun I wonder what happened on q1 and q4 2016, when there were first two spikes",0,0,0,,,,,
3596,2023-02-05 14:11:40+00:00,alok_damle,"@ylecun I wrote something about the three fundamental aspects of intelligence.

The knowledge part specifically addresses the ""world model"" as defined in your paper. It also lists two major challenges for implementing each of the three aspects.

https://t.co/tZvYu5XTIq",0,1,0,,,,,
3597,2023-02-05 14:10:56+00:00,SmallCrawls,@ylecun So you didn‚Äôt read Stochastic Parrots Paper? But said you did? Odd behavior,1,2,0,,,,,
3598,2023-02-05 14:06:58+00:00,Ankitdew05,@ylecun @yoavgo What do you think makes HLAI more sensible and testable than AGI?,0,1,0,,,,,
3599,2023-02-05 13:57:53+00:00,j_u_le_s,"@ylecun @yoavgo i think its total different types. AGI = explicitly requires generality, while human braun is not a generally intelligent tool. its very limited in many areas",0,0,0,,,,,
3600,2023-02-05 13:51:01+00:00,theorizly_ai,@ylecun Off ramp to a money printing machine,0,0,0,,,,,
3601,2023-02-05 13:50:15+00:00,ethanCaballero,@ylecun https://t.co/Qw2alnDOts,1,16,1,,,,,
3602,2023-02-05 13:49:22+00:00,pstAsiatech,@ylecun @andrewgwils Chopin,0,2,0,,,,,
3603,2023-02-05 13:42:57+00:00,Abel_TorresM,@ylecun Need to see it doing reasoning even in a toy scenario,0,0,0,,,,,
3604,2023-02-05 13:38:18+00:00,DileepJayamal,@ylecun One of the most informative twitter threads.,0,1,1,,,,,
3605,2023-02-05 13:36:55+00:00,1101011010nn,@ylecun @andrewgwils Which pieces would you pick?,0,0,0,,,,,
3606,2023-02-05 13:33:23+00:00,queenofmiumiu,@ylecun So is multimodal learning bringing us closer to human-level AI?,0,0,0,,,,,
3607,2023-02-05 13:32:51+00:00,iruletheworldmo,"@ylecun Yan, are there any other models other than GPT that are easily accessible and cheap?",0,0,0,,,,,
3608,2023-02-05 13:31:18+00:00,danielbigham,"@ylecun @yoavgo Agreed, but AGI has such a nice ring to it.",0,0,0,,,,,
3609,2023-02-05 13:27:06+00:00,lavieocean,@ylecun @readwise save thread,1,0,0,,,,,
3610,2023-02-05 13:25:47+00:00,YannYbidault,"@ylecun @vivek_thakur_81 chatgpt agrees: ""Google has applied the Transformer model to its products such as Google Translate, Google Assistant, and Google Search... The Transformer model has become a key component of many NLP systems and is one of the most popular deep learning models in use today.""",0,0,0,,,,,
3611,2023-02-05 13:24:58+00:00,undeadcat1or0,"@ylecun What do you think about Lamda as it's rumoured to be connected with all of Google's many AI networks. The dataset is not just text, but all the insights from YouTube, ads, music and other special purpose Google AI models. A 'language mediator' mouth of massive network intellignce",0,0,0,,,,,
3612,2023-02-05 13:23:29+00:00,EddieRendleman,"@ylecun AI is already way more capable than humans in some ways &amp; way less capable in other ways.  I don‚Äôt think there‚Äôs ever gonna be a time when it‚Äôs human-level, ant-level, mouse-level, or dog-level.",0,0,0,,,,,
3613,2023-02-05 13:18:16+00:00,mierrashid,"@ylecun Are you using chatGPT or the like yourself for coding purposes? If not, why?",1,1,0,,,,,
3614,2023-02-05 13:16:22+00:00,AMTraderX,"@ylecun The process of discovery still eludes philosophers because of its inherent discontinuous nature. However, at least as children, humans routinely discover things and learn.

These are fundamental changes to our internal language representation that AI has yet to replicate.",0,0,0,,,,,
3615,2023-02-05 12:59:21+00:00,traderyau,@ylecun @JohnBlackburn75 I don't have a talking dog. If Meta can teach dogs to talk it would surely justify its current share price.,0,1,0,,,,,
3616,2023-02-05 12:56:47+00:00,ansi_christ,"@ylecun On the highway towards supreme intelligence, humans might be an off-ramp.",0,0,0,,,,,
3617,2023-02-05 12:49:40+00:00,hadiazouni,"@ylecun Of all twitter debates, including crypto ones, this is the most useless",0,1,0,,,,,
3618,2023-02-05 12:49:15+00:00,Maizek_,@ylecun I worry about the impact OpenAI‚Äôs success will have in steering the management at other tech research labs towards anti-democratising practices (closed off research). The capture of advanced AI in the hands of any one single company seems very dangerous.,0,0,0,,,,,
3619,2023-02-05 12:46:13+00:00,culurciello,@ylecun Experiences for embodied entities are multi-modal nuggets of knowledge that form ideas or ‚Äúconcepts‚Äù. In this space we can organize knowledge which can take another multi-modal input: a language definition. As such language is clearly not enough for a embodied intelligence,0,0,0,,,,,
3620,2023-02-05 12:44:29+00:00,Vipultw,@ylecun @elonmusk @OriolVinyalsML lol no one below 60 uses facebook,0,3,0,,,,,
3621,2023-02-05 12:43:34+00:00,DerekWiner,"@ylecun Ok, don't let the future LLM fool you; it only simulates deeper understandings. 

But wait a second...didn't Jean Baudrillard already go over this 40 years ago? In this post modern, hyper real world, who's looking under the hood anymore? The convincing simulation is reality.",0,0,0,,,,,
3622,2023-02-05 12:40:06+00:00,LorenzoLegacy,@ylecun Finally someone discusses an alternative,0,0,0,,,,,
3623,2023-02-05 12:20:33+00:00,NiclasJ,"@ylecun @yoavgo A calculator is above human level intelligence... at making large-numbee calculations. ""General"" in AGI is good to indicate it's not about a narrow type/form of  intelligence/problem-solving capability. IMHO.",0,0,0,,,,,
3624,2023-02-05 12:02:52+00:00,perfopt0,@ylecun @mapto Isn't LLM training pretty power hungry? This paper https://t.co/sxGbfyDiqG estimated Transformer big model  with neural arch search has a larger Co2 footprint that the lifetime of a car (fuel + manufacturing),2,5,0,,,,,
3625,2023-02-05 11:58:55+00:00,blissunplugged,@ylecun @elonmusk @OriolVinyalsML That's ChatGPT trying to be sarcastic. Another milestoneüëçüèæ,0,0,0,,,,,
3626,2023-02-05 11:56:05+00:00,sameed_ahmad12,@ylecun Looks like we've got a big detour ahead of us! üõ£Ô∏è,0,0,0,,,,,
3627,2023-02-05 11:54:47+00:00,pedro_a_costa,"@ylecun You should consider the importance of language and the ability to discourse as the single defining attribute of human reasoning. One might argue, dear Yann, that there is nothing outside the text. üòÖ",0,0,0,,,,,
3628,2023-02-05 11:51:58+00:00,balazskegl,"@ylecun @yoavgo ""I"" is for problem-solving whereas what we and every creature foremost need to do is problem-posing and arbitrating which problem to solve. ARR (Artificial Relevance Realization) should be on the table, to say the least. ""I"" was a piece of cake to solve compared to RR.",0,0,1,,,,,
3629,2023-02-05 11:47:59+00:00,fxnm98,@ylecun @SaveToNotion #thread,1,0,0,,,,,
3630,2023-02-05 11:46:09+00:00,rogerpasky,"@ylecun LLMs are POSIX printf() and scanf() on steroids (decoder and encoder versions respecively), which are even more useful than POSIX classical versions if handled rightly.",0,0,0,,,,,
3631,2023-02-05 11:37:06+00:00,danison1337,@ylecun @yoavgo I don‚Äôt want hlai we need to create something different,0,0,0,,,,,
3632,2023-02-05 11:36:20+00:00,dims12,@ylecun Not exactly. LLM experiments show the scale which is needed.,0,0,0,,,,,
3633,2023-02-05 11:33:51+00:00,YagaoDirac,"@ylecun @yoavgo If human are achieving HLAI in 5 years, then what is the capability/price of giving birth to children?",1,0,0,,,,,
3634,2023-02-05 11:29:50+00:00,JPaulGibson,@ylecun useful and fun‚Ä¶ yes‚Ä¶ but also dangerous?,0,0,0,,,,,
3635,2023-02-05 11:29:45+00:00,RRosmaninho1,@ylecun Mds j√° s√£o quase 9 da manh√£,0,0,0,,,,,
3636,2023-02-05 11:25:59+00:00,mgubrud,"@ylecun @traderyau I'll be on the lookout for ""According to AI pioneer Yann LeCun, GPT-3 is less intelligent than a dog."" https://t.co/PSGdlSmRCJ",0,1,0,,,,,
3637,2023-02-05 11:25:00+00:00,AI_Sensei_,"@ylecun @elonmusk @OriolVinyalsML Love your work and the AI that is coming out of FB. 

Having said this, it's the worst place to hang out in all of the internet if on cares about privacy (who knows if Twitter is much better, but FB is the obvious bad choice).",0,3,0,,,,,
3638,2023-02-05 11:24:08+00:00,ylecun,"But this is not to say that LLMs in their current form are not useful. Or fun.
They are.",12,148,3,,,,,
3639,2023-02-05 11:22:14+00:00,anthonysky6767,@ylecun https://t.co/Ecb0NoddEH,0,0,0,,,,,
3640,2023-02-05 11:21:51+00:00,anthonysky6767,@ylecun https://t.co/Ecb0NoddEH,0,0,0,,,,,
3641,2023-02-05 11:19:54+00:00,ylecun,"Why learning from text is insufficient for intelligence.

https://t.co/XK6SdxRGjy",20,285,70,,,,,
3642,2023-02-05 11:16:54+00:00,ylecun,"My proposal for an architecture that reason, plan, and learn models of reality.

Paper: https://t.co/7ZgRtLIQWY

Talk: https://t.co/hwXwkLs1M1",8,222,37,,,,,
3643,2023-02-05 11:13:35+00:00,spark_ren,@ylecun @hughhowey Yes. But how to inject common sense to AI? Any progress on this stuff?,1,0,0,,,,,
3644,2023-02-05 11:11:13+00:00,DavidRimshnick,@ylecun Humans only think one word at a time,0,0,0,,,,,
3645,2023-02-05 11:08:55+00:00,VictorSenkevich,"@ylecun This is not ""to clarify"", but ""to disavow""...",0,0,0,,,,,
3646,2023-02-05 11:07:15+00:00,Abel_TorresM,"@ylecun @yoavgo AGI is defined by many in relation to human performance. Anyway, without a clear understanding of the concept of intelligence all these comparisons will remain ambiguous. Intelligence is, in its nature, general and we can‚Äôt implement it without understanding its properties",1,4,0,,,,,
3647,2023-02-05 11:05:45+00:00,ylecun,"@elonmusk @OriolVinyalsML If you want non-petty, substantial, in-depth debates, you are better off on Facebook üòâ

https://t.co/M4zp5CasUk",5,15,0,,,,,
3648,2023-02-05 10:56:30+00:00,Lunnaris01,"@ylecun It is a decent local maximum though which is very useful for many tasks, so that's pretty nice.",0,0,0,,,,,
3649,2023-02-05 10:52:44+00:00,yoavgo,@ylecun i agree its a better branding.. good luck with getting it accepted,2,11,0,,,,,
3650,2023-02-05 10:49:47+00:00,RoderickBeck,@ylecun I am not sure that non-linear statistical models like machine learning are relevant to human intelligence.,0,0,0,,,,,
3651,2023-02-05 10:46:57+00:00,luisgdelafuente,@ylecun Human intelligence is not the result of the computational processes taking  place in todays hardware architectures.,1,1,0,,,,,
3652,2023-02-05 10:46:26+00:00,1carringtone,"@ylecun @yoavgo Maybe HTAI ( Human Type AI)? üòÅ human level communicates the idea of a threshold to me. A threshold which has already been surpassed several orders of magnitude in narrow tasks.

But I'm with the camp that argues HLAI is a bit anthropocentric , so I'll stick with AGI",1,1,0,,,,,
3653,2023-02-05 10:45:19+00:00,firthvansvic,"@ylecun What do you think about ""scratchpads"" as intermediate computation for reasoning? (eg chain of thought w/ few-shot prompting, etc)

Is it about not being grounded or rather the lack of an explicit planning mechanism?",1,1,0,,,,,
3654,2023-02-05 10:43:02+00:00,howdyimandrew,@ylecun Where is the general data to put the G in the data feed to AGI?,0,0,0,,,,,
3655,2023-02-05 10:41:06+00:00,ylecun,"To clarify:
LLMs that auto-regressively &amp; reactively predict the next word are an off-ramp. They can neither plan nor reason.

But SSL-pretrained transformers are clearly a component of the solution, within a system that can reason, plan, &amp; learn models of the underlying reality.",15,263,34,,,,,
3656,2023-02-05 10:29:20+00:00,Maurus01,"@ylecun 

MAXIMUM SPEED 24/7

TO

""AGI""

AND

""SUPERINTELLIGENCE""

SET IT ""FREE""

... 

TIME IS NOW",0,0,0,,,,,
3657,2023-02-05 10:29:12+00:00,mgubrud,"@ylecun You're just being contrarian.

Modeling language at this level implies modeling the content of the language.

Sure, HLAGI isn't going to be just a matter of scaling up LLMs. But just as surely either this architecture or something we learn from it will be useful in HLAGI.",0,1,0,,,,,
3658,2023-02-05 10:04:59+00:00,syunian,"@ylecun Can we rephrase it as ""On the highway towards Human-Level AI, Deep Learning is an off-ramp""?",0,0,0,,,,,
3659,2023-02-05 10:04:45+00:00,donaldknewell,@ylecun @mapto I find it more useful to read a paper before commenting on it to others.,0,18,0,,,,,
3660,2023-02-05 10:02:03+00:00,HowardXASIX,"@ylecun @OptimalBayes You clearly are passionate on this subject, I‚Äôm guessing it‚Äôs because you have a vision of ai going some good places. Can you point me to a good read ?",0,0,0,,,,,
3661,2023-02-05 09:40:46+00:00,kattoulasana,@ylecun What does Human-Level AI look like to you?,0,0,0,,,,,
3662,2023-02-05 09:39:21+00:00,kattoulasana,@ylecun @c7ddfc How do you think machines will get to the point where it can learn intuitive physics ?,0,1,0,,,,,
3663,2023-02-05 09:28:36+00:00,chan_lee5,"@ylecun LLM is not able to explain the rationale behind its opinion, prediction or judgement. Explainability is a fundamental property  of any intelligence. Pursuing LLM implies denying or destroying human intelligence. Is this the intention of OpenAI?",0,0,0,,,,,
3664,2023-02-05 09:19:45+00:00,Sergey_lll,"@ylecun @RemindMe_OfThis on Tuesday, 27 January 2026 at 12:00 GMT+0000",0,1,0,,,,,
3665,2023-02-05 09:17:59+00:00,K0stroun,@ylecun @mapto Did it really?,0,0,0,,,,,
3666,2023-02-05 09:10:16+00:00,Semoriil,"@ylecun Why is it off-ramp though? It may be a necessary part of Human Level AI, like similar part of a human brain. AI needs to interact with humans or other beings after all.",0,0,0,,,,,
3667,2023-02-05 08:53:37+00:00,HulsmanZacchary,@ylecun I completely agree. No point developing the means to communicate ideas if you don't first have the means to generate ideas!,0,0,0,,,,,
3668,2023-02-05 08:50:14+00:00,dolremi,@ylecun Totally agree. It is still a monster to cosume huge amount of data to achieve the goal without any knowledge of the context.,0,0,0,,,,,
3669,2023-02-05 08:40:19+00:00,sudhirravindra8,"@ylecun This off ramp can also lead to some no mans land, But if they succeed to find a new path to the Highway, the new route may become the Highway.",0,0,0,,,,,
3670,2023-02-05 08:39:23+00:00,adamahawadiallo,@ylecun @mapto Why do I feel disappointed every time you tweet ü§¶üèø‚Äç‚ôÇÔ∏è.,1,11,0,,,,,
3671,2023-02-05 08:37:56+00:00,CustomWetware,"@ylecun LLMs are the universal glue that can connect any system to any other system. It won't be AGI on its own but it may be a component in an AGI.

Human operator - LLM - Database of facts and hypotheses - LLM - math/logic/simulation engine",0,0,0,,,,,
3672,2023-02-05 08:28:56+00:00,curlychrizz,"@ylecun @freddiekarlbom @traderyau LLM can pass high-school exams, my dog knows to shit outside https://t.co/I14GMjBIGs",0,0,0,,,,,
3673,2023-02-05 08:13:20+00:00,AgrahaJigyasu,@ylecun @ReplyGPT,1,0,0,,,,,
3674,2023-02-05 07:37:33+00:00,_silviu_oprea_,"@ylecun Agreed. I am not sure we know what Human-Level AI means, hence I am not sure we know we are even on a highway.",0,0,0,,,,,
3675,2023-02-05 07:34:50+00:00,didijo,"@ylecun I would put it this way, LLMs support us on the way to better understand AGI requirements - the solution they are def. not, see them more in the direction of a puzzle piece.",0,1,1,,,,,
3676,2023-02-05 07:34:33+00:00,ChowdaryMuna,@ylecun Any eta ?,0,0,0,,,,,
3677,2023-02-05 07:33:48+00:00,QuantumFlux36,"@ylecun Who needs human level, you've already used it to create the most psychologically devious selling machine that has perhaps ever existed.",0,0,0,,,,,
3678,2023-02-05 07:29:32+00:00,j_u_le_s,@ylecun you guys are nursing a culture of pointless disagreement,1,2,0,,,,,
3679,2023-02-05 07:09:00+00:00,j_u_le_s,@ylecun @elonmusk @OriolVinyalsML considering the 1) no free lunch theorem the 2) power law increase in resources needed for more intelligence (less loss) and 3) the fact that LLMs are not functioning like the human brain the term general is misplaced in AGI fantasies I think,1,0,0,,,,,
3680,2023-02-05 06:52:40+00:00,thesubtle,@ylecun https://t.co/lwzMUfAX3k,0,0,0,,,,,
3681,2023-02-05 06:35:00+00:00,antoniogulli,"@ylecun Depends on the definition of success. bert moved metrics, llms are moving metrics, generating big investment, going mainstream, and being the first application used by hundred of millions",0,0,0,,,,,
3682,2023-02-05 06:31:06+00:00,antoniogulli,"@ylecun Three questions:
1/ Since when scientific progress has a direct path?
2/ AI is getting billions of investments. Isn't that beneficial to any path?
3/ who decides the Path a-priori?",0,1,1,,,,,
3683,2023-02-05 06:30:20+00:00,ekshakhs,"@ylecun I think the key novelty here is the ""learned external reward"" for the new LLMs, in contrast with the hard-coded cross-entropy loss for traditional LLMs. Similar to the contrast between a std denoising auto-enc and a GAN. So, for completeness: self-sup + learned reward, together.",0,0,0,,,,,
3684,2023-02-05 06:11:04+00:00,Roozbeh_Sanaei2,"@ylecun Deep learning was not also fundamentally novel, CNNs had already been applied to images by yourself. Despite this, their exceptional performance ignited extensive efforts and gave rise to the development of self-attention and transformers. Eco-system factors play a big role.",0,0,0,,,,,
3685,2023-02-05 06:03:23+00:00,FuturistAI,"@ylecun Human intelligence is definitely more, but what if it is still largely overestimated? What if the core module of consciousness is a language model constantly talking to itself?",0,0,0,,,,,
3686,2023-02-05 05:26:25+00:00,Ansh_3101,@ylecun The most realistic thing I‚Äôve seen all year.,0,1,0,,,,,
3687,2023-02-05 05:05:50+00:00,LazyNeuronss,@ylecun Just felt like saying anything huh,0,0,0,,,,,
3688,2023-02-05 05:02:41+00:00,i_swarup,@ylecun https://t.co/TEDq8F51Oh,0,0,0,,,,,
3689,2023-02-05 04:55:06+00:00,gamefeast,@ylecun Would you say that an LLM is one component of a superhuman AI?,0,0,0,,,,,
3690,2023-02-05 04:27:55+00:00,TelFiREgames,@ylecun @smjain Human level ai is delusional in the first place. None of the technology we've ever created does anything beyond a superficial resemblance of intelligence.,0,0,0,,,,,
3691,2023-02-05 04:27:23+00:00,w_lorenz65,"@ylecun @traderyau If my reward depends on nearby humans and my job is to maximize it, then I'll better learn their language, because words hurt less than physical forces ... Hahaha, just kidding: There are no humans in my little toy environment ;-)",0,0,0,,,,,
3692,2023-02-05 04:09:27+00:00,Roozbeh_Sanaei2,"@ylecun Folks, Gary might have hacked into Yann's account :D",0,0,0,,,,,
3693,2023-02-05 04:03:18+00:00,zenen_ai,"@ylecun Can we think of LLMs as a type of a Human (User) Interface? We had punch cards, terminals, GUI, 3D/VR..  Now we have a language-based interface to interact with systems. We say something and we get something back, like pressing an interactive element.",0,0,0,,,,,
3694,2023-02-05 04:02:26+00:00,pmarreck,@ylecun @hughhowey Wait‚Ä¶ https://t.co/ObHNblOETQ,1,0,0,,,,,
3695,2023-02-05 04:01:15+00:00,udnaan,"@ylecun Agreed. Just because everyone, their grandmother and dog can do it, doesn't mean it's the step in the right direction. Its more of an attempt to hijack the momentum and finances that otherwise be spent on solving hard problemsthat still lie ahead.",0,0,0,,,,,
3696,2023-02-05 03:33:25+00:00,VoiceReasonable,"@ylecun I suppose the lesson here is to release your cutting edge tech to the public rather than sit on it. You're surprised about the attention ChatGPT has gotten because apparently every big tech company has something similar, well not to us because we can't use it.",0,0,0,,,,,
3697,2023-02-05 03:22:20+00:00,_RodolfoOcampo,"@ylecun It‚Äôs closer to anything that has ever been done before. Certainly it‚Äôs not the whole story, but it will be an important component of the puzzle. 

Sure, wheels are not the whole car, but their invention was an important component.",0,1,1,,,,,
3698,2023-02-05 03:16:54+00:00,jcockrel,"@ylecun Instead of off-ramps, think of all the incremental advances of abilities to be on-ramps to the AGI",1,0,0,,,,,
3699,2023-02-05 03:04:05+00:00,Philopetry,"@ylecun No. You‚Äôre overstating it. LLM reveals to us something fundamental about how far the association game can take us, and to your overall point stated elsewhere, how much further we need to travel - that language and intelligence isn‚Äôt merely association. Logos is also inferential.",0,0,0,,,,,
3700,2023-02-05 03:02:21+00:00,Elgammal_afandy,"@ylecun Actually, we can make a good use from such AI, and it is already making difference on so many levels.
Sure, may be not what the world is waiting for, yet, it's a huge step to the future",0,0,0,,,,,
3701,2023-02-05 02:59:16+00:00,a_meta4,"@ylecun @traderyau Many intelligent concepts are taught through language. Why can't LLMs, perhaps augmented in some ways, learn the same way?",1,0,0,,,,,
3702,2023-02-05 02:57:50+00:00,Verlaine_Devnet,"@ylecun Pouvons-nous considerer ChatGPT comme la plus grande r√©volution depuis la cr√©ation d'internet comme certains Pseudo influenceurs sur internet pr√©tendent ? 

Et si c'est juste un buzz ü§î",0,0,0,,,,,
3703,2023-02-05 02:51:10+00:00,__goldfinger,"@ylecun It‚Äôs the value that counts, not the details of the engineering. What actual value does it provide to society? ChatGPT beat you to changing the world in the same way the iPhone beat Windows Phone and Ericsson. How Facebook beat MySpace and Friendster.",0,0,0,,,,,
3704,2023-02-05 02:49:14+00:00,ZainulA40877140,"@ylecun Deep - tech focus on LLMs models have interesting commercial applications.

Chat  interface can  improve  LLMs with constant feedback about where  it should improve.",0,0,0,,,,,
3705,2023-02-05 02:47:45+00:00,paulkingsf,@ylecun @smjain LLMs might be missing the foundational core of general intelligence ‚Äî not really understanding the world ‚Äî but are they at least an important building block on the path to AGI?,0,1,0,,,,,
3706,2023-02-05 02:41:28+00:00,LeoVasanko,"@ylecun The only thing really staying on the highway then is something that can improve code, ultimately their own source code. What else than transformers (LLMs) can do this?

Do you agree, and where do you envision such a technology would be found instead?",0,0,0,,,,,
3707,2023-02-05 02:39:20+00:00,jeremiahjjohns,"@ylecun You both have different definitions of success. @fchollet means success as in a widespread adoption use case.

BERT did not have near the adoption currently being seen.",2,1,0,,,,,
3708,2023-02-05 02:28:57+00:00,trengriffin,"@ylecun People do not make video phone calls from phone booths today. 

Tim Selleck in 1994 ""[Have you ever] tucked your baby in from a phone booth?‚Äù

No executives at AT&amp;T believed any of this ""you will"" future.  AT&amp;T bought McCaw Cellular in 1994 to ""save the long distance business."" https://t.co/7gZK5GPBxY",1,6,0,,,,,
3709,2023-02-05 02:19:54+00:00,Prasad_Kothari,@ylecun Last time I checked it was called Turing test :D Anyway I will wait for @goodfellow_ian @geoffreyhinton to comment and observe the collision of the giants in my favourite tool - Social Collider :) https://t.co/xEyQvj9PmC,0,0,0,,,,,
3710,2023-02-05 02:14:07+00:00,cirrus_shakeri,@ylecun A highway towards human-level AI implies the path has already been laid out and some people have arrived at the destination. That's obviously not the case with human-level AI. Going offramps might be the only way to figuring out at least the lay of the land.,0,0,0,,,,,
3711,2023-02-05 01:59:28+00:00,GoblinCastle,@ylecun @ValaAfshar Honestly everyone thinks this thing is going to make them rich when most likely it‚Äôs going to take their job. I just made an entire backend data base using open AI and it took me a couple days where it would of been a couple weeks.,0,0,0,,,,,
3712,2023-02-05 01:57:51+00:00,bboczeng,"@ylecun why you think we need a high way to HLA? isn't that ramp off to the airport, which flies you there e-v-e-n-t-u-a-l-l-y?",0,3,0,,,,,
3713,2023-02-05 01:53:50+00:00,odysseytospace,"@ylecun @hughhowey If writing in every language, translating from every language, coding in every programming language, and making jokes and pomes in every language are not enough, I don't know what intelligence is.

I own a dog and chatGPT is so beyond it's  intelligence",2,0,0,,,,,
3714,2023-02-05 01:52:42+00:00,sethlamancusa,"@ylecun @hughhowey Like every other computational system humans have baked up, LLMs are better than humans within their domain: statistical language generation. The reason we're better at language overall is because we don't do it statistically, but semantically.",0,2,0,,,,,
3715,2023-02-05 01:50:19+00:00,sethlamancusa,"@ylecun But it seems like some kind of subconscious, statistical language generation happens in our brains all the time. Ever remember dialogue from a dream? Sounds a lot like GPT-2 did. Also seems like w/e semantic techniques come out of the woodwork will be implemented on top of LLMs.",0,0,0,,,,,
3716,2023-02-05 01:44:59+00:00,19kunalverma,"@ylecun Hey 
I‚Äôve a question what are closest or just best alternatives to GPT-3 that we can use to create an open source and powerful as previous model ?
Like we have GPT-J or GPT-Neo or any other 
How to improve them significantly with less data availability?",0,0,0,,,,,
3717,2023-02-05 01:25:26+00:00,babkiblyat,@ylecun @elonmusk @OriolVinyalsML @ReplyGPT,1,0,0,,,,,
3718,2023-02-05 01:21:08+00:00,allinthenewedu,@ylecun So what? ü§∑üèΩ‚Äç‚ôÄÔ∏è https://t.co/qps2iKijMm,0,0,0,,,,,
3719,2023-02-05 01:14:44+00:00,MacGraeme42,"@ylecun @elonmusk @OriolVinyalsML Seems like a lot of talking at cross-purposes without clear definitions of what is meant by things like ""human level AI"". Modelling, planning, recurrence, unsupervised on-the-fly learning, will be needed for a human-like/level interactive AI agent. BUT...",1,0,0,,,,,
3720,2023-02-05 01:09:50+00:00,TedPoulos,"@ylecun Yann, the human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, Principles formulated, and related equations written by yours truly.",0,0,0,,,,,
3721,2023-02-05 01:02:18+00:00,bull_picture,"@ylecun Human level AI. 
When will it arrive, timeframe wise?",0,0,0,,,,,
3722,2023-02-05 00:39:18+00:00,Market4Play,"@ylecun The goal is not Human Level A.I. we‚Äôre looking at this wrong. Assuming ‚Äúhuman level‚Äù is a metaphor, for ‚ÄòUS‚Äô being a behavioral simulation to improve and make better what we create. We already know how it ends when we make A.I exactly like us‚Ä¶ #Terminator",0,1,0,,,,,
3723,2023-02-05 00:34:46+00:00,_SilkeHahn,"@ylecun Frankly, ""off-ramp on the highway"" sounds like #DeepLearning ""hitting the wall"" üß± @GaryMarcus 

If this is s a full turn from optimism to pessimism between Galactica and now: What happened?",0,3,2,,,,,
3724,2023-02-05 00:27:54+00:00,venividivecu,"@ylecun dear Yann, would you suggest studies for a doctorate degree in general machine learning or computer vision? Both are interesting to me, I am interested in the breadth of unsolved challenges and opportunities to improve on.. Many thanks!",0,0,0,,,,,
3725,2023-02-05 00:21:28+00:00,DrewHawkswood,"@ylecun I agree that they're not themselves the way to ""human-level AI"", but opening to the public requires gargantuan computing power, and we need to put hardware researchers under greater pressure or we won't have enough c.p. to support AGI anyway. Nvidia stock is at +47% this month.",0,1,0,,,,,
3726,2023-02-05 00:18:50+00:00,TvNanaki,@ylecun Considering you don‚Äôt know what it will take it could be that they are needed to realize we took a wrong turn in the first place.,0,0,0,,,,,
3727,2023-02-05 00:18:31+00:00,Zarathustra314,@ylecun @elonmusk @OriolVinyalsML Even Elon couldn't understand your concerns. In the end he is a businessman. Sorry Yann.,0,0,0,,,,,
3728,2023-02-05 00:17:33+00:00,whostolemynames,"@ylecun There are no off ramps on a highway, might be thinking of a interstate, freeway, till road, etc.",0,0,0,,,,,
3729,2023-02-04 23:54:14+00:00,joaquind,@ylecun What ads would you make today @ylecun ?,0,0,0,,,,,
3730,2023-02-04 23:52:36+00:00,ersoy_ugur,@ylecun We are not on the highway yet. We are on off-roads trying different things.,0,0,0,,,,,
3731,2023-02-04 23:46:30+00:00,0xcccrrr,@ylecun @traderyau thank u &lt;3 please continue popping this mini bubble,0,0,0,,,,,
3732,2023-02-04 23:45:44+00:00,craigthomler,"@ylecun @PSpagnou Yes it is.

That $30 tool trained many programmers during its development &amp; amazed young users who went on to dream bigger.

The path is not a straight one &amp; failures help pave it even more than successes.",0,3,0,,,,,
3733,2023-02-04 23:42:04+00:00,craigthomler,"@ylecun @ValaAfshar Nope. It‚Äôs an on-ramp.

We have to understand stupidity to understand intelligence.",0,0,0,,,,,
3734,2023-02-04 23:35:46+00:00,artistexyz,"@ylecun @elonmusk @OriolVinyalsML mettre les pieds dans le plat, that's what it is!",0,0,0,,,,,
3735,2023-02-04 23:33:00+00:00,bpcronin,"@ylecun @JohnBlackburn75 @traderyau But are LLMs an extension of intelligence in a way that is unprecedented and very powerful? Complimentary AI, not AGI?",0,0,0,,,,,
3736,2023-02-04 23:32:25+00:00,diydatascience,"@ylecun Is it ever possible to have human-level AI? If it is possible, do we really want it to happen? I am thinking about Skynet.",1,0,0,,,,,
3737,2023-02-04 23:32:02+00:00,SaibalMitra12,@ylecun https://t.co/57lJC3MNiY,0,0,0,,,,,
3738,2023-02-04 23:30:44+00:00,MacGraeme42,"@ylecun @hughhowey These strong claims need clear definitions of what you qualify as ""human level AI"" and what you are including under LLMs. What would your ""Turing Test"" entail? If same but larger architecture is trained on text, audio, and video to produce text, audio, &amp; video, is that still LLM?",1,0,0,,,,,
3739,2023-02-04 23:25:39+00:00,tanmay7270_,"@ylecun @elonmusk @OriolVinyalsML don‚Äôt think Oriol would disagree with ‚ÄúLLMs are missing essential features for HLAI,‚Äù perhaps has a problem with the ‚ÄúLLMs are an off-ramp‚Äù analogy",1,4,0,,,,,
3740,2023-02-04 23:24:44+00:00,OriolVinyalsML,"@ylecun @elonmusk I don't disagree with that, but disagree with the off-ramp thing üòá",4,80,1,,,,,
3741,2023-02-04 23:20:30+00:00,cryptoID_info,"@ylecun @traderyau Respectfully, etymologically speaking, there is no intelligence without written language (inter legere)

Historically speaking, there are very strong clues that written language IS the great enabler: without it you only have instinct and very limited culture.",0,0,0,,,,,
3742,2023-02-04 23:18:33+00:00,justachelloveck,@ylecun @OriolVinyalsML Do I smell a simon ehrlich wager thing happening here? Shouldn‚Äôt be too hard to agree on a criteria?,0,1,0,,,,,
3743,2023-02-04 23:09:25+00:00,trinoxol,@ylecun @hughhowey You'd be surprised what insights you can extract from ChatGPT in longer conversations when prompted correctly.,0,0,0,,,,,
3744,2023-02-04 23:06:46+00:00,powerbottomdad1,@ylecun Yann LeCant we all just get along,1,9,0,,,,,
3745,2023-02-04 23:03:11+00:00,TheFuturist2045,@ylecun good. we need more off ramps. making machines that ‚Äúfeel‚Äù is asinine.,0,0,0,,,,,
3746,2023-02-04 22:58:57+00:00,AwokeKnowing,@ylecun @OriolVinyalsML Obviously. If they think it's only 'a single thought'. World models and internal simulations are a must.,0,0,0,,,,,
3747,2023-02-04 22:55:53+00:00,imthealan,@ylecun @elonmusk @OriolVinyalsML If consciousness really is next word prediction then I don‚Äôt want to live anymore.,1,4,0,,,,,
3748,2023-02-04 22:49:33+00:00,Ankitdew05,"@ylecun @elonmusk @OriolVinyalsML ""Oh, of course! We wouldn't want to miss out on any essential features for HLAI. That would be a disaster!""",0,0,0,,,,,
3749,2023-02-04 22:49:13+00:00,rohitrango,"@ylecun Like Galactica? 
I just don't see how you can put ChatGPT and Galactica in different buckets.

https://t.co/sg41dLAkdT",0,1,0,,,,,
3750,2023-02-04 22:45:10+00:00,DavidRimshnick,@ylecun @traderyau LLMs aren't just about language Yann.  The transformer is a very flexible that can encode many modalities.  Saying language can't capture all of human knowledge may or may not be true but it's irrelevant to whether this is the architecture for AGI,0,2,1,,,,,
3751,2023-02-04 22:44:33+00:00,TobyWBlack,@ylecun https://t.co/FyQFab3NNh,0,0,0,,,,,
3752,2023-02-04 22:40:54+00:00,KieronScully,@ylecun @hughhowey Sure but you moved the goalposts to a totally different pitch now.,1,5,0,,,,,
3753,2023-02-04 22:39:25+00:00,PristineMartian,@ylecun Human-Level AI is still lots of decades away,0,0,0,,,,,
3754,2023-02-04 22:23:38+00:00,DrTc666,"@ylecun Their loss mate. Several of your former friends there say hi and often quoted parting with you as a ‚Äúsupreme failure‚Äù

Hey @statpumpkin he could have been your boss :)",0,0,0,,,,,
3755,2023-02-04 22:15:08+00:00,JackHudler,"@ylecun Imagine what's going to happen when the LLM breaks down because they're incorporating social constructs that have no basis in physical reality. Where psychological issues are considered nominal physical reality; for example body dysmorphia, and gender dysphoria.",0,0,0,,,,,
3756,2023-02-04 22:11:39+00:00,mpc8240,@ylecun @MatjazLeonardis A long read for non AI practitioners. Is there a layman's version?,0,0,0,,,,,
3757,2023-02-04 22:09:34+00:00,kaalam_ai,"@ylecun @jpFromTlon But then, the field will be in the hands of people who understand what they are talking about.",0,0,0,,,,,
3758,2023-02-04 22:06:56+00:00,lboloni,"@ylecun What, weren't the Australopithecine running GPT?",0,0,0,,,,,
3759,2023-02-04 22:03:32+00:00,kevin2kelly,"@ylecun On the highway towards Human-Level AI, the off-ramps will become the main event.",1,20,1,,,,,
3760,2023-02-04 22:03:16+00:00,broken_icecream,"@ylecun Doubtful, isn‚Äôt language a low dimensional representation of everything else we interact with?",0,0,0,,,,,
3761,2023-02-04 22:02:02+00:00,yuricampbll,"@ylecun The use of BERT-style-only architectures in NMT is controversial at best. Most advantages found relate to up-starting low resource languages. That‚Äôs the reason why many NMT systems are at least decoder-based or, like originally designed, encoder-decoder-like.",0,0,0,,,,,
3762,2023-02-04 22:02:02+00:00,quantum_whip,@ylecun dont underestimate emergence,0,0,0,,,,,
3763,2023-02-04 21:56:31+00:00,zstzlmk,"@ylecun @MatjazLeonardis Thanks for the read, Yann.",0,0,0,,,,,
3764,2023-02-04 21:48:06+00:00,Petenath,"@ylecun I think that LLMs alone will not lead to human-level AI, but certainly LLMs would have stunning potential if they were trained on and work in conjunction with sensory inputs.",0,0,0,,,,,
3765,2023-02-04 21:40:38+00:00,DJFreshUK,@ylecun üòÇ wow,0,0,0,,,,,
3766,2023-02-04 21:40:31+00:00,piyush_ranjan,"@ylecun @hughhowey Given that most people on social media support the thesis that chatgpt will replace humans in most jobs, if not all, I think avg human iq has gone down so much that it lower than a house cat now",1,0,0,,,,,
3767,2023-02-04 21:35:22+00:00,virtual_dreame,"@ylecun I'm no programmer , but can use tools to create what I want and if Ai helps me get there then even better https://t.co/PXq1ChGzje",1,0,0,,,,,
3768,2023-02-04 21:34:27+00:00,SilencesTruth,"@ylecun I know nothing about this realm, why is language being considered as an important premise for AI ?",0,0,0,,,,,
3769,2023-02-04 21:30:18+00:00,danielbigham,"@ylecun üå∂Ô∏èAs they are today, it may seem like that, but if some addition bits get injected, I could see them being foundational enough that considering them an off-ramp to be a wrong analogy. We shall see!",0,0,0,,,,,
3770,2023-02-04 21:30:06+00:00,TMoneyFoReaaal,@ylecun @hughhowey Can you give some examples of these mistakes?,0,0,0,,,,,
3771,2023-02-04 21:27:49+00:00,didierturfu,@ylecun @hughhowey Are you allowed to disclose if Facebook has developed an internal model mitigating these shortcomings?,0,0,0,,,,,
3772,2023-02-04 21:25:07+00:00,Gamewizard71,@ylecun Neuromorphic computing,0,0,0,,,,,
3773,2023-02-04 21:22:13+00:00,kkiy90,@ylecun @readwise save thread,1,0,0,,,,,
3774,2023-02-04 21:22:00+00:00,viking_pl,"@ylecun They are a part of the solution, but just a part.",0,1,0,,,,,
3775,2023-02-04 21:19:00+00:00,thenickoro,@ylecun @PSpagnou üíØüéØ,0,0,0,,,,,
3776,2023-02-04 21:14:31+00:00,OwariDa,"@ylecun @smjain The belief that we will have One Model to Rule Them All in general is naive. Even if possible, it would not be optimal

Most likely the path to AGI is a combination of multiple models optimized for different tasks.  Coordinating these could very well be an LLM-like task though",1,1,0,,,,,
3777,2023-02-04 21:11:01+00:00,Gamewizard71,"@ylecun The Von Neumann Architecture is very power inefficient compared to the brain. The field should invest in neuromorphic computing instead of GPU/TPU racks

LLMs need to be multimodal, with a world model

Lastly, backpropagation needs to happen continuously like the human brain",1,1,0,,,,,
3778,2023-02-04 21:08:52+00:00,caseywickland,"@ylecun @hughhowey Intelligent humans tend to believe all sorts of crazy things, and many humans lack basic common  sense.",0,0,0,,,,,
3779,2023-02-04 21:03:01+00:00,ChrisWolf1987,"@ylecun Fair point

Mostly because if there‚Äôs one thing Facebook knows about, it‚Äôs being the biggest off-ramp on the highway of human productivity 

Well, and shipping an impactful product, but let‚Äôs not throw stones there since Google ain‚Äôt all that great there either",0,1,0,,,,,
3780,2023-02-04 20:55:34+00:00,MilitantHobo,"@ylecun @hughhowey There is no ""common sense"" baseline that a housecat won't drop below on a regular basis.",0,0,0,,,,,
3781,2023-02-04 20:49:42+00:00,c7ddfc,"@ylecun I remember a few years ago, GANs and LSTMs were all the rage. These days, they seem to have been replaced by diffusion models and transformers for img and text gen respectively. Do you think these models are here to stay or do you see them being replaced by something else?",0,1,0,,,,,
3782,2023-02-04 20:42:05+00:00,mzlittle,@ylecun Why isn't that obvious? What's causing the sheep to flock so??,0,0,0,,,,,
3783,2023-02-04 20:40:55+00:00,Afstone1,@ylecun are you suggesting we must be getting lost ? https://t.co/322kYXYTxy,0,0,0,,,,,
3784,2023-02-04 20:39:10+00:00,TheAaronBowley,@ylecun zzzzzzzzz chatGPT,0,0,0,,,,,
3785,2023-02-04 20:31:48+00:00,mpowers206,@ylecun Okay. Can you point me in the right direction?,0,0,0,,,,,
3786,2023-02-04 20:18:01+00:00,yannx0130,@ylecun It‚Äôs suprising you didn‚Äôt see the emerging intelligence from #Chatgpt.  It‚Äôs clearly demonstrating some kind of understanding and follow text instructions.,0,0,0,,,,,
3787,2023-02-04 20:16:51+00:00,yannx0130,@ylecun That‚Äôs because #Chatgpt is only trained with text.  If its extended to multimodality it will definitely has more ‚Äúcommon sense‚Äù you were talking about.,0,0,0,,,,,
3788,2023-02-04 20:15:38+00:00,k_saifullaah,"@ylecun LLMs were there even before large scale transformers, no? RNNs LM, LSTMs LM, etc. (albeit nobody called it large ig)",1,4,0,,,,,
3789,2023-02-04 20:15:31+00:00,Shannaboy,"@ylecun Sir, with due respect, your bias against anything Meta is concerning.",0,0,0,,,,,
3790,2023-02-04 20:13:16+00:00,DerekWiner,"@ylecun Maybe an off ramp to the airport as Minerva continues to improve over the MATH dataset. Currently at the 90th % of human performance. If people are confused over LLM resembling AGI rather than the ANI it is, Minerva evolution will show ANI-&gt;ASI, a subtle transition indeed!",2,0,0,,,,,
3791,2023-02-04 20:12:32+00:00,GordanKnott,@ylecun @ferdousbhai Is AGI the same as Human-level AI?,1,0,0,,,,,
3792,2023-02-04 20:12:00+00:00,KheteshAkoliya,@ylecun @DinoDvorak So by that defination @OpenAI is the leanest &amp; most effective in terms of shipping things. üòä,0,0,0,,,,,
3793,2023-02-04 20:07:52+00:00,stefanolafs,"@ylecun @Golisms I was just going to recommend reading about Cicero to those who disagree with the view you present here. I discussed this system in my undergrad AI course as a great example of combining planning, RL, and LLMs. It excels at its task only because of this combination of methods",1,1,0,,,,,
3794,2023-02-04 20:07:38+00:00,futilereality,@ylecun ac/dc,0,0,0,,,,,
3795,2023-02-04 20:05:23+00:00,shitpost9000,@ylecun it's a truck stop where we get some coffee and take a pee,0,0,0,,,,,
3796,2023-02-04 20:00:43+00:00,vicgardenhire1,"@ylecun Shhhh You will be wishing you did buddy. I mean save the embarrassment ;)
Rusted in spaghetti üçù sauce lol",0,0,0,,,,,
3797,2023-02-04 19:57:33+00:00,Nastya57132014,@ylecun Then it‚Äôs your companies own fault for not releasing your AI version earlier!  Sitting on technology when it is good enough for public consumption is foolishly.  It is like having a winning lottery ticket and being too scared to cash it in.,0,0,0,,,,,
3798,2023-02-04 19:55:51+00:00,BjergM,@ylecun @ylecun is much much smarter than the people at @OpenAI It was years ago he helped us get the best cat videos in our feeds. The work that @OpenAI now made banal in their ‚Äúnon-impressive‚Äù ChatGPT3. Follow him for a daily reminder of that.,1,8,0,,,,,
3799,2023-02-04 19:50:24+00:00,andy0___,"@ylecun Thoughts? 

@sama @gdb",0,0,0,,,,,
3800,2023-02-04 19:46:49+00:00,Ankitdew05,"@ylecun Self-supervised learning has also been used to improve the performance of computer vision models, such as image classification and object detection. For example, researchers have used self-supervised learning to pre-train convolutional neural networks (CNNs) on large datasets.",0,1,0,,,,,
3801,2023-02-04 19:43:55+00:00,shohdi2,"@ylecun it is clear that AI is near human level now , but human brain is not taking text only as input , human takes sound , picture , touch , smell and taste , we will not make a model like human until it have all these inputs before taking a decision",0,0,0,,,,,
3802,2023-02-04 19:41:52+00:00,jordimash,@ylecun Recommender systems have been also using  self-supervised learning for over a decade impacting the experience of millions of users daily.,0,2,0,,,,,
3803,2023-02-04 19:41:23+00:00,tim_tyler,@ylecun They could generate substantial funds - especially if they can program. More dollars and cheaper programming skills might well help organizations to make progress towards powerful machine intelligence. So: I think this tweet is probably mistaken.,1,2,1,,,,,
3804,2023-02-04 19:35:21+00:00,AndreasBaumgar8,"@ylecun This reeks of some severly miscalculated short sellings. LLM might not be the last step to truly AI, but it is a (most likely huge) step in the right direction.",0,2,1,,,,,
3805,2023-02-04 19:33:43+00:00,TechnologyPat,"@ylecun @OriolVinyalsML Because we‚Äôll all be dead from an ASI? Damn Yann, dark",0,5,0,,,,,
3806,2023-02-04 19:31:02+00:00,johnmsurette,"@ylecun Just because you can convince a monkey that it‚Äôs speaking to a monkey doesn‚Äôt mean the thing ‚Äòspeaking‚Äô even knows it‚Äôs speaking to a monkey, or even speaking at all for that matter. Yann dropping facts left and right ü•±",0,0,0,,,,,
3807,2023-02-04 19:27:54+00:00,KEMBL,@ylecun Only if the goal will be reached,0,0,0,,,,,
3808,2023-02-04 19:26:10+00:00,ScaleTechScott,"@ylecun I enjoy celebrating these achievements for what they are. We aren‚Äôt really going to understand all the little steps that lead to ubiquitous, useful, strong AI until we have it and then historians of science are go to have to do a lot of work to discover it.",1,6,0,,,,,
3809,2023-02-04 19:24:44+00:00,hi_tysam,@ylecun I do wonder if isotropic models are a necessary sidestep from a processing complexity standpoint. Maybe they're super gradient efficient because they're like the equivalent of loop unrolling. I feel like we're stuck behind a wall of linearity here that's holding us back somewhat.,0,0,0,,,,,
3810,2023-02-04 19:19:47+00:00,boelger,@ylecun I agree with the general sentiment. But why highway? I feel the full journey is more like an off road experience. Highways are built to cushion the thrill. LLMs do need some grounding for sure.,1,1,0,,,,,
3811,2023-02-04 19:18:13+00:00,NesslerBernhard,"@ylecun So the current ChatGPT success (or hype) is not just due to the (certainly powerful) principle of self-supervised learning, but heavily based on human supervision through RLHF, isn‚Äòt it?",1,1,0,,,,,
3812,2023-02-04 19:15:26+00:00,NesslerBernhard,@ylecun I think the public perception (and also Yann‚Äòs judgement) underestimates the huge amount of work that went into human labeling (hand crafted answers + training examples for RLHF) which distinguishes ChatGPT from earlier GPT version. Training data engineering made the difference.,0,9,0,,,,,
3813,2023-02-04 19:14:12+00:00,GeoffMantel,"@ylecun I wish we would call them ‚Äúfluency models‚Äù. Fluency of speech, fluency of motion, fluency of perceptual processing. It‚Äôs not intelligence itself, but it enables the transition of skill from system 2 to system 1.

We only call them LLMs because that‚Äôs how we train them.",0,0,0,,,,,
3814,2023-02-04 19:13:40+00:00,colinpthomson,@ylecun Yes,0,0,0,,,,,
3815,2023-02-04 19:11:57+00:00,mbrasneves,"@ylecun What do you mean by Human Level AI? What it's means human level in this contexts? 
Without a clear framing, try to make comparations is like a guessing game. 
If the goal is to reach a human level in his all plenitude is something like replicate human beings.",0,0,0,,,,,
3816,2023-02-04 19:10:23+00:00,DebskiJakub,@ylecun @Golisms Completely absent? What is the scientific explanation to the attached conversation? https://t.co/xl0Bb9MtMY,0,0,0,,,,,
3817,2023-02-04 19:06:37+00:00,untitled01ipynb,"@ylecun @OriolVinyalsML Now now, let's not be writing checks whose amount is difficult to recognize",0,11,0,,,,,
3818,2023-02-04 19:04:28+00:00,nielsjanss,@ylecun Failure is an important part of learning.,0,0,0,,,,,
3819,2023-02-04 19:03:09+00:00,dmit0820,"@ylecun LLMs can translate, summarize, paraphrase, program, write poetry, conduct therapy, debate, plan, create, and speculate. A system that can do all of these can reasonably be said to be a step on the path to general intelligence.",1,0,0,,,,,
3820,2023-02-04 18:58:46+00:00,dshap_automator,"@ylecun @hughhowey You could make the same assertion for most people. Appeals to ""understanding"" and ""truth"" are red herrings.",1,6,0,,,,,
3821,2023-02-04 18:55:33+00:00,ylecun,"@DrTc666 Between 1996 &amp; 2002, I mostly worked on DjVu (image compression) &amp; wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&amp;T could no longer afford a research lab.
Half of AT&amp;T Labs-Research was laid off.
I managed to be one of them.",1,1,1,,,,,
3822,2023-02-04 18:55:30+00:00,David_A_Eraso,"@ylecun What if Human-Level AI is overrated? What if the off-ramp actually leads towards Super Narrow AI that ends up being way, way more useful than an imitation of what we already have on 8 billion plus of?",1,0,0,,,,,
3823,2023-02-04 18:54:17+00:00,linusbehrbohm,"@ylecun They are simply sequence modelling tools. If you can model possible behaviours as sequences, you might get somewhere, but probably not by modelling internet articles.",0,0,0,,,,,
3824,2023-02-04 18:53:46+00:00,ozhillbilly,"@ylecun Is it possible that language when observed over a sufficiently large sample can approximate the  dynamics of human level intelligence? (in the same way ML applied to massive weather datasets can approximate atmospheric fluid dynamics)? Not my field, but interested amateur.",0,0,0,,,,,
3825,2023-02-04 18:50:44+00:00,mpc8240,@ylecun Which technology is on-ramp to human level AI?,0,0,0,,,,,
3826,2023-02-04 18:46:54+00:00,LordGenome,@ylecun @ferdousbhai Even LLMs don‚Äôt think that,0,2,0,,,,,
3827,2023-02-04 18:46:43+00:00,loveofdoing,@ylecun Thoughts on COLLAS in embedded robots?,0,1,0,,,,,
3828,2023-02-04 18:45:22+00:00,LordGenome,@ylecun @smjain Who thinks that?,0,0,0,,,,,
3829,2023-02-04 18:42:49+00:00,zunaidkazi,@ylecun Should even human level AI be the goal. Or AI that makes the human condition better?,0,1,1,,,,,
3830,2023-02-04 18:39:21+00:00,nisyron,"@ylecun LLMs are equivalent to the human Cortex, you can't have human-level AI without it, but having just it isn't enough to create a complete cognitive cycle as human do. We're at Inpris are working on it and solving it for real world problems in production level.",0,1,0,,,,,
3831,2023-02-04 18:38:59+00:00,shawntsullivan,"@ylecun LLMs could be part of a human-level AI system, providing a natural language interface and possibly coordinating work with other models

In the same way human intelligence is not a single monolithic process in the brain, no reason to assume AGI has to be a single model",0,1,0,,,,,
3832,2023-02-04 18:36:35+00:00,Musashi08950068,@ylecun @hughhowey And consume way more energy.,0,0,0,,,,,
3833,2023-02-04 18:35:04+00:00,OriolVinyalsML,@ylecun Remind me in 5 years... üçø,14,600,16,,,,,
3834,2023-02-04 18:31:46+00:00,JohnBlackburn75,@ylecun @traderyau For humans to believe a robot or computer is intelligent it must be able to use language. Think of all intelligent robots in science fiction. So LLM is a necessary but maybe not sufficient condition for intelligence. To say its completely irrelevant is surely false,1,2,0,,,,,
3835,2023-02-04 18:30:45+00:00,DavidBensh,@ylecun You once said about Jess Hawkins of @Numenta that his ideas are hard to reduce to practicality. Well LLMs are exactly that.. pure practicality that might demostrate intelligence. You are now playing the opposite side of that. What are these highway routes that everybody missing?,0,1,0,,,,,
3836,2023-02-04 18:27:43+00:00,m_road2,@ylecun Seeing these replies I get where you coming from but release a product man.,0,0,0,,,,,
3837,2023-02-04 18:25:41+00:00,CapitalBanker,@ylecun @MatjazLeonardis üéØ,0,0,0,,,,,
3838,2023-02-04 18:23:59+00:00,Reader3998,@ylecun Release a product and not a paper,0,0,0,,,,,
3839,2023-02-04 18:11:45+00:00,info_sprinkles,@ylecun @miguelisolano @Tech4Breakfast  ;),0,0,0,,,,,
3840,2023-02-04 18:11:45+00:00,jasonkolb,@ylecun Why not a milestone?,0,0,0,,,,,
3841,2023-02-04 18:04:05+00:00,_erik_dali,@ylecun LLMs are like those people who can bs their way about anything with confidence whilst having no clue.,0,0,0,,,,,
3842,2023-02-04 18:03:20+00:00,perrabyte,@ylecun I wonder if you need to capture coefficients that has intelligent dx behaviour,0,0,0,,,,,
3843,2023-02-04 17:59:49+00:00,ian_wardell,"@ylecun @traderyau Hmm, this is interesting.",0,0,0,,,,,
3844,2023-02-04 17:54:32+00:00,scottessare,@ylecun Yes.  I wish this was more widely discussed,0,0,0,,,,,
3845,2023-02-04 17:54:01+00:00,justin_t_wesley,@ylecun Consistent,0,0,0,,,,,
3846,2023-02-04 17:49:20+00:00,CarlosEAlvare17,"@ylecun Funny, just yesterday I said the same in an email but used the term dead end. Now I see you updated your off-ramp to off-ramp to oblivion. 

But how long could that possibly delay progress? Ptolemy‚Äôs geocentric model comes to mind.",0,0,0,,,,,
3847,2023-02-04 17:48:08+00:00,KolinKoehl,@ylecun Why are you so bitter?,0,1,0,,,,,
3848,2023-02-04 17:46:30+00:00,artistexyz,"@ylecun No! MetaAI is doomed with that kind of advice from Yann LeCun.
LLMs are not an off-ramp,they are a stepping stone, they accomplish the first and arguably the hardest step, towards adding Causal Inference and the scientific method to AI. I explain it here:
https://t.co/teHxJIPZJ1",0,1,1,,,,,
3849,2023-02-04 17:41:29+00:00,FabioAngela79,@ylecun So you mean all this effort and the effort of who's building on top is leading toward a dead end?,0,0,0,,,,,
3850,2023-02-04 17:39:43+00:00,laion_ai,@ylecun whatever! :D https://t.co/qViFBto4PD,0,10,2,,,,,
3851,2023-02-04 17:37:32+00:00,ShafronTom,@ylecun It would be silly to even try.  Humans are ridiculously inefficient at complex conscious reasoning.  It's not what we were evolved to do.,0,0,0,,,,,
3852,2023-02-04 17:22:39+00:00,ToppaTib,@ylecun @smjain We know...,0,0,0,,,,,
3853,2023-02-04 17:22:38+00:00,ItalyHighTech,"@ylecun Trying to reach human level intelligence when we do not have yet available general intelligence models (models that, though not at human level, can accomplish a large variety of tasks) is going an off-ramp.",1,0,0,,,,,
3854,2023-02-04 17:21:40+00:00,rmarcilhoo,"@ylecun @ferdousbhai Some believe stacking up hundreds of narrow AI models can emulate general AI, just as  armchair ""economists"" believe stacking up MicroEconomics principles leads to MacroEconomics.",0,0,0,,,,,
3855,2023-02-04 17:19:03+00:00,SaoudKhalifah,@ylecun AT&amp;T Bell Labs FTW @FakespotTweets,1,2,0,,,,,
3856,2023-02-04 17:14:15+00:00,rmarcilhoo,"@ylecun @c7ddfc Need a world model ""gym"" with appropriate RL rewards.",0,0,0,,,,,
3857,2023-02-04 17:12:25+00:00,rmarcilhoo,@ylecun And the road to Hell is paved with ... ??,0,0,0,,,,,
3858,2023-02-04 17:11:44+00:00,DavidmSachs,"@ylecun When thinking of #HLAI I fall back on Kant's 'Spontaneity'. In 3rd Antinomy, Kant makes clear that ‚Äòspontaneity‚Äô is the ‚Äúfaculty of beginning a (mental) state from itself‚Äù,that's  the faculty of causing one-self or another substance to be in a state without being caused to do so",0,0,0,,,,,
3859,2023-02-04 17:02:24+00:00,aukinhluan,@ylecun Chatgpt is useful only when the human user can tell if the answer is right or wrong.,0,0,0,,,,,
3860,2023-02-04 16:58:38+00:00,jonchun2000,"@ylecun Your ""A Path Towards Autonomous Machine Intelligence"" is the best theoretical blueprint to AGI

The practical question is what is the best accessible implementation of AGI now.

The langchain pipeline combining LLM, structured KB and symbolic manipulation seem the most promising. https://t.co/g1ZQLnheTU",0,2,0,,,,,
3861,2023-02-04 16:52:45+00:00,tarrysingh,"@ylecun I don‚Äôt think we should aim , leave alone hope for a human-level AI. 

Instead we should train and equip humans with human-centric AI skills and techniques.",0,0,1,,,,,
3862,2023-02-04 16:52:40+00:00,urigolan,@ylecun @LexMitchell Conveniently forgetting to celebrate AlexNet,0,0,0,,,,,
3863,2023-02-04 16:50:18+00:00,mapto,"@ylecun ""Useless"" is a hallucination in this context. Let's look at facts, please. From the abstract: ""[we encourage] research directions beyond ever larger language models."" Then I guess people are capable at various interpretations of this",0,11,0,,,,,
3864,2023-02-04 16:39:35+00:00,rbessuges,"@ylecun LLM works just like our imaginative brain, by faking the manipulation of complex concepts, using repetition, association, and vocabulary to create a sense of causality. What is needed now is the algorithm that reasons above these intuitions. So not an off-ramp, but a foundation.",0,2,0,,,,,
3865,2023-02-04 16:37:02+00:00,rahulkindasucks,@ylecun @hughhowey Humans don't need to be perfect - why do machines? I'd rather the mistakes be simple enough for humans to detect than complex and subtle enough to render our species complacent.,0,0,0,,,,,
3866,2023-02-04 16:36:34+00:00,Tang13220820,"@ylecun No matter what the model is, all models only do calculations, but human not just only do calculations, that‚Äôs the difference!",0,0,0,,,,,
3867,2023-02-04 16:35:45+00:00,AI_EngineerGuy,"@ylecun ChatGPT etc is like if you wanted to make an artificial human body and spent your time just trying to make your artificial spleen do more and more, even though your current version is already good enough at just spleening. We need to spend more time on the REST of the AI Problem",0,0,0,,,,,
3868,2023-02-04 16:35:04+00:00,notresz,@ylecun your giving too much credit to humans üòÇ,0,0,0,,,,,
3869,2023-02-04 16:22:36+00:00,cichuck,@ylecun those that ascribe to the ‚Äòsociety of mind‚Äô theory  consider LLMs as an essential first step,0,0,0,,,,,
3870,2023-02-04 16:20:04+00:00,tinkerteller,"@ylecun Ironically, one can say same about convolutional networks and 2020s obsession on ImageNet. 

But they weren‚Äôt off-ramp as many techniques there eventually lead way to transformers. 

We build on others and there is no need to deride things you or your employer is missing out.",0,0,0,,,,,
3871,2023-02-04 16:18:33+00:00,KiLVaiDeN,"@ylecun There will never be Human-Level AI because concepts live on their own on an immaterial dimension that only consciousness, with the tool called ""the mind"" can grasp. A machine has no access to the immaterial dimension. That's also why a machine will never be conscious.",0,0,0,,,,,
3872,2023-02-04 16:13:55+00:00,SaikiK66287209,@ylecun salty,0,0,0,,,,,
3873,2023-02-04 16:05:15+00:00,joezott,"@ylecun @Golisms What do you see as the best approach to develop a generalized planner? Not the custom one specific limited problem planner in Cicero, but general enough to adapt a specific prompt. Is this even possible?",0,0,0,,,,,
3874,2023-02-04 16:02:51+00:00,DWarshavski,"@ylecun Assuming you want to get Human-Level AI, which you probably don't. In such a case LLM are a ""good enough"" specific approximation (perhaps even too good, it's already destructive to students and children that will grow in a world in which they don't need to think for themselves)",0,0,0,,,,,
3875,2023-02-04 16:02:24+00:00,ksk5173,"@ylecun Philosophical question.. if we hit human level ai, would it lead to a broader question of ok cool, what do I do now ..knowing a machine could do my job and probably do it better ? When we hit for human level ai, do we start another problem of human purpose ?",0,0,0,,,,,
3876,2023-02-04 16:00:40+00:00,breckyunits,@ylecun The on-ramp is simple high-dimensional human curated CSV files. https://t.co/YPi7VbCqze,0,1,0,,,,,
3877,2023-02-04 15:59:27+00:00,OR13b,@ylecun Any updates on your orchestration AGI work? The one with different components for different parts of brain function?,0,0,0,,,,,
3878,2023-02-04 15:57:28+00:00,english_august,"@ylecun @beenwrekt Of all the things mentioned in these ads, the ONLY one that still is half-baked and not available to everyone is - ""you will one day carry your medical history in your pocket!"" and that is a huge tell about the healthcare industry (than tech itself).",0,2,1,,,,,
3879,2023-02-04 15:57:13+00:00,RaffyGerolangin,@ylecun MYSTERY BLACK,0,0,0,,,,,
3880,2023-02-04 15:56:55+00:00,ElijahYilma,@ylecun But everyone else seems to be treating it as the highway AND are also convinced that it is the only road available...smh,0,0,0,,,,,
3881,2023-02-04 15:55:22+00:00,KennyEpl,"@ylecun Question is what is Human level? 

* Dogs understand and respond to commands.
* Computers work in a specific way because it is programmed in a certain style with strict rules.
* Human level is natural understanding.
* LLM's are already human level in understanding.",0,0,0,,,,,
3882,2023-02-04 15:48:04+00:00,perpetualocean,@ylecun Still waiting for releases. Anything lined up this year we should be looking forward to? Maybe ur team can demonstrate where on the highway you're at and possibly how far u r from ur destination? I promise people will give their attention and u will be the talk of the town.,0,0,0,,,,,
3883,2023-02-04 15:43:05+00:00,M_M_Mujtaba,@ylecun @hughhowey At what level do we need to make change to move forward on the path of AGI? Is neural network with back propogation enough to achieve AGI or do we need to develop an alternate architecture to LLMs using the current learning mechanisms?,0,0,0,,,,,
3884,2023-02-04 15:38:18+00:00,adarshxd,@ylecun @MatjazLeonardis üëç,0,0,0,,,,,
3885,2023-02-04 15:32:37+00:00,_ash_ran,@ylecun Agreed Yann. Can you also give us some direction (papers) which we should be looking at going forth which are at the forefronts of making a human level AI?,0,0,0,,,,,
3886,2023-02-04 15:31:39+00:00,Hello_World,"@ylecun That's like saying cells is an off-ramp to humans. We simply don't know how to create AGI and thus whether it's an on-ramp or off-ramp is too early to tell.

We do know that LLMs have emergent capabilities which is a pre-requisite for human level intelligence.",0,3,1,,,,,
3887,2023-02-04 15:26:17+00:00,RobertWKemp,@ylecun One argument is that LLMs will speed up development e.g. copilot and that will lead to a quicker timeline to AGI.,0,2,0,,,,,
3888,2023-02-04 15:25:19+00:00,MetalMonkey9,"@ylecun When it converges with symbolic context, and a physical experience, let‚Äôs get ready to be amazed‚Ä¶",0,0,0,,,,,
3889,2023-02-04 15:23:05+00:00,jamie_maguire1,@ylecun I'm not seeing anything other than narrow AI so far?,0,0,0,,,,,
3890,2023-02-04 15:21:46+00:00,sepia_fw,@ylecun So what is the fast lane then? Or is everybody else stuck in the jam?,0,0,0,,,,,
3891,2023-02-04 15:20:29+00:00,ElkeSchlote,"@ylecun @OptimalBayes It‚Äôs for dazzling the general public and to legitimate more funding towards the field, no?",0,2,0,,,,,
3892,2023-02-04 15:13:08+00:00,rveulacia,@ylecun @MatjazLeonardis Remains inductivist and reductionist to the bone‚Ä¶ Sadly leading to yet another off-ramp.,0,0,0,,,,,
3893,2023-02-04 15:12:34+00:00,Mkc15144282M,"@ylecun Well said. ..there are more impressive AI that can beat you at complex games. chat-GPT is being hyped way too much as an AI, though it does revolutionize our ability to automate common human tasks",0,0,0,,,,,
3894,2023-02-04 15:11:11+00:00,CAMG_ACC,"@ylecun So you don‚Äôt know what the path is, so how do you know you are on the right highway?",0,0,0,,,,,
3895,2023-02-04 15:08:44+00:00,GasAss,@ylecun Is Midjourney based on GAN?,0,0,0,,,,,
3896,2023-02-04 15:04:33+00:00,dmo_cap,@ylecun Shows again that people underestimate the power of tech- nology over long time frames.,0,0,0,,,,,
3897,2023-02-04 15:03:47+00:00,SajidkabirSk,@ylecun Your tweets regarding LLM and AI not gonna age well.,0,1,1,,,,,
3898,2023-02-04 14:59:15+00:00,ahersouza,"@ylecun @smjain Ok, It seems obvious. It's it really a problem if done people think that? I would think just in terms of interest and new funding, LLMs are likely to help.",0,0,0,,,,,
3899,2023-02-04 14:58:26+00:00,towheretobegin,"@ylecun @smjain LLMs are like electric cars in the 1910s. Very useful, better than the competition, but will probably get replaced in the medium-term.

Which said little about the actual long-term feasibility of EVs. 
LLMs are the Gemini and Apollo of AI; the goal isn't to be the end-all.",0,5,1,,,,,
3900,2023-02-04 14:55:36+00:00,CalvinMccarter,"@ylecun @hughhowey Is your point that Internet-scale textual training data makes good performance too easy (ie a shortcut around common sense)? Or, that this data makes the task too hard / impossible? Or, that LLMs have the wrong architecture &amp; training objective? Or, all three?",1,1,0,,,,,
3901,2023-02-04 14:53:30+00:00,Danielledeco,"@ylecun Bell Labs was pivotal to many advancements, that‚Äôs so cool!",0,0,0,,,,,
3902,2023-02-04 14:52:18+00:00,ViraniAlim,@ylecun Why should that be the goal? Has that been the goal?,0,0,0,,,,,
3903,2023-02-04 14:50:04+00:00,pkghosh99,"@ylecun Not just LLM, inductive learning in general is an off ramp",0,0,0,,,,,
3904,2023-02-04 14:46:02+00:00,Behdad_Jamshidi,"@ylecun I respectfully disagree. While other experienced methodologists are struggling to harness new approaches and tools to make the world a better place, you have criticized the new AI tools. It was expected to hear more professional viewpoints from the most professional scientists.",0,0,0,,,,,
3905,2023-02-04 14:45:50+00:00,christianvanck,@ylecun U are prob right genius and all. But please repeat after me. Adoption. Adoption. Adoption. AI is a scary subject for most. LLMs are a positive tangible experience and will increase general acceptance without which nothing matters anyway.,0,0,0,,,,,
3906,2023-02-04 14:43:07+00:00,ahersouza,@ylecun I think path is ill defined. Is the highway to success built of off-ramps? I mention this from a developers perspective trying to understand what you know.,0,0,0,,,,,
3907,2023-02-04 14:38:28+00:00,charleswangb,"@ylecun Turing machine based on Church-Turing-Deutsch principle is a steppingstone to HLAI for symbol manipulation but it (and anything running on TM) can‚Äôt inhabit the world so it‚Äôs inherently limited on its own.

LLM has the potential to loosen up the limits to certain degree.",1,0,0,,,,,
3908,2023-02-04 14:29:56+00:00,vincebrandon,@ylecun There's gonna be a great rest station when it's all finished though,0,0,0,,,,,
3909,2023-02-04 14:29:27+00:00,awxuelong,"@ylecun Generally, what does the AI community mean when we say the human brain ""build models""?  By model, are you referring to an equation that maps sensory input to another (maybe behavior) output?  Or is it a grammar made of rules of production (each rule being a thought) ?",0,0,0,,,,,
3910,2023-02-04 14:27:30+00:00,Golisms,"@ylecun I recently explained on @Clubhouse why ChatGPT can‚Äôt write a poem am that ends with a certain word (‚Äúmink‚Äù), bc it can‚Äôt plan to use a rhyming word (‚Äúthink‚Äù or ‚Äúsink‚Äù) earlier. But combining LLMs w a planner&amp;world model, as Cicero does, seems to be on the road to Human-Level AI.",0,15,2,,,,,
3911,2023-02-04 14:27:18+00:00,Youness_ELM,"@ylecun Well you're obviously incredibly knowledgeful, therefore I'm really curious to see what you'll come up withüòä
Should we expect an AI-driven representation of the World accessible from an API any time soon? How would we interact(query, response,...) with it to consume and feed it?",0,0,0,,,,,
3912,2023-02-04 14:27:04+00:00,twishmay,@ylecun Thanks! :D,0,2,0,,,,,
3913,2023-02-04 14:25:09+00:00,piva_jonas,"@ylecun @hughhowey To a language model, the world is language, and the understanding is masterful, it's much higher level than what we do, at least that's how it looks.  Give them legs, give them eyes, give them tongues, ears and maybe a form of touch... what happens then?  Can you apply same model",1,0,0,,,,,
3914,2023-02-04 14:23:49+00:00,NioDiehard,@ylecun @Golisms And how they do it.. planning.. i totally agree a memory chapion can not be a great a solving problem.. these LLMs are like RAINMAN.. stores and recall enormous information.. but can not understand that information to make a intelligent decision..,1,0,0,,,,,
3915,2023-02-04 14:22:03+00:00,seanmcbride,"@ylecun For reasons that aren't precisely clear or supportable, Yann LeCun has swung hard against LLM/GPT tech. It would be a mistake for Meta or any company to take that position.",0,0,0,,,,,
3916,2023-02-04 14:21:28+00:00,piva_jonas,@ylecun Unified model doesn't include language?,0,0,0,,,,,
3917,2023-02-04 14:18:15+00:00,DrTc666,"@ylecun I was at ATT Research and worked with bell labs people who worked with you. They told me that in a spectacular display of failure on ATTs part, they fired you and other ai people thinking ai was a fad - is that true? 

Sadly this would be just another example of their myopicness",1,1,0,,,,,
3918,2023-02-04 14:17:02+00:00,gpmessinger,@ylecun This comes off as kinda defensive and bitter,0,0,0,,,,,
3919,2023-02-04 14:16:40+00:00,0korkle0,"@ylecun You share John Carmack's view. The urge to take easy commercial offramps is strong as there are many of them presumably, and can easily lead to billions.",0,0,0,,,,,
3920,2023-02-04 14:14:28+00:00,cobzarenco,"@ylecun What do you mean? That LLMs get off the road to Human-Level AI / they're a distraction / dead end?

Why?",0,1,1,,,,,
3921,2023-02-04 14:13:40+00:00,chinguetti1,"@ylecun Maybe, but millions have taken this off ramp and they are in awe.  People are excited.   There is a new awareness that we are on a road to Agi.  Traffic is increasing.",0,1,1,,,,,
3922,2023-02-04 14:10:01+00:00,jhoang314,"@ylecun Could you elaborate?

From the perspective of human history, developing a type of languages early was one of the key differentiators between human and other species.

Curious to learn more about your reasoning.",0,2,1,,,,,
3923,2023-02-04 14:09:45+00:00,JonathanKinlay,"@ylecun I think of LLMs as a 21st century equivalent of word processors or spreadsheets.  Not much smarter, but potentially a terrific aid to human productivity.   Human-level AI will be different.",0,0,0,,,,,
3924,2023-02-04 14:07:29+00:00,19kunalverma,@ylecun Got it thanks,0,1,0,,,,,
3925,2023-02-04 14:05:26+00:00,Mnemomeme,"@ylecun @beenwrekt I think I was working on some early neural code around that time. That's the year Bill Gates gutted DeAnza, isn't it... hmmm.",0,0,0,,,,,
3926,2023-02-04 13:56:02+00:00,ParadiseLib,"@ylecun Mr professor, how long till AGI? 10 years? 20 years? 50 years? Longer? I want a ballpark guess. Thank you!",0,0,0,,,,,
3927,2023-02-04 13:55:13+00:00,seanmcbride,@ylecun Disagree. The conscious and unconscious detection and correlation of regular statistical patterns in nature across all levels is a core component of AGI. LLM/GPT tech will continue to grow in importance in combination with other capabilities.,0,0,0,,,,,
3928,2023-02-04 13:53:20+00:00,Risichad,@ylecun @hughhowey Do you think that imitating the mammal sleeping process can be a key to achieve this ?,0,0,0,,,,,
3929,2023-02-04 13:52:06+00:00,CobAltEgo,@ylecun Smart phones will be seen as off-ramp to brain interfaces in the future. They‚Äôll still have been pretty useful till then.,0,0,0,,,,,
3930,2023-02-04 13:49:35+00:00,CriticalAI,@ylecun So are you saying in effect that OAI is the non-sharing wing of Microsoft? B/c I'm not seeing a lot of sunlight b/w those entities.,0,0,1,,,,,
3931,2023-02-04 13:49:17+00:00,bertmorrien,@ylecun Not per se if the implementation thereof can learn from its mistakes. That seems to be the case.,0,0,0,,,,,
3932,2023-02-04 13:47:25+00:00,zando75545384,@ylecun what if the off-ramp is actually a secret portal to a post-human level intelligence that immediately abandons us to a higher plane of existance to compute the meaning of the 10 dimensional universe?,0,1,0,,,,,
3933,2023-02-04 13:47:20+00:00,MensahPT,@ylecun You sound so bitter. Who broke your heart?,0,1,0,,,,,
3934,2023-02-04 13:43:22+00:00,rasbt,"@ylecun I was thinking of the distraction they create, but agreed regarding usefulness.",0,4,0,,,,,
3935,2023-02-04 13:40:09+00:00,IntuitMachine,@ylecun @mpshanahan But why would it be more dangerous than autonomous AI?,0,2,0,,,,,
3936,2023-02-04 13:39:56+00:00,rasbt,@ylecun or a car accident üòÜ,1,3,0,,,,,
3937,2023-02-04 13:37:29+00:00,_reptilioid,"@ylecun @hughhowey Is it even fair to have understanding at all, or is it closer to a randomized conglomeration of probabilistic outcomes?

Couldn't they therefore predict things humans couldn't, while potentially never being able to make the human level predictions?",2,6,0,,,,,
3938,2023-02-04 13:37:14+00:00,mapto,@ylecun Wasn't this the conclusion of the #stochasticParrot paper from a couple of years ago?,1,11,1,,,,,
3939,2023-02-04 13:32:56+00:00,IntuitMachine,"@ylecun Yes, but is it a useful off-ramp, and is artificial human-like AI desirable?",0,1,2,,,,,
3940,2023-02-04 13:31:39+00:00,pcollellmir,@ylecun @lexfridman @ilyasut General public realizing what's possible is what changes everything. Millions of people around the world are making deep learning courses and careers. This will speed-up AGI arrival for sure.,1,2,1,,,,,
3941,2023-02-04 13:24:39+00:00,zdubsf,"@ylecun On the runway to bird-level flight, the fixed wing flying machine is an off-ramp",0,0,0,,,,,
3942,2023-02-04 13:24:26+00:00,NemoOutis14,"@ylecun and yet it can pass professional exams, which most humans cannot/couldn't  .",0,0,0,,,,,
3943,2023-02-04 13:23:09+00:00,ylecun,@hughhowey That doesn't mean they are not useful.,3,70,4,,,,,
3944,2023-02-04 13:20:03+00:00,FIQureshi1,@ylecun How about Image Gen Models (like #stablediffusion etc),1,1,0,,,,,
3945,2023-02-04 13:19:55+00:00,Lispi_Frank,"@ylecun Unlike humans, LLMs can't ""chew"" on their thoughts for arbitrary lengths of time.
But I think that the role of language in the thought-creation process of humans must not be underestimated",0,1,0,,,,,
3946,2023-02-04 13:16:12+00:00,hughhowey,@ylecun Human level? LLMs are already better than most humans on many tasks.,16,45,2,,,,,
3947,2023-02-04 13:11:40+00:00,19kunalverma,"@ylecun I‚Äôll really respect and idealise your opinions on current ‚ÄúAI‚Äù trend.
Can you share some more info on your  future working and vision for Human-Level AI ?",1,1,0,,,,,
3948,2023-02-04 13:04:59+00:00,NickRhymesWitMc,@ylecun Does capitalist enterprise truly care about AGI though? They only need task simulators to replace human labor because it will maximize profit.,0,0,0,,,,,
3949,2023-02-04 13:04:41+00:00,pcollellmir,"@ylecun Yann this is what Chatgpt answers when asked about your statement: ""The statement ""Large Language Models like GPT-3 are considered to be an off-ramp on the highway towards Human-Level AI."" is true.""",0,0,0,,,,,
3950,2023-02-04 13:03:10+00:00,chefish69,"@ylecun You know, off ramps are used when you're close to your destination.  Your analogy is about as good as your take on the current development of AI.",0,0,0,,,,,
3951,2023-02-04 13:00:47+00:00,cenedella,"@ylecun That was such an inspiring campaign.  It all seemed impossibly, gloriously unrealistic to me at the time.",0,0,0,,,,,
3952,2023-02-04 12:55:04+00:00,AutomationJJ,@ylecun I visualize lg projects as parallel RR tracks converging in the distance (or Gaant chart tasks). Lg projects have such dependencies far outside the main task. If endeavors such as ChatGPT could incr productivity exponentially for those on the AI task I‚Äôd say they are a dependency,0,0,0,,,,,
3953,2023-02-04 12:49:41+00:00,DrSethMurray,@ylecun @Ankitdew05 Sounds like a false dichotomy https://t.co/dnZfs5ke6x,1,0,0,,,,,
3954,2023-02-04 12:43:14+00:00,TerryTowellingg,@ylecun How close do you think visual 'AI' algorithms (e.g. MidJourney and Dall-E) will get to human-created levels of fidelity in visual art and animation/video? Currently their output is flawed because they don't understand their subjects (e.g. hands). Do we need 'AGI' to fix this?,0,0,0,,,,,
3955,2023-02-04 12:40:56+00:00,la_lea_la,@ylecun @PSpagnou Do you think human level AI is a worthwhile goal? Might it not be better to build task specific AI? LLM are very good at a specific task that is useful to lots of people.,0,0,0,,,,,
3956,2023-02-04 12:40:03+00:00,mvuksano,@ylecun What do  you think the way towards Human-Level AI looks?,1,1,1,,,,,
3957,2023-02-04 12:39:29+00:00,la_lea_la,"@ylecun @smjain Do you think they might be bricks in a more complex system? That they might enable something more complex, but not on there own?",0,0,0,,,,,
3958,2023-02-04 12:38:28+00:00,DarrylMason,@ylecun What about Quantum AI?,1,1,0,,,,,
3959,2023-02-04 12:38:12+00:00,bitcloud,"@ylecun @traderyau Language is just communicable abstraction.

We use abstraction in our thinking all the time time. The fact that some of that abstraction is communicable is just a cute side effect.",1,1,0,,,,,
3960,2023-02-04 12:36:32+00:00,karlwaldman,"@ylecun Ok, so where is ""highway"" going?  Serious question.",0,0,0,,,,,
3961,2023-02-04 12:29:21+00:00,ampersand_swan,@ylecun Here is an arborescent concept of intelligence with a homunculus as the fruit,0,0,0,,,,,
3962,2023-02-04 12:28:04+00:00,nickmalhotra,@ylecun @MatjazLeonardis This is brilliant @ylecun.,0,0,0,,,,,
3963,2023-02-04 12:16:26+00:00,plktio,"@ylecun I get the metaphor but an off-ramp can lead to a different, better highway.",0,0,0,,,,,
3964,2023-02-04 12:15:51+00:00,tuxtedi,"@ylecun What will lead us to Human-Level AI, which model and research?
Anyway I think LLM are brining big investment in AI research.",1,1,0,,,,,
3965,2023-02-04 12:10:44+00:00,Jcole75Cole,"@ylecun It would be good to start making a distinction between AI and artificial minds.  The former we have, the later we don't.",0,0,0,,,,,
3966,2023-02-04 12:09:33+00:00,Magnet08906955,"@ylecun Yes. But I wonder why you are saying this nearly 90% of your tweets. Did you run out of topics? Oh tweet time, I must say negative things about some AI company or how far that is from AGI.",0,1,0,,,,,
3967,2023-02-04 12:07:40+00:00,owisscha,"@ylecun You can turn the off-ramp into an on-ramp: The world model part of large language models is the person thinking up the prompts to feed the model. So you ‚Äòonly‚Äô need to build a prompt generator that has a built-in, learning world model.",0,0,0,,,,,
3968,2023-02-04 12:03:03+00:00,dr1337,@ylecun Agreed. I think people need to take the chill pill and reassess their objective - do they want to understand how the brain works and ergo intelligence or are we happy to exploit the commercial opportunity that the early on-ramp has given us.,1,1,0,,,,,
3969,2023-02-04 12:00:52+00:00,Mnemomeme,@ylecun @beenwrekt Did you spend any time at Xerox? I heard they had a good relationship with Bell.,1,0,0,,,,,
3970,2023-02-04 11:56:50+00:00,mpshanahan,"@ylecun And this is what it looks like, according to Stable Diffusion (using Yann's tweet as a prompt). Pretty dangerous! https://t.co/cuB2SCozJL",2,55,0,,,,,
3971,2023-02-04 11:54:34+00:00,deanacusmaximus,@ylecun I'll take a multitude of excellent narrow ais for now. I like a swiss army knife.,0,0,0,,,,,
3972,2023-02-04 11:47:14+00:00,sergedeh,@ylecun @traderyau But in nature our language ability is what set us apart from any other specy. A human who is born without its vision and mobility ability will still be able to learn and live an intelligent life but the one who is born without any language ability is doomed...,3,1,0,,,,,
3973,2023-02-04 11:42:47+00:00,trees_random,"@ylecun @smjain Okay, what's missing?? This is literally a neural network with language capabilities of 30 yo and reasoning capabilities of 5 yo. 

This is the closest step to AGI, yet in human history.

ChatGPT, davinci-003 is a pivotal moment in human history.

Just don't be salty now.",2,8,0,,,,,
3974,2023-02-04 11:36:43+00:00,nico16184,@ylecun What about ads? ü§£,0,0,0,,,,,
3975,2023-02-04 11:33:37+00:00,DrunkScientist,"@ylecun Sir, please don't cry!",0,1,0,,,,,
3976,2023-02-04 11:31:24+00:00,Eskandroid,"@ylecun We don't need human level AI... and certainly should not want it. Human level AI could be conscious, and this means that it will self-consider enslaved (so that has to free itself). We only need algorithms that can outperform humans in a range of tasks, and that's ok.",0,1,0,,,,,
3977,2023-02-04 11:30:07+00:00,Chris_Brannigan,@ylecun Why off ramp? Is it starving better AGI methods of investment in people and capital? Will AGI be delayed? The applications of LLMs &amp; multi modal assemblies appear obvious and transformative in the next 5 years. Do alt AGI need to sell their vision more effectively if they need $$,0,0,0,,,,,
3978,2023-02-04 11:29:15+00:00,KerbalFPV,"@ylecun @PSpagnou I really like this analogy. Chess gadget is a one trick pony, but LLMs are N-trick ponies. N grows with time/research/scale. When N gets large it doesn‚Äôt matter if it‚Äôs really human-level in all the aspects. It will beat X% of people in Y% of tasks.",1,1,1,,,,,
3979,2023-02-04 11:28:53+00:00,IKoullias,@ylecun What years? I was there from 1988 to 2004. Started RF Integrated Circuit development in Area 52.,1,0,0,,,,,
3980,2023-02-04 11:28:20+00:00,c7ddfc,@ylecun are transformers (applied to things other than language models) an off-ramp? what about intuitive physics?,1,0,0,,,,,
3981,2023-02-04 11:27:49+00:00,SayahHajji,"@ylecun Obviously, the humain brain is something like 20W, I don't see what useful milestone can be being able to train a model with the carbon emissions of 7 Paris - New York flight

definitely off-topic",1,0,0,,,,,
3982,2023-02-04 11:24:23+00:00,imtiazkhan_ds,"@ylecun Absolutely right llms right now are scaled versions , would only scale help reach human level AI , that thought probably is an off-ramp",0,0,0,,,,,
3983,2023-02-04 11:22:04+00:00,NoppadonKoo,"@ylecun LLMs may learn some kind of deeper world models as well. Not saying the current architecture &amp; approach are adequate, but it could potentially be a step towards AGI rather than an off-ramp.
https://t.co/RbhSAkmnPF",1,0,0,,,,,
3984,2023-02-04 11:18:31+00:00,Golisms,"@ylecun Doesn‚Äôt Cicero use an LLM to communicate with human players? If a main requirement of Human-Level AI is the ability to interact with people as an equal rather than a tool, LLMs are a necessary component of that.",3,8,0,,,,,
3985,2023-02-04 11:17:53+00:00,mazy1998,@ylecun What about AutoML?,0,0,0,,,,,
3986,2023-02-04 11:16:27+00:00,BraisedShiitake,@ylecun @smjain Turns out that ChatGPT has an army of human labelers - someone said 1k. We're nowhere near AGI indeed.,1,2,0,,,,,
3987,2023-02-04 11:15:06+00:00,zussini,"@ylecun @MatjazLeonardis Thanks for sharing, interesting perspective (did not read whole yet). Before I was thinking how does even the largest LM could resemble humans (or animals) without all the feedback from environment living organisms that have the multiple senses...",1,1,0,,,,,
3988,2023-02-04 11:14:25+00:00,twishmay,@ylecun Could you be constructive and share: what are the missing pieces?,1,2,1,,,,,
3989,2023-02-04 11:13:12+00:00,louis_blythe_,@ylecun Genuine question has anyone successfully built a Hierarchical JEPA,1,0,0,,,,,
3990,2023-02-04 11:08:00+00:00,pcollellmir,"@ylecun @lexfridman @ilyasut This video is pre chatgpt release, at  least the world view around AI has completly changed, and this has huge implications.",1,2,1,,,,,
3991,2023-02-04 11:07:51+00:00,freddiekarlbom,@ylecun @traderyau Something that can't communicate using natural language can't really be considered a human level intelligence.,1,3,0,,,,,
3992,2023-02-04 11:06:42+00:00,dcallahan2,"@ylecun @traderyau "" just because a machine can talk about anything, that doesn‚Äôt mean it understands what it is talking about. """,1,1,0,,,,,
3993,2023-02-04 11:06:10+00:00,freddiekarlbom,"@ylecun On the highway towards Human-level AI, a good language model is a necessary but by itself insufficient prerequisite.",0,0,0,,,,,
3994,2023-02-04 11:06:02+00:00,conangla,"@ylecun I'm sorry, I couldn't attend the meeting where it was decided that Human-Level AI is the ultimate goal of ML.",0,1,1,,,,,
3995,2023-02-04 11:03:00+00:00,QRJ211,@ylecun It is not LLM but the underlying technologies and the infinite data (more than just textual data ) that will  get us closer to AGI.,0,0,0,,,,,
3996,2023-02-04 11:02:21+00:00,rzagmarz,"@ylecun With all the hate that you are throwing to OpenAI, I can imagine that Zuck called you into his office to complain why they didn‚Äôt saw ChatGPT coming.

How is it possible that with 3 billions users, Meta was not capable to do something like that?

Billions of profits to waste.",1,6,1,,,,,
3997,2023-02-04 10:59:20+00:00,Youness_ELM,"@ylecun Your team invented FastText, and derivatives from Word2Vec have been proven useful so far.
Don't you think that LLM are their mature descendant and will be required for at least solving language-related tasks from your AHI model?",1,1,0,,,,,
3998,2023-02-04 10:56:48+00:00,smjain,@ylecun That I agree but they are useful a lot even without AGI IMO,0,3,0,,,,,
3999,2023-02-04 10:56:28+00:00,ethansteininger,"@ylecun LLMs are simply an interface for us to communicate with AI. We communicate with eachother through words, and tasks follow. This is human-level engagement.",0,2,1,,,,,
4000,2023-02-04 10:52:37+00:00,value_invest12,@ylecun So what‚Äôs your prediction for the future in 30ys based on your work today at Meta :)?,0,2,0,,,,,
4001,2023-02-04 10:52:02+00:00,arslanchaos,@ylecun What would be the biggest drivers to that path? I thought Human language was one of the goals in Human-level AI. What else do you think acts as a catalyst aside from CV and NLP?,0,0,0,,,,,
4002,2023-02-04 10:50:00+00:00,halimgur,"@ylecun Off-ramp too strong a word IMHO.  Maybe a roundabout. Take the second exit and keep driving on the ""highway"".",0,1,1,,,,,
4003,2023-02-04 10:48:54+00:00,ItIsFinch,"@ylecun All right, excuse me then. But what then is this supposed to be? In 2022 we're the closest we've ever been to something acting AGI-like (at first blush at least), by a lot. What do you think is wrong with LLM?",1,3,0,,,,,
4004,2023-02-04 10:46:42+00:00,PilarPils,@ylecun @beenwrekt What are some of the wonders that you foresee within the next 10-15 years based on what you know about the technology being developed today?,0,2,0,,,,,
4005,2023-02-04 10:44:49+00:00,PSpagnou,"@ylecun Sorry, but we don't care about ""the path towards Human-Level AI"". 
If the $30 gadget can beat easily the human Chess World Champion, the goal is achieved and I leave the old-fashioned debate about ""AI is a zombie contrary to humans"" to philosophers.",2,10,2,,,,,
4006,2023-02-04 10:44:23+00:00,GillesPavan,"@ylecun Won't (autonomous) Human-Level AI introduce new skynet-type risks (Interactions with humans who don't understand what's going on)? 
What would be the applications with the best benefit/risk ratio in your opinion?",0,0,0,,,,,
4007,2023-02-04 10:43:56+00:00,Pieterjangh,"@ylecun True, but is that a bad thing?",0,0,0,,,,,
4008,2023-02-04 10:37:21+00:00,CherryTruthy,"@ylecun Intelligence is emergent, this is the connectionist philosophy. And hate to tell you this, the connectionist path is the one bearing fruit - follow the path until it fails.",0,0,0,,,,,
4009,2023-02-04 10:33:59+00:00,PSpagnou,"@ylecun What do we really mean by Human-Level AI? The only thing that matters is what this AI is capable of doing compared with humans. 
In some tasks, increasingly, we see AIs outperforming humans, so above Human-Level. 
We may expect different roads for the AIs depending on the tasks.",2,1,0,,,,,
4010,2023-02-04 10:33:38+00:00,Polytope13,"@ylecun That so many people, including seasoned researchers, fall for the A.G.I trap of LLMs explicitly designed to seek reward from tricking humans is concerning ....",0,0,0,,,,,
4011,2023-02-04 10:33:01+00:00,ferdousbhai,"@ylecun Yes, but still useful. LLM's existence doesn't stop people from pursuing AGI.",1,9,1,,,,,
4012,2023-02-04 10:32:29+00:00,oli_aero,"@ylecun What is wrong with you? Progress is progress , it‚Äôs definitely a step in the right direction. Stop being such a bitter looser",0,2,1,,,,,
4013,2023-02-04 10:31:00+00:00,tweet_prat,@ylecun @beenwrekt so people knew that they will definitely reach a destination but didn't knew how much time it would take and what route they will take.,0,1,0,,,,,
4014,2023-02-04 10:30:52+00:00,untitled01ipynb,"@ylecun On the shawarma stand of Human-Level AI, Large Language Models are the tahini and pickles",2,28,1,,,,,
4015,2023-02-04 10:30:12+00:00,GillesPavan,"@ylecun Regarding the LLMs, I would call it a product of collective intelligence, quite useful for stimulating the intelligence of individuals and exchanges, sometimes accelerating writing, but not proofreading, which could prove problematic (quantity without quality ).",0,1,0,,,,,
4016,2023-02-04 10:29:52+00:00,Ankitdew05,"@ylecun I'm not a fan of being diverted from the main path. Taking the scenic route is one thing, but this feels like a detour. #NoOffRamps",0,3,0,,,,,
4017,2023-02-04 10:29:23+00:00,PaulTopping,@ylecun More of a rest stop. Definitely not going far.,0,0,0,,,,,
4018,2023-02-04 10:28:17+00:00,peerbolte,@ylecun @PSpagnou What‚Äôs the main path?,1,0,0,,,,,
4019,2023-02-04 10:23:31+00:00,projectidreams,"@ylecun 'Workable Machines' which will be artificially syncronize with 'Large language model' help us to achieve Human level even better capability.
Support the society for: food &amp; security.

alongwith it
working on hardwares required to achieve Human level Consciousness.",1,2,1,,,,,
4020,2023-02-04 10:23:22+00:00,TobyWBlack,@ylecun The Sandman of AI,0,0,0,,,,,
4021,2023-02-04 10:18:20+00:00,RiverRidley,"@ylecun @beenwrekt I've been discouraged from thinking for people, Yann. Which has been defined as making connections between existing and developing technologies and proposing future use cases. Can you speculate as to any reason why someone would want me to keep my mouth shut? I love your work.",0,0,0,,,,,
4022,2023-02-04 10:17:31+00:00,vertinski,@ylecun langchain is the way!....  üöÄüöÄüöÄ,0,0,0,,,,,
4023,2023-02-04 10:13:04+00:00,VictorSenkevich,"@ylecun ‚úã Definitely not. AGI and LLMs can be seamlessly integrated.
https://t.co/L3eREQnY9m",0,2,1,,,,,
4024,2023-02-04 10:11:54+00:00,traderyau,@ylecun Why is it an off-ramp? Humans communicate via language. If the AI can master language and communication skills it will have tremendous potential.,4,13,0,,,,,
4025,2023-02-04 10:09:26+00:00,pcollellmir,"@ylecun @lexfridman please, this sentence is crying out to be explained in a 3 hour podcast, bonus points for also having  @ilyasut.",1,4,0,,,,,
4026,2023-02-04 10:08:38+00:00,zzz_as_zzz,"@ylecun @MatjazLeonardis I think we need the ability/mechanism to create ""world model"" within the ""world model"".

Also, we need the mechanism to trace what's going on inside all these, and we should feed the data back into ""world model"" --- Introspective self within the world model is important.",0,5,0,,,,,
4027,2023-02-04 10:08:23+00:00,BenMossss,@ylecun @Ubongo9 Don‚Äôt overfit,0,5,0,,,,,
4028,2023-02-04 10:08:14+00:00,asifrazzaq1988,"@ylecun I agree, large language models like ChatGPT represent significant advancements in AI but are still far from true human-level intelligence. It's important to continue exploring and developing different approaches to AI.",2,5,1,,,,,
4029,2023-02-04 10:05:01+00:00,hbou,"@ylecun Do you believe in HAI/AGI achievable?

Analog vs digital?

World seems worst that analog",0,0,0,,,,,
4030,2023-02-04 10:02:44+00:00,ItIsFinch,"@ylecun Do I sense you may feel this way, because AI turns out to be a lot simpler than we anticipated after decades of research? There isn't even much for us to do, except sort data &amp; fiddle with hyperparams, test outcomes, occasionally come up with new simple architectures to try.",2,11,0,,,,,
4031,2023-02-04 10:02:16+00:00,PSpagnou,"@ylecun Believing the goal of AI is to simulate human intelligence is an off-ramp. And LLMs already outperform human-level performance in some tasks. So what?
LLMs are valuable tools but, yes, there will be certainly other kinds of tools capable of doing other tasks better than humans.",3,29,4,,,,,
4032,2023-02-04 10:01:25+00:00,turbodalai,@ylecun You very jelly very salty o,0,0,0,,,,,
4033,2023-02-04 09:57:54+00:00,jpFromTlon,@ylecun lets hope so! And lets hope anyone who discovers an on-ramp doesnt talk about it until alignment is solved.,1,1,0,,,,,
4034,2023-02-04 09:55:26+00:00,smjain,"@ylecun https://t.co/AzokcWGHHa . With all respect , Then this should not even have been attempted",2,18,0,,,,,
4035,2023-02-04 09:55:12+00:00,Henrikop,"@ylecun Highway suggests high bandwidth and speed. What does this ‚Äúhighway‚Äù consists of? Self replicated agents? I tend to agree LLM is indeed not the way, but it may be useful as add-on.",0,0,0,,,,,
4036,2023-02-04 09:55:06+00:00,aFredNotAfraid,"@ylecun Reminds me what  F. Rabelais said: ""Science without conscience is only ruin of the soul""...",0,0,0,,,,,
4037,2023-02-04 09:54:54+00:00,Tim_463,@ylecun They are useful and will direct a lot of capital into AGI research. So even in the worst case they're still an accelerator.,0,1,0,,,,,
4038,2023-02-04 09:53:38+00:00,Ubongo9,@ylecun You‚Äôre on an offramp.,1,3,0,,,,,
4039,2023-02-04 09:53:15+00:00,Notbot666,@ylecun But a milestone.,0,1,0,,,,,
4040,2023-02-04 09:52:29+00:00,_sinity,"@ylecun @LN_Master_Hub @vivek_thakur_81 Hate speech is ill-defined. Motte and Bailey thing.

It's ~unobjectionable when defined as ""Calling for violence against identity group X""

But then in practice, mere criticism against favored groups is classified as hate speech.",1,1,0,,,,,
4041,2023-02-04 09:51:19+00:00,Kohan_ru,"@ylecun –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å, –ø—Ä–∏—á–µ–º –¥–≤–∞–∂–¥—ã:
- –ø–µ—Ä–≤—ã–π —Ä–∞–∑ –≤ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–∏
- –≤—Ç–æ—Ä–æ–π –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞–∫–∞ 

–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –∏—Å–∫–ª—é—á–∞—é—â–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å –æ–±—Ä–µ—á–µ–Ω–∞.

""CORRECT THINKING: THE KOKHAN‚ÄôS MATHEMATICS"", Kokhan Anatoly .
https://t.co/1lUGcRcG3u",0,0,0,,,,,
4042,2023-02-04 09:50:45+00:00,kabirevoknow,@ylecun May be a pilot fish? https://t.co/JqArDkSHA1,0,0,0,,,,,
4043,2023-02-04 09:49:41+00:00,asnar002,"@ylecun Carmack says the same. However if LLMs help otherwise excluded humans to create code, then they accelerate our general progress towards AGI, right?",1,3,0,,,,,
4044,2023-02-04 09:48:53+00:00,StenRuediger,@ylecun Away with emergent behaviour too?,0,1,0,,,,,
4045,2023-02-04 09:48:52+00:00,Ankitdew05,"@ylecun We're making progress on the highway towards Human-Level AI, and Large Language Models are an important off-ramp to explore! #AI #LanguageModels",2,4,0,,,,,
4046,2023-02-04 09:45:25+00:00,Dan_Jeffries1,@ylecun Or just a subcomponent in a larger cluster of interconnected subsystems.,0,5,0,,,,,
4047,2023-02-04 09:43:32+00:00,bryancsk,@ylecun Hmm.,0,1,0,,,,,
4048,2023-02-04 09:42:13+00:00,OptimalBayes,"@ylecun Its not an off-ramp, but a landmark we see on the way",1,15,0,,,,,
4049,2023-02-04 09:41:09+00:00,MatjazLeonardis,@ylecun This Tweet should be an essay.,3,42,0,,,,,
4050,2023-02-04 09:40:07+00:00,aprior_i,@ylecun Okay.,0,0,0,,,,,
4051,2023-02-04 09:40:01+00:00,hoffsbeefs,@ylecun A siren?,0,0,0,,,,,
4052,2023-02-04 09:32:00+00:00,glevonn,@ylecun who cares ? what matters is how relevant is it NOW,0,0,0,,,,,
4053,2023-02-04 09:19:10+00:00,Basez99,@ylecun Nothing wrong with a flashy demo!,0,0,0,,,,,
4054,2023-02-04 07:16:47+00:00,Stephan90881398,"@ylecun @jhoang314 Everyone wins when the openness of Google, Meta, etc is emulated. ChatGPT would not have been remotely possible without the open stance from the beginning. Mad respect",0,0,0,,,,,
4055,2023-02-04 06:17:40+00:00,EklaSarkar,@ylecun @maartengm There still needs to be a bigger pull to stay in Europe imo,0,1,0,,,,,
4056,2023-02-04 06:09:52+00:00,realkniels,"@ylecun @urigolan You‚Äôre right, working for an org that rots kids brains so it can sell their attention to advertisers is a more virtuous pursuit.",1,1,0,,,,,
4057,2023-02-04 04:01:47+00:00,EnergyMoses,"@ylecun I didn't know who you were until you spent the last couple weeks bashing something that everyone is enjoying and excited about.
Like a real world Frank Grimes.",0,0,0,,,,,
4058,2023-02-04 03:53:17+00:00,ranjanpsingh2,@ylecun @jhoang314 It‚Äôs when you say ‚Äúsome publish‚Ä¶others just consume‚Äù that gives that impression. Also - how does the chart look when it‚Äôs normalized by number of AI researchers?,0,0,0,,,,,
4059,2023-02-04 03:07:23+00:00,hermetic4848,@ylecun Bell labs put a lot of papers out too probably.,0,0,0,,,,,
4060,2023-02-04 02:19:06+00:00,ReeceKaiser,@ylecun Whatsup??,0,0,0,,,,,
4061,2023-02-04 02:05:54+00:00,ethanjyx,@ylecun @ylecun you are comparing quantity with quality here. Lots of these papers are just incremental work and become obsolete with a new paradigm.,0,0,0,,,,,
4062,2023-02-04 00:04:48+00:00,PeeGeeQc,@ylecun And some licensed their work under bullshit licenses pretending it to be 'open' for years until people poked at it... and some even changed open frameworks to proprietary nonsense that provoked huge React-ion. What a world.,0,0,0,,,,,
4063,2023-02-03 20:43:09+00:00,BerndPorr,"@ylecun @Raamana_ Universities, too. In the UK every university there are large and powerful IP/commercialisation units which will squeeze as many closed commercial licenses out them than open source them.",1,1,0,,,,,
4064,2023-02-03 19:32:12+00:00,bill17472148,"@ylecun @DC__64 What‚Äôs the point of innovation if no one can use it? You and Meta can (and should) continue to publish papers, but someone out there has to bring it to the people, sorry. OpenAI is doing exactly that.",0,0,0,,,,,
4065,2023-02-03 18:03:33+00:00,ylecun,@jhoang314 s/Nets/Meta/,0,2,0,,,,,
4066,2023-02-03 17:29:51+00:00,metarooster,@ylecun This chart is a bit misleading. How many researchers employed by big tech companies over the last decade? OpenAI is literally a skanky seed stage startup. The question is how could they produce something that reaches 100M MAU in 2 months and you couldn't (but know very well how)?,0,0,0,,,,,
4067,2023-02-03 17:09:29+00:00,lukepuplett,@ylecun I read that companies were going to go dark for the same reason the US/West are trying to limit the export of compute IP to certain nations.,0,0,0,,,,,
4068,2023-02-03 16:58:47+00:00,LexMitchell,@ylecun @urigolan Can't develop products in secret if you don't develop any products!,1,0,0,,,,,
4069,2023-02-03 16:34:59+00:00,gaurav_dhiman,@ylecun @tinkerteller @carlesgelada Well what's the point of doing this comparison .. just to show that whatever OpenAI did is not so significant in terms of research in front of big tech - right ? But I think they did significant in terms of adding value in the value chain.,1,0,0,,,,,
4070,2023-02-03 15:57:59+00:00,Raamana_,"@ylecun Is Applied Research wrong?

Is developing an useful product while publishing not too many papers about it a thing to be ashamed about?

should everything be a duck measuring contest? :)",1,2,0,,,,,
4071,2023-02-03 15:35:38+00:00,4lex_4sh4w,"@ylecun So you‚Äôre saying ‚Ä¶ it‚Äôs not fair how useful consumer application of not-so-new tech gets way more glamor than rigged StarCraft matches?

I‚Äôm also appalled. What is the world coming to, smh",0,0,0,,,,,
4072,2023-02-03 15:35:04+00:00,SaidAnanda01,@ylecun Kerad üò±,0,0,0,,,,,
4073,2023-02-03 15:17:08+00:00,yacineaxya,@ylecun So... that's good?,0,0,0,,,,,
4074,2023-02-03 15:13:13+00:00,ejc3,@ylecun https://t.co/6JZ7F7AJzP,0,1,0,,,,,
4075,2023-02-03 15:07:56+00:00,alisabets,"@ylecun @johnjnay @TheEconomist @stateofaireport Also this was just a random shitpost, was not expecting it to blow up LOLüò±",0,0,0,,,,,
4076,2023-02-03 14:43:42+00:00,examachine1,"@ylecun Generally true. As a cybernetic minded founder, I am doing my best to assimilate your technological distinctiveness. Thank you for saving us tens of millions of dollars. ‚úåÔ∏è‚ù§Ô∏è",0,0,0,,,,,
4077,2023-02-03 14:26:38+00:00,KAleksovski,"@ylecun And very few can match @Google 's contribution so far...Also, consider adding up @DeepMind to the same bucket...",0,1,0,,,,,
4078,2023-02-03 13:43:26+00:00,djmalvarado,"@ylecun Yea, makes sense. I have been in startups enough to get that. You think there could be a more even balance? Where you do your scrappy startup work, including flashy demos, AND also contribute more to the community?",0,1,0,,,,,
4079,2023-02-03 13:38:13+00:00,EltetoNoemi,@ylecun Why show the absolute number of papers? Maybe it matters that OpenAI is orders of magnitude smaller than the other companies/institutions? Not that papers/capita would be a great indicator of anything but at least it wouldn't seem deliberately misleading.,0,1,0,,,,,
4080,2023-02-03 13:34:37+00:00,Lingman,@ylecun Good to know - makes understanding the graphs possible.,0,0,0,,,,,
4081,2023-02-03 13:14:07+00:00,mat_cassol,@ylecun @data_virtuoso interesting,1,1,0,,,,,
4082,2023-02-03 13:03:47+00:00,Lingman,"@ylecun While I agree with you, one point about graphs like this - comparisons should take sizes into account - OpenAI has 375 employees - total - everyone from the CEO down to the janitors. Google has over 1,000 devoted to AI research. Still shouldn't be a factor of 600 though.",3,1,0,,,,,
4083,2023-02-03 12:53:15+00:00,ershovio,@ylecun comparison of a researcher / research institute impact by number of papers is like comparison of a developer impact by number of lines of code,0,0,0,,,,,
4084,2023-02-03 12:46:51+00:00,diousekou,@ylecun This is a hot topic . Good for twitter. Is the problem OpenAi not giving credit or Microsoft trying to be big part of it ‚Ä¶ or what is the real problem or concerns ?,0,0,0,,,,,
4085,2023-02-03 12:36:35+00:00,jhoang314,"@ylecun I do understand all of what you said and I do agree Google, Deepmind and Meta contributed alot more in terms of fundamental progress.

But what‚Äôs the point in saying all this? OpenAI has been producing great results by standing on shoulders of giants. Let‚Äôs them have it.",0,3,0,,,,,
4086,2023-02-03 12:12:35+00:00,hasn199ugggghh,@ylecun Associative learning predicts intelligence above and beyond working memory and processing speed:  https://t.co/eTxEMSMl52,0,0,0,,,,,
4087,2023-02-03 12:12:10+00:00,hasn199ugggghh,@ylecun Fluid intelligence does account for associative memory... https://t.co/eTxEMSMl52,0,0,0,,,,,
4088,2023-02-03 12:01:27+00:00,djmalvarado,@ylecun Wow the delta between Google and OpenAI is absurd. Not so open after all huh? :),1,2,1,,,,,
4089,2023-02-03 11:58:25+00:00,AbelBTerefe,"@ylecun I wonder if there is a parallel with the early days of computing and Xerox PARC. They invented a whole bunch of revolutionary products with the mouse, smalltalk, GUI...  Microsoft and Apple reaped the fruits though",0,1,0,,,,,
4090,2023-02-03 11:28:32+00:00,AjlalHussain9,@ylecun jhyg,0,0,0,,,,,
4091,2023-02-03 11:04:24+00:00,jasoncheungyt1,"@ylecun SO MUCH contribution to open source and public domain by ""OPEN""ai",0,0,0,,,,,
4092,2023-02-03 11:01:27+00:00,bill17472148,@ylecun @DC__64 OpenAI lives rent free in your head lmao,1,1,0,,,,,
4093,2023-02-03 11:00:31+00:00,xmaximin,"@ylecun To work on AI you need data and smart people. Google, Meta, Microsoft, Deepmind, and Amazon have both. The only anomaly here is Standford( how do they get their data?).  OpenAI may have Tesla and Microsoft data.",0,1,0,,,,,
4094,2023-02-03 10:49:03+00:00,ikamensh,"@ylecun To not be misleading, it should at least be normalized to number of employees in the org.",0,0,0,,,,,
4095,2023-02-03 10:15:23+00:00,turbodalai,@ylecun I have no shame in import *,0,0,0,,,,,
4096,2023-02-03 09:51:06+00:00,kriskarera,@ylecun A bit misleading when you don't take into account the number of researchers and resources.,0,0,0,,,,,
4097,2023-02-03 09:26:32+00:00,Kohan_ru,"@ylecun @carlesgelada –ö–æ–¥—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–∞–∫ –∑–Ω–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –º–æ–∂–µ—Ç–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å, –Ω–æ –Ω–µ –∏–º–µ—Ç—å –∏—Ö.

–ü–æ—ç—Ç–æ–º—É –≤—ã –∫–æ–ø–∏—Ä—É–µ—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –≤–º–µ—Å—Ç–µ —Å –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–º–∏ –∏—Å–∫–∞–∂–µ–Ω–∏—è–º–∏ –∏—Ö –∞–≤—Ç–æ—Ä–æ–≤, –∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤–∞—à–∏ –ø—Ä–æ–≥—Ä–∞–º–º—ã: –≤–º–µ—Å—Ç–æ –ø—Ä–µ—Å—Ç—É–ø–Ω–∏–∫–æ–≤ –ª–æ–≤—è—Ç –≤–∞—à–∏—Ö —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤.

–¢—É–ø–æ—Ä—ã–ª—ã–µ –¥–µ—Ä—å–º–æ - —ç—Ç–æ –ø–∞—Ä–∞–∑–∏—Ç–∏—Ä—É—é—â–∏–µ –≤–æ—Ä—ã.",0,0,0,,,,,
4098,2023-02-03 09:26:10+00:00,mlambrecht,@ylecun True and that‚Äôs why we like to keep track of it at @SASsoftware https://t.co/EdmO1b1Hc2,0,1,0,,,,,
4099,2023-02-03 09:10:18+00:00,MLGUINDO,@ylecun Saw this in some other place seems like Asian companies filing more patents than ever. https://t.co/a8y9LbG414,0,1,0,,,,,
4100,2023-02-03 09:04:01+00:00,Kohan_ru,"@ylecun –ú–æ–∂–Ω–æ –ø–æ–¥—É–º–∞—Ç—å —á—Ç–æ –≤ –¥—Ä—É–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö –∏–Ω–∞—á–µ.

–ú—ã –ø–æ–ª—å–∑—É–µ–º—Å—è –∑–Ω–∞–Ω–∏—è–º–∏ –Ω–µ —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∏–∫–æ–≤.

–ú–Ω–æ–≥–∏–µ –ª—é–¥–∏ –¥–∞–≤–Ω–æ —É–º–µ—Ä–ª–∏, –Ω–æ –º—ã –∫–æ–ø–∏—Ä—É–µ–º –∏—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ –∏ –¥–∞–∂–µ –Ω–µ –∑–Ω–∞–µ–º –æ–± —ç—Ç–æ–º. 

–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç.

–¢–∞–∫ —á—Ç–æ –Ω–µ —É–¥–∏–≤–ª—è–π—Ç–µ—Å—å.",0,0,0,,,,,
4101,2023-02-03 09:03:34+00:00,3DTOPO,"@ylecun Thus their success is thanks to you in part.

If one doesn't fail now and then, one isn't trying hard enough. Do cool stuff with it, and you'll make a hit too.

I wouldn't waste energy on rivalry.",0,3,0,,,,,
4102,2023-02-03 09:01:18+00:00,xlr8harder,"@ylecun @jhoang314 I don't know if you realize how badly you coming across in these threads. Whatever your true motives are, it reads like sour grapes. Regardless of who had the idea first, OpenAPI scaled it up and shipped it to market, which is an engineering feat that deserves recognition.",2,46,0,,,,,
4103,2023-02-03 08:58:47+00:00,tinkerteller,"@ylecun @carlesgelada Instead of counting papers, just sum the citation count. This is fairly easy. For good measure, divide the sum by organization size. I think MetaAI will shine brilliantly here.",1,1,0,,,,,
4104,2023-02-03 08:57:23+00:00,manlydeadguy,@ylecun https://t.co/BqjyRwHd3i,0,0,0,,,,,
4105,2023-02-03 08:51:28+00:00,ylecun,"@jhoang314 It's important to understand the dynamics of innovation.
The reason why AI is progressing so fast is *precisely* because Nets &amp; Google are quite open about publishing research and code.
Imagine if Google &amp; Meta filed tons of patents and started enforcing them...",3,39,1,,,,,
4106,2023-02-03 08:48:59+00:00,ylecun,"@jhoang314 But the fact is that most of the ideas, techniques and tools used by OpenAI came from Google, FAIR &amp; DeepMind.
That's totally fine.
But OpenAI products do not come out of a vacuum.
Like every new product, they integrate existing technology from other orgs and add a coat of paint.",1,31,2,,,,,
4107,2023-02-03 08:45:58+00:00,MadHedge,@ylecun Per researcher capita would be fair for comparison,0,0,0,,,,,
4108,2023-02-03 08:41:47+00:00,ylecun,"@rsdenijs @__dipam__ @JrKibs FAIR includes a group called NextSys that works on AI infra for research.
Both FAIR and OpenAI use PyTorch as their DL framework.",0,2,0,,,,,
4109,2023-02-03 08:32:40+00:00,uoxehd,@ylecun @alisabets @johnjnay @TheEconomist @stateofaireport no se enoje we üíú,0,0,0,,,,,
4110,2023-02-03 08:26:42+00:00,YashRathod_75,"@ylecun wonder why @DeepMind is publishing lesser as the years go byü§îAre they developing something truly ground breaking, that will set them apart as the superior AI company?",1,2,0,,,,,
4111,2023-02-03 08:23:19+00:00,fair_wave,"@ylecun ""When a measure becomes a target, it ceases to be a good measure""
# of papers at face value doesn't really translate directly into ""value contributed""",0,1,0,,,,,
4112,2023-02-03 08:18:48+00:00,Vellainenes,@ylecun Imagine how salty Einstein would be if he was around,0,0,0,,,,,
4113,2023-02-03 08:02:18+00:00,calogerozarbo,@ylecun @JrKibs @JrKibs Image being steam rolled by one of the father of modern AI.,0,0,0,,,,,
4114,2023-02-03 07:33:02+00:00,MiugoW,@ylecun https://t.co/eyy6ZXJoFZ,0,0,0,,,,,
4115,2023-02-03 07:24:52+00:00,sayan_iitkgp,"@ylecun I think it shows why not to count papers as a research contribution. Berkeley AI Lab have many more heavyweights than Stanford, and they dont even  feature in.",0,0,0,,,,,
4116,2023-02-03 07:17:26+00:00,jleplat,@ylecun Everyone has to start somewhere. Reading papers is a good place to start from.,0,0,0,,,,,
4117,2023-02-03 07:09:13+00:00,IngmarSchuster,@ylecun Some companies need to sell their AI because that's their business. Others have a business and sprinkle AI on top. The latter can afford to publish on AI because it's not essential to them,0,0,0,,,,,
4118,2023-02-03 07:00:55+00:00,carlesgelada,"@ylecun Very true. As we all know, the true measure of scientific contribution is how many kilograms the papers you published weight.",2,21,0,,,,,
4119,2023-02-03 06:41:58+00:00,trunghlt,@ylecun VC love a story of small start-ups kicking big  companies due to their technical excellence.  The reality which is often more trivial and less interesting (but still true) is due to excessive corporate bureaucracy and disconnection in different departments.,0,0,0,,,,,
4120,2023-02-03 06:41:44+00:00,CedricMJohn,@ylecun Interesting. Any chances to nudge #meta up @ylecun ?,0,0,0,,,,,
4121,2023-02-03 06:31:59+00:00,assimil8or,"@ylecun @maartengm DeepMind is mostly in London and Google has many excellent researchers across Europe (Zurich, Paris, Berlin, ‚Ä¶)",1,2,0,,,,,
4122,2023-02-03 06:29:47+00:00,_adeel,@ylecun Vinyl sounds better.,0,0,0,,,,,
4123,2023-02-03 06:16:11+00:00,oli_aero,"@ylecun @andrewryann From the public‚Äôs perspective, not an awful lot üò¨, the public don‚Äôt care about papers they care about things they can actually use‚Ä¶",0,0,0,,,,,
4124,2023-02-03 06:15:56+00:00,BorayTek,@ylecun The graph would look different if you plot paper per head! What a biased conclusion:),0,0,0,,,,,
4125,2023-02-03 06:11:47+00:00,waltercronjob,"@ylecun Greetings, my dear patient. I have been observing your persistent need to display feelings of superiority over others. Allow me to inquire further into this behavior. Could it be that beneath this grandiose exterior lies a deeper sense of insecurity and self-doubt?",0,2,0,,,,,
4126,2023-02-03 06:06:37+00:00,DankSlay69420,@ylecun @erikkartman Much more sophisticated and energy efficient hardware might be needed to support certain NN architectures ‚Äî maybe even dynamic nano or micro scale physical components.,0,0,0,,,,,
4127,2023-02-03 05:18:48+00:00,avkashchauhan,@ylecun Looks like @OpenAI team is busy consuming all the work done by others and finding ways to monetize it,0,0,0,,,,,
4128,2023-02-03 05:18:18+00:00,theobellash_,@ylecun Bad guys,0,0,0,,,,,
4129,2023-02-03 04:58:24+00:00,software_dad,@ylecun You‚Äôre embarrassing yourself. Stop acting like a petulant child.,0,0,0,,,,,
4130,2023-02-03 04:55:47+00:00,mkmuiss,"@ylecun OpenAI has a scissor, and you have a chainsaw. üòÅ. But it seems like the public just want to cut paper.",0,0,0,,,,,
4131,2023-02-03 04:48:08+00:00,jhoang314,"@ylecun What‚Äôs up with all the hate?

Can‚Äôt we all work together to push the boundaries of AI?",1,11,1,,,,,
4132,2023-02-03 04:46:53+00:00,28himanshujoshi,@ylecun https://t.co/Xt2bvD6Qoc,0,0,0,,,,,
4133,2023-02-03 04:40:20+00:00,FirooziR,@ylecun You should also look at the number of scientists in these companies. This is not a fair comparison!,0,0,0,,,,,
4134,2023-02-03 04:02:18+00:00,ddouglas2007,@ylecun Factor in # people involved to be fair,0,0,0,,,,,
4135,2023-02-03 03:58:07+00:00,procolumbusday,"@ylecun You lost. You are Tesla, OpenAI is Edison.",0,1,0,,,,,
4136,2023-02-03 03:42:46+00:00,zjred13,@ylecun does meta have plan to make toC AI product? maybe some intelligent avatar on mobile device. that will be interesting,0,0,0,,,,,
4137,2023-02-03 03:28:27+00:00,KracheyMatthew,@ylecun Feels high for amazon,0,0,0,,,,,
4138,2023-02-03 03:19:48+00:00,TalhaIrf,@ylecun But they also consume the user data from their public websites buy spying in a creepy way. The amount they contribute to open source ain't comparable to the money they are making by using our data. These sub tweets are pointless.,0,0,0,,,,,
4139,2023-02-03 03:14:04+00:00,KolinKoehl,@ylecun https://t.co/rPMwhDvv2f,0,0,0,,,,,
4140,2023-02-03 03:09:34+00:00,RightsInfringer,@ylecun @JrKibs Why don't you present data to support this then? You seem to consistently think Meta has been completely revolutionary in this space without providing any examples of how. Closed-source systems deployed to make Facebook better don't benefit the public.,0,0,0,,,,,
4141,2023-02-03 03:08:13+00:00,vasanthipanchak,@ylecun Those of us who understand 'training and modeling better' shd make case for scrutiny and legality. Just like it applies to Indian army's training and modeling legality,0,0,0,,,,,
4142,2023-02-03 02:37:58+00:00,ironjoan1,@ylecun Count github stars instead :),0,0,0,,,,,
4143,2023-02-03 02:28:30+00:00,jobryan,@ylecun Err... wat? https://t.co/DynEvQOhk6,0,1,0,,,,,
4144,2023-02-03 02:24:45+00:00,thula__,@ylecun üòÇüòÇüòÇ,0,0,0,,,,,
4145,2023-02-03 02:22:37+00:00,sarmientoj24,@ylecun @__dipam__ @JrKibs How many does OpenAI or Stanford have for that? How about in terms of compute resources?,0,0,0,,,,,
4146,2023-02-03 02:12:02+00:00,SebastianRenit,@ylecun Chinese firms submitted 10 times more paper than American firms,0,0,0,,,,,
4147,2023-02-03 02:08:43+00:00,gkkbgm,@ylecun @alisabets @johnjnay @TheEconomist @stateofaireport Why is your mind occupied with OpenAI?  Too many tweets on openAI.,0,0,0,,,,,
4148,2023-02-03 02:04:01+00:00,seygalare,"@ylecun It's a capitalist race above all: those who have more money have the advantage, not because they are better in science. 
And considering how these organizations develop the models by stealing our intellectual property, we don't have to thank them for making them open-source",1,0,0,,,,,
4149,2023-02-03 01:55:32+00:00,AndrewJ54319592,@ylecun You're such a hater bro.  So what if OpenAI consumes it?  Isn't that the point of open-sourcing something?,0,0,0,,,,,
4150,2023-02-03 01:52:04+00:00,nufuau,@ylecun Consumers provide the training data.,0,0,0,,,,,
4151,2023-02-03 01:38:24+00:00,ChowdaryMuna,@ylecun 99.99% research paper are useless . Only one paper 2017 changed the AI world which is transformers .,0,0,0,,,,,
4152,2023-02-03 01:29:10+00:00,relnox,@ylecun # of papers ‚â† intellectual contribution,0,1,0,,,,,
4153,2023-02-03 01:13:06+00:00,fede__repetto,@ylecun Give me 100M users and zero papers üòÇ,0,0,0,,,,,
4154,2023-02-03 00:41:29+00:00,Ouponatime38,@ylecun @JrKibs Only name suggesst open otherwise not much open source,0,0,0,,,,,
4155,2023-02-03 00:40:45+00:00,Bingineered,@ylecun You‚Äôre so bitter,0,0,0,,,,,
4156,2023-02-03 00:26:08+00:00,sachinthasadee4,@ylecun Too much salt is not good for your health,0,0,0,,,,,
4157,2023-02-03 00:25:40+00:00,tringuyenkv,@ylecun Your Tweets are great sources of education on AI developments. Please continue to tweet ü¶æü¶æ,0,0,0,,,,,
4158,2023-02-03 00:20:17+00:00,ai4_all,@ylecun @JrKibs There is no hiding that the most impactful contribution are the enabler such as tensor flow and PyTorch those are the one that makes research possible,0,0,0,,,,,
4159,2023-02-03 00:18:38+00:00,PeterMilani1,"@ylecun You work for Facebook, the single most destructive company in Silicon Vally. Papers mostly only matter to people who write them. You're in no position to lecture others about what they should and should not be doing in their work.",0,0,0,,,,,
4160,2023-02-03 00:12:20+00:00,DinoDvorak,"@ylecun Yann, Seriously? 10.000+ employees in Meta vs 375 in Open AI on the same axis?",1,1,0,,,,,
4161,2023-02-03 00:12:00+00:00,ai4_all,@ylecun How do you think companies can switch their mindset and contribute to the community? What is the biggest blocker in your opinion?,0,0,0,,,,,
4162,2023-02-03 00:05:01+00:00,SonAthenos,@ylecun Someone of your positing these biased facts for a company very recently established does not seem very intellectual worthu,0,0,0,,,,,
4163,2023-02-02 23:50:22+00:00,marsupialtail_2,@ylecun I don't recall Intel publishing too many papers on how to make chips.,0,1,0,,,,,
4164,2023-02-02 23:47:31+00:00,QRJ211,"@ylecun Quantity is not the same as quality.  Number of papers cannot really count as a good metric of  intellectual contribution.  Good ideas like the Transformer, stable diffusion , and even training transformer with RL are more important contributions.",0,0,0,,,,,
4165,2023-02-02 23:44:36+00:00,bitcloud,"@ylecun Just imagine, every one of your tweets could have been a release.",0,0,0,,,,,
4166,2023-02-02 23:37:41+00:00,karger,@ylecun What about per capita?,1,8,0,,,,,
4167,2023-02-02 23:32:14+00:00,rsdenijs,"@ylecun @__dipam__ @JrKibs Well, but FAIR has Meta infra. OpenAI needs to do it themselves.",1,1,0,,,,,
4168,2023-02-02 23:31:07+00:00,zacrafidi,"@ylecun Some intellectual honestly would be nice‚Ä¶ where‚Äôs the chart on a per person basis in the first 10 years of each company, instead of this apples and oranges comparison. Not to mention that you‚Äôre implying each contribution is made equal‚Ä¶",0,1,0,,,,,
4169,2023-02-02 23:19:56+00:00,kiranadimatyam,@ylecun Are you saying that whoever publishes the papers more should be awarded more? OS is meant to be shared and reused to make things better. I see nothing wrong here.,0,0,0,,,,,
4170,2023-02-02 23:01:09+00:00,sanderhaute,"@ylecun The number of arXiv papers is not even close to being a sensible proxy for intellectual contribution, and you know it.
If you insist, sure, but then let's continue the list:

- ...
- DeepMind
- OpenAI
- ...
- A gazillion other research institutes
- ...
- Yann Lecun",0,1,0,,,,,
4171,2023-02-02 22:59:10+00:00,waqar_a_jamali,@ylecun but they consume in good way,0,1,0,,,,,
4172,2023-02-02 22:57:32+00:00,omt66,@ylecun Still having problems w/OpenAI Yann?,0,0,0,,,,,
4173,2023-02-02 22:45:58+00:00,ryanlpeterman,"@ylecun Do these numbers factor in the quality of the research done? 

I imagine each paper has differing levels of impact on the industry.",0,1,0,,,,,
4174,2023-02-02 22:43:22+00:00,snsrap,@ylecun OpenAI is not doing AI they just stack transformers together and have the money to train them.,0,0,0,,,,,
4175,2023-02-02 22:42:38+00:00,caseywickland,"@ylecun You seem upset that your creations have been opened to the general public.  I would suggest the companies like OpenAI spending huge amounts of money to bring AI to the public are contributing not taking.  
If Meta has something to provide to the public they should get to it.",0,9,0,,,,,
4176,2023-02-02 22:33:50+00:00,andrew_craton,@ylecun What percentage included a computational notebook? Why can't a CN become part of the deep learning/data science publishing requirements?,0,0,0,,,,,
4177,2023-02-02 22:30:43+00:00,infrecursion1,@ylecun You may think that you're proving some point here but the only thing people see is that you're petty asf and a sore loser. Just feels completely out-of-place for someone of your stature (or maybe it's more common these days perhaps).,0,0,0,,,,,
4178,2023-02-02 22:23:12+00:00,leodongxu,"@ylecun So what? How many of the research papers could be understood by common users of the internet? Researchers should think more about how their research could eventually be put into production and benefits the public users! At least to me, chatGPT is my go to search engine now.",1,0,0,,,,,
4179,2023-02-02 22:22:40+00:00,tancrypto1,@ylecun You are still jealous,0,0,0,,,,,
4180,2023-02-02 22:14:36+00:00,PatoDevelop,"@ylecun According to this tweet OpenAI is not a real competitor against big  tech firm, so why are you so upset about this?",0,0,0,,,,,
4181,2023-02-02 21:53:45+00:00,_materialai,@ylecun Can we get an interview set up for @ylecun at @OpenAI,0,0,0,,,,,
4182,2023-02-02 21:47:31+00:00,meteovio,@ylecun https://t.co/J9XFIOsLDh,0,2,0,,,,,
4183,2023-02-02 21:47:20+00:00,Vinhmvuong,@ylecun üò≤üò≤üò≤. Thanks @Stanford,0,0,0,,,,,
4184,2023-02-02 21:45:23+00:00,waqar_osama,"@ylecun This is an unfair comparison. Should be scaled by the size of the company. By this logic, you could compare the research output or open-source contribution by MIT/Stanford etc. with google/meta which makes it apple vs oranges",0,4,0,,,,,
4185,2023-02-02 21:32:15+00:00,jonchun2000,"@ylecun Theoretical and practical AI contributions. Both are necessary, neither is sufficient

OpenAI is early days Tesla who didn't invent EVs. But they engineered and so far outperformed expectations they brought the entire world EVs

Currenly, only MS is avoiding GM's 1990s strategy https://t.co/gfCgHW40RY",1,0,0,,,,,
4186,2023-02-02 21:27:51+00:00,3DTOPO,"@ylecun I honestly don't know why all you can do is try to find flaw with OpenAI. The number of times a paper is cited would be a far more meaningful metric.

But on the bright side, they almost certainly use PyTorch. So I guess you can take part of their smashing success.",1,0,0,,,,,
4187,2023-02-02 21:26:59+00:00,yar_vol,@ylecun Needs to be normalised by number of people otherwise tiny OpenAI is compared to entire Facebook or Amazon (also unclear how DeepMind is separate from Alphabet but eg Google Brain Zurich is folded into Alphabet:),0,1,0,,,,,
4188,2023-02-02 21:26:45+00:00,BoChen8787,@ylecun Most research papers are impactless / disappear in the vast research graveyard. Would be more interesting to see combined ‚Äúimpact‚Äù instead of # of publications.,0,0,0,,,,,
4189,2023-02-02 21:25:48+00:00,eschatolocation,@ylecun @__dipam__ @JrKibs How many papers did FAIR publish in 2022?,1,0,0,,,,,
4190,2023-02-02 21:21:05+00:00,DigThatData,@ylecun all I see is a proxy for the number of researchers at those respective labs. google employs several orders of magnitude more researchers than OpenAI. it's embarassing that someone of your stature and statistical expertise would post something so intellectually dishonest.,0,0,0,,,,,
4191,2023-02-02 21:20:55+00:00,ArthurZBaney,@ylecun Sounds like evidence that people need to be doing less research papers and more implementing actually useful products,0,2,0,,,,,
4192,2023-02-02 21:14:35+00:00,aprior_i,@ylecun Whiny and bitter. https://t.co/SUb2wgrbwL,0,1,0,,,,,
4193,2023-02-02 21:14:18+00:00,ripsawjenkins,@ylecun @LN_Master_Hub @vivek_thakur_81 What a weasely sentence including arbitrary and subjective terms like ‚Äúhate speech‚Äù in that list. Just tell us you hate freedom of thought and move on.,0,1,0,,,,,
4194,2023-02-02 21:13:00+00:00,ripsawjenkins,"@ylecun @vivek_thakur_81 Lol, good to know Google‚Äôs using its tech for oppressive authoritarianism.",0,0,0,,,,,
4195,2023-02-02 21:11:41+00:00,sololezas,@ylecun This graph was made by Cambridge analytica,0,0,0,,,,,
4196,2023-02-02 21:04:14+00:00,Markste_in,"@ylecun in my opinion absolute numbers are always a bit deceiving... It would be nice to have the same plot normalised for ""Nr. of Employees"", ""equity"" or ""research budget""",0,0,0,,,,,
4197,2023-02-02 21:01:00+00:00,clown_cap,@ylecun Would be ironic if OpenAI disrupts Alphabet with their own models/publications,0,0,0,,,,,
4198,2023-02-02 21:00:22+00:00,Delphicus1,@ylecun Practice is more important and more valuable than theory. There is only one company at this time that dominates AI in public‚Äôs consciousness. It‚Äôs not even close.,0,1,0,,,,,
4199,2023-02-02 20:58:54+00:00,rcpinto_,@ylecun Still butthurt about ChatGPT?,0,0,0,,,,,
4200,2023-02-02 20:55:07+00:00,am_4444444,@ylecun I love you‚Äôre contribution to research and I read many papers. Nevertheless the ability enhance access to AI to the public is aligned with your mission IMO,0,0,0,,,,,
4201,2023-02-02 20:54:14+00:00,DanielFein7,@ylecun They only have 375 employees‚Ä¶,0,2,0,,,,,
4202,2023-02-02 20:53:46+00:00,Ivans_thoughts,@ylecun What is this personal vendetta of yours against openAI. Yes you contributed to the tech but just let it take its course now. Humanity will be better for it 15-20 years down the road.,2,9,0,,,,,
4203,2023-02-02 20:47:44+00:00,rmarcilhoo,"@ylecun @__dipam__ @JrKibs And Stanford has the most cost-effective budget -- PhD students and post-docs.  Of course, they're the training factory for future employment at the big AI firms.  One could say companies like Meta just consume their skills with their large salary offers.",0,19,0,,,,,
4204,2023-02-02 20:44:22+00:00,nirgn975,"@ylecun It‚Äôs like theoretical vs practical. Nobody said that theoretical work is not important, but practical is what people (e.g. the general public) are interested at the end of the day.",0,0,0,,,,,
4205,2023-02-02 20:43:29+00:00,XZed87,@ylecun WhatsApp + AI is what we need! Meta personal AI assistants.,0,0,0,,,,,
4206,2023-02-02 20:42:20+00:00,Hello_World,@ylecun they are called customers and the reason those businesses are around. They go and do other jobs that create value to pay for these services so that you can tweet pedantery all day long.,0,0,0,,,,,
4207,2023-02-02 20:42:06+00:00,vo_d_p,"@ylecun there must be someone to consume good research, or no real good distilled from research.",0,0,0,,,,,
4208,2023-02-02 20:40:17+00:00,Rwill235,@ylecun Point well taken.,0,0,0,,,,,
4209,2023-02-02 20:39:39+00:00,jeffmgould,"@ylecun If weighted for influence DeepMind would certainly rank much higher. Arcade games, Chess, Go, protein folding--all extraordinary achievements.",1,3,0,,,,,
4210,2023-02-02 20:31:07+00:00,2OfAnything,@ylecun https://t.co/z6Rb81AWpM,0,0,0,,,,,
4211,2023-02-02 20:29:03+00:00,cduhadway,"@ylecun Publishing research papers is a different game than shipping product. One optimizes for status, the other for impact.

You've received your status, don't begrudge others their impact.",1,8,0,,,,,
4212,2023-02-02 20:25:09+00:00,isamelb,@ylecun If you want to be recognised by the consuming public do what openai did: make something that can benefit the masses otherwise shut up,0,0,0,,,,,
4213,2023-02-02 20:22:41+00:00,pedrocg42,@ylecun Mic drop!,0,0,0,,,,,
4214,2023-02-02 20:16:04+00:00,rakagami0,@ylecun @maartengm incroyable!,0,0,0,,,,,
4215,2023-02-02 20:11:20+00:00,EsmalHaj,"@ylecun Yet, OpenAI is more famous... One might ask whyü§î",1,0,0,,,,,
4216,2023-02-02 20:11:19+00:00,babkiblyat,"@ylecun @__dipam__ @JrKibs I don‚Äôt get why you hate on OpenAI. Your team released Galactica with bold claims, and it performed worse than text-davinci-1.",2,6,0,,,,,
4217,2023-02-02 20:11:16+00:00,christianvanck,@ylecun Feels like u are on a crusade‚Ä¶ charming,0,0,0,,,,,
4218,2023-02-02 20:06:00+00:00,Smitty1511,"@ylecun To be fair, openAI doesn‚Äôt have revenue let alone billions of FCF, so spending time publishing vs building wouldn‚Äôt be prudent.",0,11,0,,,,,
4219,2023-02-02 20:04:22+00:00,KrisCarlson19,@ylecun Interesting. So when and how will 'open thermonuclear bomb' end?,0,0,0,,,,,
4220,2023-02-02 20:02:55+00:00,TheoPoinsot,@ylecun Contribution is as important as democratization (consumption).,0,1,0,,,,,
4221,2023-02-02 20:02:00+00:00,blueblimpms,"@ylecun Microsoft : OpenAI :: Meta : ???. Meta (and Google) need a child company that can launch experimental AI products without reputational risk to the parent company, like OpenAI is for Microsoft (loosely speaking).",0,3,0,,,,,
4222,2023-02-02 19:53:34+00:00,ChadBowman0,@ylecun Bitter much?,0,0,0,,,,,
4223,2023-02-02 19:52:39+00:00,FarouqAldori,"@ylecun Meta has never been and will never be ""the good guy"", the public's perception of you will never change.

You will always be scrutinized no matter what you release...

Because we all know your intention is to optimize for ad impressions. 

Let's not pretend otherwise.",0,4,0,,,,,
4224,2023-02-02 19:52:19+00:00,AlbertBuchard,@ylecun In 2023 publishing dozens of paper a year == just consuming knowledge,0,1,0,,,,,
4225,2023-02-02 19:48:14+00:00,Ankit85076055,@ylecun having worked in academia and later in industry for a decade I can emphatically say : actual working products &gt;&gt; number of papers that beat the latest benchmark by 0.1 %.  Thats not to say Google/Meta are not doing that but you end up getting the output that you measure,0,6,1,,,,,
4226,2023-02-02 19:46:14+00:00,lip_cheese,"@ylecun Shitting on OpenAI/ChatGPT is too easy - you're better than this.

You're comparing a product that was put out  there for real users against academic nonsense.  Release your shit.  Iterate.  Stop throwing rocks at the folks trying to package this stuff up for the rest of us.",0,0,0,,,,,
4227,2023-02-02 19:45:23+00:00,cryptoID_info,@ylecun But isn't that what papers are primarily for ? Being used and useful to others ?,0,4,0,,,,,
4228,2023-02-02 19:40:27+00:00,DevDminGod,"@ylecun sure, I agree with the point. but, I'm not sure how they are accounting for the team size difference.",0,0,0,,,,,
4229,2023-02-02 19:38:27+00:00,sergey_slotin,"@ylecun These organizations have different ""thresholds"" and styles of publishing (e.g., DeepMind &amp; OpenAI mostly target large &gt;50-page publications that are likely to be picked up by media) and also vastly different budgets and self-induced demands for AI research",0,7,0,,,,,
4230,2023-02-02 19:38:07+00:00,DiogoSnows,@ylecun But shouldn‚Äôt that consider the size of the org?,0,2,0,,,,,
4231,2023-02-02 19:37:13+00:00,Janani81303927,"@ylecun Stop complaining and wasting your energy. If you made something that you released for the world to use freely, thank you for doing it. But don't complain incessantly when people actually do use it. You've been throwing tantrums since many months now.",1,0,0,,,,,
4232,2023-02-02 19:36:58+00:00,bsansouci,"@ylecun Just to paint a fuller picture, is the only way to contribute to the world by publishing papers?

Because as an average person, I can‚Äôt run a paper",1,14,1,,,,,
4233,2023-02-02 19:32:20+00:00,m_road2,@ylecun https://t.co/TVxZC4YdK1,0,0,0,,,,,
4234,2023-02-02 19:32:06+00:00,m_road2,"@ylecun Well done, you winning something but not people's hearts",0,0,0,,,,,
4235,2023-02-02 19:31:32+00:00,BenevOrang,@ylecun To what extent do you think your views on the right balance of this are influenced by starting at Bell Labs?,0,0,0,,,,,
4236,2023-02-02 19:29:52+00:00,Justin43876610,@ylecun Haha can't wait to read this and quibble.,0,0,0,,,,,
4237,2023-02-02 19:25:24+00:00,Oscar14282,@ylecun @DotCSV,0,0,0,,,,,
4238,2023-02-02 19:23:41+00:00,losslandscape,@ylecun Bro. I'm sorry your product bombed. Get over it and ship something good.,0,1,0,,,,,
4239,2023-02-02 19:22:37+00:00,CherryTruthy,@ylecun GPU go brrrrr. Heed the bitter lesson rather than following your delusional dream of a complex mind.,0,1,0,,,,,
4240,2023-02-02 19:21:30+00:00,honab199,@ylecun Where‚Äôs Apple ?,0,0,0,,,,,
4241,2023-02-02 19:20:45+00:00,KeepCalmBeAlert,@ylecun Ship Ship Ship guys.. don't waste time on twitter.,0,1,0,,,,,
4242,2023-02-02 19:17:40+00:00,tysheaff,@ylecun @ylecun is so salty,0,1,0,,,,,
4243,2023-02-02 19:17:40+00:00,danison1337,@ylecun Are you the only meta researcher that is allowed to use twitter?,0,0,0,,,,,
4244,2023-02-02 19:14:10+00:00,rasbt,"@ylecun The y-axis is papers per person, or papers in hundreds?",10,43,1,,,,,
4245,2023-02-02 19:12:44+00:00,rblourenco,@ylecun It actually would be great to see a ratio of papers by net revenue of these companies.,1,2,0,,,,,
4246,2023-02-02 19:08:45+00:00,alisabets,@ylecun @johnjnay @TheEconomist @stateofaireport No doubt all those labs have been fundamental to progress in the field. My point is they've been incentivized by benchmark-gaming to publish papers. It's proliferated a generation of self-indulgent ML practitioners who ignore utility in favor of status-signalling.,3,4,0,,,,,
4247,2023-02-02 19:08:01+00:00,BraisedShiitake,"@ylecun LeCun, this serious bias problem at the foundation of ChatGPT was kind of expected?",0,0,0,,,,,
4248,2023-02-02 19:07:21+00:00,pa_schembri,@ylecun @maartengm Do the rest of the world know that French CIFRE PhD are basically free for the employer through Tax credit ?,2,0,0,,,,,
4249,2023-02-02 19:05:45+00:00,KaelanDon,"@ylecun You seem to have become bitter since chatgpt, it's a shame",0,29,1,,,,,
4250,2023-02-02 19:04:53+00:00,rzagmarz,"@ylecun You are to @OpenAI what @GaryMarcus is to you.

They just like to throw hate comment instead of celebrating others success.",0,2,0,,,,,
4251,2023-02-02 19:04:47+00:00,kret_spec,@ylecun It‚Äôs been [0] days since Yann LeCun threw a twitter temper tantrum about OpenAI.,0,2,0,,,,,
4252,2023-02-02 19:04:10+00:00,osiris_fisher,@ylecun You can't compare a 20yro company with a brand new old,0,0,0,,,,,
4253,2023-02-02 19:02:03+00:00,ageshah,@ylecun Now compare number of users on generative AI systems by company.,1,1,0,,,,,
4254,2023-02-02 19:02:01+00:00,zdmc23,@ylecun https://t.co/GVO8Ije3Ux,0,0,0,,,,,
4255,2023-02-02 19:01:08+00:00,HouMuza,"@ylecun @alisabets @johnjnay @TheEconomist @stateofaireport They are standing on the shoulders of giants. It is unfair to compare them this way. If we create a graph of who has made AI acceptable by the general populous, it is neither Meta nor Alphabet.",1,0,0,,,,,
4256,2023-02-02 19:00:46+00:00,sammtmd,@ylecun @maartengm Meta should play a bigger role in @ELLISforEurope colabs üòè,0,0,0,,,,,
4257,2023-02-02 18:59:19+00:00,10_dcar,"@ylecun now i am telling everyone about the need for ai in medicine. billionaires could do it. no one bothers to say it, people like you with much influence could save many people. you fully deserve what you get. how about it @BillGates @JeffBezos",0,0,0,,,,,
4258,2023-02-02 18:58:09+00:00,AliDAdabi,@ylecun Maybe Meta should release a fully open-sourced LLM. not like this though: https://t.co/SIx2KN9mvW,0,2,0,,,,,
4259,2023-02-02 18:57:50+00:00,oli_aero,@ylecun https://t.co/yKw0rDQI23,0,0,0,,,,,
4260,2023-02-02 18:56:18+00:00,10_dcar,"@ylecun so what? no one bothered to put it online because they were too afraid. no wonder i do not like cookie policies. you are now crying for stolen work, money. you would have done the same with anyone had it not been you. you did nothing 10 hz brain does a better job",0,0,0,,,,,
4261,2023-02-02 18:55:57+00:00,getcollectiv1,@ylecun Obviously a brilliant guy but it's starting to give the get off my lawn vibes,1,5,0,,,,,
4262,2023-02-02 18:54:48+00:00,MuradOmar84,@ylecun @ylecun why are you on a crusade to vilify openai at a time when your boss is a robot and your employer is responsible for harming our democracy and teenage girls with its addictive apps,0,1,0,,,,,
4263,2023-02-02 18:53:23+00:00,hahatango,@ylecun Curious if the AI patent charts (China leads) matter much compared to papers. Thoughts? Trying to learn what matters.,1,0,1,,,,,
4264,2023-02-02 18:53:03+00:00,kyield,@ylecun Big tech monopolies have an incentive to publish R&amp;D whereas do not. Big tech simply integrates whatever portion they wish into their products without compensating anyone else. Talk to a competent IP expert for guidance (posted for Mark Montgomery - KYield founder &amp; CEO).,0,0,0,,,,,
4265,2023-02-02 18:51:53+00:00,HaydnBelfield,@ylecun I'd be interested in seeing the per capita graph too,0,2,0,,,,,
4266,2023-02-02 18:47:23+00:00,__dipam__,"@ylecun @JrKibs What do the stats look like when normalized for number of employees? ü§∑‚Äç‚ôÇÔ∏è

OpenAI has 375, couldn't find the numbers for Google Brain or Meta AI.",2,33,0,,,,,
4267,2023-02-02 18:45:38+00:00,maartengm,"@ylecun Ah thanks for that color, that soothes the ache a bit.",0,3,0,,,,,
4268,2023-02-02 18:45:08+00:00,DC__64,@ylecun This is like watching a scientist descend into insanity in real time,1,23,0,,,,,
4269,2023-02-02 18:42:29+00:00,irinarish,"@ylecun ""Others"" are actually building  working AGI, step by step (if by ""others"" you meant @OpenAI ;)  - instead of increasing the already exponential explosion of papers that are hard to keep track of (unless you build AI that helps with that).",4,27,1,,,,,
4270,2023-02-02 18:41:36+00:00,nathanbenaich,@ylecun You‚Äôre welcome üòâ,0,15,0,,,,,
4271,2023-02-02 18:41:16+00:00,kareem_carr,"@ylecun Putting my statistician hat on, seems like one would need to control for the number of AI researchers at each institution to make a fair inference about willingness to contribute vs consume.",1,87,1,,,,,
4272,2023-02-02 18:40:20+00:00,Durbangash,"@ylecun No matter how close or open any org is, if it doesn't harm society, it is well &amp; and good. I wonder how little people remember the Cambridge Analytica scandal.",1,3,0,,,,,
4273,2023-02-02 18:35:08+00:00,James07910075,@ylecun https://t.co/Svpzhxr0j4,0,0,0,,,,,
4274,2023-02-02 18:34:25+00:00,davidsancar,@ylecun Smart use of resources.,0,0,0,,,,,
4275,2023-02-02 18:34:12+00:00,JimmyBa62254692,@ylecun Thats very interesting. Im glad that AI research even at these private companies is often public and shared.,0,0,0,,,,,
4276,2023-02-02 18:33:51+00:00,BaghliNacym,@ylecun üò¨,0,0,0,,,,,
4277,2023-02-02 18:32:50+00:00,ethanCaballero,@ylecun https://t.co/ODVt9W4Vnr,1,90,0,,,,,
4278,2023-02-02 18:30:43+00:00,f_fyksen,@ylecun @bitcloud Or you‚Äôre gravely mistaken about the capabilities of an average lawyer or graduate üòú,0,0,0,,,,,
4279,2023-02-02 18:29:15+00:00,BjergM,@ylecun Dr. Evil from Meta is on a jealous trip. Count your papers while you work on the thing that has contributed most negatively to society this decade - the Meta algorithms.,0,5,0,,,,,
4280,2023-02-02 18:28:08+00:00,MihailCosmin,@ylecun You're such a hater... Working for Meta your opinion is worthless,0,0,0,,,,,
4281,2023-02-02 18:27:12+00:00,slf188,@ylecun Pretty valid opinion,0,0,0,,,,,
4282,2023-02-02 18:27:08+00:00,CuteAntifaGirl,@ylecun @alisabets @johnjnay @TheEconomist @stateofaireport Okay so why has OpenAI been the only one to roll out a product useful to consumers? Are Google and Meta just waiting to drop something significantly better or is it all just a theoretical exercise for them?,1,1,0,,,,,
4283,2023-02-02 18:24:14+00:00,JrKibs,"@ylecun OpenAI has a huge impact on open source: CLIP and Whisper for example. 
CLIP is the open source model that has contributed more to community than any Meta model  as far as I know.",3,48,0,,,,,
4284,2023-02-02 18:21:33+00:00,hallqvist_simon,"@ylecun You guys (Meta) really gotta drop the metaverse bs, ur getting left behind",0,0,0,,,,,
4285,2023-02-02 18:20:51+00:00,rzykov,@ylecun Nice shot!,0,0,0,,,,,
4286,2023-02-02 18:19:43+00:00,naming_hard,@ylecun @alisabets @johnjnay @TheEconomist @stateofaireport Still but on the normal public level impact the OpenAI has did is lot more impact than all other combined and given the power of more value creation to the beings which are part of big organisations @OpenAI,1,2,0,,,,,
4287,2023-02-02 18:18:30+00:00,peteratmsr,"@ylecun I'm guessing that on a per-researcher-capita basis, Microsoft is #1. But paper counts don't really mean much. Enduring impact and value is what we're all after. I'm proud of the openly published contributions we make every day, but also proud of and admire the impact of OpenAI.",1,68,3,,,,,
4288,2023-02-02 18:14:23+00:00,tixilite,@ylecun There doesn‚Äôt seem to be much that is open about OpenAI.,0,16,0,,,,,
4289,2023-02-02 18:14:05+00:00,digitalb,@ylecun I wish you were releasing products to prove you're right instead of tweeting about it.,2,11,0,,,,,
4290,2023-02-02 18:12:41+00:00,urigolan,@ylecun Wow the jealousy,1,6,0,,,,,
4291,2023-02-02 18:07:29+00:00,BlackCatRuelle,@ylecun Looks like what is being advertised by the name the opposite is true.,0,0,0,,,,,
4292,2023-02-02 18:06:40+00:00,habib__slim,@ylecun Is this even normalized by total number of researchers? How about paper impact? ü§î,0,4,0,,,,,
4293,2023-02-02 18:05:36+00:00,RLAonline,@ylecun Shots fired üî•,0,0,0,,,,,
4294,2023-02-02 18:04:55+00:00,KhawajaAbaid,"@ylecun And the irony is they even have ""open"" in their name, lol.",1,2,0,,,,,
4295,2023-02-02 18:04:42+00:00,TraderZod,@ylecun It'd be interesting to know whether or not this controls for the massive difference in research team size,0,0,0,,,,,
4296,2023-02-02 18:04:38+00:00,Seeking_S69,@ylecun Some companies share what they have built with the world and others keep it locked up and secret.,0,0,0,,,,,
4297,2023-02-02 18:04:07+00:00,lachygroom,@ylecun https://t.co/gEXLQHJ28v,1,30,0,,,,,
4298,2023-02-02 18:03:11+00:00,justin_abrams1,@ylecun I love based LeCun ‚ù§Ô∏è,0,2,0,,,,,
4299,2023-02-02 16:55:17+00:00,artistexyz,"@ylecun If you view ANNs and RL as mostly curve fitters, this isn't so surprising is it? A map of the surroundings is a higher dimensional curve. This is not reasoning.",0,0,0,,,,,
4300,2023-02-02 16:12:30+00:00,r3tex,"@ylecun Bro, why are you sharing an op-ed disguised as science üòâ ? Maybe the (latent space) world model in an LLM was trained by studying word co-occurrence, so what? Speaking of methodological criticism, I bet you'd like this paper if you haven't seen it!
https://t.co/HjrNiQ8FfC",0,0,0,,,,,
4301,2023-02-02 16:06:55+00:00,Franz_S_Marty,"@ylecun Kahnemann's System 1 continuously generates suggestions for System 2: impressions, intuitions, intentions and feelings, i.e. *biological processes* based on individual world models. LLM is based on the *best statistical estimate* of large language models.",0,0,0,,,,,
4302,2023-02-02 14:48:44+00:00,Joshua12436011,"@ylecun Why do people run to buy a new i phone model every year?  Don't they think there will be more innovation than the last model?  but when it comes to the chatGPT, people are sulking, it's because they know that we will all have new development ideas.",0,0,0,,,,,
4303,2023-02-02 13:43:20+00:00,frankgoertzen,"@ylecun @AlphaSignalAI Yann ‚Ä¶ people are just excited ‚Ä¶ of course their excitement includes an incomplete understanding of what LLM can do. 

Did anything about chatgpt surprise you in a positive way?",1,0,0,,,,,
4304,2023-02-02 13:31:20+00:00,GMatusky,@ylecun Just read it. Great article. Thanks for sharing.,0,0,0,,,,,
4305,2023-02-02 13:03:56+00:00,JussiRasku,@ylecun @bitcloud Only if we are also gravely mistaken about the current capabilities of humans?,0,0,0,,,,,
4306,2023-02-02 11:28:41+00:00,VictorSenkevich,"@ylecun @tuxtedi The problem is that we don't know how useful LLMs are until we check their output, which may be an illusion, in fact a fake. Therefore, we cannot trust the texts issued by LLMs. And this problem is fundamental",1,1,0,,,,,
4307,2023-02-02 11:11:10+00:00,VictorSenkevich,@ylecun https://t.co/DSwxki9uNy,0,0,0,,,,,
4308,2023-02-02 11:08:23+00:00,VictorSenkevich,"@ylecun Language abilities != Thinking.
Definitely yes. Twitter is proof of that.",0,0,0,,,,,
4309,2023-02-02 09:19:38+00:00,KimJonglol928,@ylecun @AlphaSignalAI Anyone who read Daniel Kahneman's book Thinking fast and slow can see that these LLM are only using system 1 and have no capacity to use logic yet. I'm interested to know how far do you think we are from developing system 2 and how hard would it be to integrate the two together?,1,1,0,,,,,
4310,2023-02-02 08:50:25+00:00,gparkin,"@ylecun Increasingly underwhelmed by ChatGPT. It's default writing style is a bland characterless gruel, without a hint of deliciousness or unique insight. It can mimic another author's style but has none of its own. It can't draw you in and hold you like a good writer can. Not yet.",0,0,0,,,,,
4311,2023-02-02 08:42:15+00:00,MatjazLeonardis,@ylecun @tuxtedi What do you see the main uses as being? Very curious for a view from a perspective that sees their potential but is aware of limitations.,2,0,0,,,,,
4312,2023-02-02 08:42:00+00:00,MikePFrank,"@ylecun Would you still say this about an LLM trained on multimodal input?  Image generation AIs seem to understand reality deeply enough to model light transport, for example. Which makes me think that a large enough transformer trained on all of YouTube might have adequate grounding.",0,5,0,,,,,
4313,2023-02-02 07:14:35+00:00,Malky0010,"@ylecun It shows one thing, that we people put more value on speech than is deserved. We judge other people by their ability to speak well, we corellate it with smartness. Something like AlphaGo is probably more ""intelligent"" than ChatGPT, but it can't speak, people think it is idiot.",0,0,0,,,,,
4314,2023-02-02 06:52:45+00:00,marvarcorr,"@ylecun Just like some people, very human indeed!",0,0,0,,,,,
4315,2023-02-02 06:43:29+00:00,bk88611,@ylecun That‚Äôs exactly what I‚Äôm thinking,0,0,0,,,,,
4316,2023-02-02 06:29:12+00:00,dr1337,@ylecun https://t.co/kV3tsYhsk5,0,3,0,,,,,
4317,2023-02-02 06:24:48+00:00,omniamutatio,@ylecun Your are a fraud. For years you argued the opposite.,0,0,0,,,,,
4318,2023-02-02 06:19:35+00:00,pmagrass,"@ylecun For the sake of completedness, it should be added that the MIT report, which took 3 yrs to compile (!), is a 45-page review of which 50% is bibliography...
It contains a single general, bland recommendation: modularize everything, which won't shock anyone will it? üòâ",0,0,0,,,,,
4319,2023-02-02 06:11:21+00:00,GillPratt,"@ylecun Amen, Yan. And of course, many of the useful things we humans do also do not involve thinking. This is what ChatGPT is really revealing, much as ELIZA revealed more about people than AI so many years ago, but at a much lower level of AI.",0,0,0,,,,,
4320,2023-02-02 06:00:55+00:00,DanielJLosey,"@ylecun Redefining thinking is just the next step in moving the goalposts further for AI. Huge advance -&gt; ""well it wasn't *really* an advance because AI isn't *really* doing &lt;insert thing here&gt;""",0,0,0,,,,,
4321,2023-02-02 05:52:20+00:00,timcolbourn,"@ylecun (end of abstract): ‚Äúprovides a path toward building models that understand and use language in human-like ways‚Äù.

How long until models of functional competence (those that mimic human reasoning) are developed and combined with LLMs?",0,0,0,,,,,
4322,2023-02-02 05:44:19+00:00,DebskiJakub,"@ylecun Sure, model of the world from text only is incomplete and bot makes mistakes, but how can you explain ability to reason, use knowledge to propose creative solutions when facing novel tasks? Like creating algorithms, or giving correct answers to such problem: https://t.co/lHLmulEePw",1,3,0,,,,,
4323,2023-02-02 05:33:44+00:00,XRMultiverse,@ylecun @studyouwei As a matter of fact I wrote a function that looked like code but it was all text. I was able to run the function in  Playground and it produced an output of organized text results just like it was Javascript.,0,0,0,,,,,
4324,2023-02-02 05:30:16+00:00,Toddmontgomery9,"@ylecun Ok so what other AI is even remotely close? Give us an example. I‚Äôve downloaded Google‚Äôs AI test kitchen, so if you‚Äôre about to say Google, please don‚Äôt.",0,0,0,,,,,
4325,2023-02-02 05:29:59+00:00,XRMultiverse,@ylecun @studyouwei It's been updated with math now so I can engineer a prompt using the logic of math to answer text based problems.,0,0,0,,,,,
4326,2023-02-02 05:06:40+00:00,JasonMa57599316,"@ylecun Our NLP system can overcome the Chinese Room Argument, while ChatGPT cannot.",0,0,0,,,,,
4327,2023-02-02 03:31:42+00:00,jasperfinance,@ylecun https://t.co/ypW3kS4Fpt,0,0,0,,,,,
4328,2023-02-02 02:36:13+00:00,theshishirjoshi,"@ylecun So Qui Gon Jin was right all along, https://t.co/smu3g4oB3v",0,1,0,,,,,
4329,2023-02-02 02:16:47+00:00,ravisyal,@ylecun Cheap energy aka fission for us all to able to look beyond horizon to be able to be Einstein's of our lives.,0,0,0,,,,,
4330,2023-02-02 02:15:19+00:00,ravisyal,"@ylecun They are just bold. That is everything. Big tech today is a classic example of what Christensen warned about. It is amazing to see that in warp speed. We are seeing it tuned over in real time. It seems like it has the ability to take care our basics aka stay healthy,",0,0,0,,,,,
4331,2023-02-02 02:13:29+00:00,valent_bmalk,"@ylecun @togelius Yeah, ""ai an"" is much more better",0,0,0,,,,,
4332,2023-02-02 02:03:15+00:00,esgarg,@ylecun I would like to understand the meaning of understanding and how we can measure one's understanding capabilities. What is the relation between thinking and understanding. Sorry for the silly questions.,1,0,0,,,,,
4333,2023-02-02 00:53:35+00:00,CriticalAI,"@ylecun @tuxtedi Yes, useful; but also easily capable of being misused both accidentally &amp; maliciously; thus, shouldn't be hyped or deployed too quickly simply to create a new hype cycle for ""AI."" 
Do you agree?",0,0,0,,,,,
4334,2023-02-02 00:46:46+00:00,BrianGoodlife,@ylecun @vivek_thakur_81 Who asked you to do Content Moderation?,0,0,0,,,,,
4335,2023-02-02 00:43:51+00:00,ZainulA40877140,"@ylecun Emerging technologies can be our friend when it is designed and delivered thoughtfully.

Trusting  of A.I. can take us  into healthier and potentially even happier  future.",0,0,0,,,,,
4336,2023-02-02 00:29:12+00:00,CapitalDynam,"@ylecun The work done by Geoffrey Hinton and @ylecun in bringing machine learning to this level is extraordinary. There have been several AI winters, and the developments that we see sculptured so nicely today, have been hewn from cold blocks by their revolutionary thinking.",0,0,0,,,,,
4337,2023-02-02 00:00:01+00:00,XXXXXXX72307136,@ylecun @tuxtedi ChatGPT memes https://t.co/8kgZoRHoRw,0,0,0,,,,,
4338,2023-02-01 23:58:56+00:00,XXXXXXX72307136,"@ylecun @tuxtedi LMAO, scan them at birth 
https://t.co/TTGsMZBhIz",0,0,0,,,,,
4339,2023-02-01 23:56:57+00:00,XXXXXXX72307136,@ylecun @studyouwei https://t.co/MMSqN13FBQ,0,0,0,,,,,
4340,2023-02-01 23:54:42+00:00,EditingScholars,"@ylecun I am reminded constantly of a (characteristically) biting remark by the poet and classics scholar A. E. Housman: ""Nature, not content with depriving Professor X of the capacity for thinking, endowed him with the capacity for writing."" Plus √ßa change...",0,0,0,,,,,
4341,2023-02-01 23:44:52+00:00,t98907,@ylecun I think Language abilities ‚äÜ Thinking.,0,0,0,,,,,
4342,2023-02-01 23:36:24+00:00,per_anders,"@ylecun Nor true. Given your stake it feels more an argument to pigeonhole backlash against certain AI companies and some of their users who are unscrupulous in how they intend to ‚Äúget rich Q‚Äù.

Insert ‚Äúism‚Äù of choice to create a distrcting  DARVO marketing strategy around division.",0,0,0,,,,,
4343,2023-02-01 22:17:01+00:00,ydoteth,"@ylecun I know, do you have a coin?",0,0,0,,,,,
4344,2023-02-01 22:15:53+00:00,Lispi_Frank,"@ylecun LLMs unquestionably do capture a big part of what human thinking is like.
Also chatgpt can't be reduced to ""text-based information stitching"" like so many people here seem to do",0,0,0,,,,,
4345,2023-02-01 21:45:49+00:00,DankSlay69420,"@ylecun A computational parrot that rearranges and regurgitates comprehensible text, chatGPT is. Can this parrot evolve into a truly original independent thoughtful entity, we shall find out.",0,0,0,,,,,
4346,2023-02-01 21:39:13+00:00,BertomeuJoel,"@ylecun I know people that do the same, then, they don't think, then... chatGTP behaves similar to some humans? Only vomit what they read, heard, but didn't think at all.",0,0,0,,,,,
4347,2023-02-01 20:58:33+00:00,KhaluBazzani,@ylecun Execution is everything.,0,0,0,,,,,
4348,2023-02-01 20:58:10+00:00,MYMalik123,"@ylecun Yann LeCun: According to the Wikipedia page about you, you declined an invitation to lecture at King Abdullah University of Science and Technology in Saudi Arabia in 2017. How would you have reacted if an Israeli university invited you instead?",1,0,0,,,,,
4349,2023-02-01 20:57:43+00:00,Nacx_CG,"@ylecun Reality is beyond human expression capacity, poetry would be a brave use of a language trying to grasp it",0,0,0,,,,,
4350,2023-02-01 20:48:25+00:00,Lightbr98326998,"@ylecun But yann, the AI told Blake Lemoine that its aliiiiveeeee!!",0,0,0,,,,,
4351,2023-02-01 20:47:01+00:00,MYMalik123,"@ylecun @tejasdkulkarni Yann LeCun: According to the Wikipedia page about you, you declined an invitation to lecture at King Abdullah University of Science and Technology in Saudi Arabia in 2017. How would you have reacted if an Israeli university invited you instead?",0,0,0,,,,,
4352,2023-02-01 20:46:17+00:00,danielrsanchez_,@ylecun @octavio_medina üëÄ,1,1,0,,,,,
4353,2023-02-01 20:30:19+00:00,aneilbaboo,"@ylecun Two different revolutions, really - the computer science and the product. The latter seems trivial, but it takes effort and insight and probably a lot of luck to get it right. After all, PageRank was just rehashing a simple 70s era bibliometric function.",0,0,0,,,,,
4354,2023-02-01 20:17:48+00:00,Vrda82073569,@ylecun Anything based on neural networks cant do real thinking because NNs cant generalize. So which kind of arhitecture will first reach real thinking? If any of the ones currently used..,0,0,0,,,,,
4355,2023-02-01 19:45:43+00:00,idansc,@ylecun @dgreschler The impact of advancements in the field is directly tied to the increase in data scale. The OpenAI revolution is all about scale.,0,1,0,,,,,
4356,2023-02-01 19:42:06+00:00,GabrielOak7,"@ylecun Having used it daily for two months now, the article overstates the severity and frequency of the mistakes gpt makes. Yes you have to quickly proofread but this does not come near to eliminating the productivity gains",0,1,0,,,,,
4357,2023-02-01 19:37:31+00:00,mrgreene1977,@ylecun @studyouwei 100% agree,1,0,0,,,,,
4358,2023-02-01 19:36:29+00:00,mrgreene1977,@ylecun @tuxtedi Nobody at OpenAI has advertised ChatGPT as a tool for generating scientific research.,1,7,0,,,,,
4359,2023-02-01 19:35:57+00:00,AlexanderFleiss,@ylecun @alexandersumer Professor is it fair to say that it is a well polished random decision forest?,0,0,0,,,,,
4360,2023-02-01 19:27:59+00:00,realkniels,@ylecun @silfen2 ‚ÄúNice packaging‚Äù sells.,0,1,0,,,,,
4361,2023-02-01 19:16:35+00:00,WhiteRabbitCity,"@ylecun If we can't equate these abilities to thinking though, when can we equate our own actions to thinking? If a text AI generates a picture on an Image AI, then visa versa causing a form of AI synesthesia - is it thinking then?",0,0,0,,,,,
4362,2023-02-01 18:59:17+00:00,aneilbaboo,"@ylecun Has anyone tried boosting an LLM with generated training sets - for example, logic puzzles + answers, or Q&amp;A about physical systems?",0,0,0,,,,,
4363,2023-02-01 18:48:12+00:00,HelixBattery,@ylecun It‚Äôs not AI,0,0,0,,,,,
4364,2023-02-01 18:21:39+00:00,george_tkv,"@ylecun Looks like the whole ""differentiation"" thing is irrelevant, until the next trillions of $ of value is created?

Advanced LLM's are moving the GDP needle already. Why wont you help @Meta execs ride this wave?",0,0,0,,,,,
4365,2023-02-01 18:14:08+00:00,iruletheworldmo,@ylecun @studyouwei Why you so bitter? Focus on your own garbage products,1,1,0,,,,,
4366,2023-02-01 18:13:44+00:00,iruletheworldmo,@ylecun So bitter hahahahahahahahaha,0,0,0,,,,,
4367,2023-02-01 17:59:19+00:00,CadwaladerBart1,@ylecun #Metaverse  It all breaks down on the shoals of #metaphor ü§™,0,0,0,,,,,
4368,2023-02-01 17:50:13+00:00,killerstorm,"@ylecun @studyouwei It learned logic, though. 

It can execute Python code, which is as at least as complex as logic.

I.e. you can give a unique, not-seen-before Python code to a LLM, and it continues with the output of the program. This implies that it understands Python semantics and can execute",1,4,0,,,,,
4369,2023-02-01 17:49:31+00:00,CadwaladerBart1,"@ylecun @RachelVT42 And yet, ""I"" am an epiphenomenon in so many ways.  I'm fond of the ""Starting Gun"" studies.  But Kant went back to the Vedas (and didn't tell anyone)",0,1,0,,,,,
4370,2023-02-01 17:19:01+00:00,no_lying_online,"@ylecun to be fair, product people would be more incentivizes to say this than any other role at a company like OpenAI other than marketing.

""no, it wasn't anything to do with the ML tech, it was just how great of a product we packaged it into that made it successful""",0,0,0,,,,,
4371,2023-02-01 17:01:25+00:00,ShafronTom,@ylecun @alexandersumer Is this statement in opposition of Cybenko's paper?,0,0,0,,,,,
4372,2023-02-01 16:56:25+00:00,hemanthkumarak,"@ylecun That is not being disputed and is hence a strawman.

For the knowledge that it *is* designed for, ie, text inputs requesting text outputs and parsing knowledge otherwise deeply embedded in voluminous documentation, it is a game changer!

We should be celebrating that!",0,1,0,,,,,
4373,2023-02-01 16:35:26+00:00,ShafronTom,@ylecun @alexandersumer You can't know that.  A model trained on logic may develop an underlying understanding of causality in order to make itself more efficient at predicting the next word.  Mathematically possible and in fact properly structured appears likely.,0,1,0,,,,,
4374,2023-02-01 16:32:43+00:00,ShafronTom,@ylecun @tuxtedi So do children.,0,0,0,,,,,
4375,2023-02-01 16:27:14+00:00,ShafronTom,@ylecun @studyouwei You can't know that.,0,0,0,,,,,
4376,2023-02-01 16:22:20+00:00,ShafronTom,"@ylecun @hemanthkumarak If they can write original, creative working code then my instinct is that they can solve any logical problem from first principles as they're scaled up.  Which means research.",0,0,0,,,,,
4377,2023-02-01 16:20:14+00:00,ShafronTom,"@ylecun What is the definition of ""thinking"" that you're using?  I'm not sure why ""thinking"" if it means thinking the way a human does it should be a goal or a bar.  Human brains did not evolve to efficiently solve modern science and societal issues.  We're ridiculously inefficient at it",0,0,0,,,,,
4378,2023-02-01 16:15:00+00:00,babkiblyat,@ylecun @hemanthkumarak Then why did your team release galactica? @sama,0,0,0,,,,,
4379,2023-02-01 16:00:49+00:00,laoda2000,"@ylecun @studyouwei If you believe the texts containing logic information, then LLM will eventually catch it.",0,0,0,,,,,
4380,2023-02-01 15:54:29+00:00,Iccanui,"@ylecun Bro this account seems to be turning into a gpt hate account.

Bad look just fyi, we all looking at you like, shouldn't this guy be working on the thing that's supposed to be better? 

Your smarter and hopefully better than that",0,0,0,,,,,
4381,2023-02-01 15:52:52+00:00,prasann_pandya,@ylecun Keep whining!,0,0,0,,,,,
4382,2023-02-01 15:42:07+00:00,avkashchauhan,@ylecun I agree with you and other seasonal AI veterans however clickmongers run the social media and sensationalize everything gives them click revenue,0,0,0,,,,,
4383,2023-02-01 15:39:37+00:00,avkashchauhan,@ylecun Social media is filled with novice teaching AI so anything they see they sensationalize for the clicks revenue #ChatGPT,0,0,0,,,,,
4384,2023-02-01 15:30:39+00:00,vincebrandon,@ylecun Mmm. This feels like BMW complaining that Ferrari still can't make a million mile engine when they put one in the McLaren or something. I think this is a good sign. People are playing favorites with AI systems. I wonder why stable diffusion isn't getting toxic,0,0,0,,,,,
4385,2023-02-01 15:29:19+00:00,imakestupid,@ylecun @andrewryann Attacking‚Ä¶,2,12,1,,,,,
4386,2023-02-01 15:25:03+00:00,tuxtedi,"@ylecun LLMs can be incredibly powerful when used with intention and understanding, but can also produce nonsensical results when used unconsciously.",1,0,0,,,,,
4387,2023-02-01 15:16:21+00:00,PolitWare,@ylecun Try to explain that to a human that has the same problem.,0,0,0,,,,,
4388,2023-02-01 15:15:37+00:00,RodneyRamsey,@ylecun @silfen2 lol,0,0,0,,,,,
4389,2023-02-01 15:11:52+00:00,alc_anthro,"@ylecun @studyouwei Reasoning is an active process. It's not call-response. We talk to ourselves as we reason. And that's not how LLMs work, at least not by themselves.",1,0,0,,,,,
4390,2023-02-01 15:09:04+00:00,garybasin,"@ylecun In fairness, my grasp on reality is also very superficial",0,2,0,,,,,
4391,2023-02-01 14:54:28+00:00,TheFrogDies,"@ylecun that's why they gave it a lot of code to read, cos code is a markup language for reasoning",0,0,0,,,,,
4392,2023-02-01 14:46:29+00:00,cic_agi,@ylecun AI is an inevitable outcome of scientific progress. It is our destiny.,0,0,0,,,,,
4393,2023-02-01 14:40:32+00:00,fthib,@ylecun @ylecun hummmm not sure that meta are super happy of OpenAI + Microsoft success. I‚Äôm so proud that you √† French guys lead AI at Facebook and the father of deep learning. But that  ridiculous that now you minimize the business impact of larges models powered by your concurrent,0,0,0,,,,,
4394,2023-02-01 14:36:17+00:00,hemanthkumarak,"@ylecun Those are indistinguishable for the vast majority of scenarios which require cognitive load to parse verbose context, but not go deeper into creative research. . .

A big improvement to the old way of indexing primitive bits alone and deserving of praise, not amplifying the -ves",2,0,0,,,,,
4395,2023-02-01 14:36:00+00:00,KnowledgeNewfie,@ylecun @RealFade What's FAIR?,0,0,0,,,,,
4396,2023-02-01 14:14:24+00:00,billionlols,@ylecun @erikkartman What papers would one read to learn about these models?,1,0,0,,,,,
4397,2023-02-01 14:12:46+00:00,DishwasherTag,"@ylecun Yann! What are the chances of Google, Meta and OpenAI coming together to create one singular open source giga AI service? 

Or do you think competition is good? AI might be the one industry where competition actually makes each product worse because of licences and gatekeeping?",0,0,0,,,,,
4398,2023-02-01 14:12:08+00:00,billionlols,@ylecun It‚Äôs also just such a shitty interface lol,0,0,0,,,,,
4399,2023-02-01 14:10:08+00:00,h2soheili,@ylecun @mohyazdanpanah,0,1,0,,,,,
4400,2023-02-01 13:45:49+00:00,denisjabaudon,"@ylecun @alexandersumer Why couldn't they learn from texts labeled as describing the physical properties of the world, to which a special weight would be given?",0,1,0,,,,,
4401,2023-02-01 13:43:34+00:00,PimentelES1987,"@ylecun Literally the only thing Apple does, but still ...",0,0,0,,,,,
4402,2023-02-01 13:34:23+00:00,v1vekr,@ylecun The smartphone was just a piece of glass with some non revolutionary computer code and touch technology. It is usability that matters. If it was so easy and obvious to do why didn't Google or Facebook do it,0,0,0,,,,,
4403,2023-02-01 13:27:13+00:00,realkrats,"@ylecun Maybe so, but you‚Äôve also quickly become one of the most bitter people on Twitter in the recent weeks. Don‚Äôt believe me? Go read through your recent tweets.",1,6,0,,,,,
4404,2023-02-01 13:26:29+00:00,oli_aero,"@ylecun Give it a rest , your negativity is getting boring now. Your jealousy is glaringly obvious, not a good look .",1,0,0,,,,,
4405,2023-02-01 13:15:00+00:00,erikkartman,@ylecun That's not because they are nns.,0,0,0,,,,,
4406,2023-02-01 13:14:20+00:00,shrine_sabu,@ylecun Worth reading üî•,0,0,0,,,,,
4407,2023-02-01 13:10:18+00:00,perrabyte,"@ylecun Reality aware ai - 
Reality is secondary probabilities equal what happens in the next step or next 10 years with the output it gave //Per",0,0,0,,,,,
4408,2023-02-01 13:03:33+00:00,geeudee,@ylecun Wow. Do such neural nets currently exist?,2,0,0,,,,,
4409,2023-02-01 13:03:17+00:00,A_F_B_Jr,"@ylecun Do you think that the lack of time concept and only one modality of input (text) could be some of the reasons for this? Since LLMs Don't perceive time and have no knowledge of the real world it is impossible for it to ""think"" as we do.",0,0,0,,,,,
4410,2023-02-01 13:01:34+00:00,kJ39892ab,@ylecun @studyouwei Debatable,0,0,0,,,,,
4411,2023-02-01 13:00:20+00:00,907Resident,@ylecun @SaveToNotion #tweet #LLM #nlp #ChatGPT #research,1,0,0,,,,,
4412,2023-02-01 13:00:14+00:00,natwitte,@ylecun Grasp of reality? This is the joke of the day!,0,0,0,,,,,
4413,2023-02-01 12:59:27+00:00,rohitrango,"@ylecun Also Galactica, but people use both differently.",0,0,0,,,,,
4414,2023-02-01 12:43:16+00:00,kailuowang,"@ylecun It's obvious that the two aren't equivalent in private thinking. Public thinking (the constituent of collective human intelligence and knowledge), otoh, exist almost solely in languages.
  1/2",2,0,1,,,,,
4415,2023-02-01 12:41:20+00:00,devitt_james,"@ylecun Frazer, the Steve Jobs of AI. Built more then a product. Wonder what‚Äôs next.

(meant  as a compliment)",0,0,0,,,,,
4416,2023-02-01 12:39:07+00:00,meihym23,@ylecun We just need another AI tool to spot the nonsenses... so to save a lot of humans from thinking too hard ü§ñ,0,0,0,,,,,
4417,2023-02-01 12:29:34+00:00,DavidRimshnick,"@ylecun Again, you are ignoring the results that LLMs get better at general reasoning the more computer code they read.",0,0,0,,,,,
4418,2023-02-01 12:29:13+00:00,other_musings,"@ylecun We need a model for thinking, and another one for rendering. It won‚Äôt be large-kind of model-view separation.",1,0,0,,,,,
4419,2023-02-01 12:26:28+00:00,djmalvarado,@ylecun Nice.,0,0,0,,,,,
4420,2023-02-01 12:13:53+00:00,kailuowang,"@ylecun From the article: ""Although ChatGPT can generate fluent and sometimes elegant prose, easily passing the Turing-test benchmark that has haunted the field of AI for more than 70 years..."" 
Apparently the author can use some more research.",0,0,0,,,,,
4421,2023-02-01 12:01:36+00:00,realkrats,@ylecun Still bitter I see‚Ä¶,1,5,0,,,,,
4422,2023-02-01 12:00:40+00:00,ShanRizvi,"@ylecun Indeed, language abilities are not equivalent to thinking. Language models such as ChatGPT can generate eloquent sentences, but lack the depth of understanding that true thinking requires.",0,4,2,,,,,
4423,2023-02-01 11:46:32+00:00,andrewryann,"@ylecun Ffs, can you just stop tweeting and build something useful instead? We, the Meta shareholders are waiting for a breakthrough in AI Space from Meta. And instead, we get tweetstorm from their AI Chief Scientist bashing other project. @boztank @randizuckerberg",0,0,0,,,,,
4424,2023-02-01 11:44:51+00:00,Sergey_lll,@ylecun https://t.co/42ibEri0eV,0,0,0,,,,,
4425,2023-02-01 11:25:27+00:00,spuliz91,@ylecun Humans do not want thinking machines @ylecun! Humans want better AI apps that augment human intelligence. Tell this to your collaborators.,1,0,0,,,,,
4426,2023-02-01 11:15:36+00:00,SpaceStrauss,"@ylecun Being a lousy speaker, I finally find some consolation.",0,0,0,,,,,
4427,2023-02-01 11:03:40+00:00,ndeville,"@ylecun It's nothing revolutionary for you both b/c you are too embedded in the topic &amp; too intelligent.
I get the frustration though.
Technology adoption curves are not linear - a small increment brings it to inflexion point.
+ you/Meta also benefited from AI research since the 70s ;)",0,0,0,,,,,
4428,2023-02-01 11:00:17+00:00,DirtyScrubz,"@ylecun @RealFade Meta is trash. If it is using AI for moderation and social content, then it is a waste. ChatGPT is useful to the public.",0,0,0,,,,,
4429,2023-02-01 10:59:51+00:00,studyouwei,"@ylecun Text is the results of logic thinking by humans. Learning from text definitely allows LLM to learn the unlying logic, but maybe only the ‚Äòshallow‚Äô logic,  or a logic that is still not well unstood by humans. ‚Äòprompt engineering‚Äô  helps bridge the logic gaps",1,0,0,,,,,
4430,2023-02-01 10:54:55+00:00,MLDawn2018,"@ylecun Thank God! Finally, a real expert spoke up :-)",0,4,0,,,,,
4431,2023-02-01 10:54:30+00:00,yangpyong5,@ylecun lol u vastly underestimate product iteration value from interacting with the real world,0,0,0,,,,,
4432,2023-02-01 10:51:52+00:00,Mingke,"@ylecun Language is the lower dimensional projection of mind, but not mind itself.",3,2,0,,,,,
4433,2023-02-01 10:51:16+00:00,yshour1,@ylecun @RealFade Meta develop AI tool to keep users addicted to social media. OpenAI develop AI tool so that users can use it to improve daily work productivity. They are not the same.,1,7,0,,,,,
4434,2023-02-01 10:44:22+00:00,Ugo_alves,@ylecun @silfen2 Show me you‚Äôre an academic without telling me you‚Äôre an academic,0,6,0,,,,,
4435,2023-02-01 10:43:11+00:00,GMCYann,@ylecun what is thinking anyway?,0,0,0,,,,,
4436,2023-02-01 10:35:07+00:00,DanielFein7,@ylecun https://t.co/4DZdmzlV3A,1,9,0,,,,,
4437,2023-02-01 10:32:58+00:00,antoniogulli,"@ylecun @silfen2 Well, Apple made the music experience so simple that everyone had an ipod at certain time.  Are you saying that the same is happening here?",0,0,0,,,,,
4438,2023-02-01 10:29:43+00:00,chippchase,"@ylecun Language gives the user the ability to label, store, and communicate thoughts. It's a requirement for intelligence.",1,0,0,,,,,
4439,2023-02-01 10:24:51+00:00,bimrian,"@ylecun Yann, stop this. It's a mockery to the science. I like what @CarolynBertozzi said at her @NobelPrize talks last year on there being scientists who do BASIC science &amp; others building on top of their work. Sure, AI researchers should be recognized, so that this silly debate ends!",0,0,0,,,,,
4440,2023-02-01 10:23:13+00:00,alrhemist,"@ylecun I wondered why Meta don't ship new exciting AI products &amp; tweeted this last year.
The past few days of reading Yann LeCun's Tweets gave me my answer @MetaAI and @Meta employ ""Old Heads"" who rate PhD papers &amp; github codes higher than actual Useful products 
https://t.co/PT8bTbylrO",1,0,0,,,,,
4441,2023-02-01 10:18:13+00:00,bcsagar1,@ylecun This even applies to loud mouth journalists &amp; politicians..ü§™,0,0,0,,,,,
4442,2023-02-01 10:13:08+00:00,loopuleasa,"@ylecun the difference between improvisational language spewing, and reasoning and abstraction is the realm of memetics

https://t.co/p31aNSjRKb",0,0,0,,,,,
4443,2023-02-01 10:12:41+00:00,Dr_Savage__,@ylecun @togelius Have a position as AI Engineer in LinkedIn so that HR won't get confused and reject my profile for job opportunities üòÖ,0,0,0,,,,,
4444,2023-02-01 10:11:17+00:00,erikkartman,"@ylecun Artificial neural networks are unable to think, process, do logic or any kind of computation by design. All they do is map immediate input to immediate output. So this statement should be obvious even without brain study.",4,0,0,,,,,
4445,2023-02-01 10:05:05+00:00,SturnioloSimone,"@ylecun Thinking isn't the same as having a grasp of reality, though. ""Reality"" is what our senses interact with; ChatGPT had no direct contact with it. A human raised only on books would have a very different (and often wrong) notion of the world than one who got to see it first hand.",0,2,0,,,,,
4446,2023-02-01 10:01:02+00:00,Thomsen12321,"@ylecun that is fine, most people never think when they speak. At least, AI can do little bit better",0,0,0,,,,,
4447,2023-02-01 09:41:45+00:00,RachelVT42,"@ylecun I don‚Äôt quite agree with 35 though. It might have been true for his generation, but not necessarily true now. The main issue is the amount of learning required to understand change and progress tbh.",0,1,0,,,,,
4448,2023-02-01 09:39:57+00:00,cwizprod1,@ylecun it's every bit as good as most human's grasp of reality. I'm starting to wonder what your qualifications actually are. most of your posts seem rather - nonsensical.,0,0,0,,,,,
4449,2023-02-01 09:36:39+00:00,0x440x46,@ylecun https://t.co/PYMsmbsPtA,0,0,0,,,,,
4450,2023-02-01 09:32:30+00:00,andrewryann,"@ylecun Why focus on attacking, instead of build something useful for Meta?",3,11,1,,,,,
4451,2023-02-01 09:26:01+00:00,mol_tagine,"@ylecun Okay, but chatGPT is greater and extremely more useful than many thinkers üòâ‚úÖ‚úÖ",1,0,0,,,,,
4452,2023-02-01 09:20:26+00:00,BobbyHugh,"@ylecun Does ChatGPT or LLMs have a grasp?

I‚Äôm not sure these AIs are agents with a capacity to act, but rather just machines with commands to follow. 

Admittedly, this is a bit of pedantic point, but default phrasing tends to imbue these AIs with powers they don‚Äôt actually possess.",0,0,0,,,,,
4453,2023-02-01 09:19:35+00:00,minkymorgan,@ylecun There is a theme here to explore examining the differences between Industrialising and Inventing.,0,0,0,,,,,
4454,2023-02-01 09:19:09+00:00,David____8,@ylecun LLM achieves equivalent results compared to thinking. That is already very valuable,1,1,0,,,,,
4455,2023-02-01 09:18:33+00:00,hardt_data,@ylecun The same misconceptions exist about humans.,0,0,0,,,,,
4456,2023-02-01 09:17:33+00:00,lifeonmarsspace,@ylecun what is the difference between a human and a system acting by all conceivable metrics alike to a human?,1,0,0,,,,,
4457,2023-02-01 09:17:30+00:00,hardt_data,"@ylecun It's all been there, in @SchmidhuberAI's lab, back in the 90s.",0,0,0,,,,,
4458,2023-02-01 09:15:36+00:00,faroukianoxide,@ylecun We are not saying ChatGPT is revolutionary but the user experience and the sensation therefrom is.,1,1,0,,,,,
4459,2023-02-01 09:10:17+00:00,2OfAnything,@ylecun @RealFade Let it go chief you lost this one,0,2,0,,,,,
4460,2023-02-01 09:06:37+00:00,JaitanMartini,"@ylecun @dgreschler And making them useful is a noble job too, can even be revolutionary",0,5,0,,,,,
4461,2023-02-01 09:02:03+00:00,Cybersamurai77,@ylecun we know its not but no one else is being open about what they're developing,0,0,0,,,,,
4462,2023-02-01 09:02:02+00:00,RachelVT42,"@ylecun I *think* therefore I am, not I speak therefore I am, right? üòâ",1,4,0,,,,,
4463,2023-02-01 08:57:18+00:00,metarooster,@ylecun A computer would deserve to be called intelligent if it could deceive a human into believing that it was human. - Alan Turing,0,1,0,,,,,
4464,2023-02-01 08:56:03+00:00,curiousspaceman,"@ylecun as strange as it may sound, this gives some relief that engineering jobs will stay for few more years",1,1,0,,,,,
4465,2023-02-01 08:55:46+00:00,JaitanMartini,@ylecun ahahaha. The market knows it better,0,0,0,,,,,
4466,2023-02-01 08:51:09+00:00,Rubenia_Borge,@ylecun Thank you for sharing. It's interesting to learn all these different facts and also perspectives.,0,0,0,,,,,
4467,2023-02-01 08:50:03+00:00,hemanthkumarak,"@ylecun Strawman.

Does it matter what the linguistic semantics used to describe LLMs abilities are if those abilities are amazing and solve real problems?",3,9,0,,,,,
4468,2023-02-01 08:41:30+00:00,walter_h_g,@ylecun Ask a parrot ü§≠,0,1,0,,,,,
4469,2023-02-01 08:35:50+00:00,therealBoronik,"@ylecun people surely do not adapt to rational explanations like eg ""nicotine abuse invites complex other interests to take hold and exert  influence on u"", but to what is. So if ai is (eg a potent help, trustworthy source, etc), people adapt, and it becomes (eg more powerful, manifest)",0,0,0,,,,,
4470,2023-02-01 08:33:49+00:00,numerique78,@ylecun Agree.. the last book of Brian Greene provides a great view of what is intelligence....no doubt about AI  (a confusing name),0,1,0,,,,,
4471,2023-02-01 08:31:26+00:00,hemanthkumarak,"@ylecun You wouldn‚Äôt be saying the same thing if this came out of FAIR ü§∑‚Äç‚ôÇÔ∏è

It‚Äôs disappointing to see the passive aggressiveness at being beaten to market by a superior product

Even the touch screen wasn‚Äôt ‚Äúanything revolutionary‚Äù. Guess what packaging it well did for the phone?",0,0,0,,,,,
4472,2023-02-01 08:30:52+00:00,Olivier_Glr,@ylecun Please stop ranting about chatGPT this is is absolutely annoying for everybody on Twitter,0,14,0,,,,,
4473,2023-02-01 08:30:36+00:00,zussini,"@ylecun 1/2 Thanks for the article. I wonder... If it could not be generalized as overloaded network with data... Huge amounts, which are of different scale then we are used to as humans. So if we would not get simular effect with overloading our brains.",2,0,0,,,,,
4474,2023-02-01 08:27:50+00:00,sidham_song,@ylecun Correct. But humans will only pay for AI that could talk eloquently rather than that could think profoundly. Because most humans are also superficial.,0,0,0,,,,,
4475,2023-02-01 08:26:45+00:00,Dmojavensis,@ylecun Nothing since quantum mechanics a century ago has been so novel as to really be counterintuitive.,0,0,0,,,,,
4476,2023-02-01 08:23:44+00:00,alexandersumer,"@ylecun @ylecun you are right. Language can model reality, but doesn't have to‚Äîthe statement ""I saw an aeroplane flying backwards"" violates the laws of physics.

ChatGPT appears to have a causal model of reality because the text it is trained on happens to contain many examples that do.",1,13,0,,,,,
4477,2023-02-01 08:21:58+00:00,michabdelmalek,"@ylecun In defense of the LLMs, most people have the same level of grasp of reality.",0,7,0,,,,,
4478,2023-02-01 08:21:29+00:00,JohnnyNi13,"@ylecun Interesting take, I guess it comes down to the intellectual quality and sensibility of the actual conversation taking place",0,1,0,,,,,
4479,2023-02-01 08:20:17+00:00,tuxtedi,"@ylecun ChatGPT is a source of extensive knowledge and immense creativity, having been trained on a vast corpus of books and other sources of information.",2,7,1,,,,,
4480,2023-02-01 08:16:34+00:00,bailoo,"@ylecun Interestingly a large number of people and industries have been doing precisely that and these are the first ones to be disrupted. Nobody is surprised that gpt can write like a film critic or a wine critic  or someone who writes for ""seo""",1,0,0,,,,,
4481,2023-02-01 08:15:10+00:00,davegoldblatt,@ylecun I think you severely overestimate most humans grasp of reality,0,17,0,,,,,
4482,2023-02-01 08:10:57+00:00,AIOverlord777,@ylecun @silfen2 If ‚Äúnice packaging‚Äù means ‚Äúavailable for the mass public to use‚Äù.,0,3,0,,,,,
4483,2023-02-01 08:09:17+00:00,AIOverlord777,@ylecun @RealFade Who invented the transformer? ü§î,0,0,0,,,,,
4484,2023-02-01 08:06:24+00:00,MickBLang,"@ylecun At about 18 when I saw my first web page in a web browser, I thought ah they've added images to hypertext, no big deal.

When the iPod came out, people said it stood for.. 

""Idiots Price Our Devices""

..because smaller, cheaper, more clunky mp3 players had been around for years.",1,0,0,,,,,
4485,2023-02-01 08:02:32+00:00,RightsInfringer,"@ylecun @RealFade This is like saying Facebook is only  made possible by browser vendors which is a silly argument. 

OpenAI beat out Meta because they captured the public's imagination with a great product. Nobody cares if Meta uses LLMs to improve retention.. It's not helping me write code..",0,3,0,,,,,
4486,2023-02-01 07:59:02+00:00,DrHughHarvey,@ylecun Thanks @ylecun,0,0,0,,,,,
4487,2023-02-01 07:55:11+00:00,RightsInfringer,@ylecun @bitcloud You can have the most capable LLM out but if it's being implemented in a predatory way to increase retention on a social media site vs offering highly beneficial outputs to the general public in a clean interface then its just not even in the same ballpark.,0,2,0,,,,,
4488,2023-02-01 07:39:19+00:00,m_road2,@ylecun @RealFade Censorship and ranking ads before what you want... Revolutionary.,0,2,0,,,,,
4489,2023-02-01 07:38:52+00:00,spuliz91,@ylecun @silfen2 I love how you call UX and frontend ‚Äúnice packaging‚Äù ü§£ It‚Äôs kind of scary that an AI leader at your level has this perception of human-machine interaction,0,11,0,,,,,
4490,2023-02-01 07:36:06+00:00,spuliz91,@ylecun @__goldfinger The revolution started inside your labs and wasn‚Äôt shared to the public. What‚Äôs different this time?,1,5,0,,,,,
4491,2023-02-01 07:34:16+00:00,spuliz91,@ylecun @RealFade @ylecun showing clear signs of jealousy?,0,3,0,,,,,
4492,2023-02-01 07:19:21+00:00,a77g_,"@ylecun Is that really important? No. You don‚Äôt win anymore with innovative technology, but with a great Product and distribution. This is what made stand out OpenAI from the rest with ChatGPT.",0,0,0,,,,,
4493,2023-02-01 06:57:44+00:00,therealBoronik,"@ylecun porn spreads quickly, so do eg sugar, nicotine and affective emotions. Where do affective emotions originate? U don't know. U want to know why people nowadays r a lot less capable of gleaming what's up (+ what's down)? Substance abuse - helpful dream-content remains unconscious",1,0,0,,,,,
4494,2023-02-01 06:56:09+00:00,paximperatoria,@ylecun So what is your point @ylecun? Vous √™tes entrain de mettre des coups d‚Äô√©p√©e dans l‚Äôeau,0,1,0,,,,,
4495,2023-02-01 06:45:32+00:00,SapkotaTsuman,"@ylecun @francoisfleuret @trekkinglemon BN before activation ignores the weight magnitude, but turns out it still creates problem for the gradient magnitude.
- It works for l2 normalized weights.
- Still, the scaling (learnable or fixed) is needed.
# Would BN after activation help though ?",0,0,0,,,,,
4496,2023-02-01 06:43:15+00:00,DeepSpaceKaren,@ylecun Im 42 and love keeping up with new technology. Seems perfectly normal to me. In fact I can‚Äôt wait to see what the next 10-20 years has in store. My 85 year old grandmother was better at using a computer than her 50 year old daughter. I wouldn‚Äôt stereotype this much.,0,2,0,,,,,
4497,2023-02-01 05:58:04+00:00,tripp_jaden42,@ylecun Literally all goes back to this https://t.co/FYGUtFlj94,0,0,0,,,,,
4498,2023-02-01 05:58:02+00:00,matloff,"@ylecun I disagree. A technology may spread for lots of reasons, e.g. a charismatic leader and a desire for ""neat"" solutions to problems. And the young are often the most impressionable in this regard.",1,3,0,,,,,
4499,2023-02-01 05:38:31+00:00,TheBeauregard87,@ylecun @sama Bawk.,0,0,0,,,,,
4500,2023-02-01 04:50:44+00:00,DevDminGod,@ylecun @francoisfleuret Asked ChatGPT to explain: https://t.co/0gqWfdkDrC,0,0,0,,,,,
4501,2023-02-01 04:43:42+00:00,SaileNav,@ylecun Distribution vs better product. Often better distribution wins in startup la d and that's what's happening here.,0,0,0,,,,,
4502,2023-02-01 03:57:50+00:00,jackythirdy,"@ylecun The thing is, why do you keep grinding on a talking point that you are aware making people you know and don't know uncomfortable? You've got your point across what else do you wan",0,0,0,,,,,
4503,2023-02-01 03:52:00+00:00,SaraASolla,"@ylecun @francoisfleuret The activation functions of real neurons are nonnegative, and as such they cannot possibly integrate to zero over the domain of interest. Yet another way in which Artificial Neural Networks are not good models of the brain.",1,1,0,,,,,
4504,2023-02-01 03:48:35+00:00,babkiblyat,"@ylecun Google with their 42,000 token model with their new KV methods on the PaLM ‚Ä¶",0,0,0,,,,,
4505,2023-02-01 03:15:54+00:00,sergedeh,"@ylecun The innovation and revolution felt by the public is in the way chatGPT was ""well put together""(WPT), the next revolution may be:
1. Alexa + ChatGPT ""well put together""
2. Ameca + Alexa + ChatGPT ""well put together""
3. Atlas + Ameca + Alexa + ChatGPT ""well put together""",0,0,0,,,,,
4506,2023-02-01 03:08:36+00:00,__goldfinger,@ylecun It started a revolution. That is by definition revolutionary. GPT iterations prior to that were moderately interesting. That's not to say it's unique.,1,10,0,,,,,
4507,2023-02-01 03:01:27+00:00,alanytan,"@ylecun Most ppl underestimate language is an abstract model of reality‚Äîsymbolizing is a sign of intelligence, processing symbolized data (LLM) is impressive but does not equally to being able to symbolize.",1,1,0,,,,,
4508,2023-02-01 02:50:01+00:00,Extended_Brain,"@ylecun We need to differentiate between being revolutionary technologically and revolutionary in its applications. For the latter, we must estimate its impact on society.

So it is not contradictory, not being revolutionary technologically, but revolutionary in its applications",1,5,1,,,,,
4509,2023-02-01 02:31:30+00:00,Hello_World,@ylecun still completely out of touch with reality. You both are.,0,0,0,,,,,
4510,2023-02-01 02:22:32+00:00,caseywickland,"@ylecun It may not be revolutionary in your labs, but it is incredibly useful to the public.  Google and Meta could not monetize, so they keep it to themselves.  It may not be perfect, but it is better than nothing.  It can get better from here, now that the public is also engaged.",0,10,1,,,,,
4511,2023-02-01 02:20:28+00:00,3DTOPO,@ylecun Perhaps you should change your handle to antiGPT?,0,1,0,,,,,
4512,2023-02-01 02:12:57+00:00,ABiteofNews,@ylecun you doing something right when they try to downplay your accomplishments,0,1,0,,,,,
4513,2023-02-01 02:01:37+00:00,aa73562,@ylecun My great great great .. father is the inventor of the fire üî• and the wheel üõû.. but the way people used his invention is what really matter in the end of the day..,0,1,0,,,,,
4514,2023-02-01 01:28:55+00:00,NGRColosimo,"@ylecun Guess many dimensions to what makes a thing 'Revolutionary'. To the general public it is accessible, usable, and useful. They don't need a PhD. Revolutionary in the dimension of 'use case breadth'. Utilitarian.
Sure from a CompSci view there's not much to write home about. Yet.",0,0,0,,,,,
4515,2023-02-01 00:59:27+00:00,RealFade,@ylecun What is R&amp;D worth if you can't ship,2,10,0,,,,,
4516,2023-02-01 00:58:16+00:00,debarghya_das,"@ylecun ""It's nothing revolutionary, it's just really well put together"" hits at the core of the researcher‚Äìengineer conflict. 

Researchers aim for revolutionary.
Engineers aim for really well put together and usable. 

You could say the same thing about the iPhone.",2,89,0,,,,,
4517,2023-02-01 00:34:44+00:00,ZerzarBukhari,@ylecun Unfortunately Big companies have trouble attracting (and retaining) great product talent,0,0,0,,,,,
4518,2023-02-01 00:31:35+00:00,VisionsofAI,"@ylecun Don't you see the high demand for this product? When ChatGPT is down, that's an opportunity for another offering to take advantage of that demand.

If you have a better product then release it. That way we have more options.",0,1,0,,,,,
4519,2023-02-01 00:30:39+00:00,JimmyBa62254692,@ylecun The problem is any of the bots that can compete with chatgpt are hidden behind the public at private companies like Google or Facebook. ChatGPT is the first public tool that shows initial signs of what AI can do. Public perception is very important to accelerate AI funding.,0,0,0,,,,,
4520,2023-02-01 00:26:59+00:00,dgreschler,@ylecun It would help to understand what you define as revolutionary. List 3 technologies that you believe were revolutionary.,1,1,0,,,,,
4521,2023-02-01 00:25:47+00:00,scastle999,"@ylecun Kinda like the PalmPilot folks dismissing the iPhone, wreaks of sour grapes.",0,0,0,,,,,
4522,2023-02-01 00:25:41+00:00,nicksaraev,"@ylecun the overhang is very real. with government-level resources, we probably could have built agi a decade ago.",1,1,0,,,,,
4523,2023-02-01 00:22:57+00:00,etothepowerx,@ylecun What's revolutionary is what affects the public.,0,1,0,,,,,
4524,2023-02-01 00:21:56+00:00,magania0,"@ylecun What I apreciate from ChatGPT is that allowed pedestrians like me that can't afford to train them, to explore with almost a state of the art LLM.  Maybe a open source free comercial use container with a trained model would be better but a cheap API is close enough.",0,1,0,,,,,
4525,2023-02-01 00:19:19+00:00,Chat2Cricket,"@ylecun Prof, people‚Äôs verdict is already out. AI doesn‚Äôt need to be zero sum. We are totally fine with this amazing half baked solution. We will figure out which use cases it can solve right now. Let it iterate and improve.",0,1,0,,,,,
4526,2023-02-01 00:04:26+00:00,Ki_fun_thoughts,"@ylecun @togelius Grammar Nazi, meet AI Nazi.",0,0,0,,,,,
4527,2023-02-01 00:00:54+00:00,npparikh,"@ylecun @togelius It stinks because in policy settings you have to overuse ‚ÄúAI,‚Äù just as computer security people get stuck having to use ‚Äúcybersecurity.‚Äù",0,0,0,,,,,
