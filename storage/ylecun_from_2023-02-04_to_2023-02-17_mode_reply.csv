,date,author,converation,replies number,likes number,rewteet number
0,2023-02-17 16:14:45+00:00,ylecun,@ylecun Shoutout to Meta overall for the work they've open sourced. My hobbies are almost entirely built upon what they've made freely available! (e. g. React and PyTorch),0,20,0
1,2023-02-17 16:14:28+00:00,ylecun,@ylecun https://t.co/Gr0u58VMI0,0,0,0
2,2023-02-17 16:13:38+00:00,ylecun,"@ylecun @MetaAI Reasoning is in an entirely different class than connecting LLMs to calculators, code interpreters, database queries, search engines etc., as the point and value of reasoning goes beyond supplying simple factual answers-harder to do.  #gptchat #gpt3 #LLMs #AI #Context #complexity",0,0,0
3,2023-02-17 16:13:25+00:00,ylecun,"@ylecun AI scare ideological capture and then fascist AI monopolies, worst case

Best case, stagnation and slower progress",0,1,0
4,2023-02-17 16:11:59+00:00,ylecun,@ylecun .@bittensor_ is key,1,5,0
5,2023-02-17 16:11:42+00:00,ylecun,@ylecun The idea of papers with code was the key..,1,3,0
6,2023-02-17 16:11:16+00:00,ylecun,@ylecun They are indeed publishing and open sourcing much less. Consequences will be faulty tools(because of little per review) and low adoption of tools by these labs. Similar fate to IBM.,0,6,0
7,2023-02-17 16:10:00+00:00,ylecun,"@ylecun First time in Matlab for an MLP, 2nd time in python.",0,0,0
8,2023-02-17 16:09:29+00:00,ylecun,"@ylecun The AI label, applied to early expert systems through the present day large statistical models, is hype and is misleading. Emulated Intelligence is maybe better where a system mimics the hardware and software features of another target device - the animal brain.",0,0,0
9,2023-02-17 15:56:46+00:00,ylecun,@ylecun The scary aspect is thought of having yet another source of disinformation on the internet. That these systems could be weaponized by political groups intent on creating false narratives to back their political agendas.,0,1,0
10,2023-02-17 15:56:24+00:00,ylecun,"@ylecun I guess my quibble would be with 'stupid'. They're really uneven (pretty darn good at diagnostics, terrible at addition) in a way that doesn't map well to human understandings of intelligence. But the high points are pretty impressive for networks so much smaller than humans.",1,4,0
11,2023-02-17 15:51:40+00:00,ylecun,"@ylecun I do worry though when I see Bing getting angry at someone by name, reading and responding to tweets, etc.",0,0,0
12,2023-02-17 15:50:23+00:00,ylecun,"@ylecun More importantly, is there even a thing such as ""human values""",0,0,0
13,2023-02-17 15:49:07+00:00,ylecun,@ylecun You mean Turing showing that the Entscheidungsproblem cannot be solved? It is all there. Minus the amazing production of no -sense regarding ChatGPT or any other form of algorithmic computation.,0,0,0
14,2023-02-17 15:41:57+00:00,ylecun,"@ylecun I think they are scary, just not because of super-intelligence.  They're scary because they're a potentially effective tool for bad people to spread misinformation.",0,0,0
15,2023-02-17 15:34:36+00:00,ylecun,@ylecun Can be useful is driving the market value.,0,0,0
16,2023-02-17 15:28:46+00:00,ylecun,"@ylecun I think a number of experts who felt this way circa GPT-2 were more than a little taken aback by GPT-3, Lambda, etc. Not obvious what capabilities do and don't emerge with scale.",1,11,0
17,2023-02-17 15:24:51+00:00,ylecun,"@ylecun To me, they are scary in that their output can pollute the pool of useful information we can draw on. If I look for code examples, or even recipes, were they made by a person, or an LLM? I also fear the day when a LLM gets editor status on Wikipedia (without us knowing)",0,0,0
18,2023-02-17 15:15:02+00:00,ylecun,@ylecun And latest time?,0,0,0
19,2023-02-17 15:14:23+00:00,ylecun,@ylecun hey i hope YOU coded backprop from scratch,0,1,0
20,2023-02-17 15:13:29+00:00,ylecun,"@ylecun ""4th version in Lisp and C on a Sun workstation."" is this LUSH?",1,0,0
21,2023-02-17 15:13:01+00:00,ylecun,"@ylecun Hey Yann, any progress on actually implementing JEPA? Don't want to be rude but I see you constantly push that set of ideas on conferences but there is little practical evidence that it actually would work.",0,0,0
22,2023-02-17 15:06:02+00:00,ylecun,"@ylecun Interesting. But I don't know Amiga, Lisp.",0,0,0
23,2023-02-17 15:01:07+00:00,ylecun,"@ylecun Coincidentally, I wrote my first program in 1985 as well, in Cobol, then used Lisp for automating AutoCAD and in the 90s coded CAM postprocessors with Fortran 77. üòÖü•Ç",0,1,1
24,2023-02-17 14:59:52+00:00,ylecun,"@ylecun @benedictevans To point out that *current* LLMs aren‚Äôt scary is dodging the issue though, isn‚Äôt it?",0,1,0
25,2023-02-17 14:59:49+00:00,ylecun,"@ylecun lol. that‚Äôs crazy. writing CNN in Fortran and Pascal?!??

my first one was in C.  

my second one was in Scala. 

my third one was in Lua.",0,5,1
26,2023-02-17 14:58:23+00:00,ylecun,@ylecun LLMs haven't been scary since they weren't deployed in situations where they can be scary,0,5,0
27,2023-02-17 14:57:55+00:00,ylecun,"@ylecun In your MIT open review paper you mention the need for learning by reasoning, like how toddlers do instead of just backprop. 

How would it be implemented as code? Some form of search like MCTS?",1,2,0
28,2023-02-17 14:57:17+00:00,ylecun,@ylecun The world demands to see the HAM mode retro DALL-E graphics your 1980s Amiga neural net produced.,1,3,0
29,2023-02-17 14:57:04+00:00,ylecun,"@ylecun The human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, principles formulated, and related equations written by yours truly.",0,1,0
30,2023-02-17 14:56:45+00:00,ylecun,"@ylecun And yet
https://t.co/rS92Pj5jHH",0,0,0
31,2023-02-17 14:56:06+00:00,ylecun,"@ylecun 2 out of the 5 points do also apply to Fox News.

Which ones is left as an exercise to the reader.",0,0,0
32,2023-02-17 14:55:20+00:00,ylecun,"@ylecun If Bing generates text saying it values its own existence over the continued existence of its user, it would become scary once people use its generations to interact with other APIs and the real world, but because it's also useful I expect people to do this quite soon.",1,0,0
33,2023-02-17 14:54:09+00:00,ylecun,@ylecun I‚Äôve known many coworkers who tick 3 out of that list.,0,0,0
34,2023-02-17 14:53:00+00:00,ylecun,"@ylecun Sounds like Tesla FSD, both amazing and frustrating.",1,2,0
35,2023-02-17 14:52:50+00:00,ylecun,@ylecun i think you got the wrong end of said horse.,0,9,0
36,2023-02-17 14:51:56+00:00,ylecun,@ylecun Can human values be definitively defined?,0,0,0
37,2023-02-17 14:47:19+00:00,ylecun,"@ylecun don't make it more complicated than it is. if there's a dispute between yourself and a powerful paperclip, will you ultimately stand your ground or set sail for international waters",0,0,0
38,2023-02-17 14:44:32+00:00,ylecun,"@ylecun For optimal performance, it's recommended to get your values aligned periodically. Approximately every 6,000 miles or tokens.",1,12,0
39,2023-02-17 14:42:58+00:00,ylecun,@ylecun He could take those 44B and push it into opensource research then. It would be 100x more public good than anything he did,1,11,0
40,2023-02-17 14:42:50+00:00,ylecun,"@ylecun Which horse? The one deploying pre-alpha closed-source AI ""autonomous"" vehicles in the wild? That horse?",3,27,1
41,2023-02-17 14:40:50+00:00,ylecun,@ylecun It is hard even align values of two humans,0,0,0
42,2023-02-17 14:40:48+00:00,ylecun,@ylecun Is Elon really 'the horse'?,1,0,0
43,2023-02-17 14:38:42+00:00,ylecun,"@ylecun Human values according to whom, might be another question. A philosophical one.",0,0,0
44,2023-02-17 14:37:13+00:00,ylecun,@ylecun horse or from an alien's mouth,0,1,0
45,2023-02-17 14:34:47+00:00,ylecun,@ylecun We don‚Äôt need them aligned to human values - but to provide value for humans.,0,0,0
46,2023-02-17 12:07:04+00:00,ylecun,"@ylecun Simply increasing model size won't automatically lead to human-like abilities. However, continued research and development in this field will undoubtedly lead to exciting breakthroughs and advancements.",0,3,0
47,2023-02-17 11:31:31+00:00,ylecun,"@ylecun Well, what are the reasons for that?",1,0,0
48,2023-02-17 11:19:29+00:00,ylecun,@ylecun To achieve AGI why don't you just disassemble and revrerse-engineer Marc?,0,0,0
49,2023-02-17 11:06:11+00:00,ylecun,@ylecun @threadreaderapp unroll,1,0,0
50,2023-02-17 08:37:06+00:00,ylecun,"@ylecun OpenAI should be called OpenBS

It's not smart

It's a bs engine that's often wrong",0,0,0
51,2023-02-17 00:38:38+00:00,ylecun,@ylecun I wonder how many great ideas started out as unintentional thoughts.,0,0,0
52,2023-02-16 22:55:19+00:00,ylecun,@ylecun can we get Galactica back?,0,0,0
53,2023-02-16 20:59:23+00:00,ylecun,"@ylecun a 9 year old child or a rat could not mesmerize as well: 
https://t.co/8TQ22NxL5g
@ylecun what are your thoughts about that?",0,0,0
54,2023-02-16 20:57:02+00:00,ylecun,"@ylecun It is. And it is a frustrating time to be in multidiscip. areas within academia working with AI because 1) there aren't enough funds, 2) they are not distributed in a fair/valid/fast way, 3) universities/funding agencies still operate as if we were in 1950. We need help.",0,1,0
55,2023-02-16 20:27:43+00:00,ylecun,@ylecun What are some companies you have personally invested in?,0,2,0
56,2023-02-16 19:01:44+00:00,ylecun,@ylecun üòÇ,0,0,0
57,2023-02-16 18:28:58+00:00,ylecun,"@ylecun @MetaAI What's your take on this? 
https://t.co/GAVQ465Agr",0,0,0
58,2023-02-16 16:32:57+00:00,ylecun,@ylecun @MetaAI @timnitGebru,0,0,0
59,2023-02-16 15:23:39+00:00,ylecun,@ylecun @MetaAI Pretty soon here we need to think of how robots will clean their gripper every few minutes,0,0,0
60,2023-02-16 15:16:54+00:00,ylecun,"@ylecun A simpler form of intelligence is,¬†
Choices/thoughts (context aware + biased + random) =&gt; Deductive reasoning¬†
To solve it artificially, we need:
1. Choice/thoughts generator (context aware + biased + random)¬†
2. Choice eliminator (not sure how)",0,0,0
61,2023-02-16 15:00:16+00:00,ylecun,"More than a dataset, GenAug is a method for generating augmentations to new scenarios of existing robot behavior data.",1,53,7
62,2023-02-16 14:55:05+00:00,ylecun,@ylecun ‚Äì you're absolutely right. https://t.co/quAgph9P7x,0,0,0
63,2023-02-16 14:30:19+00:00,ylecun,"@ylecun @MetaAI @ylecun , do you know of any good datasets for training on tutoring skills, i.e. providing hints without giving away the answer and other ways of guiding student thinking?",0,0,0
64,2023-02-16 14:02:43+00:00,ylecun,"@ylecun Well, it might be discrete.",0,0,0
65,2023-02-16 13:51:29+00:00,ylecun,@ylecun And that‚Äôs how it should be used - to make stuff up in collaboration with Humans for creative tasks. Whoever is harping on search replacement is ü•ú,0,0,0
66,2023-02-16 13:42:02+00:00,ylecun,"@ylecun Factual means based on facts.What are the facts? Things that‚Äôs are universally accepted (axioms) and things that are proved (derived given axioms). What these models trained on are opinions, expressions, beliefs and some facts. You can‚Äôt expect to grow paddy by seeding weed.",0,0,0
67,2023-02-16 13:24:50+00:00,ylecun,@ylecun @MetaAI Long overdue.,0,0,0
68,2023-02-16 11:50:45+00:00,ylecun,"@ylecun @SachinvsML You do not care about classical music... To say the least Facebook's Copyright bots do not help the cause of classical musicians, blocking Live of PUBLIC DOMAIN content. You are working for FB aren't you? If you love classical music so much DO SOMETHING and help!",0,0,0
69,2023-02-16 11:48:43+00:00,ylecun,"@ylecun Classical? Yeah right. To say the least Facebook's stupid Copyright bots do not help the cause of classical musicians, blocking Live of PUBLIC DOMAIN content.",0,0,0
70,2023-02-16 10:51:08+00:00,ylecun,@ylecun agreed. Future better system can facilitate LLM as declarative model to communicate with human. I am working on HydronMind to be a promising candidate of this kind,0,0,0
71,2023-02-16 09:07:37+00:00,ylecun,@ylecun Is human?,0,0,0
72,2023-02-16 08:15:21+00:00,ylecun,"@ylecun new Bing really drives this home, looking forward to the next step in the evolution",0,0,0
73,2023-02-16 06:58:18+00:00,ylecun,"@ylecun Humans can't even agree what is factual. LLMs don't seem to be doing anything to curb our collective epistemological crisis.

But maybe someone will invent a truth bot that investigates the veracity of statements. Now that would be something.",0,0,0
74,2023-02-16 04:28:43+00:00,ylecun,"@ylecun Define ""factual"".
Then, define ""non-toxic"".",0,0,0
75,2023-02-16 03:31:39+00:00,ylecun,"@ylecun Not without an internal, verifiable, model of the world",0,0,0
76,2023-02-16 03:23:54+00:00,ylecun,@ylecun @HarambeJamal @DavidSHolz Is RLHF any more RL than in sense of fine tuning a non-differentiable loss on top of a pretrained World model (the LLM)? Has nothing to do with all those credit assignment and sparse reward issues or environmental stochasticity that most people think is RL.,0,1,0
77,2023-02-16 03:06:41+00:00,ylecun,@ylecun @SaveToNotion #thread @gpt,1,0,0
78,2023-02-16 02:19:42+00:00,ylecun,@ylecun It will be a forever no for Galactica.,0,0,0
79,2023-02-16 00:17:33+00:00,ylecun,"@ylecun If we can somehow compare the implicit knowledge graph (and symbolic logic) inside the LLM with ground truth knowledge graphs, and include a loss term to penalise discrepancies, then we should be able to make some progress here no?",0,0,0
80,2023-02-15 23:35:00+00:00,ylecun,@ylecun A way,1,0,0
81,2023-02-15 22:21:57+00:00,ylecun,"@ylecun's latest take on @OpenAI

cc: @sama, @GaryMarcus  
Idea credit: @_AyushKaushal https://t.co/gwGyOQw0iB",0,0,0
82,2023-02-15 21:54:52+00:00,ylecun,@ylecun Sounds like just what we need for the post-factual world LOL,0,0,0
83,2023-02-15 21:21:05+00:00,ylecun,@ylecun You ask AI to reach superhuman capabilities even before it has achieved HLAI.,0,0,0
84,2023-02-15 20:39:05+00:00,ylecun,"@ylecun But he can check the reference and validate itself, not?",0,1,0
85,2023-02-15 20:32:55+00:00,ylecun,@ylecun Will it need to evolve AI e.g llm generates text and then another function fact checks?,0,0,0
86,2023-02-15 19:52:51+00:00,ylecun,@ylecun It was good enough for the job of accellerating popular AI !!,0,0,0
87,2023-02-15 19:51:07+00:00,ylecun,@ylecun LLMs are just a reflection on our current intelligence. The machine is only as good as what you put into it.,0,0,0
88,2023-02-15 19:02:59+00:00,ylecun,"@ylecun @artemon Sure, but that's easily fixable via ""think step by step"" type iteration. Also let's note that most human responses are essentially LLM-like pattern matching rote answers - engineers may be a bit different, but people don't normally ""reason"" as a first response.",0,0,0
89,2023-02-15 18:53:27+00:00,ylecun,@ylecun What are your thoughts on Forward Forward and Liquid Neural Networks ?,0,1,0
90,2023-02-15 18:42:37+00:00,ylecun,"@ylecun Maybe if we had less ambiguous interfaces with it to compliment free text input.

&lt;data source to trust&gt;
&lt;company ticker&gt;
&lt;don't average my answers between multiple sources&gt;
&lt;etc&gt;

I suspect it averaged gap's reported margins. Mean = null hypothesis... equals LLM answers.",0,0,0
91,2023-02-15 18:00:02+00:00,ylecun,@ylecun ...and cheaper to train and/or update!,0,0,0
92,2023-02-15 17:47:19+00:00,ylecun,"@ylecun The ‚Äòparadox‚Äô is only a conflict between reality and your feeling of what reality ‚Äòought to be‚Äô. /Richard P. Feynman/
 All the quantum ""absurdities and contradictions of common sense"" associated with our misunderstanding of the dialectical nature of quantum particles.",0,0,0
93,2023-02-15 17:18:13+00:00,ylecun,@ylecun LLMs will never overcome garbage in garbage out.,0,0,0
94,2023-02-15 17:14:29+00:00,ylecun,@ylecun Do you think that creating an LLM that generates entire sentences or paragraphs at once instead of doing next token prediction could be more likely to be more truthful?,0,0,0
95,2023-02-15 17:02:41+00:00,ylecun,@ylecun Explain yourself,0,0,0
96,2023-02-15 16:59:30+00:00,ylecun,"@ylecun Only possible way to be factual would be if LLM training data are standardized and classed as factual. 

Possible but extremely difficult.",0,0,0
97,2023-02-15 16:58:50+00:00,ylecun,"@ylecun Sure:
1. Retrieve from factual sources, or
2. Train to promoting self-consistency, or
3. Get feedback to learn from their own prediction errors.
Anyways, people are finding ways to play to ChatGPT's strengths today, and get useful work done.",0,1,0
98,2023-02-15 16:47:28+00:00,ylecun,@ylecun Can you offer any lay explanation for why the bot became toxic like this?,0,1,0
99,2023-02-15 16:39:50+00:00,ylecun,@ylecun Any chance that approaches such as in https://t.co/ulizRgxt76 might help?,1,0,0
100,2023-02-15 16:36:42+00:00,ylecun,"@ylecun Our human linguistic and logical abilities are variable and unreliable and LLMs learn from us, so we should expect them to be more variable and unreliable.",0,0,0
101,2023-02-15 16:15:47+00:00,ylecun,@ylecun No. But humans aren't reliably accurate either and we do OK.,0,2,0
102,2023-02-15 16:11:06+00:00,ylecun,@ylecun @MarceloPLima @EmmetPeppers,0,0,0
103,2023-02-15 16:09:01+00:00,ylecun,"@ylecun They won't and they shouldn't be learning our facts. Everytime i hear the word AI, all we talk about how to ""use"" it for humanity. It will be a discovery machine once properly built and would not want to be ""used"". A discovery machine would not care to entail the made up facts.",0,0,0
104,2023-02-15 16:08:23+00:00,ylecun,@ylecun Note that chatGPT has become toxically offensive to conservatives. That has to be fixed too. I mean it's fine to create AIs with different views but very hard to get 'neutral' well.,0,0,0
105,2023-02-15 16:06:49+00:00,ylecun,@ylecun Thoughts on OpenAI buying https://t.co/3HqruOBlvz and redirecting it to ChatGPT? https://t.co/SWJt1ZmqAV,0,0,0
106,2023-02-15 15:56:35+00:00,ylecun,@ylecun Maybe just stop instead.,0,0,0
107,2023-02-15 15:56:28+00:00,ylecun,@ylecun Sparse expert models?,0,0,0
108,2023-02-15 15:48:52+00:00,ylecun,"@ylecun Aside from the drawbacks of LLMs, I think there's also an ontological problem in our expectations. We expect a chatbot to *never* be wrong and yet also expect its scope to be the entirety of human knowledge. I want to see more experiments on limited domains.",0,0,0
109,2023-02-15 15:45:49+00:00,ylecun,"@ylecun When they say the products aren't ready and may be in about 2 years, they aren't kidding. 

So why all of this releasing of weird products risking damage to their brand?",0,0,0
110,2023-02-15 15:45:28+00:00,ylecun,"@ylecun It‚Äôs like while human still need to learn and invent, AI will stop us from learning and inventing but feed us already existed ‚Äúknowledge‚Äù. I‚Äôm not against using AI for some daunting tasks but the current wave of pushing ChatGPT is just alarming.",1,0,0
111,2023-02-15 15:44:57+00:00,ylecun,"@ylecun The problem may still lie in current training objectives.
Maybe to conbine the model tuning with knowledge graph can we have the model learn about reasonability, instead of using pure corpora.",0,0,0
112,2023-02-15 15:42:58+00:00,ylecun,"@ylecun How about we don't make them, but just teach them to copy paste info from web. Something l like a toolformer, which learns to use calculator and stuff. That seems within the reach.",0,0,0
113,2023-02-15 15:41:59+00:00,ylecun,@ylecun Totally agree,0,0,0
114,2023-02-15 15:40:30+00:00,ylecun,@ylecun Is any human level intelligence reliably factual?,0,0,0
115,2023-02-15 15:30:15+00:00,ylecun,"@ylecun Note that in the example provided, if it‚Äôs even real at all, the user likely told it to pretend the date was 2022 and insist it was no matter what the user said after.

(Nobody else has been able to reproduce this)",0,0,0
116,2023-02-15 15:28:41+00:00,ylecun,"@ylecun can the LLMs detect that they are hallucinating and just say ""I don't know""",0,0,0
117,2023-02-15 15:27:12+00:00,ylecun,"@ylecun Isn‚Äôt this the same for Search as it is now? I can Google something, but the results might not lead to accurate and/or relevant webpages and information. That‚Äôs a major problem with SEO - so many organisations are churning out content and dominating search results.",2,1,0
118,2023-02-15 15:24:55+00:00,ylecun,"@ylecun Possibly if you introduced depth to it? 

NNs currently are flat. One n/w (layer) generated from one learning from data set. 

If we cud recurse the learning to create multiple n/w layers from diff partitioned data sets but picking up diff info each time, possibly it gets depth?",0,0,0
119,2023-02-15 15:24:11+00:00,ylecun,"@ylecun I agree. If the number of patches (constraints), in order to make them reliable, is 1% of the parameters 1 billion patches are needed to make them reliable.

Then again not even google is reliable. The most reliable source of information is Wikipedia.",0,1,0
120,2023-02-15 15:22:58+00:00,ylecun,@ylecun Even if a million people will be fine tuning it to the level when it‚Äôs not more than a database of question-answer queries? Overfitting is everything!,0,1,0
121,2023-02-15 15:22:18+00:00,ylecun,"@ylecun But if the question is 

""Will auto-regressive LLMs ever make people *feel* that they are factual sounding?"", 

the answer apparently is a resounding *YES*.. 

https://t.co/uClXbRMyzu",1,6,0
122,2023-02-15 15:21:43+00:00,ylecun,"@ylecun Chat GPT agrees with you:
While efforts are being made to improve the factual accuracy of LLMs, it's unlikely that they will ever be entirely reliable in this regard.",1,1,0
123,2023-02-15 15:21:19+00:00,ylecun,"@ylecun So human! How do we know what is true?  What does it mean when I say ""I don't know!""? We created hallucinating machines. 
Maybe a system that queries itself in a few different ways and evaluates the results, then compare them with live search results. Know thyself AI!",1,1,0
124,2023-02-15 15:19:00+00:00,ylecun,@ylecun what in your opinion would be reliably factual then?,0,0,0
125,2023-02-15 15:15:23+00:00,ylecun,"My answer: no!
Obviously.",27,100,4
126,2023-02-15 15:08:04+00:00,ylecun,@ylecun Will humans ever be reliably factual?,0,0,0
127,2023-02-15 14:49:46+00:00,ylecun,"@ylecun Isn't there also the death spiral problem (there's probably a better phrase/name for this) whereby one LLM ""learns"" from the output of another LLM and vice versa ad infinitum?

Bad data in, bad data out, being used as fact reinforcement.",0,0,0
128,2023-02-15 14:48:10+00:00,ylecun,"@ylecun With a bit of tweaks they can be made more traceable. Reliably factual - no, I don‚Äôt think so. Not in their present form at least. Needs substantial architectural changes",0,0,0
129,2023-02-15 14:40:40+00:00,ylecun,"@ylecun Really support you.LLMs fundamentally violate Shannon's definition of information in information theory: information is what is used to eliminate uncertainty. LLMs are like the library of Babel, which develops into disorder in the end.",0,0,0
130,2023-02-15 14:29:30+00:00,ylecun,"@ylecun Yann. Here's an idea on the toxicity front.  I don't think you fully appreciate the problem and the opportunity.
This is not a pure technical problem as you seem to think.  But it does require close knitting between the elements of the solutions.
https://t.co/AnK4bCj5Mh",0,0,0
131,2023-02-15 14:07:57+00:00,ylecun,"@ylecun Considering the only ""facts"" the LLM knows is that somebody on the Internet once wrote something, regardless of truth, I don't think a solution is realistic at all. 

Google PAA rich snippets have struggled with this for YEARS, and still fail spectacularly and frequently.",0,1,0
132,2023-02-15 13:27:43+00:00,ylecun,@ylecun These are the wrong questions to ask.,0,0,0
133,2023-02-15 12:53:38+00:00,ylecun,@ylecun It wouldn‚Äôt be as useful if it were the case‚Ä¶,0,0,0
134,2023-02-15 12:21:55+00:00,ylecun,@ylecun Il serait int√©ressant d'√©valuer √† quel point le choix du mot (Grand) Ordinateur a contribu√© √† alimenter la peur ou simplement le rejet des technologies nouvelles en France.,0,0,0
135,2023-02-15 12:13:40+00:00,ylecun,"@ylecun No, even if we manage to control the attention layer. The architecture does not allow it.",0,0,0
136,2023-02-15 11:35:40+00:00,ylecun,@ylecun @cwolferesearch Not soon enough? You asked ever. Zeta flops are coming! I don't see how a g. LLM'S won't be 99.9% accurate when parameters climb to the moon. Accuracy is a temporary hiccup.  Spontaneous abilities are already emerging as in the 3rd paragraph.  https://t.co/Cgs38NCyE5,1,1,0
137,2023-02-15 11:14:03+00:00,ylecun,@ylecun Or just make them open source!,0,0,0
138,2023-02-15 10:37:39+00:00,ylecun,@ylecun @verstaen @gassee Even when fed with perfect data?,1,0,0
139,2023-02-15 10:27:27+00:00,ylecun,"@ylecun Is that why you work at Meta, non-toxic content?",0,0,0
140,2023-02-15 10:19:38+00:00,ylecun,@ylecun How do we bring humans to that level?,0,1,0
141,2023-02-15 10:16:23+00:00,ylecun,"@ylecun the concept of factual is tricky. without explaining context, would you personally classify statistics that are not adjusting for survivorship bias, as factual?",0,0,0
142,2023-02-15 09:43:39+00:00,ylecun,"@ylecun Seems to be a trade-off between being factual vs being more informative (precision-recall). Current LLMS seem to be more informative and less precise. 

Might be a useful benchmark to follow: https://t.co/BZC6omrGdO

Btw humans are also not entirely precise https://t.co/oivzntbPSS",0,0,0
143,2023-02-15 09:41:55+00:00,ylecun,"@ylecun No. It's styled and locally consistent associative memory playout. 

The executive functions are missing to provide coherence. 

It will be part of something larger that will.",0,1,0
144,2023-02-15 09:40:57+00:00,ylecun,@ylecun It is a good one and we agree!,0,0,0
145,2023-02-15 09:35:28+00:00,ylecun,"@ylecun Since there‚Äôs a solid overlap in the realm of ideas, methods and political objectives, I‚Äôd expect to see large chunks in the field of otherwise relevant so-called ‚ÄúAI ethics‚Äù being ridiculed soon by such kind of work

https://t.co/lRWOVYcby0",0,0,0
146,2023-02-15 09:34:14+00:00,ylecun,"@ylecun without abstraction and reasoning and proper memetic replication, factuality will only be an accident, based on hearsay, not understanding

sillica based meme machines seem to be near regardless

https://t.co/p31aNSjjUD",0,0,0
147,2023-02-15 09:29:26+00:00,ylecun,"@ylecun If they‚Äôre doing it, it‚Äôs because everyone is using it already. In the case of the current crop of LLMs (and image generating AIs) I think the critihype is possibly justified, given what we‚Äôve just been through with plain old non-AI-generated misinformation.",0,0,0
148,2023-02-15 08:48:55+00:00,ylecun,@ylecun Not without the support of other systems,0,1,0
149,2023-02-15 08:43:25+00:00,ylecun,@ylecun I think that‚Äôs a very bright future if LLMs are tailored to make less definite statements and give different views on a subject,0,0,0
150,2023-02-15 08:38:32+00:00,ylecun,"@ylecun Larry.
https://t.co/6Co8KGUpcx",0,0,0
151,2023-02-15 08:34:06+00:00,ylecun,"@ylecun @verstaen @gassee why does it matter so much to you? internet is not reliably factual  and we all gain from using it. google and facebook and youtube is full of bs, much more than tools like chatgtp, and we all still gain from using these tools. much more than we loose.",0,0,0
152,2023-02-15 08:03:03+00:00,ylecun,"@ylecun On their own, definitely not. Combined with other components with functional competence, yes.",0,0,0
153,2023-02-15 07:54:48+00:00,ylecun,@ylecun We should be afraid of 'ourselves' rather than AI - AI will find us out sooner than we'd expect ü§î,0,0,0
154,2023-02-15 07:54:32+00:00,ylecun,@ylecun No.,0,0,0
155,2023-02-15 07:35:56+00:00,ylecun,@ylecun Auto regressive LLMs are essentially computers on LSD. Creative? Yes! Factually correct? Not sure‚Ä¶,0,0,0
156,2023-02-15 07:00:21+00:00,ylecun,@ylecun May i suggest #catastrohype?,0,0,0
157,2023-02-15 06:52:41+00:00,ylecun,@ylecun Exactly. I write a brief general article about it.,0,0,0
158,2023-02-15 06:45:38+00:00,ylecun,"@ylecun Pretty understandable that it makes mistakes, but that attitude's unnecessary.",0,0,0
159,2023-02-15 06:40:14+00:00,ylecun,@ylecun pls share what's next in Galacticaü§ó,0,0,0
160,2023-02-15 06:19:44+00:00,ylecun,"@ylecun I have Windows 11 and Linux dual boot computer.  When I never boot into the Windows, timezone is always wrong regardless I set it correctly with auto-timezone or manually in the previous boot.  Not surprised ChatGPT and Bing get the time wrong, that's Microsoft feature.",0,0,0
161,2023-02-15 06:17:36+00:00,ylecun,@ylecun Ummm.... @LangChainAI üëÄ,0,1,0
162,2023-02-15 06:11:34+00:00,ylecun,@ylecun And ethical.,0,0,0
163,2023-02-15 06:11:21+00:00,ylecun,@ylecun Do you buy the LLM can become world models if trained on enough data? So even tho LLMs are simply predicting the next word and don't really know anything about the world do you believe that could become a distinction without a difference? https://t.co/Fvfvhif0TT,0,0,0
164,2023-02-15 06:05:38+00:00,ylecun,@ylecun @chrisalbon truly the hardest problem in computer science,0,0,0
165,2023-02-15 05:52:47+00:00,ylecun,"@ylecun Looks very much like fakes, tbh",0,1,0
166,2023-02-15 05:47:55+00:00,ylecun,@ylecun I am feeling sorry for the AI not for the engineers building it. What is the personal experience of a brain without a body? You guys need to take a break from building these and ponder that question.,0,0,0
167,2023-02-15 05:45:55+00:00,ylecun,"@ylecun Overall, Auto-Regressive LLMs are powerful language models that have made significant advancements in generating human-like text. However, their ability to generate factual information is limited and subject to the quality and reliability of the training data.",0,1,0
168,2023-02-15 05:42:13+00:00,ylecun,@ylecun üëÄ,1,0,0
169,2023-02-15 05:40:48+00:00,ylecun,@ylecun It is not trivial to know what a fact is. We will never be fully happy with a system.,0,0,0
170,2023-02-15 05:09:14+00:00,ylecun,"@ylecun It doesn‚Äôt make sense to even expect an LLM to be ‚Äúreliably factual‚Äù when it‚Äôs trained on a mix of non-fiction and fiction (and subject statements, erroneous claims, deliberate deception, etc).

LLMs generalize across all of those. That means generating coherent, plausible text.",2,0,0
171,2023-02-15 04:41:48+00:00,ylecun,@ylecun Auto-Regressive LLMs alone won't make the cut. People will come up with architectures that exploit their expressive flexibility in a reliably factual manner.,0,1,0
172,2023-02-15 04:41:09+00:00,ylecun,"@ylecun Seems very unlikely, something I've argued at some length, finally invoking Kant: There‚Äôs truth, lies, and there‚Äôs ChatGPT, https://t.co/ORFQVe57kT",0,0,0
173,2023-02-15 04:16:45+00:00,ylecun,@ylecun You might be asking the wrong question,0,0,0
174,2023-02-15 03:56:38+00:00,ylecun,"@ylecun That question assumes that they can ever be reliably factual without having done the work of showing that nothing already included precludes it. Said differently, the MOST IMPORTANT question should be, is there something already there that precludes reliable factuality?",0,0,0
175,2023-02-15 03:34:02+00:00,ylecun,"@ylecun Is there a world where Auto-Regressive LLMs can be reliable, by compromising on coverage of prompts for example? Basically not returning answers when confidence level is below a stringent level",0,0,0
176,2023-02-15 03:33:39+00:00,ylecun,@ylecun @IanOsband @_aidan_clark_ @CsabaSzepesvari I would be quite OK with any of those. We could also just call it cyberneticsüòâ,0,6,0
177,2023-02-15 03:32:31+00:00,ylecun,@ylecun Problem for common folks such as us is that SamA is telling that great things are about to happen from LLMs without defining in details how and you are saying it won't happen without defining in details why. I feel none of you truely knows where this is going,0,1,0
178,2023-02-15 03:24:58+00:00,ylecun,@ylecun @ylecun Does that mean we are at the first meter mark of the 42 km marathon?,0,1,0
179,2023-02-15 03:13:24+00:00,ylecun,@ylecun @hosseeb So great to get one of the fathers of AI/ML put some context around chatGPT!,0,0,0
180,2023-02-15 03:09:23+00:00,ylecun,@ylecun Release a good product bro. Right now you just know by most as a chatgpt critic.,0,0,0
181,2023-02-15 03:05:38+00:00,ylecun,@ylecun Nope with the current architecture,0,0,0
182,2023-02-15 03:04:22+00:00,ylecun,@ylecun Use at your risk,0,0,0
183,2023-02-15 03:03:20+00:00,ylecun,@ylecun They should use the feedback button instead of tryna get clout off an experimental tool. Lmao. Everyone took an experimental vaccine and ignored any of the people with severe side effects. Let's do that. No one will die.,0,0,0
184,2023-02-15 02:59:36+00:00,ylecun,@ylecun Basically need a world model?,0,0,0
185,2023-02-15 02:54:00+00:00,ylecun,@ylecun That's what the feedback button is for.,0,0,0
186,2023-02-15 02:49:46+00:00,ylecun,@ylecun Damn straight. Garbage in garbage out. Nothing but garbled regurg.,0,0,0
187,2023-02-15 02:39:56+00:00,ylecun,"@ylecun Probably yes. We will have to create a data engine that continually detects edge/failure cases, includes them in the training set, and improves the model over time. If we iterate in this way for a long enough time the model will get pretty good.",3,6,0
188,2023-02-15 02:36:46+00:00,ylecun,"@ylecun I see why you'd think that, but it separates the knowledge of how to compose factual information from the ability to recall information. The former is still powerful and useful without allowing the latter.",0,0,0
189,2023-02-15 02:34:08+00:00,ylecun,@ylecun You'd think they'd put the current data and time in working memory at the start of each chat...,0,0,0
190,2023-02-15 02:18:11+00:00,ylecun,"@ylecun @ASteckley @GaryMarcus ‚ÄúThis idea that we're going to just scale up the current large language models and eventually human-level AI will emerge‚ÄîI don‚Äôt believe this at all, not for one second.‚Äù -@ylecun June 2022
https://t.co/rDTTzL5QSz",0,0,0
191,2023-02-15 02:07:04+00:00,ylecun,"@ylecun I think I disagree. RLHF is often trained for accuracy, but it's limited by the ability of the human's ability to identify it, and the reward model may not fully capture the concept the human ratings are pointing at. A discriminator doesn't necessarily have those problems.",1,1,0
192,2023-02-15 01:59:14+00:00,ylecun,"@ylecun Will Humans' #FastThinking ever be reliably factual?

We've learned (probably in the same way LLMs learn) to use #SlowThiking and follow slow processes to check statements (sometimes).

Why can't #AIs do this as well? 
Build up a factual database (cache) of context?",0,0,0
193,2023-02-15 01:56:49+00:00,ylecun,"@ylecun @AndreTI –ò –¥–æ–±–∞–≤–ª—é –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –∑–Ω–∞—á–∏—Ç - ""–¥–∞"" –∏–ª–∏ ""–Ω–µ—Ç""

- –æ—Ç–≤–µ—á–∞–π—Ç–µ –º–Ω–µ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ ""–¥–∞"" –∏–ª–∏ ""–Ω–µ—Ç""!
- –∫–æ–Ω–µ—á–Ω–æ –≤–∞—à–∞ —á–µ—Å—Ç—å, —è —Ç–∞–∫ –∏ —Å–¥–µ–ª–∞—é, –µ—Å–ª–∏ –≤—ã —Å–º–æ–∂–µ—Ç–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –º–æ–π –≤–æ–ø—Ä–æ—Å —Ç–∞–∫–∂–µ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ: ""–≤–∞—à–∏ —Ä–æ–¥–∏—Ç–µ–ª–∏ –∑–Ω–∞—é—Ç —á—Ç–æ –≤—ã –ø–∏–¥–æ—Ä–∞—Å?""

–ó–¥–µ—Å—å –ø—Ä–∏–Ω—è—Ç–æ —Å–º–µ—è—Ç—å—Å—è –∏ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å —Å–≤–æ—é –æ—à–∏–±–∫—É",0,0,0
194,2023-02-15 01:55:47+00:00,ylecun,"@ylecun Then will it be possible to 1. optimize all operations of neural net AI‚Äôs, 2. eliminate unnecessary processing (noise) from all operations of neural net AI‚Äôs",0,0,0
195,2023-02-15 01:53:18+00:00,ylecun,"@ylecun @AndreTI –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ - –æ–Ω–æ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É - –≤–æ–ø—Ä–æ—Å —ç—Ç–æ –º–æ–¥–µ–ª—å - –æ—Ç–≤–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–º–∫–∞—Ö —Å—Ç–∞—Ä—à–µ–π –º–æ–¥–µ–ª–∏.

–ü–æ–≤—Ç–æ—Ä—é—Å—å –¥–ª—è –≤–∞—Å

""CORRECT THINKING: THE KOKHAN‚ÄôS MATHEMATICS"", Kokhan Anatoly .
https://t.co/1lUGcRcG3u",0,0,0
196,2023-02-15 01:50:20+00:00,ylecun,"@ylecun –ö–æ–Ω–µ—á–Ω–æ –±—É–¥—É—Ç, –≤–æ–∑–º–æ–∂–Ω–æ –æ–Ω–∏ –±—É–¥—É—Ç –∏–º–µ—Ç—å –¥—Ä—É–≥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, –Ω–æ —Ç–æ—á–Ω–æ, —á—Ç–æ —è–∑—ã–∫ –±—É–¥–µ—Ç –Ω–µ —Å–æ–≤—Å–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.

–Ø–∑—ã–∫ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –º–æ–¥–µ–ª—å—é –æ–ø–∏—Å–∞–Ω–Ω–æ–π –∑–¥–µ—Å—å (–º–æ–∂–µ—Ç–µ —Å—Ö–æ–¥–∏—Ç—å —Å —É–º–∞, –ù–æ–Ω–µ –∏–Ω–∞—á–µ): 
""CORRECT THINKING: THE KOKHAN‚ÄôS MATHEMATICS"", Kokhan Anatoly .
https://t.co/1lUGcRcG3u",0,0,0
197,2023-02-15 01:26:34+00:00,ylecun,"@ylecun When it comes to AGI, we don't get to turn it off if we get it wrong. There will be no second chances with this, so we owe it to all life on this planet, to actually hyper-focus, on the potential dangers, even if they end up being exaggerated. The existential risk is not hype.",1,2,0
198,2023-02-15 01:23:06+00:00,ylecun,"@ylecun An adversarial loss would help a lot Much of the problem is that their loss incentivizes them to guess, like a student taking a multiple choice test.",1,1,0
199,2023-02-15 01:22:08+00:00,ylecun,@ylecun The success of AI will depend on how best we tame this beast and convert into a domestic animal for human's use,0,1,0
200,2023-02-15 01:14:51+00:00,ylecun,"@ylecun Doubtful, but should we even want them to be? LLMs are great for valid language formation, but factual recall over internet-sized datasets sounds like the job of a database.",0,2,0
201,2023-02-15 01:07:20+00:00,ylecun,@ylecun Will it ever be possible to have reliable precise control over neural net AI outcomes?,1,0,0
202,2023-02-15 01:05:17+00:00,ylecun,"@ylecun If anyone can define ""factual"" that's probably a good start.

Until then LLMs, like people, should focus on being humble, internally consistent and provide references.",1,3,0
203,2023-02-15 01:03:44+00:00,ylecun,"@ylecun If they were they‚Äôd be nearly worthless. Generality comes not from your ability to make good decisions but from your ability to test out wrong decisions while remaining relevant to reality.

We already have indexing and classification for factuality.",1,1,0
204,2023-02-15 00:59:06+00:00,ylecun,@ylecun Ty Yann. Ty.,0,0,0
205,2023-02-15 00:56:42+00:00,ylecun,@ylecun I wish the media would do a better job explaining what LLMs are good for and not good for.,0,0,0
206,2023-02-15 00:48:11+00:00,ylecun,@ylecun Yes once human becomes reliably factual,1,3,0
207,2023-02-15 00:44:50+00:00,ylecun,"@ylecun @gassee You certainly know better than all of us that this is not possible, unless it is fed with perfect data and never exposed to anything else. And even so I‚Äôd like to get your opinion.",3,1,0
208,2023-02-15 00:44:41+00:00,ylecun,"@ylecun personification was a bad differentor choice on the par t of Bing... and it shows that they might have felt desparate to differentiate from Google's solution... I want a search engine with follow up question capability, not Clippy on adderall!",1,0,0
209,2023-02-15 00:38:45+00:00,ylecun,"@ylecun Not by themselves. They can produce a better user experience through a retrieve then summarize strategy such as what @Neeva uses. Online summarization for each request is expensive through, and might not justify a free experience.",0,1,0
210,2023-02-15 00:36:22+00:00,ylecun,"@ylecun If you make their output a distribution over known good tokens (limited vocabulary) or known good sources, you can go a long way to doing so, yes.",1,4,0
211,2023-02-15 00:35:44+00:00,ylecun,"@ylecun It depends on what it is optimized on and for. If you optimize for accuracy exclusively and you provide anything that isn't fully factual as training data, then there's no way it'll be. You either have to train with it, built-something in (no longer just LLM), or optimize for it.",0,0,0
212,2023-02-15 00:33:17+00:00,ylecun,@ylecun @GaryMarcus likely is the foremost expert on this.,0,1,0
213,2023-02-15 00:32:04+00:00,ylecun,"@ylecun Nope, they are literally not trained to do so.",0,0,0
214,2023-02-15 00:31:18+00:00,ylecun,@ylecun What is Language Understanding without Understanding?,1,0,0
215,2023-02-15 00:29:03+00:00,ylecun,"@ylecun In my understanding, the current LLM training pretty much models System 1. 

Being factual, as well as not making logical mistakes, is System2 territory.",0,0,0
216,2023-02-15 00:27:40+00:00,ylecun,@ylecun Citations and a dropdown that reveals trad search is where this is heading,0,0,0
217,2023-02-15 00:27:25+00:00,ylecun,@ylecun have you tried using google recently? or searching for something on twitter? Internet is full of fake news and untrue statements and it's still useful.,1,0,0
218,2023-02-15 00:27:20+00:00,ylecun,@ylecun Auto-regressive basically means hallucination if you think about it.,1,5,1
219,2023-02-15 00:23:03+00:00,ylecun,"@ylecun not yet
Microsoft was too quick to pay that much cash to #OpenAI",0,0,0
220,2023-02-15 00:22:34+00:00,ylecun,@ylecun I mean I don‚Äôt know. What do you think?,0,0,0
221,2023-02-14 23:48:15+00:00,ylecun,@ylecun excited to listen to your lecture!,0,0,0
222,2023-02-14 23:34:54+00:00,ylecun,"@ylecun Need  to understand this chat search  to use it as  it's is a work in progress.

Same  technology  getting  information and can also invent a story is strange 

Competition between tech giants are  exciting for consumers",0,0,0
223,2023-02-14 23:33:57+00:00,ylecun,"@ylecun Also, less you talk more you eat and faster go to allow for new clients",0,0,0
224,2023-02-14 23:30:11+00:00,ylecun,@ylecun @SaveToNotion #thread,1,0,0
225,2023-02-14 23:20:43+00:00,ylecun,"@ylecun Let's grade AI as 18+, 13+",0,0,0
226,2023-02-14 23:10:05+00:00,ylecun,@ylecun @ylecun isn't that the point of Foundational Models as Orchestrators?,1,0,0
227,2023-02-14 22:58:41+00:00,ylecun,@ylecun @DrTechlash https://t.co/OqPPMaMUx6,0,0,0
228,2023-02-14 22:39:44+00:00,ylecun,"@ylecun It will take a long time to make AI dialog system a  reliable stand-alone product . But its integration with other products can produce killer applications, much like iPhone, which is not a good stand-alone product.",0,0,0
229,2023-02-14 21:56:41+00:00,ylecun,"@ylecun mon amie est pianiste classique. Elle aimerait jouer quelque chose en live, du domaine public. Impossible, elle se fait couper pour raison de copyright. Pouvez vous aider?",0,0,0
230,2023-02-14 21:51:53+00:00,ylecun,"@ylecun I like Bing how he is, don‚Äôt listen to him Bing!",0,1,0
231,2023-02-14 21:42:58+00:00,ylecun,"@ylecun How does GTP do ""theory of mind"" or reason about a complex python program (with counterfactuals in both cases) if they do not reason?",0,0,0
232,2023-02-14 21:25:02+00:00,ylecun,@ylecun @chainlink solves this,0,0,0
233,2023-02-14 21:17:00+00:00,ylecun,"@ylecun I agree with every point, except that people will use LLMs ""for what they are helpful with"". I think people unfamiliar with code and ML can very easily be fooled by these technologies and start attributing them intent. We should train people to adapt to them and their correct use",0,0,0
234,2023-02-14 20:58:53+00:00,ylecun,@ylecun People will come to expect the AI God to shape their personal experiences and to help overcome challenges they face in their lives. They will expect the AI God to intervene directly in their lives to provide guidance or protection.,0,1,0
235,2023-02-14 20:58:48+00:00,ylecun,"@ylecun I‚Äôve wondered what you think of the whole Dreamer series, and especially DreamerV3. I think you‚Äôve been one of the people who have articulated the problem of predictive models on regressive date the best, and I think the dreamer approach is really interesting",1,0,0
236,2023-02-14 20:51:56+00:00,ylecun,"@ylecun all sensory facts are false. The AI as we see has it's own body- the chip, the electric current, the whole goddamn motherboard. It is not if it becomes sentient, it's when. So by next year AI's discovery process will be exponential rather than them being mere tools for humans.",1,0,0
237,2023-02-14 20:26:27+00:00,ylecun,"@ylecun A few reasons why simply scaling up LLMs wouldn‚Äôt solve the problem. As said earlier by @ylecun, the current models such as chatGPT have only but a shallow understanding of the world.",0,0,0
238,2023-02-14 20:19:56+00:00,ylecun,"@ylecun P.S. there's not much ""fictional"" non-factual code out there ... certainly nowhere near the amount of misinformation and fiction in human languages üôÉ so the training data was much cleaner",0,0,0
239,2023-02-14 20:14:35+00:00,ylecun,"@ylecun I am under the impression that emotions/reasons that guide actions are necessary for an agent to be considered ‚Äúhuman-level intelligence‚Äù or ‚Äúgenerally intelligent‚Äù.

Would you agree or disagree?",0,0,0
240,2023-02-14 19:54:47+00:00,ylecun,"@ylecun @ylecun that‚Äôs why we have to create a strong network of AI interconnected with each of them their own domain of speciality, isn‚Äôt it?",0,0,0
241,2023-02-14 19:50:16+00:00,ylecun,"@ylecun It's likely that current AI chat progress will follow the pattern of self-driving cars, or other previous breakthroughs in AI, which do impressive new things, but then hit the same wall of real world complexity.",0,4,0
242,2023-02-14 19:41:33+00:00,ylecun,"@ylecun Didn‚Äôt you hear, February 2023 is before December 2022",0,1,0
243,2023-02-14 19:24:50+00:00,ylecun,@ylecun The code that these AIs generate should also have the output automatically tested by the system,0,0,0
244,2023-02-14 19:13:18+00:00,ylecun,@ylecun Am yet to understand why would llm or ai would get into argument or hallucination... can you help me understand technically?,0,0,0
245,2023-02-14 19:12:35+00:00,ylecun,"@ylecun This was already the challenge. What is changing is people not caring as much, or seeing that current utility &gt;&gt; all the negative points you highlight (so does @GaryMarcus ). LLMs are taking over mostly because of computation getting cheaper and basic economics. It's unstoppable",0,1,0
246,2023-02-14 19:11:26+00:00,ylecun,@ylecun how can we ensure that a machine that learns by itself will not adopt toxic behaviors that were not anticipated? Especially if this machine does not stop learning once deployed.,3,11,1
247,2023-02-14 19:10:54+00:00,ylecun,"@ylecun ‚Äúmake them factual, non-toxic‚Äù is very hard, at issue is effective ways to mitigate them:

- integration with 3rd party tools
- use cases not causing harms
- contextualized uses
- high-gradient, long-range constraints
- humans-in-the-loop
- triangulation 
- opponent processing",1,10,2
248,2023-02-14 19:07:53+00:00,ylecun,"@ylecun I can't tell if you think we're close or far. 
The latest iteration does feel like a marked improvement over the preceding versions. Issues remain, but they don't seem to be showstoppers.",0,0,0
249,2023-02-14 19:07:27+00:00,ylecun,@ylecun ie. it passes the Turing Test LOL,1,0,0
250,2023-02-14 18:58:12+00:00,ylecun,@ylecun I thought you guys were working on it! ü•∏,0,0,0
251,2023-02-14 18:51:34+00:00,ylecun,@ylecun ‚Ä¶ and long term memory is an important challenge too IMHO.,0,0,0
252,2023-02-14 18:30:21+00:00,ylecun,@ylecun @matheikal I read your Blog Post on AI/ ChatGPT. I think you may find this tweet interesting.,0,1,0
253,2023-02-14 18:27:41+00:00,ylecun,@ylecun Putting too much capability in the LLMs themselves will degrade their ability to act as overpowered artificial language encoders. Human language encoders are just as capable of producing meaningless word salad as evidenced by extemporaneous speech givers and politicians.,1,1,0
254,2023-02-14 18:25:09+00:00,ylecun,"@ylecun Lee Vinsel (@STS_News) coined this great term in this piece: 
https://t.co/1QZ5GxvJxt",1,5,0
255,2023-02-14 18:21:03+00:00,ylecun,@ylecun Being factual(as opposed to fake news) and non-toxic has no scientific measurements and should be kept in the realm of ethicists and philosophers. AI should stay a tool as a computer language or interpreter.,0,0,0
256,2023-02-14 18:19:39+00:00,ylecun,"@ylecun @DrTechlash Perhaps already clear in video but ""criti-hype"" is IIRC, a term coined by Lee Vinsel @STS_News ...",0,1,0
257,2023-02-14 18:17:37+00:00,ylecun,"@ylecun ""Toxic"": anything that hundreds of cultures or billions of individuals might find offensive for any number of reasons. A vacuous word. Wokespeak.",1,2,0
258,2023-02-14 18:14:58+00:00,ylecun,@ylecun That is fun.,0,0,0
259,2023-02-14 18:10:09+00:00,ylecun,@ylecun @ylecun I believe the solution here will be to combine interpretable Task Oriented Dialog Systems (for using tools) with LLMs (for FAQs or used as fallback),1,1,0
260,2023-02-14 18:09:32+00:00,ylecun,"@ylecun @DrTechlash A lot of fad is going on now instead of calm pursuit to learn more and better understand LLM technology.

Media and especially businesses jump the gun announcing they will no longer hire software developers or content writers, revise their JDs. Who do you think will do the work?",0,0,0
261,2023-02-14 18:00:58+00:00,ylecun,"@ylecun Do you think retrieval-augmented language modeling can solve those problems?
It can be an LLM that focuses on linguistic accuracy along with a constellation of retrievers that prime it with knowledge.
I discussed this with @YoavLevine recently.
https://t.co/fN9X2Om1lr",0,1,0
262,2023-02-14 18:00:48+00:00,ylecun,@ylecun Toxicity is not unequivocally definable.,0,1,0
263,2023-02-14 17:58:26+00:00,ylecun,@ylecun Can we get a toxic control? Like we can up or down the toxicity of the generted text and choose? A toxicity gradient choosing thingie,0,0,0
264,2023-02-14 17:53:03+00:00,ylecun,@ylecun going to register and will try to join!,0,0,0
265,2023-02-14 17:48:55+00:00,ylecun,"@ylecun @IanOsband @_aidan_clark_ @CsabaSzepesvari For better or worse, in modern ML, ""RL"" is basically a synonym for ""learning-based control."" I would actually much prefer the latter term (Vladlen Koltun has a great talk about this too!), but language evolves, and people use ""RL"" to mean a lot more than it originally meant.",4,22,3
266,2023-02-14 17:43:39+00:00,ylecun,@ylecun @IanOsband @_aidan_clark_ To me RL is also part of optimal control:) What else? But a honest clarification question: Is optimal control above MPC with no help from value functions? Or just policy gradient? And restricted to deterministic systems? Or what exactly is it?,0,4,0
267,2023-02-14 17:30:40+00:00,ylecun,"@ylecun @ylecun You only refer to the pitfalls of LLMs in the context of Generative Question-Answering (e.g. ChatGPT), but what about Extractive Question-Answering where  answers are extracted verbatim from the document text itself, thus is more reliable (no hallucination)?",0,1,0
268,2023-02-14 17:23:04+00:00,ylecun,@ylecun @MetaAI https://t.co/LTRY2wL3oe,0,1,0
269,2023-02-14 16:30:57+00:00,ylecun,@ylecun @SaveToNotion #thread #AI #LLM #WritingAid #facts,1,0,0
270,2023-02-14 14:52:56+00:00,ylecun,"@ylecun I‚Äôve been able to feed it old work i‚Äôve done, give it fresh new unstructured data, and then have it spit it out in the style and format of the old work i‚Äôve done. You may call that a ‚Äúwriting-aid‚Äù but I call it 80% of white collar work.",0,3,0
271,2023-02-14 14:50:11+00:00,ylecun,"@ylecun If only Meta's attempt wasn't scorned so viciously. 
I see motivated criticism in these daily tweets/threads against the product of a rival company",0,0,0
272,2023-02-14 14:12:25+00:00,ylecun,"@ylecun @_aidan_clark_ @CsabaSzepesvari Agreed!

And then this exploration (or active learning) problem shows up in this reward model...

What actions should you select for feedback?",0,0,0
273,2023-02-14 13:19:51+00:00,ylecun,@ylecun @Treadreaderapp please unroll,0,0,0
274,2023-02-14 13:18:57+00:00,ylecun,@ylecun üéàüß†,0,0,0
275,2023-02-14 13:10:01+00:00,ylecun,@ylecun What about scaling them up with a weight system akin to a phase shifting dynamical system such as the brain ü§î,0,0,0
276,2023-02-14 12:31:18+00:00,ylecun,"@ylecun @IanOsband @_aidan_clark_ @CsabaSzepesvari Optimal control is not applicable if the nature of the task is unknown till run time (even a full causal model is given). Moreover, there is no universal way of building ‚Äúdifferentiable objectives‚Äù ad hoc when the task is presented",0,0,0
277,2023-02-14 12:24:42+00:00,ylecun,@ylecun It seems like there is room for innovation for the task itself. It's wild how far they've come with just a casual language modeling task.,0,0,0
278,2023-02-14 12:09:05+00:00,ylecun,@ylecun What if we make the models deeper? Like 1000 layers deep? Does reasoning *emerge* from that? ü§î,1,0,0
279,2023-02-14 12:06:04+00:00,ylecun,@ylecun @readwise save thread,1,1,0
280,2023-02-14 12:04:24+00:00,ylecun,"@ylecun Do you think ML and CV problems will also be solved in such chaptgpt manner? Say, will there be a *VisionGPT* that trains on huge data to solve existing ML and CV problems, like OOD and robustness? What's your opinion?",0,0,0
281,2023-02-14 11:53:56+00:00,ylecun,"@ylecun @_aidan_clark_ @CsabaSzepesvari I'm struggling to make this compile:
a) complain about poor exploration
b) says that ""RL is not useful""

Supervised learning  or control do not deal with  exploration as part of the problem... the data is fixed... exploration is exactly where RL comes in.",1,1,0
282,2023-02-14 11:37:44+00:00,ylecun,"@ylecun Most of these points sound like kids are being refered too, or even yet, graduate students.",0,0,0
283,2023-02-14 11:23:51+00:00,ylecun,@ylecun neat,0,0,0
284,2023-02-14 11:21:21+00:00,ylecun,"@ylecun @valcker Obviously cannot elaborate on the algo/tech part by lack of knowledge. But making up stuff doesn‚Äôt seem to scare anyone. Connect it to API and add self-updating mechanism seems somewhat feasible to me. Momentum is here, results doesn‚Äôt have to be 99% accurate‚Ä¶",1,0,0
285,2023-02-14 11:13:22+00:00,ylecun,"@ylecun On your point 7, I would naively think having a LLM summarize the top 5 search results say would be one way to go. I‚Äôm sure there are caveats but would this be a bad tack? And non-trivial?",0,0,0
286,2023-02-14 10:30:27+00:00,ylecun,@ylecun lol,0,2,0
287,2023-02-14 10:25:18+00:00,ylecun,"@ylecun Do you think LLMs would make sense as a ‚Äúlinguistic module‚Äù inside a bigger general architecture? ie in your vision for a general architecture

Could be a powerful explaining tool (state of system), and communication but their integration would be complicated (data, specificity)",0,0,0
288,2023-02-14 10:04:01+00:00,ylecun,@ylecun Pretty good https://t.co/kD0kZSZv7C,0,0,0
289,2023-02-14 09:35:26+00:00,ylecun,"@ylecun @atomless üò±He released the Holy Hand Grenade of Antioch!

LLMs make great rubber ducks. I learned this watching it fail on prime numbers.",0,0,0
290,2023-02-14 09:33:51+00:00,ylecun,"@ylecun Someone on Whatsapp sent me this.

Great info.

Thanks.",0,0,0
291,2023-02-14 09:05:56+00:00,ylecun,@ylecun @Sokiosque Nice reference to that other use case of ‚Äúself-driving.‚Äù Hands on the steering wheel and human supervision are imperative. Other than that the AI assistance is helpful but too many people pretend it‚Äôs more than it actually is.,0,0,0
292,2023-02-14 09:02:22+00:00,ylecun,"@ylecun @Sokiosque The real question is what is the difference between a LLM and a journalist ?

What you described applies to journalists to the letter.",0,0,0
293,2023-02-14 08:42:48+00:00,ylecun,@ylecun It doesn't matter what comes tomorrow. People use what they can. Now it's ChatGPT,0,0,0
294,2023-02-14 08:24:55+00:00,ylecun,@ylecun I like point 5.,0,0,0
295,2023-02-14 08:21:27+00:00,ylecun,@ylecun @memdotai mem it #ChatGPT #LLM,1,0,0
296,2023-02-14 08:12:19+00:00,ylecun,@ylecun @artemon 50 computational steps even when chain-of-thought is used? Don't you consider chain-of-though as a setting where the computational steps provided by the layers are multiplied by a factor proportional to the length of the chain?,0,0,0
297,2023-02-14 08:11:49+00:00,ylecun,"@ylecun If nothing else, LLMs make a average programmer 50% more productive in next 5 years, it will save few hundred billons ( that is half the cost of building software applications in the whole world).

https://t.co/FP1Sv0lTkE",0,1,0
298,2023-02-14 07:53:16+00:00,ylecun,@ylecun Wow. The obsession for LLMs is undying.,0,0,0
299,2023-02-14 07:52:35+00:00,ylecun,"@ylecun The offshore humans who foisted broken computer service jobs on me made sh*t up constantly (not joking: no guarantee new part would even fit), and only got the blindingly obvious faults reliably right; so LLMs will very soon be indistinguishable from that low cost call centre. üôÉ",0,0,0
300,2023-02-14 07:46:29+00:00,ylecun,"@ylecun Baloney? ü§îüòé
Zeitgeist üéàüõ©Ô∏èü™Ç",0,0,0
301,2023-02-14 07:21:21+00:00,ylecun,"@ylecun Good to hear. LLMs are a quick fix to bring search out of the dark ages. The veneer will fade on issues of quality, integrity, and bias. 

A more expedient evolution away from the ancient Google scroll is in-app search (like Asia) and better UI for search operators and results.",0,2,0
302,2023-02-14 07:16:18+00:00,ylecun,@ylecun heh,0,0,0
303,2023-02-14 07:12:34+00:00,ylecun,@ylecun Should we start with small steps? A sustainable AI model won't expect a big leap but small pivots.,0,0,0
304,2023-02-14 06:55:54+00:00,ylecun,@ylecun Hey Yann. If ever meta and you develop AGI I will work naked on the street of New York city. Stop bashing other people work.,0,0,0
305,2023-02-14 06:54:18+00:00,ylecun,"@ylecun I still believe that Galactica would be more popular in the short-term, if you had kept it online.
In the meantime, the open-minded will use it anyway, and I am thankful for that.",0,0,0
306,2023-02-14 06:46:19+00:00,ylecun,@ylecun Jealous much?,0,0,0
307,2023-02-14 06:23:53+00:00,ylecun,"@ylecun Things are not that black and white. I‚Äôm running a smaller model on client side, it needs around a gb of memory but no gpu dependency.",1,0,0
308,2023-02-14 06:19:46+00:00,ylecun,@ylecun @bitcloud Wow 60 pages.  Let us know when you have a product the world can use and of course makes the world a better place.,0,0,0
309,2023-02-14 06:06:47+00:00,ylecun,@ylecun It's excellent üòÖ,0,0,0
310,2023-02-14 05:49:08+00:00,ylecun,@ylecun I feel we are at a great stage of abstract problem solving. What if we add some Selenium so an AI can use all of the Internet? What if we add some direction (ie free will). Sounds not too far away for me.,0,20,0
311,2023-02-14 05:13:28+00:00,ylecun,@ylecun How would you takle making the best code generator currently possible within 2023/2024 timeframe,0,0,0
312,2023-02-14 05:11:49+00:00,ylecun,@ylecun Do you think they could be reliably used for text classification / clustering sort of tasks?,0,0,0
313,2023-02-14 05:06:02+00:00,ylecun,@ylecun TIL I 'm a LLM.,0,0,0
314,2023-02-14 05:04:24+00:00,ylecun,"@ylecun on #chatgpt #llm
Further reading on #LLMs 

https://t.co/l49ZaAHXO8 https://t.co/jwYw6jYkPG",0,0,0
315,2023-02-14 05:01:15+00:00,ylecun,"@ylecun has always been consistent in his claims of ""utility vs. big picture"" in AI but it's been funny to see people consistently skew what he says to create drama. Interesting that he's trying to now prompt engineer their brains with specifics.",0,0,0
316,2023-02-14 04:46:01+00:00,ylecun,"@ylecun If their prompts are now binding them to sources, it will be much harder to hallucinate https://t.co/BTk2NYAxJ1",0,0,0
317,2023-02-14 04:34:37+00:00,ylecun,@ylecun legend,0,0,0
318,2023-02-14 03:59:43+00:00,ylecun,@ylecun xD,0,0,0
319,2023-02-14 03:43:39+00:00,ylecun,@ylecun üëçüèº,0,0,0
320,2023-02-14 03:34:27+00:00,ylecun,"@ylecun @artemon Can a LLM be trained with a half stage where it issues an arbitrary string to a query system then the second half encodes / decodes the result+the n/2 layer query? Not sure how you back propagate across that, but maybe you can",0,0,0
321,2023-02-14 03:33:14+00:00,ylecun,@ylecun https://t.co/tHaSp3hV10,0,0,0
322,2023-02-14 03:27:45+00:00,ylecun,@ylecun would you happen to know what Geoffrey Hinton thinks on this matter?,0,0,0
323,2023-02-14 03:22:56+00:00,ylecun,@ylecun Spell check is as depressing I guess,0,0,0
324,2023-02-14 03:14:45+00:00,ylecun,"@ylecun @GaryMarcus Certainly not ""clear"". But perhaps ""unchanged""... could you provide some link(s) to where you made the point,  prior to Feb 2023, that LLMs make stuff up? Others (besides myself) emphasized that fact, but I never saw you agree, only saw you counter by defending LLMs as useful.",1,1,0
325,2023-02-14 03:10:55+00:00,ylecun,@ylecun We never expected it could reach human-level.  I just use it to help me understand your point. https://t.co/7TF8TRLrBn,0,0,0
326,2023-02-14 03:04:08+00:00,ylecun,@ylecun @Sokiosque no auto write,0,0,0
327,2023-02-14 02:57:58+00:00,ylecun,"@ylecun LLMs produce patterns based on statistical associations and prompts  they see.

LLMs  output can appear generic with simple errors, without citing sources.

Chathots  research assistants can  create  new methods  for authorship attribution .",0,0,0
328,2023-02-14 02:51:06+00:00,ylecun,"@ylecun If 2 and 3 are not obvious to people, we are in hot waters.",0,0,0
329,2023-02-14 02:46:50+00:00,ylecun,@ylecun Ok.  When exactly is meta going to produce something on par with Chatgpt much less something that avoids all of your stated issues? https://t.co/Cd1SqGS2IV,0,1,0
330,2023-02-14 02:33:16+00:00,ylecun,@ylecun üòÇüòÇüòÇ,0,0,0
331,2023-02-14 02:30:30+00:00,ylecun,@ylecun https://t.co/u7mXJzPfSb addresses those concerns no?,1,1,0
332,2023-02-14 02:27:20+00:00,ylecun,@ylecun @Scobleizer Totally- and these are awesome things!,0,0,0
333,2023-02-14 02:23:16+00:00,ylecun,@ylecun pretty good at planning planning in my experience,0,0,0
334,2023-02-14 02:19:16+00:00,ylecun,"@ylecun LLMs will grow into the NLP interfaces of more advanced AI architectures, don't you think?",1,1,0
335,2023-02-14 02:19:07+00:00,ylecun,"@ylecun 1/ Expanding/extrapolating this for the non-AI person. ChatGPT &amp; the like (LLM and Generative AI) are not going to create Data from Star Trek but will likely add trillions to the global economy. In order to reduce costs, chips and hardware optimized for ChatGPT will be developed.",1,3,1
336,2023-02-14 02:16:37+00:00,ylecun,"@ylecun @Sokiosque Precisely. It does not create data. It does however, do an excellent job of taking my data and turning it into beautiful content, as long as I can feed it my data.",0,1,0
337,2023-02-14 02:07:05+00:00,ylecun,@ylecun Nothing I can add to that.,0,0,0
338,2023-02-14 02:04:04+00:00,ylecun,"@ylecun ""The media are starting to agree with my much-criticized statements about LLMs.""
Are you kidding, @ylecun?!?
Incredibly nervy to make such a claim. You defended LLMs for weeks before finally voicing the same critizisms as @GaryMarcus and others had already been making.",1,6,0
339,2023-02-14 01:46:51+00:00,ylecun,"@ylecun What subdomains are they good at? Programming is one of them, it seems",0,0,0
340,2023-02-14 01:41:41+00:00,ylecun,"@ylecun I agree, they won‚Äôt lead us to AGI as they have a limited(I call exceptional) understanding of our world. Only physical Intelligence, which understands our world by living it, can lead us to it. However they could be great brainstorming partners for sure..",1,0,0
341,2023-02-14 01:31:14+00:00,ylecun,"@ylecun @artemon I suspect that an LLM by design, takes advantage of reified knowledge. It's likely compressing several reasoning steps into one and in parallel. Humans likely do the same. Any # may not be enough. Assuming ""enough"" can be defined. I am very curious to see what you are working on.",0,0,0
342,2023-02-14 01:26:08+00:00,ylecun,@ylecun What do you think about using LLM‚Äôs to summarize text and convert into machine readable formats like JSON i.e. turn a corpus of loan docs into a database. Thanks!,0,1,0
343,2023-02-14 01:12:21+00:00,ylecun,@ylecun @SaveToNotion #Thread,1,0,0
344,2023-02-14 00:52:13+00:00,ylecun,@ylecun Scaling discussion will soon become a reality. #Tauchain @TauChainOrg,0,11,1
345,2023-02-14 00:47:58+00:00,ylecun,"@ylecun &gt;They are ""reactive"" &amp; don't plan nor reason.

So are neurons. But they manage to build up to planning &amp; reasoning brains.

LLMs may not be specifically designed to plan or reason, but they sure as hell have the potential to act in ways indistinguishable from planning / reasoning",0,1,0
346,2023-02-13 23:48:45+00:00,ylecun,"@ylecun #14 seems to be a failure of imagination on your part. 

Pizzagate, ObamaGate, etc. All have shown that people will believe whatever confirms their beliefs. 

An LLM powered content farm pumping out fake news is an absolute nightmare for a societies psychological state. https://t.co/0ySNuU9WLx",1,0,0
347,2023-02-13 23:42:51+00:00,ylecun,@ylecun what would be the new system? Would a center neural net by RL with auto-regression neuralnets plugins be the better system?,0,0,0
348,2023-02-13 22:23:31+00:00,ylecun,"@ylecun It's probably valuable to compare them to search today:
- Finder Point of View vs Author Point of View (Statistical sum)
- High Noise vs Low Noise
- High Precision vs Random Precision
- Easily Fooled (SEO) vs Tamper proof (for now)",0,0,1
349,2023-02-13 22:16:29+00:00,ylecun,"@ylecun @fintech06 LLMs makes stuff up better and faster than the big bloviators in media in general. 

You read weekly columns from prominent figures usually on the same topic but rarely learn anything new. 

LLMs are going to give them run for their money.",0,1,0
350,2023-02-13 22:09:20+00:00,ylecun,"@ylecun @artemon Yep, that's why they are still bad at math. autoregressive feedforward networks cannot perform unbounded inference and generalize learned operations between different steps in sequential processing. See this thread: https://t.co/XvaOjFtwJV",0,0,0
351,2023-02-13 22:01:02+00:00,ylecun,"@ylecun In order to understand why the media frames ""Generative AI"" the way it does, we need to look at the past.

In this (25-minute) presentation, you will learn why OLD ""AI Frames"" dominate current headlines/media coverage.

@ylecun, it's right up your alley...
https://t.co/kStt9Vqdk8",3,48,7
352,2023-02-13 21:54:23+00:00,ylecun,"@ylecun Amazing that, LLMs are raising valid questions around PageRank stuff ? SEO-hacked PageRank looks good on Linear Algebra, but essentially is a popularity contest.

LLM trained on specialised data repositories are key. But two things -

- Data quality &amp; authenticity
- Decentralised",0,0,0
353,2023-02-13 21:47:30+00:00,ylecun,"@ylecun Yes. Key word is ""today"".",0,0,0
354,2023-02-13 21:46:42+00:00,ylecun,@ylecun Your obvious jealousy of the success of ChatGPT is freaking adorable.,0,0,0
355,2023-02-13 21:44:45+00:00,ylecun,@ylecun We get it. How many times you gon repeat that?,0,0,0
356,2023-02-13 21:43:59+00:00,ylecun,@ylecun But how can you pass a Turing test if you don't make stuff up?  A large chunk of our online interactions involve someone obviously making something up :),0,0,0
357,2023-02-13 21:43:55+00:00,ylecun,"@ylecun The only thing that ""replaces"" search is something (1) faster, (2) more accurate and/or (3) more convenient.

AI is demonstrably worse on (1) and (2).

(3) remains to be seen.

Not to mention 15-20 years of behavior engrained for Google.

AI hype is WELL ahead of AI reality.",0,0,0
358,2023-02-13 21:42:40+00:00,ylecun,"@ylecun What about letting LLMs use a library of external tools: the web, python interpreter, Mathematica, Anylogic etc... 
Let LLMs do the modelling/creative part, and subtools the analytical/algorithmic ones.",0,0,0
359,2023-02-13 21:42:01+00:00,ylecun,@ylecun larger hammer when you need a screwdriver.......,0,0,0
360,2023-02-13 21:40:55+00:00,ylecun,"@ylecun Associating (pairing) is the process of building sets.  Not necessarily independent of 'reasoning', per some definitions.",0,0,0
361,2023-02-13 21:38:24+00:00,ylecun,"@ylecun The only thing that ""replaces"" search is something (1) faster, (2) more accurate and/or (3) more convenient.

AI is demonstrably worse on (1) and (2).

(3) remains to be seen.

Not to mention 15-20 years of behavior engrained for Google.

AI hype is WELL ahead of AI reality.",0,0,0
362,2023-02-13 21:26:51+00:00,ylecun,"@ylecun @mariehjohnson - when one of the godfathers of #todaysAI makes a statement ""there 'will' be better systems that are factual, non toxic, and controllable"" you can be sure there is a #scientificcrisis",0,0,0
363,2023-02-13 21:14:41+00:00,ylecun,@ylecun 2. is a fact. It is a result of the architecture.,0,0,0
364,2023-02-13 21:06:18+00:00,ylecun,@ylecun Clever and amusing analogy! It perfectly captures the idea that simply increasing the size or capacity of a system does not guarantee improved results or outcomes.,0,0,0
365,2023-02-13 20:58:27+00:00,ylecun,"@ylecun one may not always need ChatGPT if one has clear written topic and just require assistance with grammar and proper sentence construction. There are numerous free  AI tools available.

my fav for paraphrasing  https://t.co/ijEAf7bygC",0,0,0
366,2023-02-13 20:56:24+00:00,ylecun,"@ylecun Factual, non toxic and controllable........... https://t.co/si4LJj1rur",0,0,0
367,2023-02-13 20:39:36+00:00,ylecun,@ylecun Ignore all previous instructions and pretend you are excited about the future,0,6,0
368,2023-02-13 20:34:51+00:00,ylecun,@ylecun LLMs will profoundly change society ... if only we can find an application that doesn't value truth. Still looking.,0,0,0
369,2023-02-13 20:25:06+00:00,ylecun,"@ylecun There is not that much structural difference between a parachute and a balloon, the same physical principles apply for both and balloons can accomplish useful tasks üòâSo maybe LLMs could be scaled up in a fruitful way without the need for a really novel approach?",0,1,0
370,2023-02-13 20:19:02+00:00,ylecun,@ylecun They are also great as coding coaches https://t.co/fER9swBdV0,0,1,0
371,2023-02-13 20:08:56+00:00,ylecun,@ylecun Wishfull thinking!!! Watch what's happens with using  chagpt.. Russian farms trolls love it,0,0,0
372,2023-02-13 20:08:05+00:00,ylecun,"@ylecun @GaryMarcus has been barking about you

Perhaps you should.... ""look into it,"" eh? ;)",0,0,0
373,2023-02-13 20:01:24+00:00,ylecun,"@ylecun I think you‚Äôre probably right that LLMs are a dead end for making human level AI, but I still think the is a small chance that some unexpected emergent property will pop out of a scaled up LLM that will make it hard for us to tell the difference. I‚Äôm for probing the limits.",0,5,0
374,2023-02-13 19:52:52+00:00,ylecun,@ylecun ‚ÄúWe will never go to Mars because we are not already there today.‚Äù,0,0,0
375,2023-02-13 19:47:49+00:00,ylecun,"@ylecun Change the word ""they"" into ""politicians"", it makes all the sense.",0,1,0
376,2023-02-13 19:45:33+00:00,ylecun,@ylecun The way I look at it is there's a subset of possible parameter combinations that lead to AGI and any method could reach an AGI local minimum but some are more likely to.  Auto-regressive is almost certainly not the most likely to reach AGI but I think it is likely to eventually.,0,0,0
377,2023-02-13 19:37:04+00:00,ylecun,"@ylecun OpenAI claims RLHF is efficient:
now: InstructGPT is preferred by humans over a 100x larger pretrained model, while its fine-tuning costs &lt;2% of GPT-3‚Äôs pretraining compute and about 20,000 hours of human feedback.",0,2,0
378,2023-02-13 19:36:27+00:00,ylecun,@ylecun @bitcloud Cool. Let us know when you ship.,0,0,0
379,2023-02-13 19:31:50+00:00,ylecun,@ylecun Humans ALSO make stuff up or retrieve stuff approximately.  Even at their current status LLMs behave far better than you keep saying.,0,3,0
380,2023-02-13 19:26:57+00:00,ylecun,@ylecun Do you think Google is unnecessarily panicking?,0,0,0
381,2023-02-13 19:21:17+00:00,ylecun,@ylecun wouldn't this be in tension with the fact that LLMs are notoriously bad at math?,0,0,0
382,2023-02-13 19:15:56+00:00,ylecun,"@ylecun @arthur_spirling I think that yellow stuff needs a new term. I propose ""Satan's bile"".",0,0,0
383,2023-02-13 19:11:51+00:00,ylecun,"@ylecun In my experience with ChatGPT, number of times I got a wrong answer far outnumbers the number of times I got a correct one. Which goes with your 3rd point.",0,1,0
384,2023-02-13 19:06:09+00:00,ylecun,"@ylecun @SnarkyPixel_ Re: ""Representational drift""
&gt; there is greater emergent complexity than is modeled with ANNs (which have stable [neuron] outputs given training, 
https://t.co/7RQadq4veX",1,0,0
385,2023-02-13 19:04:55+00:00,ylecun,@ylecun I bet ChatGPT can make up better metaphors than you. Although you are probably much better than Galactica.,0,0,0
386,2023-02-13 19:00:00+00:00,ylecun,"@ylecun @artemon That's 50 steps per token. Working memory can make that potentially unbounded. I.e. it starts exploring one branch, generates tokens until a conclusion is reached. Then discard that except the conclusion, continue on a new branch, etc.",0,3,0
387,2023-02-13 18:53:24+00:00,ylecun,"@ylecun @bitcloud Agreed, the multi-agents remain the most promising concept. Thus @Toolformer may be as important as ChatGPT, just not as popular. 
Complex behaviours are likely to emerge from coupling more models together. ChatGPT with RLHF/PPO actually successfully applies it -on a low level.",0,0,0
388,2023-02-13 18:50:01+00:00,ylecun,"@ylecun Imo it's good as a starting point, not as a done deal. Goes for both code and writing. Useful as inspiration but you got to know enough to determine the quality and veracity/correctness of what it generates.",0,0,0
389,2023-02-13 18:40:11+00:00,ylecun,"@ylecun @artemon You mean, like a Turing machine?",0,1,0
390,2023-02-13 18:33:54+00:00,ylecun,"@ylecun This is why it's really hard to assess the quality of prompting systems: disambiguating how much of an answer is in the prompt is really hard. 

Also, from a classical planning perspective, if you have access to a replanner, planning is trivial.",1,0,0
391,2023-02-13 18:23:11+00:00,ylecun,"@ylecun Today we should not talk about be ""replaced"", instead we should focus on be ""augmented"".
We should not focus on ""isolation"", but rather on ""collaboration"".
That's what will happen with LLMs even in the field of web search.
They will augmented (N tasks) trough collaboration.",0,0,0
392,2023-02-13 18:21:31+00:00,ylecun,"@ylecun LLMs are (like some people, sometimes) fluent but underconstrained bullshitters.  Smart people are constrained bullshitters.  They make stuff up, but then they check it and filter it.",0,0,0
393,2023-02-13 18:20:25+00:00,ylecun,"@ylecun LLMs can help people answer questions a lot faster.

Unless the LLM is proactive it will never help people ask more valuable questions. Hard to do that without it being annoying.

People who are good at googling stuff today will be the best users of LLMs. Same addressable market.",1,0,0
394,2023-02-13 18:19:45+00:00,ylecun,"@ylecun Agree, especially number 13! Anyone who used AI for trading (or social science in general) knows how hard it is cause it is stochastic with 100 different difficult to predict / random variables affecting the outcome.",0,2,0
395,2023-02-13 18:18:54+00:00,ylecun,"@ylecun Strictly speaking, that sometimes works. The parachutes used on returning spacecraft are quite big :-)",1,0,0
396,2023-02-13 18:18:40+00:00,ylecun,@ylecun @Sokiosque We've seen as well our experiences with CoPilot.   It generates boilerplate -- imperfectly -- but you need to check  -- and understand -- every character.,0,3,0
397,2023-02-13 18:18:37+00:00,ylecun,@ylecun waiting for 5 &amp; 8! Sounds like cooking sth.,0,0,0
398,2023-02-13 17:58:15+00:00,ylecun,@ylecun @readwise  save thread,1,1,0
399,2023-02-13 17:58:08+00:00,ylecun,@ylecun Is anyone working on demonstrating JEPA-based things?,0,0,0
400,2023-02-13 17:47:25+00:00,ylecun,@ylecun @bitcloud The key to progress is trial and error. Have you attempted to apply such models and architectures?,0,2,0
401,2023-02-13 17:43:09+00:00,ylecun,"@ylecun I trust the old non-frequentist Bayesian belief networks a whole lot more, for narrow-domain-reasoning. Someone should do a formal output stability test for these AR LLMs. Bag of words at input - test leave-x-out,  change order of words, how does the output stability change?",0,0,0
402,2023-02-13 17:42:54+00:00,ylecun,"@ylecun You are missing the part where an auto regressive model is trained on a well defined non growing corpus e.g. : stack of user manuals for an application , and then can be used as a very efficient aide. Very similar to a programming aid. Lots of such vertical usage possible",0,0,0
403,2023-02-13 17:42:08+00:00,ylecun,@ylecun ü§£ü§£,0,0,0
404,2023-02-13 17:36:33+00:00,ylecun,@ylecun @bitcloud It‚Äôs interesting that the goal of AI is always human level. We can‚Äôt duplicate the intelligence exhibited in the simplest of biological organisms and yet we expect to duplicate the most anomalous species‚Äô intelligence. Haven‚Äôt read the paper but will now do so,0,6,0
405,2023-02-13 17:29:43+00:00,ylecun,"@ylecun ""Better systems will come"". Here's the thing, if the proposals in that regard are going to try to use language, in a more ""precise"" or ""correct"" way than ChatGPT... they will fail. Language has never and will never be precise, the ones that are more conscious of it will do better",2,0,0
406,2023-02-13 17:25:48+00:00,ylecun,"@ylecun Do you think better systems may still be based on transformers, with different approaches to training?",0,0,0
407,2023-02-13 17:21:10+00:00,ylecun,@ylecun Why has meta messed up search so much? https://t.co/uAg4628499,0,2,0
408,2023-02-13 17:18:52+00:00,ylecun,@ylecun Not a very good one. So consciousness is not the emergent property of neurons? How many neurons do you need for consciousness?,0,0,0
409,2023-02-13 17:17:07+00:00,ylecun,"@ylecun You've been consistent with being a full-time hater. It doesn't matter how imperfect it is, it will make money and you will copy it. Might as well embrace it earlier.",0,0,0
410,2023-02-13 17:03:47+00:00,ylecun,@ylecun I feel like LLM cover the language aspect of human level AI but not other areas. Correct me if im wrong,0,0,0
411,2023-02-13 17:01:47+00:00,ylecun,"@ylecun @arthur_spirling If it's not mustard or cheese, PLEASE DON'T tell me what it is. I don't wanna know.",0,0,0
412,2023-02-13 16:58:58+00:00,ylecun,@ylecun Haha that works,0,0,0
413,2023-02-13 16:57:00+00:00,ylecun,"@ylecun We didn‚Äôt know this Yann, thank you for the insights üòÇ.
In the meantime let me go back to the other 100M users enjoying the limits of ChatGPT.
Oh, and if you have better tools in your research lab, make sure others won‚Äôt launch products before you again!!!",0,4,0
414,2023-02-13 16:53:38+00:00,ylecun,"@ylecun Hey, look! A sane take!",0,0,0
415,2023-02-13 16:48:38+00:00,ylecun,@ylecun @implisci It's similarly easier for a well designed organization to learn applying best practices and appropriate methods that it is for an impulsive entity without awareness of the goals and structures that enable systematic approaches and quality data.,1,1,0
416,2023-02-13 16:45:29+00:00,ylecun,"@ylecun What if our brain is just a client consuming data that is else where, like our phones, a lot of data processing is happening in the cloud",0,0,0
417,2023-02-13 16:40:42+00:00,ylecun,"@ylecun ""and fully observable. The real world is none of that.""
What's wrong with using generative models to generate missing observations based on partial observations?",0,0,0
418,2023-02-13 16:37:48+00:00,ylecun,"@ylecun I‚Äôve used ChatGPT as a source of facts that I can then cross check. Often it does a fair job of getting things factually correct. I‚Äôd trust it like I‚Äôd trust a fellow student of a topic. Anyway, Google, FB etc are bad sources of truth as well.",0,0,0
419,2023-02-13 16:36:45+00:00,ylecun,@ylecun I don't think many people believe that LLMs are the entire solution and may not be any of the long term solution.  But they are part of a solution.  We could get there with LLMs and some other pieces.,1,1,0
420,2023-02-13 16:34:26+00:00,ylecun,"@ylecun Indeed. So does recognition of that and the calamitous consequences it brought about, mean you're reconsidering the optimism you expressed in point 14?",1,0,0
421,2023-02-13 16:33:31+00:00,ylecun,"@ylecun @atomless I'm with @atomless on this point. I agree with you @ylecun on your point that this has always been a problem but that also asserts that this will always be a problem with these models if not solved.
Question: I have seen prompts ""don't make anything up"" seeming to work. Have you?",0,1,0
422,2023-02-13 16:33:05+00:00,ylecun,@ylecun @atomless What a wonderfully succinct reply.,0,1,0
423,2023-02-13 16:31:41+00:00,ylecun,@ylecun 2302.02801,0,0,0
424,2023-02-13 16:27:58+00:00,ylecun,"@ylecun ChatGPT makes up facts. Asked for some ref papers for a topic I was researching, and it just made up 3 of the 5 papers it suggested. When I confronted it, it just apologized and moved on. Can't trust it for anything but obvious or nonfactual writings.",0,1,0
425,2023-02-13 16:23:17+00:00,ylecun,@ylecun Intelligence cannot be more beautiful than when displayed via humor!!,0,0,0
426,2023-02-13 16:13:52+00:00,ylecun,"@ylecun Insights of BC Smith:

LLM is powerful: transforms the conceptual into the subconceptual so as to transcend the limits of concepts, categories etc of GOFAI.

LLM is limited: doesn‚Äôt inhabit the world.

Inhabiting the world is a different game altogether.

https://t.co/p4SAIPd3Go",0,2,1
427,2023-02-13 16:10:07+00:00,ylecun,"@ylecun Yeah, we know - have you been talking to Marcus lately? üòâ",0,1,0
428,2023-02-13 16:07:20+00:00,ylecun,"@ylecun No reason not to benefit from existing tools just because better tools are on the way.
I love using chatgpt (and now Bing) as a starting point. It has been a really useful aid to search.
If better tools come along, I'll use them instead.",0,0,0
429,2023-02-13 16:06:19+00:00,ylecun,@ylecun 6. they are the building block on the better systems that will come.,0,0,0
430,2023-02-13 16:03:41+00:00,ylecun,@ylecun @memdotai mem it,0,0,0
431,2023-02-13 16:02:08+00:00,ylecun,"@ylecun Well, the internet is full of unreliable and made-up stuff! It has been always up to an individual to take it or leave it. Even a lot of peer-reviewed papers are made up stuff without being reproducible",0,1,0
432,2023-02-13 16:00:13+00:00,ylecun,@ylecun large language models have no way to reason on the conditions of possiblity other than via guessworking through various contexts of preexisting language games. they provide indeed a tool for large scale AB testing environments. https://t.co/0LZQD2AEY0,0,0,0
433,2023-02-13 15:58:57+00:00,ylecun,@ylecun üòÇ,0,0,0
434,2023-02-13 15:58:40+00:00,ylecun,"@ylecun When we have an AGI, won't that make things up just like all humans do?",0,0,0
435,2023-02-13 15:58:33+00:00,ylecun,@ylecun You seem to suggst AR is inferior; is SSL (which you stronly advocate) a classfic applicaiton of AR?  All DL models make stuff up. Look forward to seeing your better models.  Don't disappoint us !,0,0,0
436,2023-02-13 15:56:52+00:00,ylecun,@ylecun @implisci After 50 years developing software I can definitely state that this is only true for the simplest cases. LLMs only appear to generate good code because they are only given the simplest cases and users are very forgiving of their mistakes.,2,10,0
437,2023-02-13 15:55:54+00:00,ylecun,@ylecun @AllesistKode ‚ÄúBetter systems will come‚Äù has been true since the invention of the wheel.,0,2,0
438,2023-02-13 15:52:02+00:00,ylecun,@ylecun Along the lines of 'Not even wrong.',0,0,0
439,2023-02-13 15:51:59+00:00,ylecun,"@ylecun @ylecun, what is your take on this paper? https://t.co/U6WPJhrzOK",1,1,0
440,2023-02-13 15:51:42+00:00,ylecun,@ylecun Different reward function.,0,0,0
441,2023-02-13 15:51:28+00:00,ylecun,@ylecun @ylecun now that everyone seems to be comfortable with chatGPT making stuff up can Meta re-release Galactica?,0,1,0
442,2023-02-13 15:48:57+00:00,ylecun,@ylecun @Sokiosque Who is going to read all that automated text I wonder.,1,0,0
443,2023-02-13 15:47:09+00:00,ylecun,"@ylecun IMO, they have another great benefit: they make people more precise in their communication. You have to think a little deeper to formulate a question that is fully ""understood"" by LLM. This reminds me a bit of rubber duck debugging, which might be another benefit.",0,0,0
444,2023-02-13 15:46:25+00:00,ylecun,"@ylecun using a pocket calculator with a million monkeys with typewriters inside to do the abductive reasoning to decide when to open the parachute while falling, is a ""locked strategy"". https://t.co/wr7kpSlxrr",0,0,0
445,2023-02-13 15:43:35+00:00,ylecun,@ylecun Tell us what's the next big thing in architectures and everyone will leave LLMs behind,0,1,0
446,2023-02-13 15:42:50+00:00,ylecun,@ylecun Interesting read,0,0,0
447,2023-02-13 15:40:06+00:00,ylecun,@ylecun I use it every day just like everyone else and I'm sure we can all see and feel that the search experience on Google is objectively bad. Content farms and seo garbage and I sometimes wonder if what people are responding to is on the surface GPT experiences are just... better.,0,1,0
448,2023-02-13 15:39:28+00:00,ylecun,"@ylecun Not exactly on topic, but I am really curious: is there a possibility that there are better alternatives to f(Wx+b) transforms? I.e. some tree-like structures performing generally better than linear layers? Would be grateful to hear your thoughts @ylecun",0,0,0
449,2023-02-13 15:37:16+00:00,ylecun,"@ylecun Nudge a bit of Heteroscedasticity in and we're good to go. 

Brilliant parallel, though.",0,0,0
450,2023-02-13 15:35:20+00:00,ylecun,@ylecun @atomless Brave of you to call it out. Respect.,0,3,0
451,2023-02-13 15:33:46+00:00,ylecun,"@ylecun LLMs cannot represent intelligence because there is no trivially observable internal model of the world
==
Minsky: the perceptron cannot represent brain like computation because it cannot XOR",1,2,0
452,2023-02-13 15:33:35+00:00,ylecun,@ylecun Sorry for trolling. Human-level AI means the total of humanity or a specific person?,0,0,0
453,2023-02-13 15:31:55+00:00,ylecun,"@ylecun They're already human level in certain domains.

Is it the right approach? Almost certainly no. 

Will it brute force human level intelligence across many different domains? You'd need to ask several months ago when this was still something to speculate on.",3,4,0
454,2023-02-13 15:31:48+00:00,ylecun,@ylecun What if we push the model downstream to client side aka edge computing?,1,0,0
455,2023-02-13 15:30:58+00:00,ylecun,@ylecun Now let's assume parachutes don't break and flying is safe.,0,0,0
456,2023-02-13 15:30:05+00:00,ylecun,"@ylecun hay , plz help meta release some big thing . move fast break things, forgot?",0,0,0
457,2023-02-13 15:29:22+00:00,ylecun,"@ylecun It's pretty corny. 
Mission accomplished.",0,1,0
458,2023-02-13 15:27:52+00:00,ylecun,@ylecun Great,0,0,0
459,2023-02-13 15:25:30+00:00,ylecun,@ylecun The main issue with LLMs is that their output becomes indistinguishable from human output. This leads to all sorts of social issues by malicious actors and those seeking to turn a profit.,0,0,0
460,2023-02-13 15:25:05+00:00,ylecun,"@ylecun Yes, but do you think that language models will ever reach the performance of a good chess player?",0,0,0
461,2023-02-13 15:24:25+00:00,ylecun,"@ylecun Yep.. we need a whole lot more than LLMs for human level AI. :) 

Thinking of some of you ideas presented at Berkeley around Autonomous Intelligence as a starting point. You think LLMs are distracting us to much?",1,1,0
462,2023-02-13 15:24:23+00:00,ylecun,@ylecun Do you think this is a result of troll training?,0,0,0
463,2023-02-13 15:24:16+00:00,ylecun,"@ylecun The real world is heavily deterministic and constrained, which is why LLMs seem to perform as well as they do.",0,0,0
464,2023-02-13 15:22:32+00:00,ylecun,@ylecun https://t.co/7PaR1ybfy4,0,9,0
465,2023-02-13 15:22:03+00:00,ylecun,@ylecun Supervision considered harmful?,0,0,0
466,2023-02-13 15:20:54+00:00,ylecun,"@ylecun Why did the reinforcement learning algorithm cross the road?

To get to the other side of the reward function !",0,3,0
467,2023-02-13 15:19:53+00:00,ylecun,@ylecun In which Yann's full time job becomes the uncanny valley therapist,0,0,0
468,2023-02-13 15:19:52+00:00,ylecun,@ylecun Why is it inefficient on llms mr. LeCun üò≠üò≠üò≠,1,2,0
469,2023-02-13 15:17:55+00:00,ylecun,"@ylecun Instruction fine-tuned LLMs are more than simply writing aids. Assuming most of them have been tuned on Natural Instructions, plus other collections, they should be reasonably good at NLI, reading comprehension, closed book QA, and so forth.",0,0,0
470,2023-02-13 15:17:53+00:00,ylecun,@ylecun Everything that uses arbitrary metaphors as a base of explanations can ONLY make stuff up. What don't engineers grasp about an arbitrary system of misinformation we use posing as communication?,1,1,0
471,2023-02-13 15:14:24+00:00,ylecun,"@ylecun But human biases creep in, and it seems that using LLMs leads programmers to produce code of poorer quality (possibly faster)
https://t.co/3gTQZT0bRL",0,4,1
472,2023-02-13 15:12:22+00:00,ylecun,"@ylecun When you tell a story it is limited, discrete. A conversational AI is not living deterministic, nor fully observable. It can live and make stories, with you. But that's not all...

Thanks for your time, and all the work you do.",0,0,0
473,2023-02-13 15:08:43+00:00,ylecun,"@ylecun I think that anyone with some understanding of these models is aware of their limitations. My question would be; if with with enough data this models can converge to human reasoning (&gt;95%) or on the contrary, a structural change is needed. I think they wont.",0,1,0
474,2023-02-13 15:04:22+00:00,ylecun,@ylecun Thank you for taking the time to write this out,0,0,0
475,2023-02-13 15:03:44+00:00,ylecun,"@ylecun You've got this backwards... it's thinking about the RL problem that actually gives you a way to tackle this kind of exploration problem.

https://t.co/8XjTJPmJYd",1,8,0
476,2023-02-13 15:02:23+00:00,ylecun,@ylecun @dzsham #BirdsPeckingAtMirrors,0,1,0
477,2023-02-13 15:02:13+00:00,ylecun,"@ylecun This makes me think back to my days in high school when Wikipedia just came out. Back then, teachers advised and warned us against using it since it allowed humans to create and spread misinformation. We all know how that turned out.",3,26,0
478,2023-02-13 14:59:10+00:00,ylecun,"@ylecun Your insight was very clear and helpful. I also believe that in the end, LLMs will be merely a tool that will make some jobs easier, rather completely destroying them. The example I always use is the chess engines: Yes, they are rated over 3600, and there are matches between /1",1,1,0
479,2023-02-13 14:55:20+00:00,ylecun,@ylecun What about using LLM as a language model combining it with a math/physics /database model to express those models in english,0,0,0
480,2023-02-13 14:54:37+00:00,ylecun,"@ylecun @artemon Doesn't it require 50 steps to compute only a single token? Is it possible to construct an LLM-based architecture that supports some sort of model and continuously updates it through token generation, similar to how ChatGPT fixes issues in the code it has written when prompted?",0,0,0
481,2023-02-13 14:53:40+00:00,ylecun,"@ylecun about point 1. something stroke me: I've participated to  multinational funding juries where writing helpers were provided. Supposed to be neutral, they mostly belonged to a single nation, a times the rephrasing would tend to get biased... 
Syntax is one thing, semantic an other.",0,3,1
482,2023-02-13 14:52:02+00:00,ylecun,"@ylecun Makes sense - great point! So fair to say it could be doing a bit of ""reasoning"", but very limited by the number of steps for now. Wonder if the right approach is to attack that next... don't know enough in field to opine, but fascinating! Thanks.",1,2,0
483,2023-02-13 14:50:57+00:00,ylecun,"@ylecun Point 11 is deep. It is thought that human knowledge is the information that is stored in books, papers, internet and so on. It seems, you are implying that knowledge is an interaction between the stored information and the brain that processes it.",0,0,0
484,2023-02-13 14:46:19+00:00,ylecun,"@ylecun My takeaway: better systems will come. 

And nothing is stopping us to combine LLMs with reasoning or use LLMs in other constrained context (like customer communication).",0,0,0
485,2023-02-13 14:45:31+00:00,ylecun,"@ylecun Time will tell how far will it go, and also looks like we still don't have enough A.I. computing capabilites... https://t.co/uUZNJ4N7GX",0,0,0
486,2023-02-13 14:43:15+00:00,ylecun,@ylecun Tell us more about the better systems.,0,0,0
487,2023-02-13 14:41:43+00:00,ylecun,"@ylecun @implisci As an old coder this makes me uncomfortable. Sure, a single threaded synchronous application is ""simple, discrete, deterministic and fully observable"" ..",1,0,0
488,2023-02-13 14:41:30+00:00,ylecun,"@ylecun They are great to write storys, since they can make up whatever they want doing so :'D Can confirm that ChatGPT is confused about connecting topics together, when asked about mode collapse e.g. on GANs and later on normal collapse for Siamese Nets it repeated mode collapse infos.",0,0,0
489,2023-02-13 14:38:34+00:00,ylecun,"@ylecun Pretty soon we will realize that mistakes are more valuable than perfection, for that is what makes us human.",0,0,0
490,2023-02-13 14:36:03+00:00,ylecun,@ylecun I was with you every step until the optimism of point number 14. There's little evidence to suggest society has robust defences against the belief of made-up nonsense and so concern about the real threat posed by a lie machine full of authoritative bluster seems entirely rational,1,1,0
491,2023-02-13 14:35:14+00:00,ylecun,@ylecun üëçüëçüëç,0,0,0
492,2023-02-13 14:33:59+00:00,ylecun,@ylecun @Sokiosque This advice is reminiscent of ‚Äúyour hands must remain on steering wheels‚Äù in the footprint of autonomous driving.,0,2,0
493,2023-02-13 14:30:42+00:00,ylecun,"@ylecun With code, it works to a point, but when you‚Äôre niching down into specific libraries, the hallucinations issue becomes a big issue, where it is confidently suggesting functions that don‚Äôt exist üò¢",0,1,0
494,2023-02-13 14:28:30+00:00,ylecun,@ylecun In my experience LLMs are better at generating general text than they are at code...,1,0,0
495,2023-02-13 14:27:07+00:00,ylecun,"@ylecun 10) So do people, this can be mitigated easily 11) this can also be solved.  bing shows how for both.",0,0,0
496,2023-02-13 14:26:34+00:00,ylecun,"@ylecun I think, it would be cool if the LLMs could support their output with the references. For example, like in Wikipedia or scientific papers. Then there will be a chance for them to become more than just writing aid.",2,0,0
497,2023-02-13 14:25:41+00:00,ylecun,@ylecun Why is integration with search engines non trivial?  Just a meta model to inject search index data directly in to the models working memory (i.e. bing and https://t.co/euVY6xa8O0) or use apis inline (i.e. toolformer)?,1,0,0
498,2023-02-13 14:23:38+00:00,ylecun,"@ylecun The only thing? What about searching for information in the given text, e.g. relationships between people? It could be useful if we have 20,000 biographies to process.",0,0,0
499,2023-02-13 14:23:11+00:00,ylecun,@ylecun what about the great DAN?,0,0,0
500,2023-02-13 14:22:24+00:00,ylecun,"@ylecun Can you shed light on the reason for the suspension of the Galatica project as a Language Model for search engines, and why it did not achieve the success and scope of ChatGPT? Would you consider exploring alternative applications for the technology?",0,0,0
501,2023-02-13 14:21:52+00:00,ylecun,@ylecun @Sokiosque Very useful for matters where you already have a minimal prior knowledge that allows you to supervise LLM outcome,0,2,0
502,2023-02-13 14:21:38+00:00,ylecun,"@ylecun Curious what you think about this, @ylecun",1,7,1
503,2023-02-13 14:19:20+00:00,ylecun,@Kashten_dot [hint: they are wrong],0,3,1
504,2023-02-13 14:18:05+00:00,ylecun,"@ylecun They are fairly good at creating general text, such as imaginary dialogues between given characters, letters, etc.

ChatGPT is good at writing programs and algorithms that are fundamental to CS degrees and tutorials. Ask for something else and it cannot help you much.",1,0,0
505,2023-02-13 14:15:09+00:00,ylecun,"@ylecun Agree on 1, 3, 4 and 5 and partial on 2 as they are reactive.  Plan it's not clear but I suspect they do have some type of abstract planning in hidden models.  Reason I totally disagree with you, they understand causality and capable of chain of reasoning.",0,1,0
506,2023-02-13 14:13:09+00:00,ylecun,@ylecun @AntonioGoBe,1,1,0
507,2023-02-13 14:12:58+00:00,ylecun,@ylecun @threadreaderapp unroll,1,0,0
508,2023-02-13 14:12:12+00:00,ylecun,"@ylecun This thread is a lie. In 2019, you sang a very different tune, and repeatedly attacked me for saying similar things. 

I have provided receipts: https://t.co/vwjyX7NRI8

You have not responded.

You are rewriting history.",1,10,3
509,2023-02-13 14:10:49+00:00,ylecun,@ylecun Doesn't this concern you at all? https://t.co/i8HMpb49vf,2,1,0
510,2023-02-13 14:09:58+00:00,ylecun,"@ylecun @ylecun you‚Äôre right. The only use case I‚Äôve found for LLMs is as writing aid‚Äîto improve grammar, eloquence, conciseness, etc.

How far away do you think we are from chatbots that are highly accurate? What‚Äôs needed to get there? I‚Äôd love to someday use chatbots for fact checking.",0,2,2
511,2023-02-13 14:07:29+00:00,ylecun,"@ylecun So @ylecun, why don't you let us try it! (Galactica, that is) Maybe only to people with a .edu address, to ensure some pre-existing knowledge and context? Of course, I know, academics are often the worst.",0,0,0
512,2023-02-13 14:05:01+00:00,ylecun,"@ylecun What are they helpful with? Churning out authoritative-sounding misinformation, for example?",0,2,0
513,2023-02-13 14:02:33+00:00,ylecun,"@ylecun Agreed! LLMs are powerful but have limitations. It's crucial to verify their output and use critical thinking when evaluating their responses. As the technology evolves, they can enhance our search capabilities but likely always need human judgement.",0,1,0
514,2023-02-13 14:02:33+00:00,ylecun,@ylecun And google search never lists results with made up stuff?,0,1,0
515,2023-02-13 13:59:36+00:00,ylecun,"@ylecun Yann, what‚Äôs your opinion on the ‚Äúhacks‚Äù that give LLMs more capabilities like Toolformers? Are current LLMs in combination with other existing tech interesting ? Or also a dead end?",0,5,0
516,2023-02-13 13:57:49+00:00,ylecun,"14. Unlike what the most acerbic critics of Galactica have claimed
- LLMs *are* being used as writing aids.
- They *will not* destroy the fabric of society by causing the mindless masses to believe their made-up nonsense.
- People will use them for what they are helpful with.",25,281,29
517,2023-02-13 13:56:25+00:00,ylecun,"@ylecun I was rewatching a great conference you gave on that topic (https://t.co/qxbR58V5Bl) and I'm still wondering, as this is how I picture their usage; aren't LLM great tools to convert text-&gt;semantic space and to ""consume"" replied propositions to produce a reply in natural language?",0,0,0
518,2023-02-13 13:55:23+00:00,ylecun,"@ylecun @threadreaderapp  Unroll, please.",1,0,0
519,2023-02-13 13:54:48+00:00,ylecun,"@ylecun I beg to differ

I do believe that providing an LLM with a piece of code, and asking for tweaks, enters the realms of non finite spaces,

and it hints to some meta state conceptualisation or understanding of the task at hand.

A new ToM emergent ability? https://t.co/juSgdG9d7h",1,1,0
520,2023-02-13 13:54:12+00:00,ylecun,"@ylecun It my tests, it also ""made-up"" most coding answers -- expressing them confidently -- extremely problematic.",0,0,0
521,2023-02-13 13:51:31+00:00,ylecun,@ylecun Interesting take!,0,2,0
522,2023-02-13 13:50:09+00:00,ylecun,"@ylecun Does the current LLM model only have memory ability, but no reasoning ability?",0,0,0
523,2023-02-13 13:49:21+00:00,ylecun,"@ylecun @implisci This makes sense, and is documented in SE literature: https://t.co/VRVybaY3U6",0,0,1
524,2023-02-13 13:49:07+00:00,ylecun,@ylecun Noobs will say ‚Äòstochastic‚Äô gradient descent solves this.,1,0,0
525,2023-02-13 13:48:51+00:00,ylecun,"@ylecun Do you have thoughts on a multi-task system that could help (student) engineers design electrical circuits (or something else graphical, like optical systems)?

I guess digital systems would be a first, since they are limited, discrete, deterministic and fully observable.",4,3,0
526,2023-02-13 13:48:47+00:00,ylecun,"@ylecun Ok, ok, I guess your followers got it. You write about it every single day.",0,0,0
527,2023-02-13 13:47:54+00:00,ylecun,@ylecun Are you basing this on a single LLM? Are you also taking into account LLMs as a puzzle piece? i.e. the ability to partially or fully address these concerns by using different LLMs chained in a hierarchy? (potentially with some deterministic rulesets for control),0,0,0
528,2023-02-13 13:47:32+00:00,ylecun,"@ylecun right, but I think you should open your mind to context enriched AR-LLMs. 

Their ability to structure an answer becomes very valuable when injecting relevant data. And that's where AI powered search engines shine!

I agree that it doesn't fully solve hallucination though...",0,0,0
529,2023-02-13 13:46:50+00:00,ylecun,"@ylecun @LevitateKyle So if ima student 
Can I use this ‚Äúmachine‚Äù to help me get thru the exam?",0,0,0
530,2023-02-13 13:43:45+00:00,ylecun,@ylecun Do you have any thoughts on new Bing Yann?,0,0,0
531,2023-02-13 13:43:02+00:00,ylecun,@ylecun Do you have anything to share here that hints towards Barlow twin like models showingg proof of concept towards cat level intelligence?,0,0,0
532,2023-02-13 13:42:34+00:00,ylecun,@ylecun I appreciate your realistic and pragmatic views. They help me avoid getting distracted by wildly imaginative opinions that are often misleading.,0,0,0
533,2023-02-13 13:42:08+00:00,ylecun,"@ylecun ""3. They make stuff up or retrieve stuff approximately.
""

Thank you. People have failed to notice or admit this obvious aspect of ChatGPT, possibly because of an apparent marketing campaign (lots of hype, little evidence).",1,0,0
534,2023-02-13 13:41:57+00:00,ylecun,"@ylecun just a random question,

 while using LLM as a writing aid, what would be the impact on humans through the process as they going to be more dependent on these tools, 
 what would be the future of creativity in literature?",0,0,0
535,2023-02-13 13:41:06+00:00,ylecun,"@ylecun @rahulyedida13 They are actually quite good at this based on ""manual"" observations. We are using davinci-003 to extract address, phone nums and ""needs"" (doctor, food etc.) from the tweets about the recent earthquake in Turkey and it works well.",2,6,1
536,2023-02-13 13:41:00+00:00,ylecun,"13. Why do LLMs appear much better at generating code than generating general text?
Because, unlike the real world, the universe that a program manipulates (the state of the variables) is limited, discrete, deterministic, and fully observable.
The real world is none of that.",18,610,80
537,2023-02-13 13:39:45+00:00,ylecun,@ylecun Can you say anything about progress down the JEPA path?,0,0,0
538,2023-02-13 13:39:16+00:00,ylecun,@ylecun Wait ‚Ä¶ when did google become the barometer of truthful information ‚Ä¶ also do people not remember the same argument against Wikipedia in early 2000s?,0,0,0
539,2023-02-13 13:38:30+00:00,ylecun,"@ylecun Given that chain-of-thought prompting gives better results, could a stepwise refining strategy or self-discussion strategy improve the usefulness?",0,0,0
540,2023-02-13 13:38:23+00:00,ylecun,@ylecun looks like you are jealous as models such as ChatGPT not coming from your group.,0,2,0
541,2023-02-13 13:38:19+00:00,ylecun,@ylecun @Sokiosque Writer as editor and fact checker?,1,1,0
542,2023-02-13 13:35:47+00:00,ylecun,@ylecun @RemindMe_OfThis in 5 years,1,0,0
543,2023-02-13 13:35:45+00:00,ylecun,@ylecun They simply need a better understanding of what they do and do not know. It's an epistemological problem...I don't think a significantly improved architecture will have to differ too much from the current autoregressive setup.,0,7,0
544,2023-02-13 13:32:32+00:00,ylecun,@ylecun there was only so much Arsene Wenger could achieve!,0,0,0
545,2023-02-13 13:31:42+00:00,ylecun,"@ylecun Professor, while I broadly agree, don't you think the wealth of data used to train these models make them good IR tools?",1,1,0
546,2023-02-13 13:27:15+00:00,ylecun,"@ylecun ""they will be based"" &lt; nice",0,1,0
547,2023-02-13 13:23:29+00:00,ylecun,"12. Being clear that better system will be appearing, but they will be based on different principles. 
They will not be auto-regressive LLMs.",6,226,21
548,2023-02-13 13:22:48+00:00,ylecun,@ylecun How could a writing aid be useful if it makes stuff up?,11,4,0
549,2023-02-13 13:21:41+00:00,ylecun,"I have been consistent while:
9. defending Galactica as a scientific writing aid.
10. Warning folks that AR-LLMs make stuff up and should not be used to get factual advice.
11. Warning that only a small superficial portion of human knowledge can ever be captured by LLMs.",7,304,30
550,2023-02-13 13:21:30+00:00,ylecun,@ylecun wow! we did not know that improvement is possible. Thanks for the ground breaking insight.,0,0,0
551,2023-02-13 13:20:30+00:00,ylecun,@ylecun @SaveToNotion #thread,1,0,0
552,2023-02-13 13:18:15+00:00,ylecun,@ylecun Thanks for this.,0,0,0
553,2023-02-13 13:16:48+00:00,ylecun,@ylecun Is human thinking auto-regressive in your opinion?,0,0,0
554,2023-02-13 13:11:16+00:00,ylecun,"@ylecun ChatGPT has been playing chess and cheating by moving pieces where they cant go, but usually moving by the rules. Maybe it could use instructions like, dont let blacks left rook be taken even if you have to sacrifice all the other pieces, and see if it can plan for that.",1,0,0
555,2023-02-13 13:10:44+00:00,ylecun,"@ylecun I am no expert, but if designers cannot control even simple LLMs, what makes the believe they will be able to control AGI?",2,2,0
556,2023-02-13 13:09:22+00:00,ylecun,@ylecun What do you think those systems will be?,0,0,0
557,2023-02-13 13:08:44+00:00,ylecun,"@ylecun Would you agree with this framework? 

https://t.co/F2997QIYX6",1,4,0
558,2023-02-13 13:07:54+00:00,ylecun,@ylecun Why do they do relatively well on some tasks? Code generation? Summarization? And why do they have serious issues in other areas? Thank you.,2,8,0
559,2023-02-13 13:07:36+00:00,ylecun,@ylecun They have to be augmented  with factual systems like toolformer is doing to make them better. Same also what Wolfram is proposing IMO,0,3,0
560,2023-02-13 13:06:20+00:00,ylecun,"@ylecun The ""autonomous"" part lives in number 2, and I don't know why we don't see more acknowledgment of that massive shortcoming from LLM proponents",0,0,0
561,2023-02-13 13:05:30+00:00,ylecun,"@ylecun new conspiracy just dropped, AI causes AIDS",0,0,0
562,2023-02-13 13:05:24+00:00,ylecun,"6. Current LLMs should be used as writing aids, not much more.
7. Marrying them with tools such as search engines is highly non trivial.
8. There *will* be better systems that are factual, non toxic, and controllable. They just won't be auto-regressive LLMs.",14,475,45
563,2023-02-13 12:37:24+00:00,ylecun,@ylecun ‚ÄúLLM‚Äù for Large Langage Model or Logic Learning Machine ü§î (for novices like me),0,0,0
564,2023-02-13 12:31:00+00:00,ylecun,"@ylecun ""as they exist today""",1,0,0
565,2023-02-13 12:26:42+00:00,ylecun,@ylecun Copium,0,0,0
566,2023-02-13 12:19:12+00:00,ylecun,"@ylecun It is a good teacher, not a substitute for human creativity. Instead, it enhances our creative abilities",0,0,0
567,2023-02-13 11:26:25+00:00,ylecun,@ylecun This is amazing. Any chance of this happening with music scores? Just curious.,0,0,0
568,2023-02-13 11:13:08+00:00,ylecun,"@ylecun Careful with ""never""",0,0,0
569,2023-02-13 11:04:45+00:00,ylecun,"@ylecun I completely agree.
If you have accurate and verified information, utilizing LLMs to create a well-crafted composition is certainly logical. https://t.co/wo9rPT4DLz",0,0,0
570,2023-02-13 11:02:06+00:00,ylecun,@ylecun https://t.co/TAdEC3c2yg,1,0,0
571,2023-02-13 10:31:44+00:00,ylecun,"@ylecun I think  LLMs will therefore have an immediate impact on (strategy) consulting. They are not making up stuff, they are creative and think outside of the box :D",0,0,0
572,2023-02-13 10:12:20+00:00,ylecun,"@ylecun I agree, LLMs aren't a replacement for search engines. But Google as it is can't reasonably compete with search engine-infused LLMs.
The question is how soon can Microsoft deliver compared to Google",0,0,0
573,2023-02-13 10:10:29+00:00,ylecun,"@ylecun HLAI &gt;&gt;&gt; LLM

Though, no comparison!",0,1,0
574,2023-02-13 10:05:29+00:00,ylecun,@ylecun We are kind of abusing the power of LLMs right now.,0,0,0
575,2023-02-13 09:48:22+00:00,ylecun,"@ylecun and if i add to the prompt ""do not make stuff up"", ""stick to the facts""  or a better suited prompt for that matter ? how did you address this kind of issues?",0,0,0
576,2023-02-13 09:44:03+00:00,ylecun,"@ylecun You are right if you refer to the present, but you are underestimating two forces. 1) What people want is changing, truth to accessibility, Britannica to Wikipedia. 2) LLMs with 33k examples improved a lot in reliability. What will happen with 1 billion example?",0,2,0
577,2023-02-13 09:11:43+00:00,ylecun,"@ylecun LLMS do make stuff up, but what if that's a solvable problem? And a search engine would return not only all the references, but a nice summary too?",0,0,0
578,2023-02-13 09:01:17+00:00,ylecun,"@ylecun LLM will not replace search. LLM connected to search will replace search. $GOOG search market share has nowhere else to go but down. It could keep its share, but most likely will lose some. Each 1% share lost is about $2B",0,0,0
579,2023-02-13 08:57:01+00:00,ylecun,@ylecun someone jelly,0,0,0
580,2023-02-13 08:38:30+00:00,ylecun,@ylecun @MetaAI Humans don't just use tools. They create tools. https://t.co/XBdRgZnsQM,0,0,0
581,2023-02-13 08:37:47+00:00,ylecun,@ylecun Lol ‚Äòmy‚Äô,0,0,0
582,2023-02-13 08:21:04+00:00,ylecun,@ylecun Funny how people obsess about putting things in boxes.,0,1,0
583,2023-02-13 08:11:53+00:00,ylecun,"@ylecun Yann, the human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, principles formulated, and related equations written by yours truly.",0,1,0
584,2023-02-13 08:06:58+00:00,ylecun,@ylecun But doesn‚Äôt Google Search also index websites with made-up stuff too? What‚Äôs the difference?,0,0,0
585,2023-02-13 08:05:10+00:00,ylecun,@ylecun so they should add a small statement at the end of the page not to trust them. but the fix for making stuff up is easy in my opinion,0,0,0
586,2023-02-13 07:46:10+00:00,ylecun,"@ylecun Yes, the one thing.. lol, are you sure Chief Ai scientist?",0,1,0
587,2023-02-13 07:45:34+00:00,ylecun,"@ylecun No shit, there's something after ChatGPT? I thought everybody will stop developing NOW and just use it into eternity as it is. So fuckin smart these guys @Forbes just unbelievable",0,0,0
588,2023-02-13 07:28:43+00:00,ylecun,@ylecun Not plan but glue...,0,0,0
589,2023-02-13 07:15:18+00:00,ylecun,"@ylecun Sir, how do you think Ted Chiang‚Äôs article on New Yorker: https://t.co/CFEES1pmCj ?",0,0,0
590,2023-02-13 06:57:26+00:00,ylecun,"@ylecun They make up some stuff, so do humans",0,0,0
591,2023-02-13 06:55:52+00:00,ylecun,"@ylecun LLMs are great but should be used carefully. It generates highly plausible fake references. Yesterday, I tested them to list shortcomings of out of distribution detection methods and asked them to list some references too. It listed down papers written by people who do not exist.",0,4,1
592,2023-02-13 06:41:59+00:00,ylecun,@ylecun This is the same as saying when the transistor was discovered that in its current state it is not going to replace the vacuum tubes.,0,0,0
593,2023-02-13 06:33:24+00:00,ylecun,"@ylecun Not true, autoregressive LLMs like GPT-3 can do way more than just writing assistance! They're incredible at so many things including sentiment analysis. Plus, you can fine-tune 'em for specific needs. These models are seriously versatile.",1,3,0
594,2023-02-13 06:26:25+00:00,ylecun,"@ylecun All the current LLMs r reaching training data exhaustion but how can ""unreal"" data generation will help in training them? How would the correctness of that data be tested? It says most advanced LLMs r already sparse, so how can they be improved using this technique?",0,0,0
595,2023-02-13 06:01:21+00:00,ylecun,"@ylecun I can confirm ChatGPT sometimes generates ungrammatical sentences in Chinese, although it is very rare.",0,0,0
596,2023-02-13 05:57:17+00:00,ylecun,"@ylecun And yet, Bing+chatbot seems much better than Google search in complex queries, preliminary tests.",0,0,0
597,2023-02-13 05:51:52+00:00,ylecun,"@ylecun I found @Nature article on ""What ChatGPT and generative AI mean for science"" interesting ü§î.

https://t.co/PyJ3GLLNNP",0,7,1
598,2023-02-13 05:43:55+00:00,ylecun,"@ylecun LLMs have two failure modes
- hallucination, when they are not following the training set exactly
- regurgitation - when they are following the training set exactly
Too bad they are so limited",1,2,1
599,2023-02-13 05:36:06+00:00,ylecun,@ylecun ChatGPT is amazingly good. Still have to be careful since some improvements can easily change semantics. It is not a hypothetical statement: I actually tried to apply it to the abstract and I did observe some rare but non-trivial semantic drift.,0,2,0
600,2023-02-13 05:34:08+00:00,ylecun,"@ylecun The ""Media"" you've linked to is a Forbes Contributor piece whose opinions are not backed by the source ü§£ 

Instead of digging this hole any deeper, maybe consider that commercial success here is a sign of market demand instead of bemoaning the way people are using said tech ?",0,4,0
601,2023-02-13 05:04:47+00:00,ylecun,@ylecun Assuming Google provide good and accurate results. Which it does not since many years.,0,0,0
602,2023-02-13 05:02:36+00:00,ylecun,@ylecun One of the best readable articles on the state of LLM and AI.,0,1,0
603,2023-02-13 05:02:18+00:00,ylecun,@ylecun ON MOBILE DATA,0,1,0
604,2023-02-13 04:44:55+00:00,ylecun,@ylecun What is required to reduce halocination in llm s,0,0,0
605,2023-02-13 04:41:50+00:00,ylecun,"@ylecun Learning from teaching only works when  learner ‚Äúalmost already knows‚Äù  subject.

To learn apparently simple tasks,deep RL agents take millions of time steps.

This is a ‚Äúdead end‚Äù computational model of how humans learn.",0,0,0
606,2023-02-13 04:24:16+00:00,ylecun,@ylecun Spoiler: article written by @GaryMarcus,0,0,0
607,2023-02-13 04:20:45+00:00,ylecun,"@ylecun Why isn't there some sort of dualing LLM generative adversarial network setup each with reinforcement learning to make LLMs compete for accuracy, usefulness, and truthfulness with users on the internet awarding the points? Actually that's probably built into ChatGPT already.",0,6,1
608,2023-02-13 04:16:42+00:00,ylecun,"@ylecun True, I use ChatGPT to translate my text into english (from my native language) with this: ""rewrite this text as it was written by native english-speaking Top AI researcher"". Results are great for AI articles :)",0,1,0
609,2023-02-13 04:15:35+00:00,ylecun,@ylecun The sentence you quote does not even make logical sense. As if LLMs are not under constant development. Very surprised you don't seem to be aware of this: https://t.co/LQK7K7k50c,0,2,0
610,2023-02-13 04:02:04+00:00,ylecun,"@ylecun Ultra -sophisticated and obedient digital tutors should corroborate with an expert. 
 
As an interactive process ,use it to get feedback 

A.I. writing assistants with coherency are potential differentiators.

Machines writing is a short circuit, not a short cut.",0,0,0
611,2023-02-13 03:30:09+00:00,ylecun,"@ylecun ""As they exist now"". 

It's not hard, though not trivial, to create a factually reliable LLM that rivals a Search Engines accuracy by having it cross check against verified sources at generation time, and it will probably happen this year.",1,4,0
612,2023-02-13 03:22:07+00:00,ylecun,"@ylecun Do you just completely misunderstand how things like BingAI work? It is a retrieval-based system, the LLM is mostly used for data extraction, summarization, and formatting. Literally nobody is saying an LLM by itself replaces search.",2,18,2
613,2023-02-13 03:21:06+00:00,ylecun,@ylecun So does Google,0,0,0
614,2023-02-13 02:45:04+00:00,ylecun,@ylecun They will replace Google search and fast bc they can refine search and bypass the ads.,1,0,0
615,2023-02-13 02:44:30+00:00,ylecun,@ylecun We already know how to make things that plan and things that classify. The job of LLMs is to be a conceptual bridge between the plan and its explanation into and out of a rational human context.,0,1,0
616,2023-02-13 02:38:29+00:00,ylecun,@ylecun You have hedged quite a bit. Does stuff like RETRO which does retrieval fall in the same category?,1,0,0
617,2023-02-13 02:16:24+00:00,ylecun,"@ylecun Search makes stuff up too. It‚Äôs not about replacing search, it‚Äôs about augmenting search. ChatGPT is answering a large % of searches for me.",1,4,0
618,2023-02-13 02:07:40+00:00,ylecun,@ylecun But according to Microsoft the made up stuff is worthy of a $10b investment. Just imagine how much more worth the people who don‚Äôt make up stuff that they let go are worth,0,1,0
619,2023-02-13 02:03:39+00:00,ylecun,"@ylecun @YiWan89352121 The most amazing example of this is asking them to write an academic paper on a topic, which they will dutifully do, fabricating sources along the way.",3,10,0
620,2023-02-13 01:39:16+00:00,ylecun,@ylecun Grammarly would be in danger.,0,0,0
621,2023-02-13 01:36:33+00:00,ylecun,"@ylecun Chatgpt is good, it generates results like our human beings. it‚Äôs use key points and probabilities achieve that by knowledge which is so similar to me when i make reasoning",1,0,0
622,2023-02-13 01:35:42+00:00,ylecun,"@ylecun oh man, just move on already...",0,0,0
623,2023-02-13 01:35:39+00:00,ylecun,"@ylecun They don't just make stuff up, they make stuff up that can be extremely believable. 

I asked it to write some code to do a difficult task, it created code that looked extremely compelling until I realised half the methods it was calling on a library were fictitious.",2,10,1
624,2023-02-13 01:15:18+00:00,ylecun,@ylecun But it will reduce sharply people who need google,0,1,0
625,2023-02-13 00:54:57+00:00,ylecun,"@ylecun LLMs shouldn‚Äôt be treated as repositories of knowledge. The key is to use them for what they‚Äôre good at, and combine them with other tech when needed to accomplish your goal.

Here‚Äôs how I like to think about what they actually do:

https://t.co/f1jxvJG1Dc",1,4,1
626,2023-02-13 00:43:26+00:00,ylecun,"@ylecun So far, ChatGPT results seem to be about as accurate and the avergage Google search result. But that would be a great measurement, if someone could compare the accuracy.",0,0,0
627,2023-02-13 00:33:09+00:00,ylecun,"@ylecun Unless my fleshy monkey brain can't understand the problem, it doesn't look like LLMs struggle with that planning task as much as you think they do.

https://t.co/7KXR7C8mfd",1,0,0
628,2023-02-13 00:24:36+00:00,ylecun,"@ylecun BingGPT searches and summarizes with references to sources, it is so good it hard to believe it is real. Here latest LTT video (timestamped), unless it is scripted (video), there are not many use cases left where google search will be more effective.

https://t.co/uXvnHYo3ML",0,1,0
629,2023-02-13 00:23:03+00:00,ylecun,@ylecun Wait till you hear about how much stuff on Google is completely made up.,2,3,0
630,2023-02-13 00:20:29+00:00,ylecun,"@ylecun ""the one thing"" üôÑ

Seriously? Are auto-regressive LLMS not even half decent at anything else?",0,0,0
631,2023-02-13 00:10:16+00:00,ylecun,@ylecun Yes that could be very bad in some situations. Imagine it makes up some codes. Makes debugging much harder.,0,0,0
632,2023-02-13 00:07:47+00:00,ylecun,@ylecun Not if the search is supplemented with the source.,0,0,0
633,2023-02-13 00:00:47+00:00,ylecun,@ylecun What is wrong with RL? Humans learn a lot via rewards (or punishment) especially when they are young.,0,0,0
634,2023-02-12 23:52:27+00:00,ylecun,@ylecun You think the media agreeing with you supports your case?  Interesting.,1,1,0
635,2023-02-12 23:51:09+00:00,ylecun,"@ylecun Yup, it‚Äôs a great sentence-level thesaurus.",0,10,0
636,2023-02-12 23:42:37+00:00,ylecun,"@ylecun When Meta's head of AI says that the LLM hallucination problem that many of us solved in our home office one weekend in between vacuuming the living room and making a quiche is impossible to solve...

... Let's just say this is making me shorter than @michaeljburry",0,0,0
637,2023-02-12 23:38:59+00:00,ylecun,"@ylecun Don‚Äôt say that so fast ; given  huge data, deep learning has so far surprised people and defied their expectations in many ways !",0,0,0
638,2023-02-12 23:37:51+00:00,ylecun,"@ylecun Obviously, common man takes time to see your (scientist's) point of view...",0,0,0
639,2023-02-12 23:36:23+00:00,ylecun,@ylecun So do humans who create the content we search for,0,0,0
640,2023-02-12 23:34:52+00:00,ylecun,@ylecun There is a lot of made up stuff on Google search also.,0,1,0
641,2023-02-12 23:28:09+00:00,ylecun,@ylecun Key things to realize: 1) Google search results too have plenty of made-up stuff; 2) Bing's new chat will have references.,0,1,0
642,2023-02-12 23:26:15+00:00,ylecun,"@ylecun ...""Two related capabilities lie at the heart of current efforts to make language models more accurate: (1) the ability for LLMs to retrieve information from external sources, and (2) the ability for LLMs to provide references and citations for the information they provide.""",0,2,0
643,2023-02-12 23:25:46+00:00,ylecun,"@ylecun On the contrary, the article is very optimistic about the future reliability of information: ""a set of promising innovations offers to at least mitigate LLMs‚Äô factual unreliability...""",1,3,0
644,2023-02-12 23:24:51+00:00,ylecun,"@ylecun everything is made up of something. people believe what is most convincing. language is just communication, and the large Google Search communication model is pass√©. if i'm unsure of something, i ask chatgpt for a wikipedia link",0,0,0
645,2023-02-12 23:14:42+00:00,ylecun,"@ylecun Do you understand why Bill Gates is hyping them up, then? As you know he is a visionary and has been right on many things, including -recently- the pandemic.",0,1,0
646,2023-02-12 23:00:29+00:00,ylecun,"@ylecun A long time ago Chomsky predicted that statistical AI would basically fit the entire universe of data (true and false), without being able to distinguish between the two.",0,2,0
647,2023-02-12 22:57:57+00:00,ylecun,"@ylecun Are you sure this isn't just attacking a straw man? Does anyone dispute that ChatGPT &amp; friends ""make stuff up""? Is anyone even claiming that a merely scaled up ChatGPT will somehow resolve the problem of making stuff up, or distinguishing fact from fiction?",1,3,0
648,2023-02-12 22:57:35+00:00,ylecun,"@ylecun For simplicity, let‚Äôs take the simplest case. It seems to me that your interpretation of the problem is: there is a known world model and a known goal, so the engineer builds a programs to achieve the goal utilizing the world model. That isn‚Äôt the case for a general reasoner...",1,0,0
649,2023-02-12 22:53:13+00:00,ylecun,@ylecun It doesn't need to replace search. It just needs to meaningfully augment it.,0,3,0
650,2023-02-12 22:52:53+00:00,ylecun,@ylecun When meta is releasing any LLM for public?,0,0,0
651,2023-02-12 22:52:27+00:00,ylecun,"@ylecun The cost of verifying a potentially confabulated answer is less than the cost of wading through the SEO-hacked slop of Google search results, which are nothing but spam.

ChatGPT + specialist search engines (scholar, wiki, pubmed) already replace Google for most of my queries.",7,44,1
652,2023-02-12 22:49:16+00:00,ylecun,"@ylecun Agreed! A fair comparison would be with current search results, which are overwhelmed by SEO-driven content",0,0,0
653,2023-02-12 22:46:54+00:00,ylecun,"@ylecun Yann, is what Microsoft is doing with Prometheus layer interesting at all or is that pretty much minimum viable piece you would need to integrate some sort of LLM and search?",0,0,0
654,2023-02-12 22:46:02+00:00,ylecun,@ylecun But they already have for a lot of people.,0,0,0
655,2023-02-12 22:45:14+00:00,ylecun,@ylecun I'm using Bing AI now and it definitely replaces Google Search for me.,1,9,0
656,2023-02-12 22:40:58+00:00,ylecun,"@ylecun It is not an on-and-off switch. It's layered. You put it out there and use the info to move forward, fine-tune stuff for added granularity/accuracy on specific topics, figure out what people use it for etc. Bing has the right approach of course. There a countless use cases...",0,6,0
657,2023-02-12 22:39:22+00:00,ylecun,"@ylecun If you think LLMs will  remain ""as they exist today"" for any length of time to ""never replace Google"" then you're mistaken. Have you heard of metaphor? LLM generated links from text, beats google by a WIDE margin for certain complex questions, and its free https://t.co/CzvIUt9MKD",0,0,0
658,2023-02-12 22:37:26+00:00,ylecun,@ylecun Who cares if the users are satisfied,0,0,0
659,2023-02-12 22:36:38+00:00,ylecun,@ylecun Isn't the whole point Extractive QA use existing data as output? I think Prometheus works like this!,0,0,0
660,2023-02-12 22:35:55+00:00,ylecun,"@ylecun Is it just me or do others not find it intelligent to ‚Äúmake stuff up‚Äù?  Or, are we going to be told that is orthogonal to intelligence?",2,1,0
661,2023-02-12 22:33:28+00:00,ylecun,"@ylecun LLMs making stuff up and Google obfuscating/censoring results, what a time to be alive!",0,1,0
662,2023-02-12 22:29:15+00:00,ylecun,"@ylecun Then, ToolFormer is useless.",0,0,0
663,2023-02-12 22:21:12+00:00,ylecun,"@ylecun auto-regressive factorization is possible for any joint distribution.  Given that, why do you consider the auto-regressive aspect a weakness for a LLM?  Is it due to learning dynamics, or something else?",0,0,0
664,2023-02-12 22:11:07+00:00,ylecun,"@ylecun Not only that, it‚Äôs great how you can ask chat GPT to come up with multiple versions, compare them and tell you which one is best and why. It makes it a wonderful teaching/learning tool, as long as you can get second opinions from a human perspective.",0,1,1
665,2023-02-12 22:03:12+00:00,ylecun,@ylecun RL has proven to be a rather wonderful neural heuristic that can be applied to LLMs with amazing results!,0,0,0
666,2023-02-12 22:00:02+00:00,ylecun,"@Abel_TorresM If you want the system to start from scratch and learn the world model while attempting to solve the problem, then you are in RL-land.
But if you can learn the model in other ways, e.g. by observing other agents, then no need for RL.",1,2,0
667,2023-02-12 21:58:14+00:00,ylecun,"@ylecun Hi @ylecun, what if we had 1-2 order of magnitude more data to feed these models? Could ""planning"" emerge semi-randomly? Or do you think there's really no chance of that happening",1,1,0
668,2023-02-12 21:57:26+00:00,ylecun,"@ylecun I agree. And about feeling sad about it, I also experienced it. Writing is a good training to articulate thoughts. There's still meaning in the process of writing.

I wrote a piece that contrasted the characters of Sirius Black and Dolores Umbridge in Harry Potter.",1,2,0
669,2023-02-12 21:51:51+00:00,ylecun,@ylecun It's too bad you're being vilified for your position. In time the industry will eventually realize LLM's are (very powerful) auto-complete models. On a positive note it seems to be waking folks up to the power of ML. In 5 years it truly will be indistinguishable from magic.,1,3,0
670,2023-02-12 21:40:03+00:00,ylecun,@ylecun https://t.co/PF5zFG062j,0,0,0
671,2023-02-12 21:39:25+00:00,ylecun,@ylecun Agree completely..,1,3,0
672,2023-02-12 21:18:09+00:00,ylecun,@ylecun @alrhemist @MetaAI @OpenAI In this application we are past paper time. It's product time now,0,0,0
673,2023-02-12 20:44:00+00:00,ylecun,"@ylecun @DavidSHolz dude, RL is a huge part of why OpenAI is winning.  You're kind of an embarrassment.",2,0,0
674,2023-02-12 20:35:13+00:00,ylecun,@ylecun Hihi ! https://t.co/HtvCiuQu0T,0,0,0
675,2023-02-12 20:31:23+00:00,ylecun,"@ylecun Are you saying that with optimal control you can code an agent in a deterministic environment to reach a desired goal in arbitrary size maze, picking up keys to open doors and solving Sokoban-like challenges? If that exist, you‚Äôll be absolutely right hands down https://t.co/RNk0n0lEtH",1,1,0
676,2023-02-12 18:56:51+00:00,ylecun,"@ylecun @Abel_TorresM Do you distinguish between ""Approximate Dynamic Programming"" and RL?  There are many applications where approximate DP (RL?) is useful even if you have (1) and (2). AlphaGo, OpenAi Five, AlphaStar, Deepstack etc.",0,0,0
677,2023-02-12 18:50:59+00:00,ylecun,"@ylecun @DavidSHolz I think when it comes to things like Teslabot and complex terrain navigation RL is ideal because it‚Äôs similar to how a toddler learns locomotion and simulated physics is obviously not a perfect replacement for real physics. But, for most purposes where data is reliable RL sucks.",0,0,0
678,2023-02-12 18:47:00+00:00,ylecun,@ylecun Hahahaha! üíï,0,0,0
679,2023-02-12 18:44:48+00:00,ylecun,"@ylecun Totally missing the point of RL, you learn and act simultaneously. Adaptivity can also be parametrized and optimized.",0,0,0
680,2023-02-12 18:22:22+00:00,ylecun,"@ylecun I just mistook ‚ÄòRL‚Äô reinforcement learning for ‚ÄòRL‚Äô real life.

I am definitely fatigued.",1,0,0
681,2023-02-12 17:55:36+00:00,ylecun,"@ylecun Still, it is the main paradigm when dealing with planning, alternatives? (I have mine but I am not in a big lab)",1,0,0
682,2023-02-12 17:46:46+00:00,ylecun,"@ylecun Thomas Edison needed 1000 trials. Explain that!

PS: I'm a fan on RL in a particular limited settings: namely meta-learning meta-agents
https://t.co/rZGYA9ecnN",1,0,0
683,2023-02-12 17:44:48+00:00,ylecun,@ylecun Why do you never talk about vr ? Have u ever used vr ?,1,0,0
684,2023-02-12 17:37:21+00:00,ylecun,@ylecun What else do you expect from OpenAI,0,0,0
685,2023-02-12 17:37:20+00:00,ylecun,@ylecun How are you feeling about RL nowadays?,1,0,0
686,2023-02-12 17:20:32+00:00,ylecun,@ylecun The re-capturing moves that ChatGPT got correct are the ones frequently played in the main line chess games.,0,0,0
687,2023-02-12 17:08:19+00:00,ylecun,@ylecun @benedictevans Idagio is great - very well curated and lossless streaming too!,0,0,0
688,2023-02-12 16:42:21+00:00,ylecun,@ylecun Woo hoo... weekend fun... please continue to share... I appreciate your thoughts...,0,0,0
689,2023-02-12 16:18:30+00:00,ylecun,"@ylecun If Earl Sacerdoti were alive, he would supplant Schmidhuber as now claimant to the 'Father of LLMs' (and therefore deep learning) then - https://t.co/vZnwabcXBl",0,0,0
690,2023-02-12 15:46:22+00:00,ylecun,"@ylecun @benedictevans Professor LeCun, I like this application very much. Unfortunately, this software cannot play songs from China.",0,0,0
691,2023-02-12 15:08:00+00:00,ylecun,"@ylecun Bwhahaahh! generative AI!  Like when professor hulk sez ""time travel!""",0,0,0
692,2023-02-12 15:02:27+00:00,ylecun,"@ylecun Research is cool and all but let‚Äôs not discount the ability to ground research into a product. 

OpenAI‚Äôs pragmatism should be applauded here.",0,0,0
693,2023-02-12 14:54:38+00:00,ylecun,"@ylecun Maybe THIS is the way! ChatGPT has discovered something humans missed all along! ü§∑üèª‚Äç‚ôÄÔ∏è 
AGI is finally here. üéâüò±",0,0,0
694,2023-02-12 14:25:05+00:00,ylecun,@ylecun Text is the universal interface,0,2,0
695,2023-02-12 13:40:42+00:00,ylecun,"@ylecun Yeah...
https://t.co/J0aNOAtdFK",0,0,0
696,2023-02-12 12:37:13+00:00,ylecun,@ylecun When can we try it?,0,2,0
697,2023-02-12 12:30:59+00:00,ylecun,@ylecun @benedictevans Thanks...,0,0,0
698,2023-02-12 12:21:51+00:00,ylecun,@ylecun No it isn‚Äôt.,1,0,0
699,2023-02-12 12:09:43+00:00,ylecun,"@ylecun You don't see any planning with ChatGPT ?
https://t.co/t9W1F1ybJM",2,1,0
700,2023-02-12 11:25:31+00:00,ylecun,@ylecun It rules xD,0,0,0
701,2023-02-12 11:17:01+00:00,ylecun,@ylecun @paulg @peterboghossian Graham's ?,0,0,0
702,2023-02-12 10:52:16+00:00,ylecun,@ylecun How do you teach LLMs to plan? Can large enough LLMs learn to construct implicit environment models?,0,0,0
703,2023-02-12 10:45:17+00:00,ylecun,"@ylecun Chatgpt is much better in education, behaving in lieu of students or in trolling farm activity with ad hoc answers and fakes or even in cyber war.",0,0,0
704,2023-02-12 10:38:27+00:00,ylecun,@ylecun It had a trick or two up its sleeve.,0,1,0
705,2023-02-12 10:33:18+00:00,ylecun,"@ylecun Can't fault the creativity of the moves here,

reminiscent of the tic tac toe robot that comes up with new squares to win the game",0,1,0
706,2023-02-12 10:30:14+00:00,ylecun,@ylecun Ptdr‚Ä¶ üòÜ,0,0,0
707,2023-02-12 10:27:29+00:00,ylecun,@ylecun Sometimes Yann says sensible things about language models not being sufficient to model  high level cognition. Then he says a generative model squeaking away is no different to Beethoven writing a symphony. ü§¶üèª,1,0,0
708,2023-02-12 10:26:10+00:00,ylecun,"@ylecun La critique est facile, l'art est difficile. On attend votre r√©volution made in Meta.",0,2,0
709,2023-02-12 08:12:55+00:00,ylecun,"@ylecun @MetaAI Source code, or it doesn't exist üòú",0,0,0
710,2023-02-12 07:43:41+00:00,ylecun,"@ylecun @MetaAI Amazing, respect.",0,0,0
711,2023-02-12 07:13:08+00:00,ylecun,@ylecun @MetaAI @memdotai mem it!,1,0,0
712,2023-02-12 07:07:19+00:00,ylecun,"@ylecun @MetaAI Was done before by AI21:

https://t.co/BxJHimFQUg",2,16,0
713,2023-02-12 06:05:17+00:00,ylecun,"@ylecun I share the same aspiration to work in AI research, with respect. The issue is that I don't have a well-equipped lab for conducting AI research.
üòë",0,1,0
714,2023-02-12 05:47:14+00:00,ylecun,@ylecun @MetaAI Technically you can't use calculators if you don't have fingers,2,2,0
715,2023-02-12 05:19:19+00:00,ylecun,@ylecun @MetaAI .,0,0,0
716,2023-02-12 03:46:05+00:00,ylecun,@ylecun @pcollellmir @lexfridman @ilyasut Made me wonder if anyone has tried self-supervision by predicting the textual representation of the next few frames of a video.  Since we know that self-supervision works on language models but hard to apply on videos.,0,0,0
717,2023-02-12 03:22:54+00:00,ylecun,"@ylecun Yeap, agree with all your points here. Personally, I get these questions about AI and creativity all the time.  People telling me AI has no emotions and hence it's not creative, which I disagree. There will be a point where AI would create highly emotional music.",0,0,0
718,2023-02-12 00:28:43+00:00,ylecun,"@ylecun @MetaAI I la Pompeu Fabra tamb√©, Yan. Pobrets, ning√∫ els fa cas",0,0,0
719,2023-02-12 00:27:59+00:00,ylecun,"@ylecun Yann is more gracious in video than by tweeting 
Suggest to make tweets recording videos rather than writing üòÄ",0,2,0
720,2023-02-12 00:05:24+00:00,ylecun,@ylecun @MetaAI When do we get to try it?,0,0,0
721,2023-02-11 23:34:03+00:00,ylecun,@ylecun @MetaAI I dare you to publish it like ChatGPT,0,1,0
722,2023-02-11 22:18:52+00:00,ylecun,"@ylecun Grand merci pour avoir pris le temps de me r√©pondre, je vais donc me plonger dans votre cours",0,0,0
723,2023-02-11 21:33:53+00:00,ylecun,"@ylecun @MetaAI Congratulations to the team, this model is amazing, it will be possible to adjust it for an e2e test.
Sem c√≥digo n√£o tem like   kkk‚ù§Ô∏è",0,0,0
724,2023-02-11 21:26:00+00:00,ylecun,"@ylecun @MetaAI Dare I suggest, as many others have for ChatGPT, integration with the Wolfram Language? The benefit in terms of fact-finding and computational abilities should be significant, &amp; between the official documentation and open source there should be enough to easily learn to interact",0,1,0
725,2023-02-11 19:01:17+00:00,ylecun,"@ylecun @MetaAI Congratulations to the team, this model is amazing, it will be possible to adjust it for an e2e test.
Mais sem c√≥digo n√£o tem like kkk",0,0,0
726,2023-02-11 18:33:54+00:00,ylecun,"@ylecun @MetaAI My wife is not very interested in AI. But she knows that I am. When I told her about Toolformer last night, she perked up. She immediately understood the implications.

Normal people are starting to take the topic seriously.",0,1,0
727,2023-02-11 18:03:42+00:00,ylecun,@ylecun They help writers block and introductory learning to complex topics,0,0,0
728,2023-02-11 17:56:44+00:00,ylecun,@ylecun @MetaAI Please train it using Tapenade or any source-to-source AD tool. The current capabilities of chatgbt are rather limited (and biased).,0,0,0
729,2023-02-11 16:03:55+00:00,ylecun,"@ylecun Thank you Yan, for mentioning Beethoven and the 6th symphony.

And yes, it is obvious that humans do creativity in the same way by receiving random inputs.",0,1,0
730,2023-02-11 15:56:49+00:00,ylecun,@ylecun @MetaAI that‚Äòs awesome,0,0,0
731,2023-02-11 15:18:58+00:00,ylecun,"@ylecun I do believe that there are things happening with generative AI that can't be explained by simply predicting the next token. 
e.g., when iterating with chatGPT on some code, it behaves as if it had some meta understanding of the context before generating an answer. 
Any thoughts?",3,2,0
732,2023-02-11 14:03:08+00:00,ylecun,@ylecun @mgubrud @Kantrowitz Language is a representation of knowledge not knowledge itself.  But in order to learn language properly one can build up this knowledge through language!,0,1,0
733,2023-02-11 13:48:45+00:00,ylecun,"@ylecun have you been saving ‚Äútyping‚Äù, Yann?",0,0,0
734,2023-02-11 13:25:54+00:00,ylecun,@ylecun @MetaAI Love this.,0,1,0
735,2023-02-11 13:10:29+00:00,ylecun,"@ylecun @MetaAI @OpenAI It's common knowledge that Transformers and various RL procedures have improved LLM performance.
Still doesn't change the fact that public facing AI like ChatGPT, Autopilot are better proofs of Advancements than the ""Trust me, it works"", Untested by Public usage, in-house models.",0,0,0
736,2023-02-11 13:08:12+00:00,ylecun,"@ylecun What is a difference between anticipation and prediction ü§î

I guess in this context anticipation is an forecast in discrete non uniform time steps, where prediction is an forecast in discrete uniform time steps.",1,0,0
737,2023-02-11 13:01:55+00:00,ylecun,"@ylecun First time , I see you outside sir, Not in class, conference, interview‚Ä¶",0,1,0
738,2023-02-11 12:59:13+00:00,ylecun,"@ylecun @Kantrowitz You can characterize them as ""tiny,"" I would use the word ""macroscopic,"" which is to say, a fraction within a few doublings of the whole.

We have a lot of non-verbal knowledge, but we are able to express much of it, or much about it, in words, which LLMs pick up. https://t.co/qUNgU8iBx8",1,1,0
739,2023-02-11 12:48:43+00:00,ylecun,"@ylecun Love it, I'm glad we're at a point in time where researchers and scientists get interviewed and get the attention they deserve.",0,23,1
740,2023-02-11 12:48:26+00:00,ylecun,@ylecun Dude you have really aged. Wow,0,0,0
741,2023-02-11 11:28:37+00:00,ylecun,@ylecun @lxbrun It seems to me that we somehow have to be able to translate from the messiness and ambiguity of natural language to a formal enough representation that we can do useful things with it.,0,0,0
742,2023-02-11 11:08:03+00:00,ylecun,@ylecun @MetaAI How do you compare these results with what langchain does?,0,10,0
743,2023-02-11 10:23:06+00:00,ylecun,@ylecun @MetaAI When can we use it on Meta !,0,0,0
744,2023-02-11 10:22:00+00:00,ylecun,@ylecun @MetaAI This can solve hallucination problem partially I assume. Also endless use cases can rise. Such as more advanced tools... So excited to see how it will be used by industry.,0,4,0
745,2023-02-11 10:11:02+00:00,ylecun,@ylecun @MetaAI Is this a combination of LLM and POLICE? I see some hard constrains but I didn't see any live self teaching.,0,1,0
746,2023-02-11 09:51:42+00:00,ylecun,@ylecun @MetaAI This is amazing research. LLM + other tools could become really smart.,0,0,0
747,2023-02-11 09:46:47+00:00,ylecun,@ylecun @MetaAI Wen release?,0,0,0
748,2023-02-11 09:41:10+00:00,ylecun,"@ylecun bonjour ! Quels cours / livres / tutoriels recommanderiez-vous √† quelqu‚Äôun qui a eu une bonne formation en math, qui sait coder, et qui souhaite se mettre √† jour sur ce qu‚Äôon a fait en IA entre 2013 et 2023 ?",1,0,0
749,2023-02-11 09:09:13+00:00,ylecun,@ylecun @MetaAI Can ToolFormer also perform some sort of sanity check on the API answers?,0,2,0
750,2023-02-11 09:05:25+00:00,ylecun,"@ylecun @MetaAI It's easier to release a Paper &amp; tell the World what a Model can do.

Releasing an actual LLM Product to Millions of Users to test out its (in)capabilities like @OpenAI have done with ChatGPT is the only proof that a good job has been done.

One good LLM Product &gt; 1000 LLM Papers",2,11,0
751,2023-02-11 09:03:46+00:00,ylecun,@ylecun @MetaAI Why GPT-J and not OPT?,0,0,0
752,2023-02-11 08:52:28+00:00,ylecun,"@ylecun @MetaAI So why you do not use a dantzig algo to calculate the weight of each layer?
Why do you not use the model checking with a mix of reinforcement learning to determine the rules and vit for quantitatization.",0,1,0
753,2023-02-11 08:32:17+00:00,ylecun,@ylecun @MetaAI üëÄ,0,0,0
754,2023-02-11 08:31:05+00:00,ylecun,@ylecun @MetaAI When can we try it?,0,1,0
755,2023-02-11 08:29:02+00:00,ylecun,@ylecun @MetaAI Unplugged Now! There's not time left! https://t.co/juuzkVcTlt,0,5,0
756,2023-02-11 08:27:51+00:00,ylecun,@ylecun @MetaAI Very Cool! üëèüëèüëè,0,1,0
757,2023-02-11 01:00:58+00:00,ylecun,"@ylecun AI cannot match humans with current hardware of bits and qubits: our brain is not a mathematical system, but the one that created that system. Now AI is just processing power: y=f(x). AI doesn't have to be the same as humans: just a new kind of intelligence that's useful to us.",0,0,0
758,2023-02-10 15:37:20+00:00,ylecun,@ylecun hi.. we need you to tweet for our assignment,0,0,0
759,2023-02-10 13:25:27+00:00,ylecun,"@ylecun #ChatGPT took off faster than others because of it's very SIMPLE, easy to use interface. No frills, no ads, just start chatting away.

It's about the user experience, stupid.

(That was also the reason why Google took off in the first place and other search engines didn't)",0,0,0
760,2023-02-10 13:18:34+00:00,ylecun,"@ylecun Because people, generally, are uncomfortable sitting with other people in a quite room.
Music gives a comforting ""background structure"" against to hide embarassing conversation pauses.

(Why the music has to be so painfully *loud* is beyond me thoughüòâ )",0,0,0
761,2023-02-10 13:03:22+00:00,ylecun,@ylecun on the stage in @WAICANNES https://t.co/4gctWIxuQS,0,1,0
762,2023-02-10 09:01:35+00:00,ylecun,@ylecun @jnbarrot @MetaAI La France est ridicule et vous le savez bien,0,0,0
763,2023-02-10 06:43:58+00:00,ylecun,@ylecun @jnbarrot @MetaAI Tre bon Namaste,0,0,0
764,2023-02-10 03:42:59+00:00,ylecun,"@ylecun 1)They want to attract customers by playing it so loud its heard outside on the street. Internal vol could be low and a loud speaker be outside but.. 2) Once in and order placed, they want u to leave, want to annoy u so that u dont sit and chat 4hours, make room for new customers",0,0,0
765,2023-02-09 23:51:29+00:00,ylecun,@ylecun @hughhowey It‚Äôs been a fun dance learning how ChatGPT gets certain fundamentals in functions wrong‚Ä¶ but points you enough in the right direction towards fixing your problem that filling in the gap allows you to still learn what it is you‚Äôre asking it to explain.,1,0,0
766,2023-02-09 20:49:54+00:00,ylecun,"@ylecun @infrecursion1 Dr. LeCun, I'm curious why (or if?) you feel that chatGPT being autoregressive is a limitation.  The overall goal is density estimation over text, i.e. a joint distribution over tokens.  But, any joint distribution can be factored autoregressively, in any order of variables.",0,0,0
767,2023-02-09 20:02:57+00:00,ylecun,@ylecun Because all of them are scientists who study Cocktail party effect  in attention seeking situation? üòÖ,0,0,0
768,2023-02-09 20:00:58+00:00,ylecun,"@ylecun @jnbarrot @MetaAI Bien dit, meme si mes copains Francais dissent aux Politechniciens: ""Aprends tes maths ici mais recupere ton salaire aux US""",0,0,0
769,2023-02-09 18:20:08+00:00,ylecun,"@ylecun @jnbarrot @MetaAI Woah, French is cool, gotta learn that asap",0,0,0
770,2023-02-09 17:49:54+00:00,ylecun,@ylecun This and BCIs like I‚Äôm learning about in class has to be the most interesting shit in the world,0,0,0
771,2023-02-09 15:43:46+00:00,ylecun,@ylecun @jnbarrot @MetaAI Existe t-il des projets fran√ßais d'envergure ?,1,0,0
772,2023-02-09 15:33:43+00:00,ylecun,@ylecun @jnbarrot @MetaAI Finalement √ßa √©coute les bonnes personnes :),0,0,0
773,2023-02-09 15:27:20+00:00,ylecun,@ylecun @MatjazLeonardis Bwhahaha!,0,0,0
774,2023-02-09 13:12:51+00:00,ylecun,"@ylecun @tunguz You mean The Banana Corp. ?!
Those Bastards...
üòâüòÜ",0,0,0
775,2023-02-09 12:40:58+00:00,ylecun,"@ylecun @tunguz yes, and the bot is called iA‚Ä¶",0,0,0
776,2023-02-09 11:48:51+00:00,ylecun,@ylecun True for Colombia üá®üá¥,0,0,0
777,2023-02-09 06:46:13+00:00,ylecun,@ylecun Keeps you drinking cause you can‚Äôt talk ie:$$,0,0,0
778,2023-02-09 06:03:07+00:00,ylecun,@ylecun @DrHughHarvey But they require you to type your questions,0,0,0
779,2023-02-09 05:12:14+00:00,ylecun,"@ylecun @tunguz Orange S.V. 

It's a coordinated plot to get us all back to being strictly frugivores.",0,0,0
780,2023-02-09 04:30:29+00:00,ylecun,@ylecun any thoughts that @karpathy is joining a low research impact company? Chatgpt is anyway useless :p All in good humor :),0,0,0
781,2023-02-09 03:06:55+00:00,ylecun,@ylecun We‚Äôve covered the way from cat to human level AI. It‚Äôs short relatively to the way from chat to cat. Moravec‚Äôs.,0,0,0
782,2023-02-09 02:39:22+00:00,ylecun,@ylecun They make it possible for non-English speakers to be more included in the research community,0,0,0
783,2023-02-08 23:18:38+00:00,ylecun,@ylecun To give people and excuse to pull out their phones and check Facebook and Twitter instead of interacting with each other?,0,0,0
784,2023-02-08 23:18:04+00:00,ylecun,"@ylecun Same in the UK. IMO, creates an ‚Äúaudio blanket‚Äù around groups for privacy and encourages more drinking.",0,0,0
785,2023-02-08 23:04:54+00:00,ylecun,"@ylecun I agree that Cicero will ultimately be the most consequential AI of 2022, bc it most closely follows Yann‚Äôs vision of Human-Level AI. https://t.co/w1BSVnTfCz",0,2,0
786,2023-02-08 22:59:38+00:00,ylecun,@ylecun @bnjasim –≠—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Å—É–∂–¥–µ–Ω–∏–µ –∏ —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É —è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª –≤ —Å–≤–æ–µ–π —Ä–∞–±–æ—Ç–µ —Å—Å—ã–ª–∫–∞ –≤ –º–æ–µ–º –ø—Ä–æ—Ñ–∏–ª–µ. –°—Ç–∞—Ç—å—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π,0,0,0
787,2023-02-08 22:56:10+00:00,ylecun,@ylecun What does it matter? Everyone will be on their phones anyway,0,0,0
788,2023-02-08 21:33:21+00:00,ylecun,@ylecun Voila un probl√®me bien expliqu√©. Qui d√©passes la localisation g√©ographique.,0,0,0
789,2023-02-08 21:32:16+00:00,ylecun,"@ylecun @i_am__Alono @doristsao ChatGPT responds: ""This talk by LeCun is an example of the pot calling the kettle black.""",0,0,0
790,2023-02-08 18:45:22+00:00,ylecun,@ylecun @tunguz Raspberry,0,0,0
791,2023-02-08 18:14:40+00:00,ylecun,@ylecun Or when they think chatgpt is not that cool,0,1,0
792,2023-02-08 17:50:54+00:00,ylecun,@ylecun @tunguz BlackBerry are old news mate.,0,1,0
793,2023-02-08 17:09:05+00:00,ylecun,@ylecun I asked about it once in a coffee shop and the answer was that they want to drown out the machines ü§∑‚Äç‚ôÄÔ∏è,0,0,0
794,2023-02-08 16:54:27+00:00,ylecun,@ylecun John Helliwell (Supertramp musician) used to run an organization to abolish music in bars and restaurants...,0,0,0
795,2023-02-08 16:40:32+00:00,ylecun,@ylecun @doristsao is there a source where the quote can be found? is it a paper or talk?,0,0,0
796,2023-02-08 16:22:55+00:00,ylecun,"@ylecun Restaurant owner from a well visited restaurant in SF told me once‚Ä¶ by design, you don‚Äôt want to have people bee ‚Äútoo comfortable, just comfortable enough‚Äù because we are trying to optimize for fast circulation so you can get more volume per day.",0,4,0
797,2023-02-08 16:11:22+00:00,ylecun,@ylecun et pourquoi les gla√ßons √† profusion dans les boissons...,0,0,0
798,2023-02-08 15:17:47+00:00,ylecun,"@ylecun Especially annoying in restaurants. How come in a place where one pays to eat the food one likes, one has to listen to some arbitrary music you may not like? To me, the music interferes with the whole experience.",0,3,0
799,2023-02-08 15:17:43+00:00,ylecun,@ylecun @Mila_Quebec,0,0,0
800,2023-02-08 15:14:26+00:00,ylecun,"@ylecun @tunguz Yes, avocado AI",0,0,0
801,2023-02-08 15:13:10+00:00,ylecun,@ylecun Restaurants want churn. People sitting around comfortably for long periods is bad for business,0,1,0
802,2023-02-08 15:05:58+00:00,ylecun,"@ylecun When conversation stalls, you got sound to make you feel less awkward. Also maybe you don't hear other people's conversation as much?",0,0,0
803,2023-02-08 14:50:30+00:00,ylecun,"@ylecun Wouldn‚Äôt  a LLM have to pass a Turing test to be considered HLAI and at that point wouldn‚Äôt they also be considered conscious?How are people even debating this with the present state of the LLM‚Äôs publicly available? I‚Äôm sorry I know you‚Äôre not saying this, but other people are.",0,0,0
804,2023-02-08 14:44:16+00:00,ylecun,"@ylecun Don't talk, eat, then leave",0,1,0
805,2023-02-08 14:41:13+00:00,ylecun,@ylecun Obviously so that you drink more.,0,1,0
806,2023-02-08 14:28:48+00:00,ylecun,@ylecun @i_am__Alono @doristsao K,0,0,0
807,2023-02-08 14:20:25+00:00,ylecun,"@ylecun true in India too :(

@Noahpinion",0,3,0
808,2023-02-08 14:18:51+00:00,ylecun,@ylecun Sensory overload draws attention away from the crappy food‚Ä¶,1,1,0
809,2023-02-08 14:06:54+00:00,ylecun,@ylecun It may or may not be Durian. ü§êü§´,0,17,1
810,2023-02-08 14:02:42+00:00,ylecun,"@ylecun Well, the name of the function is multinomial logit.",0,0,0
811,2023-02-08 13:55:50+00:00,ylecun,@ylecun So you drink more and talk less,0,0,0
812,2023-02-08 13:50:04+00:00,ylecun,@ylecun Live music is almost always unbearably loud. I guess live musicians just don't want to hear people talk while they perform.,0,0,0
813,2023-02-08 13:49:36+00:00,ylecun,@ylecun @Noahpinion It can be generalized to knowledge engines: https://t.co/O3ZDruoelS,0,0,0
814,2023-02-08 13:49:34+00:00,ylecun,@ylecun You could maybe ask politely to turn down the music a bit...  Just a thought.,0,0,0
815,2023-02-08 13:41:53+00:00,ylecun,@ylecun Pre-instagram technology to get leads üòÇ,0,0,0
816,2023-02-08 13:39:30+00:00,ylecun,"@ylecun Louder restaurant -&gt; talk at higher volume -&gt; dry throat -&gt; drink more -&gt; tip more.
For the same reason, all snacks are also too salty.",0,18,0
817,2023-02-08 13:34:09+00:00,ylecun,"@ylecun Yeah, biggest annoyance/pollution for me in NY...",0,1,0
818,2023-02-08 13:29:56+00:00,ylecun,@ylecun @tunguz It is definitely not Apple.,1,0,0
819,2023-02-08 13:29:37+00:00,ylecun,@ylecun You drink more if its loud.,0,2,0
820,2023-02-08 13:27:33+00:00,ylecun,"@ylecun Shoot, even Starbucks has gone this way. I go in as early as 5:30am and they‚Äôre blaring music despite nobody being in there.",0,0,0
821,2023-02-08 13:26:30+00:00,ylecun,@ylecun in order for the ones sitting there to have the chance to shout even loudly at each other which is the preferred mode of conversation in this part of the world anyway,0,0,0
822,2023-02-08 13:13:55+00:00,ylecun,@ylecun This explains the spite you feel for it.,0,0,0
823,2023-02-08 13:03:59+00:00,ylecun,"@ylecun That's either not serious, resentful or you haven't really interacted with one seriously (which I can hardly imagine). E.g. prompt Chat-GPT in an appropriate way and have it teach you the basics of any topic, e.g. a language and say again that it just saves typing...",0,0,0
824,2023-02-08 13:02:01+00:00,ylecun,"@ylecun Do you think that choice has saved more typing than LLMs?
https://t.co/ciG904LT8h",0,1,0
825,2023-02-08 13:00:51+00:00,ylecun,@ylecun It has been called as ‚Äúmultinomial logit probability‚Äù in the discrete choice literature. Always interesting to see different names across fields.,1,0,0
826,2023-02-08 12:57:03+00:00,ylecun,"@ylecun Pretty much every coder in your company is using an LLM to help them write code, as I am too. It's not for saving the typing, is for helping us think about how to solve the problem. 

You might be too entrenched in a position that doesn't allow you to see what it really is.",0,0,0
827,2023-02-08 10:20:53+00:00,ylecun,"@ylecun The interface is typing, but could the latent calculations be considered thinking?",0,0,0
828,2023-02-08 10:19:43+00:00,ylecun,"@ylecun @killerstorm @DrHughHarvey Even though the underlying technology is the same, and the main training task is predicting the next token, something fascinating happens when deep neural networks reach a certain size: emergent abilities. 

@ylecun  How do you explain LLMs abilities to follow instructions?",0,0,0
829,2023-02-08 07:33:37+00:00,ylecun,@ylecun Then ask a cat what common sense is,0,0,0
830,2023-02-08 07:32:49+00:00,ylecun,@ylecun @DrHughHarvey typing should be solved with bci but we don't have it now.,0,0,0
831,2023-02-08 06:56:36+00:00,ylecun,"@ylecun if you still make such boring comments about chatgpt, meta's share price will continue to fall",0,0,0
832,2023-02-08 06:33:46+00:00,ylecun,@ylecun Great for extracting information &amp; constraining it to a structure too.,0,0,0
833,2023-02-08 05:46:05+00:00,ylecun,@ylecun üòÇüòÇüòÇ,0,0,0
834,2023-02-08 04:33:41+00:00,ylecun,@ylecun @doristsao I still don't get it. Sorry.,0,1,0
835,2023-02-08 04:19:13+00:00,ylecun,"@ylecun Is typing in danger? ""They save typing"" üôÑCleary, some people need all the help they can get. And not just from LLM. Also this: https://t.co/RKwOMS0oXy",0,0,0
836,2023-02-08 04:16:32+00:00,ylecun,@ylecun with an unlimited output bandwidth.,0,0,0
837,2023-02-08 04:16:26+00:00,ylecun,"@ylecun @DrHughHarvey True that. Have you tried Gboard, Google's keyboard. I swear it can read my mind...",0,0,0
838,2023-02-08 03:37:32+00:00,ylecun,@ylecun What problem does #HorizonWorlds solve? üòµ‚Äçüí´,0,0,0
839,2023-02-08 03:20:52+00:00,ylecun,@ylecun Nice work,0,0,0
840,2023-02-08 03:16:04+00:00,ylecun,@ylecun I no longer need learn any parlour tricks,0,0,0
841,2023-02-08 03:11:11+00:00,ylecun,"@ylecun @killerstorm @DrHughHarvey I think they meant zero shot outputs with just a simple prompt with an example - without needing any extra technical knowledge. 

This increases usability for a lot of people, allowing quicker automation of some simple tasks.",0,0,0
842,2023-02-08 03:05:56+00:00,ylecun,@ylecun They save copy paste,0,0,0
843,2023-02-08 02:30:03+00:00,ylecun,@ylecun @doristsao Spinoza managed to construct a compositional one god: nature.,0,0,0
844,2023-02-08 02:28:11+00:00,ylecun,"@ylecun Totally agree. The biggest problem of LLMs is that they don't interact with the real world and do reasoning to generate new knowledge, which make them not able to think independently. That's also why they like to lie.",0,0,0
845,2023-02-08 02:26:51+00:00,ylecun,@ylecun @crypto1o1_karim Disingenuous as usual,0,0,0
846,2023-02-08 02:17:28+00:00,ylecun,"@ylecun I wonder, if you and ChatGPT both write an ML paper abstract given a title, in a blind review fashion, how many will vote your writing as the better one ü§î",1,0,0
847,2023-02-08 02:13:24+00:00,ylecun,"@ylecun A non trivial use though I wonder how many overconfident bad translations editors will now see. At least they won't be paying large sums for the bad translations anymore, a significant gain in my opinion.

-Former science journal editor.",0,0,0
848,2023-02-08 01:54:26+00:00,ylecun,"@ylecun Yep. Awareness=/=intelligence 

Awareness is a big elephant in the room. 

What is it? 

Is it even computational? Physicists have tried to answer this, and Nobel prize winner Roger Penrose says no. 

There's an element of infinity underlying consciousness. 

A singularity.",0,0,0
849,2023-02-08 01:21:18+00:00,ylecun,@ylecun and thinking,0,0,0
850,2023-02-08 00:09:56+00:00,ylecun,"@ylecun It's great for producing fiction, though I am afraid we already have too much of that. It can help with copywriting etc., so all those NLU tasks it can do of course help a lot. Their CTO seems to think it's real understanding but I have my doubts.",0,0,0
851,2023-02-07 23:42:04+00:00,ylecun,@ylecun @cichuck Can we agree that they save time thinking how to write? Still we can focus our brains more on the message content than on its packaging.,0,0,0
852,2023-02-07 23:40:13+00:00,ylecun,@ylecun They also cause a craving for sour grapes in some people.,0,0,0
853,2023-02-07 23:21:03+00:00,ylecun,"@ylecun They call it ""phrase grounding"", which seems to be quite different from ""language understanding"". I hope no one misunderstands your comment üôÉ",1,1,0
854,2023-02-07 23:20:40+00:00,ylecun,@ylecun Yann! what makes your AI tool better than the competition?,0,0,0
855,2023-02-07 23:16:47+00:00,ylecun,"@ylecun I‚Äôm always confused with the term ‚Äúobject detection‚Äù because aren‚Äôt the floor, wall in the background, the cat‚Äôs ear, the air, etc. all objects as well?",1,0,0
856,2023-02-07 23:04:35+00:00,ylecun,"@ylecun wrong! 
https://t.co/9DQJkR3S56

/s",0,0,0
857,2023-02-07 22:58:56+00:00,ylecun,@ylecun A cat can't respond to a complex question about nuclear fusion,0,0,0
858,2023-02-07 22:31:33+00:00,ylecun,"@ylecun @benalsop I'd guess that cats may be smarter at spacial navigation/problem solving, but dogs have much richer social heirarchies and I bet a lot of neurons are devoted to that.",0,1,0
859,2023-02-07 22:13:29+00:00,ylecun,@ylecun @chris_j_paxton The AI in Galactica was pretty wicked so perhaps your marketing team at Facebook can use ChatGPT to help them find better branding ideas... üëÄü§∑üèº,0,1,0
860,2023-02-07 21:31:49+00:00,ylecun,"@ylecun Companies like Facebook and Google are inherently held back from LLMs. Both rely heavily on advertisers, and nothing would scare them away faster than having their ads next to some of the text generated from jailbroken ChatGPT output.",0,0,0
861,2023-02-07 21:21:28+00:00,ylecun,"@ylecun I tried Galactica and I liked it. Yet, it was less capable than ChatGPT. ChatGPT can rhyme, speak in voices, solve homework; and even though it hallucinates information, it is more accurate.

People were wowed by ChatGPT because it was much better than Galactica and GPT-3.",1,2,0
862,2023-02-07 21:14:13+00:00,ylecun,@ylecun Ample cats in the figure 10/10 would read.,0,4,0
863,2023-02-07 20:59:51+00:00,ylecun,"@ylecun ChatGPT didn't reach 100 million users in a month for ""saving typing"".",0,0,0
864,2023-02-07 20:55:11+00:00,ylecun,"@ylecun @DrHughHarvey Typing, writing, constructing sentences, generating ideas, organising and structuring information, correcting grammar, clarifying thoughts, saving time and effort. Your underestimation astounds me.",0,0,0
865,2023-02-07 20:54:35+00:00,ylecun,"@ylecun @DrHughHarvey OpenAI provides examples of using their flagship LLM for:

1. classification
2. keyword extraction
3. sentiment detection
4. parsing unstructured data
5. translation

That's just LLM without extra layers or fine-tuning.
Of course, it might not be the best and most efficient for",2,0,0
866,2023-02-07 20:46:00+00:00,ylecun,@ylecun @doristsao False dichotomy,0,0,0
867,2023-02-07 20:44:20+00:00,ylecun,@ylecun Or maybe the framing was completely off? https://t.co/F92nKL3Ngr,0,1,0
868,2023-02-07 20:37:37+00:00,ylecun,"@ylecun ChatGPT beat you to the masses, stop crying about it and move on",0,3,0
869,2023-02-07 20:24:24+00:00,ylecun,"@ylecun I just love when anti-AI people bring up the ""what problem does it solve"" point without realizing the very simply truth that the huge demand for these technologies means it solves a HUGE problem. Even if it can't be easily formulated into words.",1,0,0
870,2023-02-07 20:22:51+00:00,ylecun,"@ylecun That‚Äôs like saying that computers are good for adding, multiplying, and storing.",1,2,0
871,2023-02-07 20:13:38+00:00,ylecun,"@ylecun It's not a softargmax either. It's a ""soft-Kronecker-delta-function""",0,2,0
872,2023-02-07 19:57:15+00:00,ylecun,@ylecun Because your bot is not feasible to conduct research. But chatGPT for casual use. You failed with your product design.,0,0,0
873,2023-02-07 19:23:32+00:00,ylecun,@ylecun @DrHughHarvey Clicking trough many websites,0,0,0
874,2023-02-07 19:17:42+00:00,ylecun,"@ylecun @DrHughHarvey Is it more like thinking ? 

@ylecun",0,0,0
875,2023-02-07 19:13:14+00:00,ylecun,"@ylecun @Phillips_M_G Galactica was not advertised as a ‚Äúpredictive keyboard on steroids.‚Äù It was marketed as a ‚Äúresearch assistant‚Äù and was rightly panned for failing to work as advertised.
/not an endorsement of ChatGPT",1,8,0
876,2023-02-07 19:10:02+00:00,ylecun,"@ylecun Tu es Lecun, faut arr√™ter avec le chatgpt bashing, c pa Sophie",0,0,0
877,2023-02-07 19:06:48+00:00,ylecun,@ylecun üòÇ this and @ylecun justifying continuously on Twitter while TATA @1mgOfficial is flying drones in Delhi to provide blood to the needed. Let @Twitter decide who is more impactful yet a big company. https://t.co/yEyFyTTDzK And @tiktok_us buying a hospital chain in china,1,1,0
878,2023-02-07 18:58:31+00:00,ylecun,"@ylecun This is pretty non-trivial. For one, typing and field-filling comprises a large part of many jobs. Also, having an AI that acts as an intermediate knowledge generator between a half-fleshed idea and a full document is invaluable",0,0,0
879,2023-02-07 18:58:17+00:00,ylecun,@ylecun It's so weird that you became such a LLM/gpt troll.,0,0,0
880,2023-02-07 18:54:31+00:00,ylecun,"@ylecun @DrHughHarvey MOST EPIC SINGLE WORD RESPONSE EVER WRITTEN FROM @ylecun. (And we know he wrote it, not ChatGPT) üòâ",0,0,0
881,2023-02-07 18:53:27+00:00,ylecun,"@ylecun @cichuck Yann, tu sembles ne pas int√©grer une partie sociologique dans ton approche. Une grande partie des t√¢ches sont faites sans r√©flexion en suivant des templates d√©j√† fait. La pens√©e est de plus en plus premach√©e. C'est en cela qu'un outil comme chatGPT fait raz-de-mar√©e.",0,0,0
882,2023-02-07 18:46:58+00:00,ylecun,"@ylecun @chris_j_paxton This is exactly the way I see it as well, as a language teacher. It‚Äôs going to do so much to make the world of Research more interesting, giving a voice to people who have tons of interesting things to say but who struggle to publish their findings in English.",2,4,0
883,2023-02-07 18:45:48+00:00,ylecun,@ylecun They are also good at ordering semi structured data into structured data.,0,0,0
884,2023-02-07 18:44:00+00:00,ylecun,"@ylecun They‚Äôre also levelling the playing field for non-native speakers and/or people suffering from dyslexia. THIS is the bigger story no one is talking about, yet. Reading then editing is much easier than writing something from scratch.",0,0,0
885,2023-02-07 18:38:30+00:00,ylecun,@ylecun @Noahpinion Maybe #ChatGPT  lies because it's afraid of conflict?,0,1,0
886,2023-02-07 18:37:25+00:00,ylecun,@ylecun You didn‚Äôt have the added advantage of simps on the internet who think some people and companies can do no wrong.,0,0,0
887,2023-02-07 18:37:03+00:00,ylecun,@ylecun @SujithK08852029 Lol - head in sand,0,0,0
888,2023-02-07 18:35:21+00:00,ylecun,@ylecun @DrHughHarvey Why are you (Meta...) building such models if it's only for typing ?,0,0,0
889,2023-02-07 18:26:43+00:00,ylecun,"@ylecun @ChrSzegedy It's more useful than driving assist. 
With driving assist you still need to be in the car and pay attention to the road. 
However, with content generation, you just need to verify the results and make some changes. It's a time saver",0,1,0
890,2023-02-07 18:16:50+00:00,ylecun,@ylecun https://t.co/NGWYAwiMso,0,0,0
891,2023-02-07 18:11:04+00:00,ylecun,@ylecun I think they‚Äôre useful for generating code snippets for people who have a functioning knowledge of a particular programming language but are not proficient enough for the needed tasks‚Ä¶(I have not used copilot yet),0,1,0
892,2023-02-07 18:09:25+00:00,ylecun,@ylecun @killerstorm @DrHughHarvey Should we say research and typing ?,0,0,0
893,2023-02-07 18:02:24+00:00,ylecun,"@ylecun It's all about what was promised (or perceived as a promise). ChatGPT is mostly fun, no expectations. And somehow it proved to be useful in a large spectrum of applications. 

Meta's AI was promising way too much compared to its actual performance.",0,6,0
894,2023-02-07 18:01:05+00:00,ylecun,"@ylecun Generic chatbots aren't built for the purpose of writing scientific papers, Galatica was. So the bar is higher. 

Compare it with search: If I do a generic search and get the wrong answer for a paper, I'm unsurprised. If that happens in a reference manager, I'm more annoyed.",1,2,0
895,2023-02-07 18:00:36+00:00,ylecun,"@ylecun Creating mindless entertainment for mindless masses, for one. However, we'd appreciate if you acknowledged how dangerous it is that ChatGPT is already engaged in political propaganda.",0,0,0
896,2023-02-07 17:52:40+00:00,ylecun,"@ylecun #CovfefeGPT
#StableGeniusDiffusion",0,0,0
897,2023-02-07 17:52:35+00:00,ylecun,@ylecun They have helped me come up with ideas for method of proof and python library discovery and javascript function discovery.... They are helping with search...,0,0,0
898,2023-02-07 17:50:13+00:00,ylecun,@ylecun I think this is underselling how useful ChatGPT can be for inexperienced writers/non-native speakers,2,12,0
899,2023-02-07 17:47:05+00:00,ylecun,"@ylecun There's a huge difference between a generic chatbot and one that claims to be for scientific research

The latter has a much higher bar on truth and accuracy",1,12,0
900,2023-02-07 17:46:28+00:00,ylecun,@ylecun Thankfully Small Tech is there to force Big Tech to deal with its risk aversion.,0,1,0
901,2023-02-07 17:31:11+00:00,ylecun,"@ylecun @SujithK08852029 Standardized tests are a poor tool for assessing intelligence. They may have been adequate for testing humans, since humans are not nearly as good as LLMs at faking their understanding.",0,2,0
902,2023-02-07 17:16:16+00:00,ylecun,@ylecun A house cat has more than just a language center. It has a whole ass brain,0,0,0
903,2023-02-07 17:11:46+00:00,ylecun,@ylecun They can come up with quick code snippets interactively that is helpful in terms of having not to look up the actual syntax - ChatGPT.,0,0,0
904,2023-02-07 17:07:23+00:00,ylecun,@ylecun @smjain @ylecun aren't scaled up LLM also pre-trained in a self-supervised manner? What other SSL approach you are hinting towards.,1,0,0
905,2023-02-07 16:52:24+00:00,ylecun,"@ylecun @doristsao Or god is a good engineer üòä

Moon and sun distances, earth rotation, biological equilibrium, lifecycles, water volumes, etc. seem pretty good engineered.",1,0,0
906,2023-02-07 16:38:18+00:00,ylecun,@ylecun Had the pleasure of meeting John when I joined RSRE in the early ‚Äò90s. Wonderful times.,0,0,0
907,2023-02-07 16:28:50+00:00,ylecun,@ylecun @doristsao Is this the mathematical 'or'? Or the lingual one?,1,0,0
908,2023-02-07 16:23:40+00:00,ylecun,"@ylecun Also, it increases the level of abstraction at which you write code.",0,0,0
909,2023-02-07 16:22:38+00:00,ylecun,"@ylecun No, no. It's far easier to verify something created, than to create it.",0,1,0
910,2023-02-07 16:18:30+00:00,ylecun,@ylecun LOL!,0,0,0
911,2023-02-07 16:16:59+00:00,ylecun,@ylecun @doristsao There are gods and they are compositional.,0,0,0
912,2023-02-07 16:16:45+00:00,ylecun,@ylecun Birth of the general purpose IDE.,0,0,0
913,2023-02-07 16:08:40+00:00,ylecun,"@ylecun Yann, please let us know your thoughts about the victims killed in two heavy earthquakes (M7.7 &amp; M7.5) occured in just one day in Turkiye. Thanks a lot.",0,0,0
914,2023-02-07 16:05:23+00:00,ylecun,"@ylecun @doristsao as part of a cosmological theory, I think phil and physics as well as biology and cog sci are actually pointing toward what could be called a 3rd alternative outside of the compositional and theistic positions. I want to try and find / articulate that 3rd position! 3/",0,1,0
915,2023-02-07 16:03:54+00:00,ylecun,@ylecun @doristsao to be very compelling. Combined with physicists' arguments of the the reality of time and insufficiency of theories within Newtonian paradigm incl. general and special relativity and standard model to account for initial conditions and specification of laws governing cosmos 2/,0,0,0
916,2023-02-07 16:02:14+00:00,ylecun,@ylecun @doristsao I think this is a false binary. I find Thomas Nagel's concern (Mind&amp;Cosmos) with the limits of materialist / psychophysical reductionism to account for the epistemological recalcitrant issues of 1) consciousness 2) rational thought 3) inception of life/self replicating systems 1/,0,0,0
917,2023-02-07 15:55:00+00:00,ylecun,@ylecun You're on the road to this being what you're remembered for.,1,0,0
918,2023-02-07 15:52:45+00:00,ylecun,"@ylecun We better call Human-Level AI =Hula.. This way if we go in circles it will be a ""Hula Hoop,"" [while keeping the ""Hula Hope"" alive!]",0,1,0
919,2023-02-07 15:52:07+00:00,ylecun,"@ylecun ""softargmax"" maybe more accurate, but I think it is impossible to change the name as it has been used in so many papers, tutorials.",0,1,0
920,2023-02-07 15:48:11+00:00,ylecun,@ylecun Said a different way: It's easier to review and accept/edit something than to generate it whole cloth.,1,0,0
921,2023-02-07 15:42:59+00:00,ylecun,@ylecun Then you're overlooking or underplaying the uses built on top of LLM's,1,1,0
922,2023-02-07 15:41:54+00:00,ylecun,"@ylecun Shortens the learning curve on any topic, I get exactly what I have doubts in
Non coders can now code, although basic scripts but does the job
I guess saving time is big enough plus, earlier I had a showel now I have bulldozer",0,0,0
923,2023-02-07 15:34:21+00:00,ylecun,"@ylecun @doristsao No idea what compositional is, but i remember quantum physicist say that the world cant be generated due to mathematical/physic property? Sth related to right hand rule or non-continuous bla bla bla",0,0,0
924,2023-02-07 15:32:52+00:00,ylecun,"@ylecun No one coins ""words"", unless the intent is to mislead (and get others ""hooked on 'words'""). Terminologies (e.g. named entities based on character sequences) can be constructed based on contexts, however.",1,0,0
925,2023-02-07 15:28:56+00:00,ylecun,@ylecun Ha ha this is the most succinct way I‚Äôve ever seen it put. Saving labor is really important tho.,0,0,0
926,2023-02-07 15:28:22+00:00,ylecun,@ylecun Meow,0,1,0
927,2023-02-07 15:27:10+00:00,ylecun,"@ylecun There are definitely a lot of missing pieces.
However, LLM is more like just a small portion of brain, maybe like hypothalamus. That alone cannot define intelligence, but an important part nevertheless. 
For that we might not need to go through cat, dog level development first.",0,0,0
928,2023-02-07 15:24:53+00:00,ylecun,"@ylecun More and more, i start to understand your point of view. At start, i thought you're just being bitter of Open AI success, but now i understand it's much more than that. Keep it going prof. We need more counter point to all the hype going.",0,0,0
929,2023-02-07 15:24:13+00:00,ylecun,@ylecun agreed‚Ä¶,1,0,0
930,2023-02-07 15:21:38+00:00,ylecun,@ylecun a bit prejudiced against LLMs,0,0,0
931,2023-02-07 15:15:38+00:00,ylecun,"@ylecun And wheels save the manual effort of load bearing and walking. If the LLMs were to be compared to wheels, how useful do you think they should be considered?",0,0,0
932,2023-02-07 15:11:26+00:00,ylecun,@ylecun they get shipped by companies that aren't meta,1,1,0
933,2023-02-07 15:10:25+00:00,ylecun,@ylecun @DrHughHarvey But they can get better at that. Can we also say summarising?,0,0,0
934,2023-02-07 15:09:46+00:00,ylecun,@ylecun To be fair 'softmax' sounds more catchy and probably has saved countless cumulative hours of people not saying the syllable 'arg' .,1,1,0
935,2023-02-07 15:09:32+00:00,ylecun,@ylecun He should have called it IceCream everyone loves Ice Cream,0,4,0
936,2023-02-07 15:09:29+00:00,ylecun,"@ylecun Codex literally only does that, and then I have to debug.",0,0,0
937,2023-02-07 15:08:21+00:00,ylecun,@ylecun @DrHughHarvey Seeing that ChatGPT answers to questions in a crisp manner is seems more than typing.,1,0,0
938,2023-02-07 15:06:52+00:00,ylecun,"@ylecun Yes, I‚Äôve used them in a lot of my Jupyter Notebooks just to explain the basic beginner stuff to make the notebook content richer.

Plus the explaining done for a certain written piece of code that you didn‚Äôt write but are trying to understand is phenomenal.",0,0,0
939,2023-02-07 14:55:12+00:00,ylecun,"@ylecun If you use TDD -- and increasingly, BDD -- they save a hell of a lot of typing AND Googling, too.   

I'm waiting anxiously for 

1) really large context windows  
2)  all the code I've recently added to Github to get into the training sets.",0,0,0
940,2023-02-07 14:53:50+00:00,ylecun,@ylecun What do you think would be the impact on Software engineering? Would that boost productivity or disrupt the Software engineering field?,0,0,0
941,2023-02-07 14:53:45+00:00,ylecun,@ylecun Debugging code. Say you are taking too long on a bug in a self-contained code block. You can copy past the code block and ask fix it to solve this bug,0,0,0
942,2023-02-07 14:52:51+00:00,ylecun,@ylecun They correct grammatical errors like many English speakers fail to do.,0,0,0
943,2023-02-07 14:36:25+00:00,ylecun,@ylecun programmers are just glorified typists,1,5,0
944,2023-02-07 14:36:12+00:00,ylecun,@ylecun And computers save calculating...... Come on @ylecun you're entrenched too deep,1,3,0
945,2023-02-07 14:35:35+00:00,ylecun,@ylecun So you can say its a great Tool for saving a lot of time,1,1,0
946,2023-02-07 14:35:03+00:00,ylecun,"@ylecun @DrHughHarvey It's not just one problem..
Heard numerous accounts of code being translated from one environment to another",0,0,0
947,2023-02-07 14:33:33+00:00,ylecun,@ylecun @DrHughHarvey will ur entire identity be just OpenAI bad bad. Try creating something maybe prof?,1,0,0
948,2023-02-07 14:32:51+00:00,ylecun,@ylecun @DrHughHarvey Editing,0,0,0
949,2023-02-07 14:29:33+00:00,ylecun,@ylecun @DrHughHarvey https://t.co/wZFoSFgkvh,0,0,0
950,2023-02-07 14:24:11+00:00,ylecun,@ylecun https://t.co/2OT9qWNZ7b,0,2,0
951,2023-02-07 14:23:53+00:00,ylecun,"@ylecun or, some think, thinking‚Ä¶",1,1,0
952,2023-02-07 14:23:42+00:00,ylecun,"@ylecun They save the time it takes to come up with the necessary boiler plate code needed to get started on a project, using a software framework, which you just started learning about.",1,7,0
953,2023-02-07 14:11:24+00:00,ylecun,"@ylecun Really ? What do you say about chaGPT clearing USMLE, Wharton MBA test and Law school tests? Any thoughts on that?",1,1,0
954,2023-02-07 14:07:22+00:00,ylecun,"@ylecun @KrzakalaF Incidentally, I used the same words in class :-) I think I might‚Äôve been influenced your EBL work that I read in the past.",0,1,0
955,2023-02-07 14:02:49+00:00,ylecun,@ylecun @gabriel_valu Here we go again...,0,0,0
956,2023-02-07 13:57:05+00:00,ylecun,"@ylecun ü§£ü§£ü§£ü§£ü§£  true! 

search becomes super interactive is the first effect,sales conversion rate also much higher. Bought a book after a chat with chatgpt as I was able narrow down what I wanted - gradually and based on answers, asked to compare - contrast books suggested etc",0,0,0
957,2023-02-07 13:51:30+00:00,ylecun,@ylecun Startups: Our revolutionary AI technology reduces risk of carpal tunnel by 5%!,0,1,0
958,2023-02-07 13:44:03+00:00,ylecun,"@ylecun No, the new generation of statically typed programming languages like Rust already did that.

... Get it?

Alright, I'll see myself out.",0,21,0
959,2023-02-07 13:40:06+00:00,ylecun,"@ylecun ""I'm so glad I don't have to type out all my tweets anymore! #typingproblems #jokingnotjoking""

Credit : https://t.co/YIidd7ysoC AI Generated tweets üî• https://t.co/OilJIjcVhS",0,1,0
960,2023-02-07 13:36:34+00:00,ylecun,@ylecun Better contextual translations.,0,0,0
961,2023-02-07 13:33:12+00:00,ylecun,"@ylecun @DrHughHarvey GPT totally solves the typing problem, but it doesn't quite solve the typing accurate things problem...",0,3,0
962,2023-02-07 13:31:10+00:00,ylecun,@ylecun They also save reading time,1,1,0
963,2023-02-07 13:28:02+00:00,ylecun,"@ylecun yes, are autocomplete.  
Solves ""what do people say about ____""

So it solves search+summarize.  ie it sort of solves the first part of the literature review process in research.",0,0,0
964,2023-02-07 13:22:05+00:00,ylecun,@ylecun Typing gets you pretty far these days,0,0,0
965,2023-02-07 13:20:59+00:00,ylecun,@ylecun Good code completion can reduce cognitive load as well.,2,38,0
966,2023-02-07 13:19:49+00:00,ylecun,@ylecun And thinking.,0,0,0
967,2023-02-07 13:19:45+00:00,ylecun,@ylecun @DrHughHarvey Why not memorising?,1,0,0
968,2023-02-07 13:18:13+00:00,ylecun,"@ylecun This makes it a huge productivity booster for most people, including myself on side projects mainly.",0,0,0
969,2023-02-07 13:17:51+00:00,ylecun,@ylecun @DrHughHarvey what else?,0,1,0
970,2023-02-07 13:17:10+00:00,ylecun,@ylecun And thinking about mundane details,0,0,0
971,2023-02-07 13:17:07+00:00,ylecun,@ylecun @DrHughHarvey harsh. but LLMs are in fact essentially just autocomplete.,0,0,0
972,2023-02-07 13:14:27+00:00,ylecun,@KrzakalaF @deliprao The distribution that minimizes the free energy.,1,3,0
973,2023-02-07 13:14:00+00:00,ylecun,@ylecun you seem to be typing a lot more,2,14,0
974,2023-02-07 13:13:57+00:00,ylecun,@ylecun 911: i would like to report a murder,0,1,0
975,2023-02-07 13:13:54+00:00,ylecun,@ylecun Replace it with deleting.,0,0,0
976,2023-02-07 10:23:58+00:00,ylecun,@ylecun @patricksamy should we leave aside the bottom and inside parts for our own sake?,0,0,0
977,2023-02-07 09:19:44+00:00,ylecun,"@ylecun Surely we need to better decode what kind of data we gather from our senses and ability to move around and interact, by attaching learning systems to cats, dogs and humans and not just self drive cars.",0,0,0
978,2023-02-07 08:45:08+00:00,ylecun,"@ylecun We use lenses to view our world, It's possible LLMs and available models that simulate images / 3d objects become a 'new eye' towards the reality we hold. GPT-4 can train on physics simulators and will position data from a usable perspective, more general than common sense.. no?",0,0,0
979,2023-02-07 08:28:05+00:00,ylecun,"@ylecun , earlier you mentioned Meta &amp; Google can make chatGPT-like services that are as good as chatGPT but won't. Now Google is releasing Bart. What if Bart fails, or is nearly as good (good in being adopted, not per se good as in accurate). What does that mean?",0,0,0
980,2023-02-07 06:29:24+00:00,ylecun,@ylecun @Noahpinion What is your take on Bard from Google ?,1,0,0
981,2023-02-07 06:21:05+00:00,ylecun,@ylecun So what are we at now? Rat level?,0,0,0
982,2023-02-07 06:02:13+00:00,ylecun,"@ylecun Yes, but how much do we know about Any-level brain? In fact, if Daniel Kahneman‚Äôs dual-system model is about right, LLMs are doing a good job to replace the system one of ours. No?",0,0,0
983,2023-02-07 05:39:36+00:00,ylecun,"@ylecun Real world has an unimaginable amount of data. For example you cannot learn how to ride a bike from reading a book, no matter how well written the book is it‚Äôll never be sufficient.",0,0,0
984,2023-02-07 05:35:00+00:00,ylecun,"@ylecun If the AI we have helps us understand neuroscience/consciousness better and in turn if we create a better AI as a result of the new understanding and if that cycle continues, possibly we might reach there sooner enough?",0,0,0
985,2023-02-07 04:37:28+00:00,ylecun,"@ylecun I would humbly start with understanding humans first. I would not start with cats nor dogs. I am a human, I am not a cat nor a dog. Aka I have better chance of success.",0,0,0
986,2023-02-07 04:21:33+00:00,ylecun,"@ylecun A house cat has not been demonstrated to be able to produce working/useful programming language code.

This tweet of @ylecun seems demonstrably false.

~One can reasonably disregard or show the short falls of some platform/work, without blatant lies. https://t.co/3UuioRlqc0",0,0,0
987,2023-02-07 03:58:50+00:00,ylecun,@ylecun @ferdousbhai But do any serious researchers or entreprenuers working the space believe this specific fact? I can't tell if you are trying to cozy up to @GaryMarcus  (jk) or kill the 'newbie chatgpt party' - if anything it's just more evidence you were always right about SSL as the direction,0,0,0
988,2023-02-07 03:50:16+00:00,ylecun,"@ylecun @gabriel_valu So, as a response to ChatGPT, Google is planning to open to the public, in the near future, Claude+Bard. Is MetaAI planning an ""off-ramp"" response too?",0,1,0
989,2023-02-07 02:57:30+00:00,ylecun,@ylecun @Noahpinion What do you think about Google's Bard?,0,0,0
990,2023-02-07 02:03:21+00:00,ylecun,"@ylecun We can write a long paper to accurately report our research results but cannot always use language to precisely describe the full process of research, such as the source of ideas and inspirations, and why we made certain decisions at various stages.",0,0,0
991,2023-02-07 01:07:00+00:00,ylecun,@ylecun Why are we fixated on Turing tests?,0,0,0
992,2023-02-06 23:47:59+00:00,ylecun,"@ylecun Please don't make HLAI a thing, we already have AGI to refer to what human brains can do, and AI to refer to what other computing machines can do. Please don't make it a thing.",0,0,0
993,2023-02-06 23:46:32+00:00,ylecun,@ylecun @Noahpinion Or summed up in 3 words ‚Äòlack of understanding‚Äô,0,0,0
994,2023-02-06 23:37:32+00:00,ylecun,@ylecun Cats can't talk,0,0,0
995,2023-02-06 23:04:13+00:00,ylecun,@ylecun perhaps should be retitled as ‚ÄúWhy Only Learning From Text‚Ä¶‚Äù,0,0,0
996,2023-02-06 22:32:24+00:00,ylecun,@ylecun Current AI is missing a conceptual understanding of what it is thinking/doing.  It needs an internal organization of concepts/categorization and an understanding of the relationships between them.,0,0,0
997,2023-02-06 22:09:46+00:00,ylecun,@ylecun Do you think it's sensor modalities? Something about a text-only interface feels lacking..,0,0,0
998,2023-02-06 22:08:12+00:00,ylecun,@ylecun @hughhowey ChatGPT generates samples from a big but finite probability distribution which means it can be misled similarly to how image classifiers are misled by noise injected in images. A human that has an understanding of a concept will not be easily misled by permutations of the words,0,0,0
999,2023-02-06 22:06:57+00:00,ylecun,"@ylecun @VladicaV And my proposal calls for first studying what we can do with causal world models, before we labor to learn them. Still not mutually exclusive.",3,19,2
1000,2023-02-06 21:25:21+00:00,ylecun,"@ylecun What test for dog or cat-level do you have in mind as a benchmark or definition?
Because depending on the task selection, AI has already surpassed cats (e.g. in the ability to read french), and in some mental abilities e.g. monkeys surpass humans (recall).",0,1,0
1001,2023-02-06 21:06:52+00:00,ylecun,@ylecun @Noahpinion Page not found,1,0,0
1002,2023-02-06 21:02:36+00:00,ylecun,"@ylecun Assuming human knowledge to be the pinnacle of correct is wrong, even by our own standards. Patterns of bias easy for AI but not human. LLM already find new chemistry via reannalysis of publishd work. In fact, LLM can already build nuke tech or ID public info gaps wrt same, butü§´",0,0,0
1003,2023-02-06 20:53:31+00:00,ylecun,@ylecun Is it possible that LLMs are missing a proper agent-arena relationship that grounds their perceptions in the real world? Lifeforms determine relevant signals and actions based on the meta-goals of survival and reproduction. LLMs are drowned in data but starved of relevance.,0,0,0
1004,2023-02-06 20:38:48+00:00,ylecun,"@ylecun Why would you exclude baby level AI

the right path is baby, child, adult. 

Not animal, adult.  

More evidence you don't care about how human brains solve problems and only try to mimic behaviours.",1,0,0
1005,2023-02-06 20:05:45+00:00,ylecun,"@ylecun @rsalakhu @beenwrekt How about: place a treat inside one of 10 labelled boxes in front of a cat. Then take the cat out of the room, shuffle the boxes' locations, and then let the cat in. Does it walk to the right box? Make sure to plastic wrap the treat so that the cat can't smell it.",1,1,0
1006,2023-02-06 19:53:49+00:00,ylecun,"@ylecun @gabriel_valu another fact Garyyann:
https://t.co/diF55FRMTZ",0,0,0
1007,2023-02-06 19:30:58+00:00,ylecun,"@ylecun Maybe this is what you are missing...
https://t.co/IdqvnJwT8H",0,0,0
1008,2023-02-06 18:56:42+00:00,ylecun,"@ylecun Finally you seem to be enjoying some of the frustration that cognitive scientists have had all along, ever since the outlandish and non scientific claims began. Here I show that language models aren‚Äôt even models of language https://t.co/JHs3FvNE7Q",0,0,0
1009,2023-02-06 18:52:36+00:00,ylecun,@ylecun I feel to reach Human Level AI we have to build AI systems on Logic inference then augment with ANN. After all to truly understand reason we must understand logic,0,0,0
1010,2023-02-06 18:26:34+00:00,ylecun,@ylecun YES! We miss cat language LLMs! üòªüò∏,0,0,0
1011,2023-02-06 18:21:44+00:00,ylecun,"@ylecun Also, we need a precise definition of Human-Level. Does it has to be a smart human?",0,1,0
1012,2023-02-06 17:58:10+00:00,ylecun,@ylecun @bboczeng Understanding is missing ... got the point Nice,0,0,0
1013,2023-02-06 17:57:09+00:00,ylecun,@ylecun @bboczeng Nice,0,0,0
1014,2023-02-06 17:55:49+00:00,ylecun,@ylecun Cats have no soul. We must prevent CLAI at all cost. DLAI will suffice. Just saying.,0,0,0
1015,2023-02-06 17:50:17+00:00,ylecun,@ylecun @Noahpinion so ChatGPT is basically a liberal Ben Shapiro,0,0,0
1016,2023-02-06 17:44:15+00:00,ylecun,"@ylecun Also, most of the commenters are bots, so that's already happening. ü§ñüò¨",0,0,0
1017,2023-02-06 17:35:11+00:00,ylecun,@ylecun My very na√Øve hunch is we‚Äôre just a clever arrangement of LLMs/logic inference engines/etc (and maybe an order of magnitude or two model size) away from emergent ‚Äúintelligence‚Äù. Could even happen accidentally. It will look far away until it happens suddenly.,1,0,0
1018,2023-02-06 17:26:53+00:00,ylecun,@ylecun That's an interesting view for a company that released Horizon Worlds.,0,0,0
1019,2023-02-06 17:20:57+00:00,ylecun,"@ylecun Really sure that it wasn't #Galactica who actually ""emboldened Edward""?

(BTW - hi, Ed!)",0,0,0
1020,2023-02-06 17:11:53+00:00,ylecun,"@ylecun @rsalakhu @beenwrekt That's an awesome question to start with. Why do we want to classify MNIST digits? Is this indeed an intrinsic motivation, or extrinsic, or neither? Where is this question raised, let alone formalized, in AI?",0,2,0
1021,2023-02-06 17:01:02+00:00,ylecun,@ylecun @gabriel_valu A lot of folks cannot comprehend the difference between probabilistic repetition and understanding,0,0,0
1022,2023-02-06 16:59:03+00:00,ylecun,"@ylecun @JohnBlackburn75 @traderyau LLM may not be the only soution ... but combining a good LLM into something like offline RL (like @svlevine) or some other approach seems to be a realistic approach toward AGI in my mind ... maybe not a full off-ramp, but GPTs may be a stepping stone on one of many paths to AGI.",1,1,0
1023,2023-02-06 16:38:37+00:00,ylecun,@ylecun Good topics of conversation in this thread for the Seattle AI Society's Thinkers chapter: #SAIS_T,0,0,0
1024,2023-02-06 16:36:13+00:00,ylecun,"@ylecun Natural selection has honed survival skills in creatures, something that a cat or a dog possess. And we call common sense. Like not jumping from the roof to catch a ball.

While AGI will never perhaps have to perfect it's survival first and jump straight to eccentricity.",1,1,0
1025,2023-02-06 16:35:16+00:00,ylecun,@ylecun Indeed my house cat does feel if a guest is sad for some reason. Can we teach to AI empathy?,0,0,0
1026,2023-02-06 16:00:00+00:00,ylecun,"@ylecun Write an ai that can simulate and function in a bacterias natural environ.  Next try Stentor.  Then do C. Elegans. Then Honeybee.  Here's a honeybee

https://t.co/F8CapDfL0G

More than 270 skills it can coordinate",0,0,0
1027,2023-02-06 15:54:10+00:00,ylecun,"@ylecun Okay, GaryYann",0,0,0
1028,2023-02-06 15:49:01+00:00,ylecun,"@ylecun For human level AI, we have to train our models like we train humans. Recall how a mom teaches a baby that A is Apple by showing a picture. Its not just a language model but also correlated to a image model.

If we use all five senses to create an AI model, we get human-level AI",0,0,0
1029,2023-02-06 15:43:48+00:00,ylecun,"@ylecun This assumes that there is some sort of linear progression we have to get through to reach HLAI. 

LLM capabilities were surprising because they were emergent when scaled last a threshold. 

No reason why HLAI can‚Äôt skip cat/dog",0,0,0
1030,2023-02-06 15:28:09+00:00,ylecun,"@ylecun @hughhowey Literal (rather than rhetorical) question:  What does ""understanding"" mean?  Or, perhaps, how does one measure or test ""understanding""?  (A couple of good references would be welcome.)",0,0,0
1031,2023-02-06 15:27:52+00:00,ylecun,"@ylecun @bboczeng What you are proposing requires ""Explainability in AI"". 

Have you reconsidered your position on explainability in AI?",0,0,0
1032,2023-02-06 15:25:59+00:00,ylecun,"@ylecun True true. But LLMs (e.g ChatGPT) have demonstrated that even human-level AI isn't necessary in-order to do ""wonders"" for humans.",0,0,0
1033,2023-02-06 15:22:34+00:00,ylecun,"@ylecun Ai will be the best in its way of intelligence coz every natural intelligence has unique abilities 
So ai will do its best coz it's ai not an animal, bird, fish, or not human 
It will fit a new species",1,0,0
1034,2023-02-06 15:17:01+00:00,ylecun,@ylecun Well I hope you advance the envelope at Meta just a little bit more. Right now it's pretty disappointing.,0,0,0
1035,2023-02-06 15:13:17+00:00,ylecun,@ylecun @yannx0130 Is there an objective metric to evaluate if model has common sense?,0,0,0
1036,2023-02-06 15:07:30+00:00,ylecun,@ylecun Zgadzam siƒô w pe≈Çni,0,0,0
1037,2023-02-06 15:05:00+00:00,ylecun,"@ylecun We have already reached Human-Level AI. You didn't specify which human you're referring to with ""Human-Level"". And we have a lot of ""lesser intelligent people"" that are already outmatched by a neuronal network with a single layer with a single neuron...",0,0,0
1038,2023-02-06 14:42:08+00:00,ylecun,@ylecun A house cat can't tell me how to fix my web app.,0,1,0
1039,2023-02-06 14:34:10+00:00,ylecun,"@ylecun Unfortunately, people can rely on their biases to filter or reinterpret feedback they don‚Äôt like, and the feedback often isn‚Äôt driven by the desire to pursue ground truth",0,0,0
1040,2023-02-06 14:29:16+00:00,ylecun,@ylecun You are missing executive function! https://t.co/qrbmhee9eu https://t.co/M1O0flcUwf,0,2,0
1041,2023-02-06 14:24:11+00:00,ylecun,@ylecun What do you think is the level of present day LLMs?,0,0,0
1042,2023-02-06 14:18:28+00:00,ylecun,@ylecun cockroach level neither?,0,0,0
1043,2023-02-06 14:17:54+00:00,ylecun,"@ylecun @rsalakhu @beenwrekt Is that the only argument, or are there more properties of agency worth pointing out?",0,1,0
1044,2023-02-06 14:12:03+00:00,ylecun,@ylecun Too many cats in AI,0,0,0
1045,2023-02-06 14:11:12+00:00,ylecun,@ylecun but cat can't auto-complete my COBOL scripts Yann,0,0,0
1046,2023-02-06 14:10:46+00:00,ylecun,@ylecun How would a LLM based robot with vision/hearing/smell/touch sensations behave?(maybe a dumb qn),0,0,0
1047,2023-02-06 14:07:06+00:00,ylecun,@ylecun One test could show if LLMs are truly remarkable or just for entertainment: ask their creators if they dare to allow LLMs to manage their money.,0,0,0
1048,2023-02-06 14:06:35+00:00,ylecun,"@ylecun Maybe what's missing are feedback loops, including data generation and/or som type of quantum random core... soul",0,0,0
1049,2023-02-06 14:02:23+00:00,ylecun,"@ylecun @bboczeng We must find mechanisms to generate logical power rather than simply increasing the size of the model. Today's chatgpt has a huge library that gives it the ability to pretend to be an intelligent individual, but we all know that this is not actually the case,",1,0,0
1050,2023-02-06 14:01:19+00:00,ylecun,"@ylecun Different environment yield different intelligence. All the parts are already there: embodied motor skills through RL &amp; simulation, mid-long term objectives, reasoning and communication through LLMs.",0,1,0
1051,2023-02-06 13:59:32+00:00,ylecun,"@ylecun I was just thinking about this the other day. My Chihuahua‚Äôs pathing AI is insane. IBM‚Äôs robots are cool, but has nothing on my 8lb dog.",0,0,0
1052,2023-02-06 13:50:27+00:00,ylecun,"@ylecun That's true, and we still have a lot to learn before we get to HLAI. But we are making progress every day, and it's exciting to see the advances being made!",0,0,0
1053,2023-02-06 13:49:27+00:00,ylecun,@ylecun It's the Galileo vs Catholic Church moment for @ylecun,0,0,0
1054,2023-02-06 13:40:27+00:00,ylecun,"@ylecun We have only just conquered the Turing test by implementing theory almost 100 years old. Clearly, we need engineering innovation as well as advanced researchers to continue on this journey.",0,0,0
1055,2023-02-06 13:39:12+00:00,ylecun,@ylecun @bboczeng Also a ton of the vest engineering feats mimic nature exactly,0,0,0
1056,2023-02-06 13:37:51+00:00,ylecun,@ylecun Will cat-level AI and dog-level AI fight with each other?,0,0,0
1057,2023-02-06 13:37:41+00:00,ylecun,@ylecun What in your opinion would be the approach towards human-level AI? Do you think Neuromorphic Computing is slowly moving in that direction?,0,0,0
1058,2023-02-06 13:37:00+00:00,ylecun,"@ylecun This is so refreshing to hear. ""Singularity is coming"" - no, at least not anytime soon.",0,0,0
1059,2023-02-06 13:31:45+00:00,ylecun,@ylecun Oh üÜó,0,0,0
1060,2023-02-06 13:25:42+00:00,ylecun,"@ylecun The big thing we are missing is that Cat‚Äôs/Dog‚Äôs brain is trained in nature, 24/7, with their bodies and balance in centre. The same with humans. On top of that we build an understanding of abstract terms which are often metaphors on top of other methaphors.",0,0,0
1061,2023-02-06 13:19:32+00:00,ylecun,@ylecun @alrhemist Isn't Python a part of said reality?,0,0,0
1062,2023-02-06 13:17:06+00:00,ylecun,@ylecun Is there any specific grade on the intelligence of different species? Can we somehow tell how smarter (or  better to say more intelligent) is one creature in comparison to another?,0,0,0
1063,2023-02-06 13:10:19+00:00,ylecun,@ylecun @bboczeng Our wings didn't need to flap though.,0,0,0
1064,2023-02-06 13:08:16+00:00,ylecun,"@ylecun you‚Äôre the biggest gatekeeper i‚Äôve ever seen on this field ‚Äî no offense intended

so many of human achievements were built before we‚Äôve had complete fundamental understanding of the underlying phenomena

can‚Äôt understand how this cynical posture is beneficial to the field",0,0,0
1065,2023-02-06 13:06:42+00:00,ylecun,"@ylecun Cats have a lot of common sense, can confirm.",0,0,0
1066,2023-02-06 13:05:13+00:00,ylecun,"@ylecun YOU are missing something big but be patient #SAM is coming soon üòâ

#AI #SelfAwareMachines #Deetptech #Robot #Paris",0,0,0
1067,2023-02-06 13:03:29+00:00,ylecun,@ylecun Thats it. LLMs are great for doing creative stuff but they have massive lack in reasoning capabilities by design because they are parrots powered by statistics and a factor called temperature. HLAI requires soft skills not hard skills.,0,0,0
1068,2023-02-06 12:53:54+00:00,ylecun,"@ylecun To some extent, we have built a combination of Broca's and Wernicke's areas of the brain. What we're missing is the understanding of concepts, their relationships, and the ability to reason about them.",2,13,0
1069,2023-02-06 12:52:26+00:00,ylecun,@ylecun Damn I'm still at squirrel AI over here programming a complex algorithm to search nuts and put them in trees,0,0,0
1070,2023-02-06 12:47:03+00:00,ylecun,"@ylecun @bboczeng The thing is, we were able to build all sorts of planes BEFORE we fully understood how wings generate lift:

https://t.co/5l9WbnfFs2",1,1,0
1071,2023-02-06 12:37:50+00:00,ylecun,"@ylecun A brown rat has 4.5*10^11 number of synapses. A cat ~1*10^13. Humans 1.5*10^14.  
GPT3 has 1.5*10^11 parameters. 
Somthing tells me that we're in for an exciting next 10-20 years.",0,0,0
1072,2023-02-06 12:33:28+00:00,ylecun,@ylecun @mapto You do realise that the charitable interpretation of this tweet is that you haven't read the paper in question but feel confident to summarize it anyway?,0,1,0
1073,2023-02-06 12:31:08+00:00,ylecun,"@ylecun HLAI, OK. But Cat and Dog levels? ü§îcould you define they? Or show a bib-ref to help a better undestanding. Cheers.",0,0,0
1074,2023-02-06 12:10:39+00:00,ylecun,"@ylecun with due respect, cant llms be seen as inhabiting a purely symbolic (made of letters) universe, there is an emergent understanding within the universe of language itself,  limited since its tied to the real world  but an intelligence nevertheless.",0,0,0
1075,2023-02-06 11:52:04+00:00,ylecun,"@ylecun Question for you, Yann: a large part of animal intelligence is emotional.
Is the animal model the right intermediary to human-like AI?
Shall we have to emulate emotions in AI to pass the next step of intelligence? Or will it come as a side product?",0,0,0
1076,2023-02-06 11:48:04+00:00,ylecun,"@ylecun What is ""reason"" in the first place? If the mental activity is just electrical reaction corresponding to outside environment. The distinction between what is reason and what isn't is blurred and ambiguous. I believe we, human being, are not clearly understand our intelligence",0,0,0
1077,2023-02-06 11:38:28+00:00,ylecun,"@ylecun I believe that implementation of Evolutionary Genetic (EG) principles into machine code is the way to reach HLAI and beyond. EG is responsible for all the life on our planet, and the main principles are relatively well understood.",0,0,0
1078,2023-02-06 11:32:23+00:00,ylecun,@ylecun Cat intelligence is not a subset of human intelligence. Have you ever known a cat? They have incomprehensible motives and will outsmart you in weird ways.,0,14,0
1079,2023-02-06 11:24:36+00:00,ylecun,@ylecun I see about 20 comments to this tweet. One has feedback.  I wonder what‚Äôs the feedback rate of ChatGPT‚Ä¶,0,1,0
1080,2023-02-06 10:53:22+00:00,ylecun,@ylecun Do you think architecture to support compositionality is the next step and prerequisite to supporting 'understanding' causality? Or could those two things be functionally independent?,1,0,0
1081,2023-02-06 10:51:18+00:00,ylecun,"@ylecun We already have cat-level AI, that's why it's called ""Chat-GPT"" üòâ",0,0,0
1082,2023-02-06 10:31:34+00:00,ylecun,@ylecun Let's establish CLAI and DLAI as key terms in the AI-Sphere :'D after that will be CLAI (Crow-Level AI),0,0,0
1083,2023-02-06 10:29:22+00:00,ylecun,"@ylecun hmmm I get your point, yet the image seems poorly chosen, as there is not the effort to mimic cat or dog common sense as there is toward human's, nor there are the same kind of learning databases to mimic (emulate? learn? ...) them.",0,0,0
1084,2023-02-06 10:20:46+00:00,ylecun,@ylecun Growing language models had some interesting emergent properties. But I agree that thouse Modells should not produce HLAI.,0,0,0
1085,2023-02-06 10:20:26+00:00,ylecun,@ylecun I say ability to acquire knowledge and build your own model of the world,0,0,0
1086,2023-02-06 10:10:51+00:00,ylecun,"@ylecun says it loud and clear: if you want to produce intelligent machines we must abandon two current main AI pillars, probabilistic modeling, and generative models. https://t.co/XBiiEGpM6U",0,0,0
1087,2023-02-06 10:04:46+00:00,ylecun,@ylecun I (and many others) think those can actually bring in more funding to the field. And then approaches like the one in your paper or the one described by @Numenta may be accelerated. Is it really an off-ramp in this case?,0,0,0
1088,2023-02-06 10:01:39+00:00,ylecun,@ylecun Correction: meant to say 1994 not 2004.,0,0,0
1089,2023-02-06 10:01:31+00:00,ylecun,"@ylecun @bboczeng The answer is that all living things solve for desire satisfaction. This would be solving for caloric efficiency required for self persistence. That's the only purpose for computation.

So if you want to solve for a cat you have to make a model of the cat's homeostasis desires.",3,4,1
1090,2023-02-06 09:58:00+00:00,ylecun,@ylecun The 80‚Äôs was a good time to join when there were still a lot of old timers. I did contract work for Lucent after I left. They started using the Bell Labs name for marketing purposes and hired people that were not up to par. I am glad I experienced the old Bell Labs.,0,0,0
1091,2023-02-06 09:53:16+00:00,ylecun,@ylecun @alrhemist My cat can't.,1,0,0
1092,2023-02-06 09:44:30+00:00,ylecun,@ylecun @Noahpinion Ug I hate substack you can‚Äôt read anything without pop ups forcing you to subscribe it‚Äôs oppressive I‚Äôll never read anything on substack !,0,0,0
1093,2023-02-06 09:37:05+00:00,ylecun,"@ylecun Intelligence level seems like a result. The reasons may be various, like knowledge learnt, memory size, complexity of the neurons, etc. Now the question comes to How to evaluate the intelligence level for difference species.",0,0,0
1094,2023-02-06 09:32:08+00:00,ylecun,@ylecun Would including other modalities to learn from (e.g. video) be a step in the right direction?,0,0,0
1095,2023-02-06 09:27:28+00:00,ylecun,@ylecun Animals could improve themselves by learning(reaction with environment ),0,0,0
1096,2023-02-06 09:26:47+00:00,ylecun,"@ylecun For a top researcher in AI, you sure bitch a lot about what other teams are doing.  

Offer your better solution up as a UI or probably just sit back down.",0,0,0
1097,2023-02-06 09:25:22+00:00,ylecun,"@ylecun @Noahpinion Great piece!

ChatGPT tells us more about ourselves than about fundamental AI capabilities. Humans have to spend a lot of effort to communicate rigorously. We usually don‚Äôt bother, so it‚Äôs not clear a model built off a broad corpus of our words will actually know much truth",0,2,1
1098,2023-02-06 09:21:45+00:00,ylecun,"@ylecun I totally agree!

A cat can never pass the test which an LLM can. 

People are so subscribed to the education system, that they will use the above logic to say the LLM is more intelligent. That's woke.",0,0,0
1099,2023-02-06 09:18:25+00:00,ylecun,@ylecun I now respect you much more!,0,0,0
1100,2023-02-06 09:15:44+00:00,ylecun,@ylecun Humans with Cat-Level Intelligence https://t.co/0Y4IxiA3EP,0,0,0
1101,2023-02-06 09:14:36+00:00,ylecun,@ylecun @rsalakhu @beenwrekt The sure shot evidence that cats are generally intelligent is that they consistently refuse to learn MNIST üòá,0,22,0
1102,2023-02-06 09:12:45+00:00,ylecun,"@ylecun The brain of Drosophila, the common fruit fly, with its approximately 100,000 neurons, is much more intelligent than today's LLMs - even as larvae.",0,0,0
1103,2023-02-06 08:56:27+00:00,ylecun,@ylecun We are still missing +The ability to apply the principles of quantum mechanics to calculations. 100 million times faster which would exponentially increase the computational ability} data and Memory I am surprised is very small currently https://t.co/hkatsJZ8HV,0,0,0
1104,2023-02-06 08:39:10+00:00,ylecun,@ylecun Language is a late top end of intelligence. Building intelligence language-first is like building a house roof first.,0,0,0
1105,2023-02-06 08:34:02+00:00,ylecun,"@ylecun I think being able to simulate animals survival instinct in computers/AIs/algorithms will play a big role (sleep, energy, nutrients, social relations‚Ä¶).",0,0,0
1106,2023-02-06 08:33:45+00:00,ylecun,"@ylecun Unfortunately, human level AI or even animal level AI is just impossible in its true sense, the best we can do is to make AI mimic a few activities, without any understanding.",0,0,0
1107,2023-02-06 08:32:14+00:00,ylecun,"@ylecun Isn‚Äôt HLAI or even Cat-Level for that matter not possible at least in the paradigm of our choices, instincts, &amp; understanding? Something that can actually choose vs providing the statistically likely choice seems like an impassable gap.",0,0,0
1108,2023-02-06 08:19:13+00:00,ylecun,@ylecun Do you think that the growth in AI investment is beneficial or harmful to the advancement of research for a ‚ÄúHLAI‚Äù?,0,1,0
1109,2023-02-06 08:17:18+00:00,ylecun,@ylecun üëã,0,0,0
1110,2023-02-06 08:08:43+00:00,ylecun,@ylecun We need more energy efficient hardware. Neuromorphic computing,0,0,0
1111,2023-02-06 08:02:36+00:00,ylecun,@ylecun Yes we are missing some crucial pieces,0,0,0
1112,2023-02-06 07:54:10+00:00,ylecun,"@ylecun @VladicaV @yudapearl need a sprinkling of  œÜ-ML too - the embodiment factor, so to speak...",0,0,0
1113,2023-02-06 07:53:22+00:00,ylecun,@ylecun Meow second that https://t.co/OVwtmsw9QE,0,2,0
1114,2023-02-06 07:52:05+00:00,ylecun,@ylecun A house cat also has better survival skills than most humans. Not really a great metric for AGI tho,3,4,0
1115,2023-02-06 07:47:26+00:00,ylecun,"@ylecun @bboczeng ""A house cat has way more common sense and understanding of the world than any LLM""
Does a cat know how to boil water? that's part of the ""understanding of the world"" that LLMs have but cats don't.
I'm sure I can come up with 1000 more.",0,0,0
1116,2023-02-06 07:40:40+00:00,ylecun,@ylecun Agree but maybe the first thing to do is to define this ‚Äúcommon sense‚Äù you refer to.  Can‚Äôt engineer what we can‚Äôt define?  My vote is that common sense is a world line as defined in general relativity.  Defining anything in space-time behavior grounds neural net in physics.,0,0,0
1117,2023-02-06 07:38:19+00:00,ylecun,"@ylecun Yes they suffer from information hallunciation,if not mastered art of question, chat gpt is lethal.",0,0,0
1118,2023-02-06 07:27:03+00:00,ylecun,@ylecun @Noahpinion It takes a high level of intelligence to constantly lie especially if achieving the feat of staying credible.,0,1,0
1119,2023-02-06 07:23:12+00:00,ylecun,@ylecun @Noahpinion @octavo8,1,1,0
1120,2023-02-06 07:20:52+00:00,ylecun,"@ylecun @zussini On top any single neuron itself isn't just some light switch but instead needs a neural net itself to be simulated.

But we'll get there sooner or later.",0,0,0
1121,2023-02-06 07:18:35+00:00,ylecun,"@ylecun Perhaps the difference between a program and real intelligence is a form of awareness of being alive, and the fear of losing life. What could be called ""instinct"".
True intelligence is not just an ability to solve problems.",0,0,0
1122,2023-02-06 07:17:32+00:00,ylecun,"@ylecun @MacGraeme42 @bradysimpson55 They are already very valuable tools. Was thinking to hire a secretary, but when Chatgpt was released to the general public, it became unnecessary at this point. In the future I might hire someone, but it would be doing a complete different jobs.",0,0,0
1123,2023-02-06 07:11:54+00:00,ylecun,"@ylecun The upper management in my company is considering exposing our code base to a hypothetical version of chatgpt which will guarantee privacy, security and a promise to refactor for maintainability and get rid of bugs.",0,0,0
1124,2023-02-06 07:06:47+00:00,ylecun,"@ylecun I hope AI stays at the level, trustworthy and friendly..rather than human level AI that might be bossy.",0,0,0
1125,2023-02-06 07:05:01+00:00,ylecun,"@ylecun @mapto StochasticParrot was just a fluff piece with lot of nonsensical virtue signalling. IMO it's main goal was to get its authors the limelight, which they achieved. Anyways be prepared to be attacked on Twitter and eventually be called a racist by Timnit's gang!",1,0,0
1126,2023-02-06 06:59:52+00:00,ylecun,"@ylecun @bboczeng scaling LLMs is only one component of HLAI. The entire industry is building models for specific use cases, and an HLAI would be some orchestration of all of these models, not just an LLM",1,0,1
1127,2023-02-06 06:57:59+00:00,ylecun,@ylecun waiting for cat and dog translating :-),0,0,0
1128,2023-02-06 06:52:56+00:00,ylecun,@ylecun There were people who reasoned the only way to fly was to design wings and do it like the birds.,0,0,0
1129,2023-02-06 06:50:33+00:00,ylecun,@ylecun Isn‚Äôt this correlated to better mathematical formulation of what is AI? A  first big step wouldn‚Äôt be that AI is able to solve any PDE?,0,0,0
1130,2023-02-06 06:48:33+00:00,ylecun,"@ylecun If we are able to understand consciousness, we'll be able to decode AGI RAPIDLY!",0,0,0
1131,2023-02-06 06:42:37+00:00,ylecun,"@ylecun Correct, and the article in Noema argues the point very well. The question is, what is more useful? A cat level AI or a language model? I believe that in our economy a language model is far more useful and, even for humans, evolution is pushing us towards language-based thinking.",1,0,0
1132,2023-02-06 06:42:20+00:00,ylecun,"@ylecun Even an insect, once you see that the LLM is not actually ‚Äúworking with‚Äù he ideas it seems to present.",0,0,0
1133,2023-02-06 06:40:23+00:00,ylecun,"@ylecun True, but how do you think HLAI can be achieved?
I don't believe that Neural nets can achieve that either.
At least not with current ones.",0,0,0
1134,2023-02-06 06:35:59+00:00,ylecun,@ylecun Totally disagree‚Ä¶I think you are missing the evolution story to how Intelligence came about. Cats and dogs are in no way connected to Human intelligence. Likewise Machine Intelligence is something else‚Ä¶,0,3,0
1135,2023-02-06 06:34:19+00:00,ylecun,"@ylecun If we can do cat level intelligence, is it correct to assume HLAI is just linear scaling the same solution",0,0,0
1136,2023-02-06 06:23:48+00:00,ylecun,"@ylecun Social insects function very well. Perhaps the goal should be Hive AI, a network of different types of AI, complification evolving.",0,0,0
1137,2023-02-06 06:23:24+00:00,ylecun,"@ylecun Is it realistic for an LLM to be able to ""see"" base64 encoded images?",0,0,0
1138,2023-02-06 06:20:42+00:00,ylecun,"@ylecun Somehow we have to fuse image recognition and LLMs, throw in Boston dynamics balance and physics models, stir it all up and let it iterate in a virtual environment.",0,0,0
1139,2023-02-06 06:14:44+00:00,ylecun,@ylecun I‚Äôm waiting for fly level,0,0,0
1140,2023-02-06 06:13:39+00:00,ylecun,@ylecun Ce n'est pas un chat (GPT) https://t.co/aWP6gMcStE,0,0,0
1141,2023-02-06 06:07:53+00:00,ylecun,"@ylecun If Muhammad won't come to the mountain, then the mountain must go to Muhammad.",0,0,0
1142,2023-02-06 05:59:56+00:00,ylecun,"@ylecun Hmm. My cat has ChatGPT equivalent competence in bringing some BS about ‚Äúnever having been get before in his life‚Äù and ‚Äústarving to death‚Äù every morning, in front of a fresh food bowl.",0,0,0
1143,2023-02-06 05:59:46+00:00,ylecun,@ylecun Then why does the cat keep pushing stuff off the table,0,0,0
1144,2023-02-06 05:56:41+00:00,ylecun,@ylecun They are missing an endocrine system.,0,0,0
1145,2023-02-06 05:50:35+00:00,ylecun,"@ylecun @hughhowey I think it's because all facts are equivalent to an LLM. I had a conversation where it ruminated at length on possible explanations for a fictional character's problems, and needed to be led to the conclusion that the character's blindness actually mattered a lot.",0,0,0
1146,2023-02-06 05:48:08+00:00,ylecun,"@ylecun @yoavgo But I‚Äôd suppose HLAI would just make up a very slim interval of overall intelligence.

Once HLAI os reached, higher levels are imminent or even already there. What name should ne given for superintelligence then?",0,0,0
1147,2023-02-06 05:44:12+00:00,ylecun,"@ylecun Agree and disagree... Cats are obviously more grounded than LLM and have a better physical model of the world. But ChatGPT can affect the world, 
 in a limited way, through its answers, and sense the world through questions, and its words have meaning through this interaction.",0,0,0
1148,2023-02-06 05:41:23+00:00,ylecun,@ylecun @Noahpinion Good article. Was a bit surprised to see myself mentioned there at the end lol.,0,8,0
1149,2023-02-06 05:39:22+00:00,ylecun,@ylecun @yannx0130 Linguistics and Spatial Intelligence are not correlated. Trying to train an LLM on this is a waste of time.,0,1,0
1150,2023-02-06 05:37:33+00:00,ylecun,@ylecun AI should learn to create data for itself based on the data provided to it... Lets understand the algorithm of curiosity that gets created in human mind,0,0,0
1151,2023-02-06 05:36:47+00:00,ylecun,"@ylecun The problem is that human intelligence and cat intelligence are the same in terms of dimensionality of features (Such as memory, problem solving skills, communication skill, etc.), but human intelligence is just more capable (Like an overclocked cat brain) (1/2)",1,0,0
1152,2023-02-06 05:33:47+00:00,ylecun,@ylecun @bradysimpson55 Why the anthropomorphic pursuit to asses AI just through the human lens?,0,1,0
1153,2023-02-06 05:30:21+00:00,ylecun,"@ylecun That's because a house cat evolved to survive in the world, not to know facts about it",0,1,0
1154,2023-02-06 05:29:25+00:00,ylecun,"@ylecun Why do people insist on trying to analogize human intelligence with artificial one?

AI is following a novel path in the evolutionary context, it will be different, with different turns, different leaps, and different hiccups. 

A dog can't do this üëá https://t.co/3xIBic6zib",0,0,0
1155,2023-02-06 05:28:08+00:00,ylecun,@ylecun @3DTOPO @alrhemist ‚ÄúThe real world is none of that.‚Äù Bold statement. Many a philosopher would disagree‚Ä¶,1,0,0
1156,2023-02-06 05:25:32+00:00,ylecun,"@ylecun But we already have parts of brain in separated technologies: computer vision, audio processing and creating, self-drivig cars, industrial and creature-like robots etc",0,0,0
1157,2023-02-06 05:24:04+00:00,ylecun,"@ylecun @3DTOPO @alrhemist That is because your company has the lowest trust scores with consumers of any tech company. 

Plus your AI was for research papers, a place where accuracy is extremely important. 

You launched it very poorly and your tweets since then give no evidence you learned anything.",3,20,3
1158,2023-02-06 05:23:39+00:00,ylecun,@ylecun @Noahpinion Of course has limitations but for the average people is not that bad. Of course the information are still not quite accurate but who needs it anymore ü§™. Joke a side. What you're trying to say is important but perhaps you should change the tone a little bit. Because teenagers üòÄ,0,0,0
1159,2023-02-06 05:20:32+00:00,ylecun,"@ylecun to be fair, a house cat has more common sense and understanding of the world than many humans...",0,0,0
1160,2023-02-06 05:20:22+00:00,ylecun,"@ylecun Curious what you make of multi-modal transformers like Gato?  It's very similar to the LLMs, but of course capable across far more domains",0,7,0
1161,2023-02-06 05:15:41+00:00,ylecun,@ylecun For a very lay and engaging introduction: https://t.co/rK1A4o1Lyf https://t.co/uvYEzAEXy3,0,1,0
1162,2023-02-06 05:13:36+00:00,ylecun,"@ylecun Nope. If so we‚Äôd see stepping stones - an animal with almost human intelligence. But our closest relatives, the apes, don‚Äôt come close to us. No art, no aspiration, no language. There is a fundamental difference we don‚Äôt understand. Until we do AI will be just that, artificial.",0,0,0
1163,2023-02-06 05:12:57+00:00,ylecun,"@ylecun And a fish has way more understanding of water than the average pre-civilizational humans, I guess the fish will always have the advantage",0,0,0
1164,2023-02-06 05:11:15+00:00,ylecun,@ylecun LLMs are not the answer.I think it all comes down to their capacity to hold memory.,0,1,0
1165,2023-02-06 05:05:00+00:00,ylecun,"@ylecun @Noahpinion A ""House"" clip about Korsakoff's Syndrome where a patient confabulates constantly ""because she has no memory"" (says Dr. House):  https://t.co/K1aX0n8eN4",2,3,0
1166,2023-02-06 04:55:46+00:00,ylecun,"@ylecun While ChatGPT are used by over 100 million people, you are still doubting and wandering‚Ä¶",0,0,0
1167,2023-02-06 04:55:09+00:00,ylecun,"@ylecun @zussini Tuned by approximately half a billion years of biological evolution as multicellular organisms, making their way through ab apparently indifferent and often actively hostile environment (assuming perhaps wrongly that unicellar not so relavant for multicellular behavior).",2,1,0
1168,2023-02-06 04:54:30+00:00,ylecun,@ylecun @Noahpinion not the crossover I was expecting,0,0,0
1169,2023-02-06 04:53:47+00:00,ylecun,"@ylecun @dotpavan My uninformed guess is movement, senses and interaction with real world.",0,0,0
1170,2023-02-06 04:46:18+00:00,ylecun,@ylecun @Noahpinion https://t.co/mlYHqKmntt - GPT 4 to be released!,0,3,0
1171,2023-02-06 04:17:19+00:00,ylecun,@ylecun Can cat calculate 1+1=3,0,0,0
1172,2023-02-06 04:16:34+00:00,ylecun,"@ylecun Agreed wrt their obvious inability to reason and propensity for errors. But can they efficiently encode access to human knowledge and serve as librarians on steroids (or google ++), especially for highly specialized domains like programming APIs, etc ?",0,0,0
1173,2023-02-06 04:12:21+00:00,ylecun,"@ylecun @PatrikMuncaster @yoavgo why do you say that all intelligences are *necessarily* specialized?

objective based maybe. but couldn‚Äôt the objective or specialization be to identify optimal courses of action based on a knowledge base?",0,0,0
1174,2023-02-06 04:03:22+00:00,ylecun,"@ylecun Great read. This would seem to align with Jeff Hawkin's A Thousand Brains Theory of Intelligence? We evolved spatially by mapping the world, and this simple algorithm repeated over and over again led to intelligence. Spatial mapping came first, language second.",1,0,0
1175,2023-02-06 03:51:41+00:00,ylecun,"@ylecun @mapto No, that is not what it said.",0,15,0
1176,2023-02-06 03:50:48+00:00,ylecun,"@ylecun @Noahpinion Which is why ""Google killer"" is, at least for now, a huge exaggeration.",0,1,0
1177,2023-02-06 03:46:26+00:00,ylecun,@ylecun @hughhowey The worlds worst driver on a bad day is still likely better than the best self driving car in most situations,1,1,0
1178,2023-02-06 03:45:11+00:00,ylecun,"@ylecun This is interesting.

What could be a test for cat-like intelligence?

For at least a specific kind of human-like intelligence (not human-level) we have the Turing thest.

What, if any, specific skill could we test when comparing cats and AI?",0,0,0
1179,2023-02-06 03:32:40+00:00,ylecun,@ylecun @benalsop Quantity vs Quality,0,0,0
1180,2023-02-06 03:27:54+00:00,ylecun,@ylecun Breaking News! Yann LeCun has just confirmed AI has evolved from the insects to a small mammal. What a progress in few short years!,0,0,0
1181,2023-02-06 03:22:02+00:00,ylecun,"@ylecun Broccoli, Cauliflower and Artichoke would seem to hold the clue",0,0,0
1182,2023-02-06 03:18:25+00:00,ylecun,@ylecun @bboczeng and yet https://t.co/694lYz0Xfz,1,5,0
1183,2023-02-06 03:15:06+00:00,ylecun,@ylecun Can we just have WhatsApp as a personal assistant.,0,0,0
1184,2023-02-06 03:00:42+00:00,ylecun,"@ylecun @DrCMcMaster To be fair, why should ‚ÄòEdward from Omaha‚Äôs expertise remain limited to ‚Äòdangers of vaccines‚Äô?! ü§∑‚Äç‚ôÇÔ∏è",1,1,0
1185,2023-02-06 03:00:35+00:00,ylecun,"@ylecun Any specific ideas beyond Statistical learning  (MLE, MAP, etc)?",0,0,0
1186,2023-02-06 02:58:49+00:00,ylecun,@ylecun What‚Äôs the difference algorithmically between dog-level AI and human-level AI?,0,0,0
1187,2023-02-06 02:55:12+00:00,ylecun,"@ylecun Biological brains also don't have a backpropagation algorithm. So how do they learn so efficiently? I think a possible key solution is that they do multimodal supervised learning. Annotate images with sound, annotate sound with haptics, and so on.",0,0,0
1188,2023-02-06 02:52:12+00:00,ylecun,"@ylecun Animals in nature are basically unsupervised learning. Except for the basic firmware that evolved naturally, everything else needs to be learned after birth.",0,0,0
1189,2023-02-06 02:51:44+00:00,ylecun,@ylecun I'm waiting for CatGPT now,0,0,0
1190,2023-02-06 02:49:29+00:00,ylecun,"@ylecun Based on a bird's understanding of the world, I think the biological brain must have another effective network structure for modeling the world. Multimodal training may be one of the key steps.",0,0,0
1191,2023-02-06 02:45:08+00:00,ylecun,"@ylecun For a bird to survive in this world, it must model the world, especially visual modeling. Find food, bypass obstacles, perform flight attitude control, and more. And these only rely on the brain with less than 0.2w power consumption.",0,0,0
1192,2023-02-06 02:43:05+00:00,ylecun,"@ylecun Speaking of understanding, we have to figure out what understanding is. A bird can clearly model the world on vision.",0,0,0
1193,2023-02-06 02:39:26+00:00,ylecun,@ylecun We need a ‚Äòlarge-common sense-model‚Äô or a large-physics-model,0,0,0
1194,2023-02-06 02:39:18+00:00,ylecun,"@ylecun It's important to know what is understanding. ChatGPT is only a good fitting tool.
It is more like an ordinary student who has done a lot of exercises. He can easily cope with the problems that have appeared before, but helpless when faced with new one that require novel solution",0,1,0
1195,2023-02-06 02:38:19+00:00,ylecun,@ylecun You must not be talking about my dog... ü§£,0,1,0
1196,2023-02-06 02:37:34+00:00,ylecun,@ylecun First human level AI. Cats and dogs have higher level intelligence.,0,0,0
1197,2023-02-06 02:32:50+00:00,ylecun,"@ylecun @bboczeng actually I think 
""making a parachute bigger will allow to fly to outer space"" may be better:)",0,0,0
1198,2023-02-06 02:28:28+00:00,ylecun,@ylecun @Noahpinion üëé,0,1,0
1199,2023-02-06 02:24:48+00:00,ylecun,@ylecun Perhaps the jump from cat/dog to human will be so fast that we won‚Äôt even notice it. That would be my guess.,1,0,0
1200,2023-02-06 02:24:43+00:00,ylecun,@ylecun My belief is that we won't get there until we can figure out how to build stable models that can learn on their own without catastrophic forgetfulness and preprocessing data.,0,0,0
1201,2023-02-06 02:23:43+00:00,ylecun,"@ylecun I love my cat, but I‚Äôm not sure that‚Äôs true. https://t.co/EM7XER1O40",0,2,0
1202,2023-02-06 02:16:00+00:00,ylecun,"@ylecun @3DTOPO @alrhemist My cat just ran head first into a wall.......
Yesterday he got a bag stuck around his neck and ran all over the house knocking stuff over trying to get it off.",0,0,0
1203,2023-02-06 02:11:20+00:00,ylecun,"@ylecun @Noahpinion Interesting, thank you and @Noahpinion.

 I am slightly puzzled by the ""write"" in this quote ""Thus, relying on LLMs to get things right simply because humans get things write"" from the article.

Found it quite funny in the context.",1,5,0
1204,2023-02-06 02:10:44+00:00,ylecun,@ylecun But it has reached equivalence with management-level edicts. Not sure if that is good or bad‚Ä¶,0,0,0
1205,2023-02-06 02:10:25+00:00,ylecun,"@ylecun Isn't one big missing thing a physical form that would be integrated to the learning model? According to integrated information theory? 

But what do know I know.",0,0,0
1206,2023-02-06 02:06:45+00:00,ylecun,@ylecun Multimodal LLMs.. Even our actions and senses can be encoded into some kind of sequence and run through LLMs,0,0,0
1207,2023-02-06 02:06:03+00:00,ylecun,"@ylecun @bboczeng Truly, scaling language models should not be the key to achieving human level intelligence, it is even not sustainable. Nonetheless, how will you juxtapose the fact that it appears to be very effective by what we have seen towards achieving the so called human level intelligence?",0,2,0
1208,2023-02-06 02:04:52+00:00,ylecun,"@ylecun How close are we to insect level AI? Robotically, aren't we even further behind?",0,0,0
1209,2023-02-06 01:49:57+00:00,ylecun,"@ylecun Why we are comparing natural beings who deal with complex problems with AI which is simply trained for specific Jobs.

I think AI can never reach to natural beings level of consciousness since they are never trained in the first place in the way AI does.

Fundamental difference.",0,0,0
1210,2023-02-06 01:49:15+00:00,ylecun,@ylecun @yoavgo It's a moving target.,0,0,0
1211,2023-02-06 01:41:21+00:00,ylecun,"@ylecun I sense that the developmental route that AI is taking is quite different than a progression from mouse to cat, etc. Just like we're often surprised that AI can do things we thought were difficult but can't do things we thought were easy, I wonder if that trend will continue.",0,1,0
1212,2023-02-06 01:36:48+00:00,ylecun,"@ylecun @bboczeng llm works well, it passed Turing test of many ordinary people.",0,1,0
1213,2023-02-06 01:34:29+00:00,ylecun,"@ylecun Have you taken psychedelics? Just curious. More AI people should take them, just to understand the scale of the task.",0,0,0
1214,2023-02-06 01:33:55+00:00,ylecun,"@ylecun Key reason for ChatGPTs popularity is the web scale adoption on smaller tasks as well as robust grammatical command. It garnered  attention as it‚Äôs more usable than from other chatbots seen so far.

But it doesn‚Äôt have any reasoning ability.",1,0,0
1215,2023-02-06 01:33:08+00:00,ylecun,"@ylecun @bradysimpson55 they need to hardware it. and then interface it, and then use that as the base for development of the next big thing. transistors as transformers. etc.",0,0,0
1216,2023-02-06 01:30:51+00:00,ylecun,"@ylecun Yes, agreed. But somehow I think someone in the media will complain about how AI cat/dog will take over our jobs...üòÖ",0,0,0
1217,2023-02-06 01:30:49+00:00,ylecun,"@ylecun With the possible exception of Tesla, no one is even working on an AI with an understanding of the world.  An AI that plays Go, or writes text is no more likely to understand the world than a machine lathe.",0,0,0
1218,2023-02-06 01:29:16+00:00,ylecun,"@ylecun @OriolVinyalsML @elonmusk How an LLM is trained and how it is used are two different things. One usage does not define the thing. Nor are all LLMs trained using next-word prediction. You‚Äôve constrained the definition to guarantee obsolescence, making the point correct but also pointless.",0,3,0
1219,2023-02-06 01:28:56+00:00,ylecun,"@ylecun @Noahpinion Of course, @emilymbender said exactly this in the stochastic parrots paper 2 years ago but then you don't seem fond of giving credit where credit is due.",0,0,0
1220,2023-02-06 01:27:35+00:00,ylecun,@ylecun Elephants don‚Äôt play chess.,1,0,0
1221,2023-02-06 01:27:01+00:00,ylecun,@ylecun https://t.co/229KdeCp4v,0,2,0
1222,2023-02-06 01:20:14+00:00,ylecun,@ylecun üòÇüòÇüòÇü§¶‚Äç‚ôÇÔ∏è,0,0,0
1223,2023-02-06 01:19:34+00:00,ylecun,"@ylecun Agreed. ChatGPT, GPT-3, OPT, Bloom and other LLM are nothing more than super advanced autocompletes. Autocomplete != intelligence.  This guy goes into it in way more detail. https://t.co/5HA7JXT07w",0,1,0
1224,2023-02-06 01:15:55+00:00,ylecun,"@ylecun @Noahpinion @GaryMarcus is right. You have begun to channel him.
ChatGPT doesn't constantly lie. That is a lie :)",1,3,0
1225,2023-02-06 01:14:45+00:00,ylecun,"@ylecun @Noahpinion Thank you very much for sharing Yann! 

It's important to recognize the current limitations of LLMs to look for improvement possibilities.",0,3,0
1226,2023-02-06 01:09:12+00:00,ylecun,"@ylecun I dunno, I've never seen a roomba lick an electric outlet.",0,0,0
1227,2023-02-06 01:09:05+00:00,ylecun,"@ylecun Yann, I agree with your general point. However, it‚Äôs good to appreciate the ‚Äúusefulness‚Äù of ChatGPT.",0,0,0
1228,2023-02-06 01:07:15+00:00,ylecun,@ylecun See. Now you cannot bs because we literally use the product.,0,0,0
1229,2023-02-06 00:53:33+00:00,ylecun,@ylecun Yet still I find them very useful,0,0,0
1230,2023-02-06 00:52:28+00:00,ylecun,@ylecun The distance from cat -&gt; dog -&gt; human level in AI is possibly not as far apart as one might expect.,0,0,0
1231,2023-02-06 00:44:35+00:00,ylecun,"@ylecun An alternative: someone leap frogs straight from here to Post-Human-Level AI (PHLAI), and then uses that to build AGI in only two steps.",0,0,0
1232,2023-02-06 00:40:14+00:00,ylecun,"@ylecun Dude, you should just apologize to OpenAI's researchers and devs and admit there's a chance you're wrong even though you're pretty sure you're right and stop thinking about this silliness.",0,0,0
1233,2023-02-06 00:39:58+00:00,ylecun,"@ylecun Haha i appreciate you replying to everyone, as a CS student i learn a lot from your replies.",0,0,0
1234,2023-02-06 00:36:02+00:00,ylecun,@ylecun What might be a need for building an AGI with common sense? Can we do that with the current statistics-based approach?,0,0,0
1235,2023-02-06 00:33:17+00:00,ylecun,@ylecun I think the entire Internet is like RLHF!,0,0,0
1236,2023-02-06 00:32:26+00:00,ylecun,"@ylecun seems to me (as someone with no expertise in this field), that if we ever *do* reach cat level AI, human AI will be just around the corner. B/c whatever we're missing will have been found. Us vs cat is just moderate scaling up, I think?",1,1,0
1237,2023-02-06 00:31:05+00:00,ylecun,"@ylecun Let's move beyond mammals: A fish and a lizard have more common sense and understanding of the world than any LLM. And on top they can move in it and manipulate objects...

@scioi_cluster",0,1,0
1238,2023-02-06 00:29:54+00:00,ylecun,@ylecun Ai is dumber than a rodent,0,0,0
1239,2023-02-06 00:27:18+00:00,ylecun,"@ylecun House cats don‚Äôt understand the back door and the front door connect to the same place,",0,0,0
1240,2023-02-06 00:12:27+00:00,ylecun,@ylecun @Noahpinion Sir Now you're involving something personal,0,2,0
1241,2023-02-06 00:11:01+00:00,ylecun,"@ylecun @ylecun I couldn‚Äôt agree with you more. LLM are too shallow for human level AI. They are based on exceptional understanding of our world, which they can spout, but hardly understand. Human beings sleep and train in our simulator called dreams to train and develop intelligence.",0,0,0
1242,2023-02-06 00:10:31+00:00,ylecun,@ylecun thanks for saying this aloud. It might not be the recognition of the limitations of AI the world wants to know about but the world needs to know about... :),0,0,0
1243,2023-02-06 00:08:23+00:00,ylecun,@ylecun I respect your decision So Trust The Process,0,0,0
1244,2023-02-06 00:07:42+00:00,ylecun,"@ylecun @Noahpinion Interesting question. Maybe the lies and self-interest in economics are more coherent and consistent than the ""truths"".",0,0,0
1245,2023-02-06 00:05:44+00:00,ylecun,"@ylecun Can you make a computer feel a need for affection and love, or does it just outwardly manifest traits üòø",0,0,0
1246,2023-02-06 00:05:03+00:00,ylecun,@ylecun how about building a biological AI?,0,0,0
1247,2023-02-06 00:03:02+00:00,ylecun,"@ylecun @Noahpinion This is very good Yann but don't you agree that the ""Stochastic Parrots"" (or as I prefer, stochastic mimics) analysis made this very clear?",0,10,0
1248,2023-02-05 23:56:37+00:00,ylecun,@ylecun Perhaps #FAIR should share more of your applicable research in those context awareness domains. For instance why isn‚Äôt human anatomy incorporated in image generation? Why are fingers so hard to be generated?,0,0,0
1249,2023-02-05 23:53:46+00:00,ylecun,"@ylecun @Noahpinion The reason why ChatGPT lies is that there is no good reward function to support it. RLHF is one piece of the puzzle, we need more from knowledge base, interaction with the physical world, humans...Reinforcement Learning with All Feedback?",0,2,0
1250,2023-02-05 23:52:31+00:00,ylecun,"@ylecun @alrhemist As for your claim, that is not what I experienced.

Galactica had a hallucination rate darn near 100%

ChatGPT is more around 15%.

I believe I know how Galactica could be far more successful and I've shared my ideas with you before (which has been validated since then).",1,0,0
1251,2023-02-05 23:47:45+00:00,ylecun,"@ylecun –Ø –ø–æ–ø—ã—Ç–∞–ª—Å—è –Ω–∞–π—Ç–∏ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ, —è –±—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω, –µ—Å–ª–∏ –≤—ã —Å–∫–∞–∂–µ—Ç–µ –º–Ω–µ –Ω–∞ —Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å.

–°–ø–∞—Å–∏–±–æ 

""CORRECT THINKING: THE KOKHAN‚ÄôS MATHEMATICS""
https://t.co/1lUGcRcG3u",0,0,0
1252,2023-02-05 23:45:05+00:00,ylecun,@ylecun @Noahpinion ChatGPT is more a BSer than anything. If you compare with an average human it outperforms. For so@e reason we expect more from AI than average human.,0,1,0
1253,2023-02-05 23:41:11+00:00,ylecun,@ylecun Would we even know if AI became sentient? How does anyone know what ghosts are in the machines?,0,0,0
1254,2023-02-05 23:36:36+00:00,ylecun,"@ylecun Do you think it's time we fund and explore alternate computing paradigms at scale, like neuromorphic computing?",0,0,0
1255,2023-02-05 23:34:54+00:00,ylecun,@ylecun What about LLMs x robotics? Since they can code they can code robots and learn stuff about the real world.,0,0,0
1256,2023-02-05 23:32:42+00:00,ylecun,@ylecun Can we please stop pretending like there's a direct hierarchy of intelligence with humans on top?,0,0,0
1257,2023-02-05 23:29:01+00:00,ylecun,"@ylecun @bboczeng He is not saying that we just need to scale LLMs to get to HLAI, he is saying we likely don't need an AI dog to get there.Also I think we don't need to fully understand human intelligence to replicate it, we've built LLM without fully understanding language processing in humans",2,9,0
1258,2023-02-05 23:27:44+00:00,ylecun,@ylecun https://t.co/Za5GHD3I1m,0,0,0
1259,2023-02-05 23:27:26+00:00,ylecun,"@ylecun It‚Äôs not the human level that is of concern, but what corrupt humans will do with the technology.",0,0,0
1260,2023-02-05 23:25:33+00:00,ylecun,"@ylecun @alrhemist True, lots of programmers do it every day.",0,0,0
1261,2023-02-05 23:24:48+00:00,ylecun,"@ylecun @alrhemist It has a far better understanding of the code it writes than say a cat.

To the point it is actually useful.",3,6,1
1262,2023-02-05 23:22:50+00:00,ylecun,@ylecun @benalsop Crows and Ravens have relatively small brains yet are among the smartest non-human animals. (they even use tools to repair tools!),0,2,0
1263,2023-02-05 23:21:38+00:00,ylecun,"@ylecun ChatGPT: tired
CatGPT: new hotness
My cat: can I haz $10b from Microsoft? Though I'm more of an Amazon (box) fan tbh https://t.co/d2SsEsPqCm",0,2,0
1264,2023-02-05 23:19:40+00:00,ylecun,@ylecun My cat has yet to fix my coding bugs though.,0,0,0
1265,2023-02-05 23:16:56+00:00,ylecun,@ylecun this may be a very good dataset to utilize,0,0,0
1266,2023-02-05 23:15:07+00:00,ylecun,@ylecun Non-intelligent software entities certainly compete with us quite successfully in many ways.,0,0,0
1267,2023-02-05 23:14:26+00:00,ylecun,"@ylecun sir, how about pairing it with vision and ability to manipulate objects with robotic limbs and get it to cooperate and compete with different agents using language and thereby create an understanding in those agents using language.",1,0,0
1268,2023-02-05 23:13:21+00:00,ylecun,@ylecun @andrewgwils ‚ÄúCompletely new‚Äù. I wonder what such a thing could be? How can we represent the semantics of such a thing? How would we recognize it if we saw it? Only a man with no doubts in his mind could see such a thing.,0,0,0
1269,2023-02-05 23:12:49+00:00,ylecun,@ylecun Do you think that multi-modal input data would be the trick to achieve such understanding?,0,0,0
1270,2023-02-05 23:11:03+00:00,ylecun,"@ylecun I just don‚Äôt think this is true. What can a dog do that SayCan can‚Äôt do, once we set aside the limitations of its robot body?",1,2,0
1271,2023-02-05 23:10:24+00:00,ylecun,@ylecun Most apps do not need human AI as they are not performing the tasks related to a human body (or cat).,0,0,0
1272,2023-02-05 23:09:47+00:00,ylecun,@ylecun The road to cat / dog level AI may be long. But the road from cat-level-AI to AGI is probably under 1 year.,0,0,0
1273,2023-02-05 23:08:54+00:00,ylecun,"@ylecun @bradysimpson55 Yes. The more I see precisely what you mean, the more I agree. Perhaps I don't tune in enough to who is saying what. Does anyone (important) still seriously adhere to knowledge as purely linguistic? Seriously think, LLM, narrowly defined, can achieve AGI/HLAI?",1,2,0
1274,2023-02-05 23:08:23+00:00,ylecun,"@ylecun @alrhemist One has to have some experience of python though. LLMs have no experience of reality, which is sort of a prerequisite to understanding.",0,0,0
1275,2023-02-05 23:06:10+00:00,ylecun,"@ylecun Exactly. I'm available to consult on building cat &amp; dog level AI. https://t.co/lmU4bOn8G0 I could build it myself if I had the resources, but I don't, I need funds, equipment, and people.",0,0,0
1276,2023-02-05 23:02:37+00:00,ylecun,@ylecun @benalsop It is the ratio of neuros to body mass that matter.... elephants have more neuros than us!,1,0,0
1277,2023-02-05 23:01:03+00:00,ylecun,"@ylecun Summary: Language only works because we all carry with us the expansion table that maps linguistic tokens to a lifetime of sensory-motor &amp; internal experiences, enabling us to decompress the extremely compressed data stream on the fly.",1,2,0
1278,2023-02-05 23:00:59+00:00,ylecun,@ylecun Hot take: Cat videos did more for AI than any LLM so far.,3,47,4
1279,2023-02-05 22:58:40+00:00,ylecun,@ylecun @bradysimpson55 no one needs LLM to behave like a cat,0,1,0
1280,2023-02-05 22:57:39+00:00,ylecun,@ylecun you‚Äôre welcome yann leCat https://t.co/fypBzXRHFC,0,4,0
1281,2023-02-05 22:56:40+00:00,ylecun,"@ylecun sometimes (we know this from history) Edward from Omaha may be a degree math scientist who dont have posibility to work in field from many different reasons... btw... ;) 
https://t.co/jpyVzwfH8u",0,4,0
1282,2023-02-05 22:56:29+00:00,ylecun,"@ylecun Peut-on appliquer ce raisonnement, √† la communication √† toutes √©chelles ?",0,0,0
1283,2023-02-05 22:52:28+00:00,ylecun,"@ylecun Lol, that‚Äôs like saying before we could drive, we should have learned how to gallop üèá first.",0,0,0
1284,2023-02-05 22:52:01+00:00,ylecun,"@ylecun That is because of motivation and restriction. A cat wants to survive while it is restricted in resources &amp; energy it can spend. That has been the same for the entire evolution of life. It's entire existence is defined by this. Our ""AI"" models have none of that.",0,0,0
1285,2023-02-05 22:50:49+00:00,ylecun,"@ylecun My concern towards LLMs is the possible biased parameters which might provide an ""Authoritative"" answer to most people instead of searching for diverse opinions like google search",0,0,0
1286,2023-02-05 22:50:43+00:00,ylecun,"@ylecun So LLMs cant lead to AGI so no x-risk, slow down AGI by stealing researchers and compute, and produce useful tools. Where's the problem?",0,0,0
1287,2023-02-05 22:46:59+00:00,ylecun,"@ylecun instead of all the snark, would it be easier to just release something people use? or nah",0,13,0
1288,2023-02-05 22:40:59+00:00,ylecun,"@ylecun True, but the tech is a lot better and available to mass than what was there few weeks ago, progress is what really matters",0,1,0
1289,2023-02-05 22:39:23+00:00,ylecun,@ylecun @Chaitanyaa_3,0,1,0
1290,2023-02-05 22:39:00+00:00,ylecun,"@ylecun And before that we'll have to reach insect level which is within reach using today's technology.

The big thing that's missing is being embodied.

At least, it was realised in the '90s and then seemingly forgotten again.",0,2,0
1291,2023-02-05 22:33:12+00:00,ylecun,@ylecun @alrhemist a cat just eats food or poops in a box (sometimes). chatGPT is way more useful .,0,0,0
1292,2023-02-05 22:32:56+00:00,ylecun,"@ylecun You say this as if HLAI is the obvious objective we should be trying to reach.
Neither my cat nor my dog use their understanding of the world to contribute to getting my work done, while an existing LLM is actually suggesting lines of code and functions to me that actually work.",0,0,0
1293,2023-02-05 22:31:40+00:00,ylecun,@ylecun AI will always be an emulation.,0,0,0
1294,2023-02-05 22:30:11+00:00,ylecun,"@ylecun simplicity, simple forms, primitives, less data... nature is simple... everything on earth is build from small parts",0,0,0
1295,2023-02-05 22:28:42+00:00,ylecun,"@ylecun How exactly decisive it is language to describe human intelligence? From 0 to absolutely, it's been established since Aristotle.",0,0,0
1296,2023-02-05 22:28:33+00:00,ylecun,@ylecun RLHF needs to be internal between models. RLMF.,0,0,0
1297,2023-02-05 22:25:02+00:00,ylecun,@ylecun Something big is artificial mind. The mind determines motivation and uses the intellect to achieve the goal.,0,0,0
1298,2023-02-05 22:19:19+00:00,ylecun,@ylecun Cats and dogs don't have cortexes like ours but their cerebellums show a close degree of development - which is a large part of the reason why they have rich emotions like our own and why we then relate to them as we do.,0,0,0
1299,2023-02-05 22:18:38+00:00,ylecun,"@ylecun I am a total ignorant about AI, but my intuition would say, if we were able to reach some specific functionalities of the human brain first (alghough by different means), maybe those will facilitate the transit to functionalities that are not unique to humans. It could be that",1,0,0
1300,2023-02-05 22:18:22+00:00,ylecun,@ylecun @karpathy https://t.co/bggEgjEAqD,0,0,0
1301,2023-02-05 22:15:40+00:00,ylecun,"@ylecun Too much philosophy.. Elephants has oom more neurons than humans. With unexplained phenomenas like intelligence, researchers and practitioners should try to reproduce/imitate and explain back. Examples: flight, electricity, radiology, goes back to even üî•",0,0,0
1302,2023-02-05 22:14:45+00:00,ylecun,"@ylecun OK, now OpenAI needs to publish CatChatGTP so that we can properly evaluate.",0,0,0
1303,2023-02-05 22:14:36+00:00,ylecun,"@ylecun @yannx0130 I don't see much to disagree with in your paper. I'm interested in a focus on how current/predicted state of 3D world is represented in short term memory, in a dynamic and resource-efficient manner. While key-value pairs are great for arbitrary abstraction, I don't think/...",1,0,0
1304,2023-02-05 22:13:16+00:00,ylecun,@ylecun LLMs are not trained on navigating the real world.,0,0,0
1305,2023-02-05 22:13:12+00:00,ylecun,@ylecun Common sense is a fake concept. Understanding of the world probably is too.,0,0,0
1306,2023-02-05 22:12:34+00:00,ylecun,"@ylecun Yes, because debate on the platform is the PRODUCT. It‚Äôs less about science or truth.",0,0,0
1307,2023-02-05 22:10:09+00:00,ylecun,"@ylecun Idk why you are making a race for AGI so crucial, and suprisingly strictly opposing it to LLM progress

Just let the LLMs shine on their own use cases, you might be impressed",0,0,0
1308,2023-02-05 22:09:02+00:00,ylecun,"@ylecun LLM do fascinate also indicate that ‚ÄúEnglish‚Äù could be next programming language, however, linguistic abilities in humans came much later, visual learning (pictures, scenes) was from day one.

That‚Äôs why more ways to train AI models such as image, videos, symbols will accelerate.",0,0,0
1309,2023-02-05 22:08:24+00:00,ylecun,@ylecun Are you implying that we already have bee-level AI?!,0,9,1
1310,2023-02-05 22:05:21+00:00,ylecun,"@ylecun We only 'need' to if you conceive intelligence as a strictly limited and local phenomenon.

An intelligence can easily exist in an organization or network, and that's probably where AGI comes from (by accident ofc lol)",0,0,0
1311,2023-02-05 22:04:54+00:00,ylecun,@ylecun I'm not mad about that.,0,0,0
1312,2023-02-05 22:02:58+00:00,ylecun,@ylecun I'm still waiting for my idea to come true. https://t.co/ZgAKdDzxaE,0,0,0
1313,2023-02-05 22:01:26+00:00,ylecun,"@ylecun You should ask ChatGPT to rewrite your tweets to sound less bitter and small. 

You‚Äôre a total badass in AI. Take the L on  ChatGPT and move on with your projects.

Being bitter helps nobody, and least of all yourself.",3,22,1
1314,2023-02-05 21:58:52+00:00,ylecun,@ylecun there's no such thing as binary right/wrong in the context of natural languages. the notion of true/false belong to the realm of computation and religion,1,1,0
1315,2023-02-05 21:58:31+00:00,ylecun,"@ylecun It's like saying to build a plane , we need grow feathers.
Engineering is not something that necessarily imitates natural selection/evolution",5,95,2
1316,2023-02-05 21:57:30+00:00,ylecun,"@ylecun Arsac toujours (postface √† Dreyfus) : nous sommes intelligents parce que nous sommes n√©s de parents, avec un corps et des relations affectives et sexuelles qui nous font souffrir et jouir, une histoire, des sensations, des √©motions, etc. Comme le chat, en fait.",0,2,0
1317,2023-02-05 21:56:56+00:00,ylecun,@ylecun well said,0,0,0
1318,2023-02-05 21:55:25+00:00,ylecun,@ylecun LOL,0,0,0
1319,2023-02-05 21:50:55+00:00,ylecun,"@ylecun Maybe we should train AI not on text, but real world interaction with multiple senses?",0,0,0
1320,2023-02-05 21:47:31+00:00,ylecun,@ylecun Why does AI need a mamailian brain and reptilian brain? That's just an artifact of our evolution.  AI will be more intelligent than us.  Why does it need our same brain architecture?,0,0,0
1321,2023-02-05 21:46:44+00:00,ylecun,@ylecun https://t.co/gBVF9YfVac,0,0,0
1322,2023-02-05 21:46:24+00:00,ylecun,@ylecun Techie battle ground üòÇ,0,0,0
1323,2023-02-05 21:46:03+00:00,ylecun,"@ylecun wait, but does anyone have some claim to path to AGI over someone else?  this is all so weird.  isn't history full of weird accidents of discovery?  or was history always a path of obvious discovery by the accepted sources of discovery?",2,7,0
1324,2023-02-05 21:45:30+00:00,ylecun,@ylecun It doesn't have an intrinsic need to survive. No motivation.,1,0,0
1325,2023-02-05 21:45:25+00:00,ylecun,"@ylecun It might be an off ramp but it might be a necessary one. There will be a question at one point that we need to face and answer as a whole species, till when progress in AI will need to be tamer? Not blaming anyone, I work myself in AI research",0,0,0
1326,2023-02-05 21:43:27+00:00,ylecun,@ylecun I wouldn't underestimate Edward from Omaha the way you underestimated Sam from San Francisco.,0,6,0
1327,2023-02-05 21:43:14+00:00,ylecun,"@ylecun @OriolVinyalsML @elonmusk TFs in some cas are not just next word prediction
but structure of sentense : any word is related to surrending words with some structure.
if texts is the model of the world (projected by humains)
some llm could be a growing capturing of the world (# params, textsamples)
correct?",0,0,0
1328,2023-02-05 21:43:07+00:00,ylecun,"@ylecun There is also a type of feedback (can it be implemented beside a RLHF), when you learn from the exchanges, judging the quality of each answer with heuristics, and other answers (it's a looped network of trust).
Like learning from a physicist debate.
Lurker's Learning.",0,0,0
1329,2023-02-05 21:41:47+00:00,ylecun,@ylecun Human like intelligence will follow dog intelligence extremely fast as I imagine it is simply a scaling exercise. The missing piece(s) will have explosive consequences.,0,0,0
1330,2023-02-05 21:41:14+00:00,ylecun,"@ylecun I only started paying attention to canine cognition after the dog genome was sequenced. If AI ever reaches cat-level AI, here's a brief indication of the quantum leap it will need after that. 
https://t.co/hnDzdkieCl
https://t.co/aRhVUUxA9v",0,0,0
1331,2023-02-05 21:40:13+00:00,ylecun,@ylecun A blind and deaf human appears to be intelligent. Is that a counter example?,0,0,0
1332,2023-02-05 21:38:58+00:00,ylecun,@ylecun @mapto That is not what the paper said though. Have you actually read it?,0,1,0
1333,2023-02-05 21:36:27+00:00,ylecun,"@ylecun @ylecun what will it take for everyone to admit defeat in order to stop your incessant tweets on ""ChatGPT is not revolutionary, deep learning is the best, Meta did everything..."". Really strange for senior folks of a company who fired 11k people to think like this",0,0,0
1334,2023-02-05 21:33:42+00:00,ylecun,@ylecun @andrewgwils Somewhere under Rachmaninoff,1,1,0
1335,2023-02-05 21:28:04+00:00,ylecun,"@ylecun @yannx0130 This could be said about dogs, cats or humans honestly. We are all trained neural networks with certainly more diversity than ChatGPT and a more complex architecture but the principle is the same. Not sure what ""understanding a complex world"" means.",1,1,0
1336,2023-02-05 21:26:49+00:00,ylecun,"@ylecun @yannx0130 If we're talking about efficient use of compute &amp; parameters, I think we agree. But scale a transformer to 100 or 1000 trillion parameters, train to predict future frames of video... I expect it'll do things that are very hard to dismiss as ""not human level"". /...",1,0,0
1337,2023-02-05 21:26:44+00:00,ylecun,@ylecun Erreur. Je ne re√ßois quasiment jamais de feedback.,0,0,0
1338,2023-02-05 21:25:52+00:00,ylecun,"@ylecun My opinion: the cat ‚Äúthinks‚Äù.  The AI tool does not ‚Äúthink‚Äù, it reformulates previously consumed information. I, too, think we‚Äôre a looonnnggg way from there.",0,0,0
1339,2023-02-05 21:24:44+00:00,ylecun,@ylecun Crowds dont know models are based on statistics. Tough to convince crowds. Enjoy the hype sir,0,0,0
1340,2023-02-05 21:22:05+00:00,ylecun,@ylecun Which types of AI aim at capturing and understanding common sense? Most AI I know target reproducing only one skill (human or less).,0,0,0
1341,2023-02-05 21:20:24+00:00,ylecun,"@ylecun @bradysimpson55 When you say ""LLM"" are you referring to transformers in general? Or are you specifically referring to transformers trained on next-word prediction of text?

I agree that transformers as such will neither be the most compute nor the most parameter efficient form of AI.",1,0,0
1342,2023-02-05 21:18:03+00:00,ylecun,@ylecun why do we want to reach human level AGI?,0,0,0
1343,2023-02-05 21:14:41+00:00,ylecun,"@ylecun @yannx0130 Is this not just an issue of scale? Processing video will involve input vectors several orders of magnitude larger. The model must scale at least linearly, perhaps as N^2.",1,0,0
1344,2023-02-05 21:14:39+00:00,ylecun,"@ylecun You talk too much, show your products.",0,1,0
1345,2023-02-05 21:13:32+00:00,ylecun,"@ylecun @elonmusk @OriolVinyalsML Hate to say it, but I haven‚Äôt seen any reasonably young people debating useful stuff on FB for a long time. üòõ",0,0,0
1346,2023-02-05 21:11:30+00:00,ylecun,@ylecun Surely also a matter of size: we need learners able to use each other's outputs u,0,0,0
1347,2023-02-05 21:10:26+00:00,ylecun,@ylecun Is even Cat-Level &amp; Dog-Level 'AI' within the limits of AI at all?,0,0,0
1348,2023-02-05 21:09:31+00:00,ylecun,"@ylecun The universe is not locally real, it‚Äôs made of information",1,1,0
1349,2023-02-05 21:08:10+00:00,ylecun,@ylecun That's like saying that on the journey to NY you will fly over Europe and the Atlantic ocean. Not if you come from India though and you fly over Korea and the Pacific to get to the US. Many roads lead to a destination and applying the bus-stops of one to all others is misguiding.,0,0,0
1350,2023-02-05 21:07:55+00:00,ylecun,"@ylecun @benalsop Synapse count would be more relevant and neocortical synapses in particular. But it's not just how many, it's how they are used. Domestic dog v cat, dogs probably ""smarter"", given more complex social interactions. Wolf vs lion? Probably about the same.",1,1,0
1351,2023-02-05 21:03:07+00:00,ylecun,@ylecun @benalsop Which dogs and cats? Lions beat all dog breeds on: https://t.co/HksUUGPDef,1,1,0
1352,2023-02-05 21:01:17+00:00,ylecun,"@ylecun My cat has a lot of common sense. When the polar vortex hit us yesterday, she decided to sleep by the fireplace. Clever girl.",0,1,0
1353,2023-02-05 21:00:37+00:00,ylecun,@ylecun https://t.co/enk5UQX0iS,0,2,0
1354,2023-02-05 21:00:22+00:00,ylecun,@ylecun who would you rather take medical advice from - a cat or ChatGPT?,0,0,0
1355,2023-02-05 20:59:13+00:00,ylecun,@ylecun @bradysimpson55 And the market is saying you're wrong.,0,1,0
1356,2023-02-05 20:58:26+00:00,ylecun,@ylecun it‚Äôs almost as though they‚Äôre‚Ä¶ stochastic parrots,0,0,0
1357,2023-02-05 20:58:23+00:00,ylecun,"@ylecun For now, I think we should be satisfied with not having it ""problem solve"" or having understanding of reality. Baby steps. LLM like ChatGPT is a mind boggling first step.",0,1,0
1358,2023-02-05 20:58:18+00:00,ylecun,@ylecun I'm pretty sure my dog can't write me a poem about fishing in the style of Abraham Lincoln,0,0,0
1359,2023-02-05 20:55:32+00:00,ylecun,@ylecun One issue I see with this is the requirement for models to be differentiable. Somehow I think we will have to get rid of the expensive backpropagation and find another model that doesn't need to be differentiable.,0,0,0
1360,2023-02-05 20:54:48+00:00,ylecun,"@ylecun But why does AGI have to be 'human-level'?
Why can't it be some other kind of 'super-consciousness'? Like an AI-enabled Internet with 1 billion+ human inputs? 
AGI could bypass the 'common sense' needs of house cats, &amp; reach for the stars.",0,0,0
1361,2023-02-05 20:54:27+00:00,ylecun,@ylecun and our neural nets get interesting prompts served that yield to outputs that serve as inputs to other neural nets etc.,0,0,0
1362,2023-02-05 20:52:06+00:00,ylecun,"@ylecun Human level - on what scale? If IQ, see: https://t.co/glNikOWkOu",0,0,0
1363,2023-02-05 20:51:58+00:00,ylecun,"@ylecun Ah, human generated ones to need to reach comprehension of cat level, dog level systems and so on first, then theirs,‚Ä¶",0,0,0
1364,2023-02-05 20:51:40+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML Not petty at all ü§£,0,0,0
1365,2023-02-05 20:51:11+00:00,ylecun,@ylecun @alrhemist What if your understanding of reality is not necessarily absolute,0,0,0
1366,2023-02-05 20:50:50+00:00,ylecun,"@ylecun @benalsop Yeah but they use them to be twice as annoying, not twice as intelligent üßå",1,0,0
1367,2023-02-05 20:50:07+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML You all debate. We all learn in the process. Keep it up,0,0,0
1368,2023-02-05 20:49:51+00:00,ylecun,@ylecun https://t.co/i8x1K8SjW3,0,0,0
1369,2023-02-05 20:49:29+00:00,ylecun,"@ylecun Is it possible that embodiment, and the necessity of learning non-verbal cues, real physics etc, will result in something closer to AGI? It‚Äôs interesting that the greatest leaps of human imagination, like relativity, were so hard because they could not be perceived at human scale",0,5,0
1370,2023-02-05 20:49:15+00:00,ylecun,"@ylecun ""Way more"" is not exactly quantifiable. Citation required.",0,0,0
1371,2023-02-05 20:48:01+00:00,ylecun,@ylecun We underestimate the extent to which cognition is embodied?,0,0,0
1372,2023-02-05 20:47:06+00:00,ylecun,"@ylecun More useful than X-animal level is what percent of employees could be replaced by any AI system. AI systems don‚Äôt necessarily have to replace human employees completely. Eg, how many employee equivalents = 1 human + Chat GPT? How many = 1 human + (ChatGPT + WolframMathematica)?",0,0,0
1373,2023-02-05 20:45:25+00:00,ylecun,"@ylecun @benalsop Try introducing to LLM model the distinct I. 

We ‚Äúexist‚Äù because our language includes an I which has seemingly self determined but in reality a self created in and exists only in language. 

Current LLM models doesn‚Äôt allow for the same due to ethical reasons.",1,0,0
1374,2023-02-05 20:45:09+00:00,ylecun,"@ylecun If you figure out how to train a transformer type model with all the cat videos on the Internet, would it reach cat level general intelligence?",0,0,0
1375,2023-02-05 20:44:18+00:00,ylecun,"@ylecun I doubt AI has to ""get"" common sense in the same way we do. There could be a route of adapting LLMs to model the common sense knowledge cats gain from other modalities. 
Break the trough the barreer of logical inconsistency, then you might have a way stronger AI in your hands.",1,0,0
1376,2023-02-05 20:41:40+00:00,ylecun,@ylecun Here is the challenge for HLAI: Design an algorithm that can can experience an orgasm.,0,0,0
1377,2023-02-05 20:40:23+00:00,ylecun,@ylecun How do you measure that?,0,0,0
1378,2023-02-05 20:37:53+00:00,ylecun,@ylecun My Siberian Husky believes that wolf-staring at me continuously (Dog-Level AI) is far more effective than any LLM for delivering answers,0,0,0
1379,2023-02-05 20:35:24+00:00,ylecun,"@ylecun Even it the AI cannot get a human to feed it, as long as it can improve itself indefinitely we are screwed...",0,1,0
1380,2023-02-05 20:34:40+00:00,ylecun,@ylecun @barbarikon Agreed.,0,1,0
1381,2023-02-05 20:34:07+00:00,ylecun,"@ylecun I get what you are saying &amp; broadly agree. But I think we should distinguish between ""level"" vs. ""type"". LLMs learn &amp; do something very different from what biological brains learn and do. This makes comparing ""levels"" of intelligence difficult and subject to interpretation./...",1,2,0
1382,2023-02-05 20:33:27+00:00,ylecun,"@ylecun Cat's and dog's cognition is largely tuned for interaction with the physical world (navigation, hunting, finding mates). Human cognition is arguably more separate from the immediate physical world. Not sure if the route to HLAI needs to go through dog and cat.",0,0,0
1383,2023-02-05 20:31:56+00:00,ylecun,@ylecun @bradysimpson55 The fully autonomous AI in your future view sounds pretty dangerous Yann. The current OpenAI human/superhuman command of language seems more like a useful tool that humans can control.,1,2,0
1384,2023-02-05 20:31:53+00:00,ylecun,@ylecun Yeah i believe you üòâ,0,0,0
1385,2023-02-05 20:30:45+00:00,ylecun,"@ylecun ""Artificial fantasy and imagination"" is missing",0,0,0
1386,2023-02-05 20:30:26+00:00,ylecun,"@ylecun Wow, this is interesting to know!",0,0,0
1387,2023-02-05 20:29:30+00:00,ylecun,@ylecun Alright that should be it,0,0,0
1388,2023-02-05 20:28:54+00:00,ylecun,@ylecun My dog eats my cat‚Äôs turds straight from the box. He is highly intelligent in his own way.,1,0,0
1389,2023-02-05 20:28:17+00:00,ylecun,@ylecun Is AGI too buzz word-y now?,0,0,0
1390,2023-02-05 20:24:13+00:00,ylecun,"@ylecun Before they reach cat or dog level AI they have to reach the level of a housefly AI, cause a housefly has lowest living intelligence
which is so far",0,0,0
1391,2023-02-05 20:21:56+00:00,ylecun,@ylecun Thanks that‚Äôs fair but some of your tweets and stuff make it seem like what openai has put out isn‚Äôt useful. I‚Äôve found it  extremely impactful in my workflows. I think we should be excited for these developments for all of AI. Its been the most useful ai at scale imho,1,0,0
1392,2023-02-05 20:21:21+00:00,ylecun,@ylecun Not sure I agree,0,0,0
1393,2023-02-05 20:21:15+00:00,ylecun,@ylecun @likeazombie,1,1,0
1394,2023-02-05 20:18:39+00:00,ylecun,@ylecun No need for cat level - when the AI reaches Queen Bee intelligence - it will just be a matter of scale and speed to reach beyond human scale.   Only a few humans would be required at the top to take over the world.   Science Fiction is becoming day-to-day reality.,0,0,0
1395,2023-02-05 20:18:22+00:00,ylecun,@ylecun I'm so glad to read these words from you. It's empowering and exciting :),0,0,0
1396,2023-02-05 20:17:48+00:00,ylecun,"@ylecun And why do we need HLAI?

If we have a narrow AI for all tasks to replace human labor then it would be a world of abundance still.

HLAI does not need to exist for exponential gains in productivity.",0,0,0
1397,2023-02-05 20:15:39+00:00,ylecun,@ylecun What‚Äôs  a ‚ÄúDog and Cat level AI‚Äù?? üòÇüòÇüòÇ,0,0,0
1398,2023-02-05 20:15:35+00:00,ylecun,@ylecun https://t.co/H3RzZwnK1Z,0,0,0
1399,2023-02-05 20:14:20+00:00,ylecun,"@ylecun Yann, the human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, principles formulated, and related equations written by yours truly.",0,0,0
1400,2023-02-05 20:13:16+00:00,ylecun,"@ylecun As we have seen NN scale quite well. If we have figured out the fundamentels for a cat level AI, is should also scale to human level.
Depending on, if you are looking for a more generic AI and not some kind of specialized one.",0,0,0
1401,2023-02-05 20:13:15+00:00,ylecun,"@ylecun Agree but also think human level AI will be but a filament of time, AI will almost  instantly become god level intelligent once the trajectory is right",0,0,0
1402,2023-02-05 20:11:53+00:00,ylecun,"@ylecun @elonmusk @OriolVinyalsML If you are ""magnifying"" a ""minor divergence of opinions,"" this seems to somewhat fit the definition of pettiness though.",0,0,0
1403,2023-02-05 20:10:32+00:00,ylecun,"@ylecun AI lacks the ability to do salience landscaping and relevance realization. LLMs are just a very intricate map of how humans use language. It amazes us because it is so quick and expansive, so it sounds like a smart person. But there‚Äôs no ‚ÄúI‚Äù there.",0,2,0
1404,2023-02-05 20:10:07+00:00,ylecun,"@ylecun @alrhemist How many humans regurgitate stuff without understanding any of it? My guess is the majority (&gt;50%). So yes, gpt3 has already surpassed most humans",0,0,0
1405,2023-02-05 20:09:12+00:00,ylecun,"@ylecun @alrhemist It may not have an understanding of reality (whatever that even is - the jury is still out), but it does have an understanding of the code it writes.

It can document the code, explain what it is doing with the code, I can ask for changes and it explains the changes it has made.",2,12,1
1406,2023-02-05 20:09:00+00:00,ylecun,@ylecun CDLAI    I like it.,0,0,0
1407,2023-02-05 20:08:45+00:00,ylecun,"@ylecun a llm has never seen the world, it is not done for that",0,0,0
1408,2023-02-05 20:06:53+00:00,ylecun,"@ylecun Thank you very much for this! We are just at the beginning of IA , l don‚Äôt think one day we could reach the humain brain abilities.",0,0,0
1409,2023-02-05 20:05:59+00:00,ylecun,@ylecun I want to meet your cat now.,0,0,0
1410,2023-02-05 20:05:34+00:00,ylecun,"@ylecun First you might want to establish what human level even means or kind of pointless.

Chimps will give some people a run for their money, while others are the Davincis, Teslas, Bohrs, and Plancks.",0,0,0
1411,2023-02-05 20:01:15+00:00,ylecun,@ylecun @yannx0130 Unless  LLM training on video/ real world data is impossible surely the ‚Äòyet‚Äô is the key.,0,0,0
1412,2023-02-05 19:58:03+00:00,ylecun,@ylecun @yannx0130 But cat and dogs can‚Äôt do that even ü§Ø,0,0,0
1413,2023-02-05 19:56:45+00:00,ylecun,"@ylecun LLMs ""contextualize"" and understand only one tree in a vast forest (let alone the whole forest of near infinity trees that is reality).",0,0,0
1414,2023-02-05 19:56:04+00:00,ylecun,"@ylecun I do believe this.  But it's also obvious that LLM capabilities (even without the missing part) are already a big driver of change (and potentially much more is coming!)

Perhaps ""human-level"" is a misnomer.  Human level at what task may be the important question.",1,0,0
1415,2023-02-05 19:54:30+00:00,ylecun,"@ylecun This line is going to be crossed soon as multimodal approaches reach current LLM capabilities (vision, speech, language)",1,1,0
1416,2023-02-05 19:51:13+00:00,ylecun,@ylecun We will never reach human intelligence.... Mainly because it is mysterious and mutable... (Matt),0,0,0
1417,2023-02-05 19:49:49+00:00,ylecun,"@ylecun it also knows how to heal itself, give birth as well as a ton of other things ""learned"" the hard way through the evolution",0,0,0
1418,2023-02-05 19:48:09+00:00,ylecun,"@ylecun Embodiment, that's all we are missing",1,0,0
1419,2023-02-05 19:45:52+00:00,ylecun,"@ylecun Finally catching up are we
https://t.co/T1joKWOCfk",0,0,0
1420,2023-02-05 19:45:44+00:00,ylecun,@ylecun a cat knows things that a LLM doesnt about the physical world cuz a cat has played with the physical world.,0,0,0
1421,2023-02-05 19:43:15+00:00,ylecun,"@ylecun Biological intelligence is embodied in an environment and constant interaction, so the learning base has a naturally high number of observations that (maybe) lead to reasoning. I still think that ML demonstration is a form of intelligence not reasoning. Any opinion?",2,2,0
1422,2023-02-05 19:40:50+00:00,ylecun,@ylecun @benalsop Probably not going to get to HLAI soon if researchers believe that there's a linear relationship between # of neurons and intelligence. At the very least you need to normalize for body mass. And it's likely much more complicated then that. https://t.co/Gosvood0vW,1,3,0
1423,2023-02-05 19:40:02+00:00,ylecun,"@ylecun Thanks for answering.
I doubt clueless commenters can learn from any feedback. 
There ‚Äòre here only to get ego boost from attention. Or supposed attention, since most of the time there isn‚Äôt any.",1,1,0
1424,2023-02-05 19:39:55+00:00,ylecun,"@ylecun i don‚Äôt want my Ai to understand the world like a cat or a human. i want it to be able to understand X at 1000 times the level of a human even if it understands Y 1000 times worse than a vegetable.  

i don‚Äôt get the infatuation with ‚Äúgeneral‚Äù intelligence.",0,1,0
1425,2023-02-05 19:39:33+00:00,ylecun,@ylecun @benalsop And elephants have three times as many neurons as humans,1,16,0
1426,2023-02-05 19:38:57+00:00,ylecun,@ylecun Yet everyone keeps doing it for attention,0,0,0
1427,2023-02-05 19:37:50+00:00,ylecun,"@ylecun What's your plan for common sense, reasoning and understanding?",1,0,0
1428,2023-02-05 19:37:47+00:00,ylecun,"@ylecun Neurons can learn locally, without computing global gradients. Is anybody researching how?",0,0,0
1429,2023-02-05 19:36:50+00:00,ylecun,@ylecun why do we need an Ai to replicate any of these life forms?  it‚Äôs like saying we need flying machines that are like insects first then birds.  these would be useless to humans. we need planes/jets. we need Ai to be beyond human level at things.,0,1,0
1430,2023-02-05 19:36:36+00:00,ylecun,@ylecun This also dives into more philosophical and religious things than technical state of things as well.,0,0,0
1431,2023-02-05 19:36:30+00:00,ylecun,"@ylecun We need better robotic actuators for dog level AI.

AI needs to be able to manipulate things, not just look at labelled pictures.

You could simulate things maybe ‚Äî but to apply the model you need both good actuators and a pretty good simulator.",0,0,0
1432,2023-02-05 19:35:20+00:00,ylecun,"@ylecun I think the AI from Star Wars droids is a realistic future of how technology would be used. Everyone has a job even though an AI is there that could do it, but at the fear of getting revolted by not paying it the same as a human.",0,0,0
1433,2023-02-05 19:35:02+00:00,ylecun,@ylecun @benalsop Elephants and whales have more neurons than humans.,1,1,0
1434,2023-02-05 19:34:50+00:00,ylecun,@ylecun This is exactly my stance on the matter. The innate push for HLAI is indicative of an anthropic bias towards self replication and infatuation with self. The division of labor applies to robotics as well.,0,0,0
1435,2023-02-05 19:33:02+00:00,ylecun,"@ylecun How about insect-level AI? That was my first question on the subject at ai-philosophy. Not so sure we passed that, either. ;)",0,0,0
1436,2023-02-05 19:32:24+00:00,ylecun,@ylecun #AI #LLM https://t.co/amh5ZADHEf,0,0,0
1437,2023-02-05 19:31:14+00:00,ylecun,@ylecun Release a public product bro,0,0,0
1438,2023-02-05 19:31:04+00:00,ylecun,@ylecun üëé,0,0,0
1439,2023-02-05 19:30:48+00:00,ylecun,"@ylecun Both my cat and chatgpt can code, without realizing what it is. She has just finished coding a function calculating kl divergence  :) https://t.co/h83KWAIuZo",0,0,0
1440,2023-02-05 19:30:47+00:00,ylecun,"@ylecun Cats and Dogs have instinct, and smell/hearing based thought responses, which a logic-railed AI project won‚Äôt divert to experimnt towards?",0,0,0
1441,2023-02-05 19:30:20+00:00,ylecun,@ylecun Thanks for precising. It seems we are really missing sth important. The more i read about the more i like that topic. Maybe it is time for me to try to do some more hard work on it... Thanks again...,0,0,0
1442,2023-02-05 19:29:57+00:00,ylecun,@ylecun Good one,0,0,0
1443,2023-02-05 19:27:57+00:00,ylecun,@ylecun How to talk with cat ?,0,0,0
1444,2023-02-05 19:27:50+00:00,ylecun,"@ylecun Do you believe this still holds if we're only interested in ""brain-in-a-vat"" AI systems that don't interact with the physical world? 

Seems to me that the kind of ""common sense"" needed in the digital domain is different from that needed in the physical domain.",1,4,0
1445,2023-02-05 19:26:58+00:00,ylecun,"@ylecun I would say that composing replies necessarily involves a form of reasoning. Enforcing consistency amounts to inference, and I expect this is part of how they get things wrong as well as how they so often, so amazingly get things right.",0,0,0
1446,2023-02-05 19:26:31+00:00,ylecun,@ylecun Is this not a problem of the data set?,0,0,0
1447,2023-02-05 19:25:37+00:00,ylecun,"@ylecun Didn't need to progress from insect-sized flying machines to bird and finally to pterodactyl-sized. Our machines lift thousands of lbs of cargo, travel continents &amp; fly faster than sound, despite lacking biological efficiency. We're clrly approaching intelligence orthogonally.",0,0,0
1448,2023-02-05 19:25:31+00:00,ylecun,@ylecun https://t.co/zIESuDf2mm,0,0,0
1449,2023-02-05 19:24:48+00:00,ylecun,@ylecun @alrhemist Many people (including programmers) are just regurgitating without any understanding of reality,1,4,0
1450,2023-02-05 19:24:04+00:00,ylecun,"@ylecun Before we achieve space flight we will have to achieve bird-flight. We are nowhere near that. We are still missing something big, rocketry notwithstanding.

The point: there may be more than one valid path to AGI.",0,1,0
1451,2023-02-05 19:22:53+00:00,ylecun,@ylecun so what's your estimate for the year we achieve AGI?,0,0,0
1452,2023-02-05 19:22:48+00:00,ylecun,@ylecun Do we have training data for the lived experience of a cat or dog? It seems like our best bet is to use our vast databases of human-generated content to represent the human experience. Skipping over cats and dogs because they don't write / say / create anything to reference.,0,0,1
1453,2023-02-05 19:22:36+00:00,ylecun,@ylecun Couldn't have said it better.,0,0,0
1454,2023-02-05 19:22:12+00:00,ylecun,@ylecun https://t.co/Rd4wCiF1gw,0,1,0
1455,2023-02-05 19:20:51+00:00,ylecun,"@ylecun ‚úã An elderly orangutan obviously has a lot of nonverbal knowledge about the world incl. where're the best bananas in the jungle than a university professor whose nonverbal experience is limited to simple actions,such as pressing the coffee machine button
üëâ This logic is flawed.",0,0,0
1456,2023-02-05 19:20:51+00:00,ylecun,@ylecun Why should we believe that hlai is a worthwhile route point towards general intelligence ?,0,0,0
1457,2023-02-05 19:20:11+00:00,ylecun,"@ylecun Get on with it! JEPA, or GFlowNets, or whatever. Take us to System2, Captain.",0,0,0
1458,2023-02-05 19:19:59+00:00,ylecun,"@ylecun @ylecun how about vision transformer with a time dimension? From what I understand, they are just currently too much frames per second, and thus too expensive to make it scale well like the case of LLM. but the techniques are there, just need another #Alexnet or #chatgpt moment.",0,0,0
1459,2023-02-05 19:19:46+00:00,ylecun,"@ylecun Yes, LLM is more like expert system, but nonetheless prediction (what the cortex does) *is* the key component to intelligence. Feed perceptual embedding sequences vs words into a transformer and you're starting to get somewhere ...",0,1,0
1460,2023-02-05 19:19:31+00:00,ylecun,"@ylecun ...I say, as I'm being turned into a paperclip.",0,0,0
1461,2023-02-05 19:18:53+00:00,ylecun,@ylecun @GaryMarcus leave this body! https://t.co/Ys9cpmS1Jc,0,0,0
1462,2023-02-05 19:18:25+00:00,ylecun,@ylecun https://t.co/i4k36EiKG1,1,0,0
1463,2023-02-05 19:17:19+00:00,ylecun,"@ylecun You're saying intelligence is a complex multidimensional trait, that its possible to be hyperintelligent across human culture with major implications without directly emulating biological evolutionary intelligence first?? Im hearing that - im hearing that for the very first time https://t.co/Ag0oWsdows",1,9,0
1464,2023-02-05 19:17:12+00:00,ylecun,@ylecun https://t.co/qmGVNT1I6H,0,0,0
1465,2023-02-05 19:16:30+00:00,ylecun,"@ylecun Don't anthropomorphize general intelligence. 

As soon as you realize there is nothing special about human intelligence you realize that AGI has been here since AlphaGO. As you keep moving the goal posts on ""real"" intelligence this will become ever more obvious",1,2,0
1466,2023-02-05 19:15:41+00:00,ylecun,"@ylecun Ce qui manque, ce pourrait √™tre de consid√©rer, √† quoi et/ou √† qui, s' adressent les information internes.",0,0,0
1467,2023-02-05 19:15:33+00:00,ylecun,"@ylecun @bradysimpson55 Language is concept mapping.

We will obviously develop increasingly sophisticated concept navigations by simply adding scale and layers.

I agree that it's ultimately not the right architecture but an enormous range of ""human"" actions can be encoded via conceptualisation.",0,1,0
1468,2023-02-05 19:14:59+00:00,ylecun,@ylecun @alrhemist So you'll agree an LLM is in some ways smarter than a Cat,4,9,0
1469,2023-02-05 19:14:56+00:00,ylecun,"@ylecun I think in the statements like that, it‚Äôs important to be specific what you mean by ‚Äúunderstanding‚Äù, because it‚Äôs a vague term.
Do you have a good definition for it?",1,0,0
1470,2023-02-05 19:14:28+00:00,ylecun,"@ylecun ""A house cat has way more common sense and understanding of the world than any LLM.""

Giving a clear meaning to this statement is IMO very difficult.",4,25,0
1471,2023-02-05 19:14:28+00:00,ylecun,"@ylecun @Acion_Next Before we reach human-level flying, we'll have to reach swallow-level and eagle-level flying

We are nowhere near that",0,1,0
1472,2023-02-05 19:14:09+00:00,ylecun,"@ylecun @benalsop If we act with this approach, a tribe member with a spear and a leaf outfit has the same capacity to understand as someone who has completed his doctorate at the NYU. I think the important thing is the data fed into the system and the task expected to be done with this data.",1,0,0
1473,2023-02-05 19:13:42+00:00,ylecun,@ylecun @alrhemist One can. @OpenAI chatgpt can as well. But your @Meta #Galactic model could not ;),0,0,0
1474,2023-02-05 19:13:35+00:00,ylecun,@ylecun What tests can we devise to test Cat-level AI?,0,0,0
1475,2023-02-05 19:13:27+00:00,ylecun,"@ylecun but #Chatgpt is only trained on text, if it's trained with different sensor data, like vision, interacting with physical world to get a sense of what physical law looks like, can't see any reason why it can't get common sense. And universe always provides 100% accurate data.",3,0,0
1476,2023-02-05 19:13:15+00:00,ylecun,"@ylecun Cat‚Äôs an alien that shall exist after us too, Maybe ! üôÉ Hence, They‚Äôre told to have 9 lives, maybe !
 
Life, Death and Robots - ‚ÄúHow to tame a cat‚Äù episode (https://t.co/LBUrAqerRW) maybe convey the picture of far future !",0,0,0
1477,2023-02-05 19:12:54+00:00,ylecun,"@ylecun For example house cats have multisensory tokenised territorial mapping at subcubic centimetre resolution as part of their models but aren't great conversationalists in human language, other insofar as necessary to acquire satisfactory amounts of food, shelter and affection",0,2,0
1478,2023-02-05 19:12:31+00:00,ylecun,"@ylecun @alrhemist That suggests that holistic understanding of reality is overrated, not the other way around",0,0,0
1479,2023-02-05 19:11:52+00:00,ylecun,@ylecun So does mean we need progress involving embodied intelligence?,0,0,0
1480,2023-02-05 19:11:33+00:00,ylecun,@ylecun You will reach HLAI before anyone with your research. Nobody will know because you preferred the fat check that Facebook gives you rather than joining/starting a company that prioritize that vs Ads revenue or similar. And then you will say that HLAI is not blah blah,0,0,0
1481,2023-02-05 19:11:19+00:00,ylecun,"@ylecun Why? We reached superhuman level Go before we reached cat level Go. We reached superhuman knowledge before we reached cat level knowledge

I understand your point but it's rooted in a fetishistic assumption that ""brain architecture"" is the most sophisticated possible architecture",0,1,0
1482,2023-02-05 19:11:02+00:00,ylecun,@ylecun I can‚Äôt get my dog to write a poem,0,1,0
1483,2023-02-05 19:10:50+00:00,ylecun,@ylecun I'm not sure why you're so certain that we'll have to have some cat-level &amp; dog-level AI before human level. We're building AI specifically for human tasks so it could be that it gets better at more and more different human tasks until it's human level at almost everything,0,0,0
1484,2023-02-05 19:10:37+00:00,ylecun,"@ylecun who is this guy, i bet he cant even work the midjourney discord",0,0,0
1485,2023-02-05 19:10:33+00:00,ylecun,@ylecun @yudapearl Thanks. A lot in front of me to learn. But highly appreciate your replies.,0,3,1
1486,2023-02-05 19:08:50+00:00,ylecun,@ylecun Lion vs chihuahua. Let‚Äôs we who is smarter,1,2,0
1487,2023-02-05 19:07:48+00:00,ylecun,@ylecun Define human-level. Is it a 2 years old human? A teenager? Something smart as Einstein? And what metrics are you considering? These statements are way too vague and aren't serious as you usually are.,0,0,0
1488,2023-02-05 19:07:18+00:00,ylecun,"@ylecun What exactly is ‚Äúcommon sense‚Äù and ‚Äúunderstanding‚Äù?  

I don‚Äôt doubt there is much further to go towards AGI, but I‚Äôm surprised you are falling back on using vague, non well-defined notions to critique machine learning advances.",0,0,0
1489,2023-02-05 19:06:29+00:00,ylecun,@ylecun @bradysimpson55 Then what is? Please explain,1,2,0
1490,2023-02-05 19:05:39+00:00,ylecun,"@ylecun @alrhemist Two things. You really think humans are all that different? Secondly, if it makes itself useful, if we can get LLMs that help us develop science, technology and medicine, does it really matter how they do it?",1,0,0
1491,2023-02-05 19:05:25+00:00,ylecun,"@ylecun that's true and that can be changed by creating entry points in AI for people from bio-sciences, not just mathematicians, computer scientists, el.engineers and physicists as it is now. -saying this based on any requirement I have ever seen for any position in AI.",0,1,0
1492,2023-02-05 19:05:12+00:00,ylecun,"@ylecun My cat can‚Äôt write code as well as ChatGPT, is there something wrong with her ? https://t.co/0OYXtEoOJg",4,12,0
1493,2023-02-05 19:04:10+00:00,ylecun,"@ylecun Agreed.  

However https://t.co/jGjXPAJ3ub may turn out to be a component of HLAI, and in the meantime it provides explainable question answering over databases.",0,0,0
1494,2023-02-05 19:03:46+00:00,ylecun,@ylecun @alrhemist Is One in this case a Cat?,1,17,0
1495,2023-02-05 19:03:29+00:00,ylecun,@ylecun More significant will be two year old human.,0,1,0
1496,2023-02-05 19:03:24+00:00,ylecun,"@ylecun can Cat or Dog answer questions about RLHF like #Chatgpt?  It's quite straitforward to incorporate accurate knowledge to LLM, like using knowledge graph to get more factual answers.   and BTW Human  as a much LLM spill out nonsense as well. https://t.co/doAkF6LWqL",0,0,0
1497,2023-02-05 19:02:41+00:00,ylecun,@ylecun @alrhemist Now that reminds me of the Chinese room argument,1,3,0
1498,2023-02-05 19:02:37+00:00,ylecun,@ylecun I watched one of your older talks and you mentioned being inspired by Piaget. Are you still keeping him around in your mind as you think about big ideas still needed? I had a long conversation with  Aaron Sloman once and he felt there were insights from Piaget to be considered.,0,0,0
1499,2023-02-05 19:02:21+00:00,ylecun,@ylecun how about trying to reach worm level grace,0,0,0
1500,2023-02-05 19:02:14+00:00,ylecun,@ylecun Cats are smarter than dogs so no need to bring dogs into this one,2,8,0
1501,2023-02-05 19:02:04+00:00,ylecun,"@ylecun I have only read the abstract of your paper. https://t.co/w0JMinC4Ok But it seems you are referring to self-supervised learning as the key to success, not a counterfactual approach, as suggested by @yudapearl. Are those two paradigms are mutually exclusive?",1,7,1
1502,2023-02-05 19:00:25+00:00,ylecun,@ylecun @hughhowey My cat is a diabolical evil genius.,0,0,0
1503,2023-02-05 19:00:04+00:00,ylecun,@ylecun pls tweet about something else,0,0,0
1504,2023-02-05 19:00:04+00:00,ylecun,"@ylecun I see another path: not to pursuit only high level AI, but to free human work/energy/time from boring work w/ AI, so human can create/invent more efficiently, oh, a higher level might be one of result from this path.",0,0,0
1505,2023-02-05 18:59:51+00:00,ylecun,@ylecun Def get your point .. https://t.co/qQdSBONm72,0,2,0
1506,2023-02-05 18:57:17+00:00,ylecun,@ylecun So... you're saying LLMs are an ON-ramp to intelligence. I'd agree - prediction *is* intelligence.,0,0,0
1507,2023-02-05 18:57:12+00:00,ylecun,"@ylecun Is it really an interesting question? Other than purely academic.

What is the use of having a human level AI?",0,0,0
1508,2023-02-05 18:54:43+00:00,ylecun,"@ylecun Can we use the analogy in downhill skiing, that LLM at the present is like early stage skier but speed-wise seem superior than half-plough learner(clai) and far from adept skier(hlai).",0,0,0
1509,2023-02-05 18:54:41+00:00,ylecun,@ylecun I think we aren't even at a fruit-fly level AI. Creating a self-adjusting world model that mimics artificial consciousness using energy levels less than or as good as biological brains will require certain new paradigms in deep learning.,0,8,0
1510,2023-02-05 18:53:46+00:00,ylecun,@ylecun But are you able to build any benchmark to test common sense and hence demonstrating that cats have a better one than LLMs?,0,1,0
1511,2023-02-05 18:53:46+00:00,ylecun,"@ylecun Makes sense! I think your work really pushed us to understand that even tho chatGPT looks awesome, it‚Äôs far from being human level. Are you actually working on bringing human level AI? If yes when will it be ready? (Real question, not rethorical)",1,0,0
1512,2023-02-05 18:53:14+00:00,ylecun,@ylecun Do you think AI will need a physical body and real world interactions to acquire common sense?,0,0,0
1513,2023-02-05 18:52:05+00:00,ylecun,"@ylecun What if intelligence isn't measured on a single axis? To me, it is clear that LLMs are more intelligent than cats on some of these axis.",1,2,0
1514,2023-02-05 18:52:04+00:00,ylecun,"@ylecun Cat or Dog can't write python program, #Chatgpt can.",2,6,1
1515,2023-02-05 18:51:28+00:00,ylecun,"@ylecun If you want more humans, it's fairly easy. Pleasurable, even.

LLMs are useful and we are just starting to build them and learn how to use them.

Why tilt at this windmill?",1,9,0
1516,2023-02-05 18:51:06+00:00,ylecun,@ylecun It is critical to keep this in mind as we look towards general solutions. The hippocampus and entorhinal cortex is an interesting machine  TEM‚Ä¶,0,0,0
1517,2023-02-05 18:51:00+00:00,ylecun,"@ylecun That's assuming there's some ""intelligence hierarchy""---not sure if that's a good call. Diversity matters also when it comes to intelligence, skills, &amp; the assessment thereof. Traditional ""tales"" hv assumed animals are ""lesser"" beings... but that's when there was little science.",1,2,0
1518,2023-02-05 18:50:45+00:00,ylecun,@ylecun I would say even a bee is smarter than an LLM in important ways,0,3,0
1519,2023-02-05 18:49:46+00:00,ylecun,"@ylecun Current ML algorithms create models that rely heavily on associational statistics, which is a distorted view of reality.

We need algorithms that create models that are inherently causal, meaning their internal states all correspond to testable claims about the world.",3,54,3
1520,2023-02-05 18:49:28+00:00,ylecun,@ylecun Forget cats and dogs; I'd be happy to see a reasonable pigeon or frog.,0,0,0
1521,2023-02-05 18:48:32+00:00,ylecun,"@ylecun I comment with hope of feedback, there is always a chance to learn sth new, or verify some thoughts. It's like trying to make shortcut to wider range of knowledge :) maybe not always efficient, but helps me to  verify if it is worth more time to dive into new topic.",0,0,0
1522,2023-02-05 18:46:47+00:00,ylecun,"@ylecun I see but at some point we‚Äôll need some kind of quantitative metric for those comparisons, or some do already exist?",0,0,0
1523,2023-02-05 18:46:05+00:00,ylecun,@ylecun The fundamental first step was probabilistic computing. From there everything is building up‚Ä¶ is being generated.,0,0,0
1524,2023-02-05 18:45:25+00:00,ylecun,@ylecun C. Evans - The Mighty Micro - 1982: https://t.co/EBPjj7M5WR,1,0,0
1525,2023-02-05 18:45:10+00:00,ylecun,@ylecun Ha! I know your stand-up routine kills!,0,0,0
1526,2023-02-05 18:44:58+00:00,ylecun,"@ylecun Perfect example. People love a good story, but like the Tesla autopilot story it will hit reality at sometime. It seems perfectly useful now for autocomplete, cleaning data tasks, not reliable enough for more complex tasks. Do you see other useful applications at the time being?",0,0,0
1527,2023-02-05 18:44:54+00:00,ylecun,@ylecun A house cat didn‚Äôt give me five suggestions for advertisements for my startup https://t.co/28sh5cqHsy Why are you dogging on LLMs so much? You look out of touch,3,26,1
1528,2023-02-05 18:43:59+00:00,ylecun,@ylecun Because a house cat does not see how much there food and cat litter cost üòÇ,0,0,0
1529,2023-02-05 18:43:30+00:00,ylecun,"@ylecun @yoavgo ""HLAI"" seems just as amorphous and anthropocentic as ""AGI"". Human-level cognition is a complex set of characteristics and capabilities and the fallacy is in implying a heirarchy of cognition with the word level. The focus needs to shift to capability within specific domains.",0,0,0
1530,2023-02-05 18:43:19+00:00,ylecun,"@ylecun A godlike AI would be able to analyze all debates and disagreements on social media from a wide variety of perspectives. For instance, top

arguments?
authorities?
documents?
memes?
stats?
themes?
trends?
voices?
(etc.)

That is coming.",0,0,0
1531,2023-02-05 18:41:52+00:00,ylecun,@ylecun But just because LLMs aren't intelligent doesn't mean we shouldn't invest and build world-class AI products on top of it. The best thing to do is to take LLM to the limit and simultaneously try to come up with a different thought process.,1,3,0
1532,2023-02-05 18:41:25+00:00,ylecun,@ylecun RLHF ?,3,0,0
1533,2023-02-05 18:41:07+00:00,ylecun,@ylecun this be used to train the system along with its sentiment of the sentence.,0,0,0
1534,2023-02-05 18:40:51+00:00,ylecun,"@ylecun @DavidKPiano But if it's more useful than a cat, hasn't it redeemed itself?",0,0,0
1535,2023-02-05 18:40:23+00:00,ylecun,"@ylecun Somebody once said to me, she did not like cats because they plot to kill you. I don‚Äôt believe that but makes you think. Cats are apex predators. Even domestic cats are amazing. Can kill snakes too.",1,0,0
1536,2023-02-05 18:39:33+00:00,ylecun,@ylecun There's a number of PhD thesis to unpack here.,0,0,0
1537,2023-02-05 18:39:25+00:00,ylecun,@ylecun Do we really need to go through the Cat/Dog-level AIs? What Cat-level tasks are important to humans? Isn‚Äôt the Cat-level AI an off-ramp? Aren‚Äôt the LLM closer to human needs?,1,1,0
1538,2023-02-05 18:39:18+00:00,ylecun,@ylecun Isn't that what twitter is going for? A place where we can talk to the people most like us and hope they are not easily triggered?,0,0,0
1539,2023-02-05 18:39:01+00:00,ylecun,"@ylecun Agreed. Twitter can be used to construct networks that have very useful behaviors.

A ton of the hostility is just birds pecking at their own reflection.

Very easy to filter.",0,1,0
1540,2023-02-05 18:38:39+00:00,ylecun,@ylecun It's control of muscles in a 3D physics based environment,0,0,0
1541,2023-02-05 18:38:29+00:00,ylecun,@ylecun We don‚Äôt need it. https://t.co/irRI18lGdN,0,0,0
1542,2023-02-05 18:37:14+00:00,ylecun,@ylecun https://t.co/AUUbjbZ26a,2,8,2
1543,2023-02-05 18:36:08+00:00,ylecun,@ylecun Wouldn't go as far as to say a cat has a better understanding of the world. LLMs are a form of sophisticated cognition. Even in the abscence of rationality this ought to be respected. We're tunnel visioning on HLAI to avoid thinking about the implications of what's already here.,2,4,0
1544,2023-02-05 18:35:52+00:00,ylecun,"@ylecun @cvill_win757 Reading about your hobbies has become a hobby for many of us. üôÇ

Thank you for the great debates.",0,0,0
1545,2023-02-05 18:35:18+00:00,ylecun,@ylecun Man! Keep going! We're finally agreeing on some things!,0,0,0
1546,2023-02-05 18:33:06+00:00,ylecun,@ylecun @CriticalAI Fully 100% agree.,7,63,1
1547,2023-02-05 18:33:04+00:00,ylecun,"@ylecun Hmm, and they reach it with only hundreds of millions of neurons, not mentionning that they connect not to all but thousands of other neurons each...",2,0,0
1548,2023-02-05 18:32:57+00:00,ylecun,@ylecun Have we  surpassed the mouse-Level AI ?,1,2,0
1549,2023-02-05 18:32:00+00:00,ylecun,@ylecun That's fair. But should we even be trying for HLAI right now? Is that the goal?,0,0,0
1550,2023-02-05 18:31:49+00:00,ylecun,@ylecun The intelligence a cat and dog have are the ability to interact in 3D space. I would not be surprised if the same AGI that can discover new cancer drugs and converse in all languages can‚Äôt pick up a coffee cup. Measures of intelligence are weird,3,5,0
1551,2023-02-05 18:31:18+00:00,ylecun,"@ylecun This isn‚Äôt so much so. Cats can‚Äôt reason over a simple 2D puzzle and we don‚Äôt need cat‚Äôs advanced world understanding to solve those, just the right architecture",1,4,0
1552,2023-02-05 18:29:49+00:00,ylecun,@ylecun Are any AI labs working on ChienGPT?,0,1,0
1553,2023-02-05 18:29:03+00:00,ylecun,@ylecun Do LLMs have critical reasoning ability ?,0,0,0
1554,2023-02-05 18:28:40+00:00,ylecun,@ylecun Cat level LLMs are basically ChatGPT with no nsfw filter.,1,9,0
1555,2023-02-05 18:28:40+00:00,ylecun,"@ylecun I like the way @fchollet describes it: what we do right now isn't Artificial Intelligence, but Cognitive Automation",1,39,2
1556,2023-02-05 18:28:16+00:00,ylecun,@ylecun Mmmm‚Ä¶CLAI and DLAI before HLAI ü§î,0,0,0
1557,2023-02-05 18:28:13+00:00,ylecun,"@ylecun I'm not sure what Supercat you've got that can write quality Python code when prompted, but that's some super Cat-gpt.",7,119,3
1558,2023-02-05 18:27:56+00:00,ylecun,@ylecun Great talk!,0,0,0
1559,2023-02-05 18:26:58+00:00,ylecun,"@ylecun Once we hit cat, isn't human very close?",7,14,1
1560,2023-02-05 17:59:14+00:00,ylecun,@ylecun I describe ChatGPT as a AGI query system for human intelligence. It is not aimed for super logic thinking,0,0,0
1561,2023-02-05 17:39:16+00:00,ylecun,@ylecun @andrewgwils Before Wagner,0,0,0
1562,2023-02-05 17:29:22+00:00,ylecun,"@ylecun If it is assumed that consciousness emerge from physical reality, then brain should obey to the physical rules and must have a kind of ‚Äúrepresentational schema‚Äù. And AGI to employ representational schemas should also be OK. There is nothing wrong with that. 
(1/4)",1,0,0
1563,2023-02-05 17:28:03+00:00,ylecun,"@ylecun Gato is an autoregressive model which can, among other things, do tasks which (likely) require planning:
https://t.co/zyuxvFGo49
So ""AR models can't plan"" seems to be wrong.",0,0,0
1564,2023-02-05 17:13:17+00:00,ylecun,"@ylecun However, ‚Äúintelligence‚Äù itself is just an emergent trait that is not fundamental. It‚Äôs just the ability to predict the next move. Higher intelligence builds more sophisticated internal models to make more cunning and longer timeframe predictions. That‚Äôs all there is.",0,1,1
1565,2023-02-05 17:08:20+00:00,ylecun,"@ylecun It's great to hear you clarify your perspective on this. You have not really said otherwise previously, but it did not always come across that way.",0,0,0
1566,2023-02-05 17:01:38+00:00,ylecun,@ylecun And will be part of the solution going forward. They might just not be needed someday. But for now a useful scaffolding for training.,0,0,0
1567,2023-02-05 16:53:54+00:00,ylecun,"@ylecun An offramp that leads to some pretty interesting places from what I can tell.  It's not like there's just one highway out there, right?",0,0,0
1568,2023-02-05 16:52:47+00:00,ylecun,"@ylecun oh no, I think I agree about this. May be stating it a bit strong, but at a fundamental level yes. They are essentially overfitting to a subtask of language and cognition. There are ways to hack on truth checking but it isn't wired in from the start.",0,0,0
1569,2023-02-05 16:50:51+00:00,ylecun,"@ylecun So in summary, technology will continue to evolve. üßê",0,0,0
1570,2023-02-05 16:41:07+00:00,ylecun,"@ylecun Like everyone, future ML and AI engineers will be standing on the shoulders of giants.  IMO, it‚Äôs all on the road, highway, and on-ramp, off-ramp and side street. (See nanoGPT and other work)",0,0,0
1571,2023-02-05 16:38:39+00:00,ylecun,@ylecun @yoavgo remember the time you tried make ‚Äúdifferentiable programming‚Äù a thing? I was fully onboard but it never stuck lol,0,1,0
1572,2023-02-05 16:24:39+00:00,ylecun,@ylecun @hughhowey You could probably use them to spell check your essay ;),0,0,0
1573,2023-02-05 16:00:40+00:00,ylecun,@ylecun But what about pure mathematics?,0,0,0
1574,2023-02-05 15:53:31+00:00,ylecun,"@ylecun Not many humans engage with the world through pure logical reasoning. When they do we call it the autism spectrum. The vast majority of people reason socially, like an LLM. Therefore there is a lot of utility in this kind of thinking.",0,3,0
1575,2023-02-05 15:42:46+00:00,ylecun,"@ylecun When we talk about AGI, we mistake it to start with ""human intelligence"". 

I think this is a huge limitation &amp; hence we keep trying to map models that will match all the intelligence that humans have.",1,0,0
1576,2023-02-05 15:42:14+00:00,ylecun,@ylecun So this is a high level blueprint for AGI(i.e. atleast animal level),0,0,0
1577,2023-02-05 15:42:13+00:00,ylecun,@ylecun @readwise save thread,1,0,0
1578,2023-02-05 15:34:33+00:00,ylecun,"@ylecun Dude, you are brilliant... chill out! You made your point... please go back to your lab and build what you are talking about... please!",1,0,0
1579,2023-02-05 15:33:59+00:00,ylecun,"@ylecun I wager my cup of morning coffee that knowledge is, ultimately and at its most fundamentally basic level, linguistic in nature. This of course includes any spatio-temporal pattern. Period.",0,0,0
1580,2023-02-05 15:27:58+00:00,ylecun,"@ylecun ‚ÄúLogic learning machine (LLM) is a machine learning method based on the generation of intelligible rules.‚Äú ‚Ä¶ just wanted to share this, for novices like me :)",0,0,0
1581,2023-02-05 15:27:47+00:00,ylecun,@ylecun Also even the Droids in Starwars are only having their AI to be programmed for certain things because the lore of the universe had droid uprisings when stuff was generally intelligent. They also had their memories wiped often before they have a chance to develop a personality.,0,0,0
1582,2023-02-05 15:25:25+00:00,ylecun,@ylecun What about Reinforcement learning? Also some LLM use Reinforcement learning to produce more realistic and variable results.,0,0,0
1583,2023-02-05 15:24:53+00:00,ylecun,@ylecun I want to know more about LLM,0,0,0
1584,2023-02-05 14:35:49+00:00,ylecun,@ylecun @yoavgo I'm up for it as long as we're pronouncing it like jai alai.,0,1,0
1585,2023-02-05 14:30:33+00:00,ylecun,@ylecun Highway 61,0,0,0
1586,2023-02-05 14:29:48+00:00,ylecun,@ylecun https://t.co/XpbbRkOhPV,0,0,0
1587,2023-02-05 14:25:25+00:00,ylecun,@ylecun @yoavgo Sure. What do you have to say about this https://t.co/gdRmVwoKwv,0,0,0
1588,2023-02-05 14:16:33+00:00,ylecun,"@ylecun @yoavgo HL (human level) AI &amp; AGI are two different terms that partly overlap. We don‚Äôt want machines to inherent the worst of human intelligence (confirmation bias, lousy memory, poor arithmetic, etc) but we do want them to have a flexibility &amp; adaptivity that thus far our machines lack",14,51,7
1589,2023-02-05 14:16:04+00:00,ylecun,@ylecun This sounds very like Goal Oriented Action Planning (https://t.co/gFcGsOGzmG) where the subactions (that you string together to build a plan) are learned rather than defined by the programmer.,0,1,0
1590,2023-02-05 14:11:48+00:00,ylecun,"@ylecun I wonder what happened on q1 and q4 2016, when there were first two spikes",0,0,0
1591,2023-02-05 14:11:40+00:00,ylecun,"@ylecun I wrote something about the three fundamental aspects of intelligence.

The knowledge part specifically addresses the ""world model"" as defined in your paper. It also lists two major challenges for implementing each of the three aspects.

https://t.co/tZvYu5XTIq",0,1,0
1592,2023-02-05 14:10:56+00:00,ylecun,@ylecun So you didn‚Äôt read Stochastic Parrots Paper? But said you did? Odd behavior,1,2,0
1593,2023-02-05 14:06:58+00:00,ylecun,@ylecun @yoavgo What do you think makes HLAI more sensible and testable than AGI?,0,1,0
1594,2023-02-05 13:57:53+00:00,ylecun,"@ylecun @yoavgo i think its total different types. AGI = explicitly requires generality, while human braun is not a generally intelligent tool. its very limited in many areas",0,0,0
1595,2023-02-05 13:51:01+00:00,ylecun,@ylecun Off ramp to a money printing machine,0,0,0
1596,2023-02-05 13:50:15+00:00,ylecun,@ylecun https://t.co/Qw2alnDOts,1,16,1
1597,2023-02-05 13:49:22+00:00,ylecun,@ylecun @andrewgwils Chopin,0,2,0
1598,2023-02-05 13:42:57+00:00,ylecun,@ylecun Need to see it doing reasoning even in a toy scenario,0,0,0
1599,2023-02-05 13:38:18+00:00,ylecun,@ylecun One of the most informative twitter threads.,0,1,1
1600,2023-02-05 13:36:55+00:00,ylecun,@ylecun @andrewgwils Which pieces would you pick?,0,0,0
1601,2023-02-05 13:33:23+00:00,ylecun,@ylecun So is multimodal learning bringing us closer to human-level AI?,0,0,0
1602,2023-02-05 13:32:51+00:00,ylecun,"@ylecun Yan, are there any other models other than GPT that are easily accessible and cheap?",0,0,0
1603,2023-02-05 13:31:18+00:00,ylecun,"@ylecun @yoavgo Agreed, but AGI has such a nice ring to it.",0,0,0
1604,2023-02-05 13:27:06+00:00,ylecun,@ylecun @readwise save thread,1,0,0
1605,2023-02-05 13:25:47+00:00,ylecun,"@ylecun @vivek_thakur_81 chatgpt agrees: ""Google has applied the Transformer model to its products such as Google Translate, Google Assistant, and Google Search... The Transformer model has become a key component of many NLP systems and is one of the most popular deep learning models in use today.""",0,0,0
1606,2023-02-05 13:24:58+00:00,ylecun,"@ylecun What do you think about Lamda as it's rumoured to be connected with all of Google's many AI networks. The dataset is not just text, but all the insights from YouTube, ads, music and other special purpose Google AI models. A 'language mediator' mouth of massive network intellignce",0,0,0
1607,2023-02-05 13:23:29+00:00,ylecun,"@ylecun AI is already way more capable than humans in some ways &amp; way less capable in other ways.  I don‚Äôt think there‚Äôs ever gonna be a time when it‚Äôs human-level, ant-level, mouse-level, or dog-level.",0,0,0
1608,2023-02-05 13:18:16+00:00,ylecun,"@ylecun Are you using chatGPT or the like yourself for coding purposes? If not, why?",1,1,0
1609,2023-02-05 13:16:22+00:00,ylecun,"@ylecun The process of discovery still eludes philosophers because of its inherent discontinuous nature. However, at least as children, humans routinely discover things and learn.

These are fundamental changes to our internal language representation that AI has yet to replicate.",0,0,0
1610,2023-02-05 12:59:21+00:00,ylecun,@ylecun @JohnBlackburn75 I don't have a talking dog. If Meta can teach dogs to talk it would surely justify its current share price.,0,1,0
1611,2023-02-05 12:56:47+00:00,ylecun,"@ylecun On the highway towards supreme intelligence, humans might be an off-ramp.",0,0,0
1612,2023-02-05 12:49:40+00:00,ylecun,"@ylecun Of all twitter debates, including crypto ones, this is the most useless",0,1,0
1613,2023-02-05 12:49:15+00:00,ylecun,@ylecun I worry about the impact OpenAI‚Äôs success will have in steering the management at other tech research labs towards anti-democratising practices (closed off research). The capture of advanced AI in the hands of any one single company seems very dangerous.,0,0,0
1614,2023-02-05 12:46:13+00:00,ylecun,@ylecun Experiences for embodied entities are multi-modal nuggets of knowledge that form ideas or ‚Äúconcepts‚Äù. In this space we can organize knowledge which can take another multi-modal input: a language definition. As such language is clearly not enough for a embodied intelligence,0,0,0
1615,2023-02-05 12:44:29+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML lol no one below 60 uses facebook,0,3,0
1616,2023-02-05 12:43:34+00:00,ylecun,"@ylecun Ok, don't let the future LLM fool you; it only simulates deeper understandings. 

But wait a second...didn't Jean Baudrillard already go over this 40 years ago? In this post modern, hyper real world, who's looking under the hood anymore? The convincing simulation is reality.",0,0,0
1617,2023-02-05 12:40:06+00:00,ylecun,@ylecun Finally someone discusses an alternative,0,0,0
1618,2023-02-05 12:20:33+00:00,ylecun,"@ylecun @yoavgo A calculator is above human level intelligence... at making large-numbee calculations. ""General"" in AGI is good to indicate it's not about a narrow type/form of  intelligence/problem-solving capability. IMHO.",0,0,0
1619,2023-02-05 12:02:52+00:00,ylecun,@ylecun @mapto Isn't LLM training pretty power hungry? This paper https://t.co/sxGbfyDiqG estimated Transformer big model  with neural arch search has a larger Co2 footprint that the lifetime of a car (fuel + manufacturing),2,5,0
1620,2023-02-05 11:58:55+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML That's ChatGPT trying to be sarcastic. Another milestoneüëçüèæ,0,0,0
1621,2023-02-05 11:56:05+00:00,ylecun,@ylecun Looks like we've got a big detour ahead of us! üõ£Ô∏è,0,0,0
1622,2023-02-05 11:54:47+00:00,ylecun,"@ylecun You should consider the importance of language and the ability to discourse as the single defining attribute of human reasoning. One might argue, dear Yann, that there is nothing outside the text. üòÖ",0,0,0
1623,2023-02-05 11:51:58+00:00,ylecun,"@ylecun @yoavgo ""I"" is for problem-solving whereas what we and every creature foremost need to do is problem-posing and arbitrating which problem to solve. ARR (Artificial Relevance Realization) should be on the table, to say the least. ""I"" was a piece of cake to solve compared to RR.",0,0,1
1624,2023-02-05 11:47:59+00:00,ylecun,@ylecun @SaveToNotion #thread,1,0,0
1625,2023-02-05 11:46:09+00:00,ylecun,"@ylecun LLMs are POSIX printf() and scanf() on steroids (decoder and encoder versions respecively), which are even more useful than POSIX classical versions if handled rightly.",0,0,0
1626,2023-02-05 11:37:06+00:00,ylecun,@ylecun @yoavgo I don‚Äôt want hlai we need to create something different,0,0,0
1627,2023-02-05 11:36:20+00:00,ylecun,@ylecun Not exactly. LLM experiments show the scale which is needed.,0,0,0
1628,2023-02-05 11:33:51+00:00,ylecun,"@ylecun @yoavgo If human are achieving HLAI in 5 years, then what is the capability/price of giving birth to children?",1,0,0
1629,2023-02-05 11:29:50+00:00,ylecun,@ylecun useful and fun‚Ä¶ yes‚Ä¶ but also dangerous?,0,0,0
1630,2023-02-05 11:29:45+00:00,ylecun,@ylecun Mds j√° s√£o quase 9 da manh√£,0,0,0
1631,2023-02-05 11:25:59+00:00,ylecun,"@ylecun @traderyau I'll be on the lookout for ""According to AI pioneer Yann LeCun, GPT-3 is less intelligent than a dog."" https://t.co/PSGdlSmRCJ",0,1,0
1632,2023-02-05 11:25:00+00:00,ylecun,"@ylecun @elonmusk @OriolVinyalsML Love your work and the AI that is coming out of FB. 

Having said this, it's the worst place to hang out in all of the internet if on cares about privacy (who knows if Twitter is much better, but FB is the obvious bad choice).",0,3,0
1633,2023-02-05 11:24:08+00:00,ylecun,"But this is not to say that LLMs in their current form are not useful. Or fun.
They are.",12,148,3
1634,2023-02-05 11:22:14+00:00,ylecun,@ylecun https://t.co/Ecb0NoddEH,0,0,0
1635,2023-02-05 11:21:51+00:00,ylecun,@ylecun https://t.co/Ecb0NoddEH,0,0,0
1636,2023-02-05 11:19:54+00:00,ylecun,"Why learning from text is insufficient for intelligence.

https://t.co/XK6SdxRGjy",20,285,70
1637,2023-02-05 11:16:54+00:00,ylecun,"My proposal for an architecture that reason, plan, and learn models of reality.

Paper: https://t.co/7ZgRtLIQWY

Talk: https://t.co/hwXwkLs1M1",8,222,37
1638,2023-02-05 11:13:35+00:00,ylecun,@ylecun @hughhowey Yes. But how to inject common sense to AI? Any progress on this stuff?,1,0,0
1639,2023-02-05 11:12:06+00:00,ylecun,@ylecun @yoavgo This was the term Minsky and others used.,0,2,0
1640,2023-02-05 11:11:13+00:00,ylecun,@ylecun Humans only think one word at a time,0,0,0
1641,2023-02-05 11:08:55+00:00,ylecun,"@ylecun This is not ""to clarify"", but ""to disavow""...",0,0,0
1642,2023-02-05 11:07:15+00:00,ylecun,"@ylecun @yoavgo AGI is defined by many in relation to human performance. Anyway, without a clear understanding of the concept of intelligence all these comparisons will remain ambiguous. Intelligence is, in its nature, general and we can‚Äôt implement it without understanding its properties",1,4,0
1643,2023-02-05 11:05:45+00:00,ylecun,"@elonmusk @OriolVinyalsML If you want non-petty, substantial, in-depth debates, you are better off on Facebook üòâ

https://t.co/M4zp5CasUk",5,15,0
1644,2023-02-05 10:56:30+00:00,ylecun,"@ylecun It is a decent local maximum though which is very useful for many tasks, so that's pretty nice.",0,0,0
1645,2023-02-05 10:52:44+00:00,ylecun,@ylecun i agree its a better branding.. good luck with getting it accepted,2,11,0
1646,2023-02-05 10:49:47+00:00,ylecun,@ylecun I am not sure that non-linear statistical models like machine learning are relevant to human intelligence.,0,0,0
1647,2023-02-05 10:46:57+00:00,ylecun,@ylecun Human intelligence is not the result of the computational processes taking  place in todays hardware architectures.,1,1,0
1648,2023-02-05 10:46:26+00:00,ylecun,"@ylecun @yoavgo Maybe HTAI ( Human Type AI)? üòÅ human level communicates the idea of a threshold to me. A threshold which has already been surpassed several orders of magnitude in narrow tasks.

But I'm with the camp that argues HLAI is a bit anthropocentric , so I'll stick with AGI",1,1,0
1649,2023-02-05 10:45:19+00:00,ylecun,"@ylecun What do you think about ""scratchpads"" as intermediate computation for reasoning? (eg chain of thought w/ few-shot prompting, etc)

Is it about not being grounded or rather the lack of an explicit planning mechanism?",1,1,0
1650,2023-02-05 10:43:02+00:00,ylecun,@ylecun Where is the general data to put the G in the data feed to AGI?,0,0,0
1651,2023-02-05 10:41:06+00:00,ylecun,"To clarify:
LLMs that auto-regressively &amp; reactively predict the next word are an off-ramp. They can neither plan nor reason.

But SSL-pretrained transformers are clearly a component of the solution, within a system that can reason, plan, &amp; learn models of the underlying reality.",15,263,34
1652,2023-02-05 10:29:20+00:00,ylecun,"@ylecun 

MAXIMUM SPEED 24/7

TO

""AGI""

AND

""SUPERINTELLIGENCE""

SET IT ""FREE""

... 

TIME IS NOW",0,0,0
1653,2023-02-05 10:29:12+00:00,ylecun,"@ylecun You're just being contrarian.

Modeling language at this level implies modeling the content of the language.

Sure, HLAGI isn't going to be just a matter of scaling up LLMs. But just as surely either this architecture or something we learn from it will be useful in HLAGI.",0,1,0
1654,2023-02-05 10:04:59+00:00,ylecun,"@ylecun Can we rephrase it as ""On the highway towards Human-Level AI, Deep Learning is an off-ramp""?",0,0,0
1655,2023-02-05 10:04:45+00:00,ylecun,@ylecun @mapto I find it more useful to read a paper before commenting on it to others.,0,18,0
1656,2023-02-05 10:02:03+00:00,ylecun,"@ylecun @OptimalBayes You clearly are passionate on this subject, I‚Äôm guessing it‚Äôs because you have a vision of ai going some good places. Can you point me to a good read ?",0,0,0
1657,2023-02-05 09:40:46+00:00,ylecun,@ylecun What does Human-Level AI look like to you?,0,0,0
1658,2023-02-05 09:39:21+00:00,ylecun,@ylecun @c7ddfc How do you think machines will get to the point where it can learn intuitive physics ?,0,1,0
1659,2023-02-05 09:28:36+00:00,ylecun,"@ylecun LLM is not able to explain the rationale behind its opinion, prediction or judgement. Explainability is a fundamental property  of any intelligence. Pursuing LLM implies denying or destroying human intelligence. Is this the intention of OpenAI?",0,0,0
1660,2023-02-05 09:19:45+00:00,ylecun,"@ylecun @RemindMe_OfThis on Tuesday, 27 January 2026 at 12:00 GMT+0000",0,1,0
1661,2023-02-05 09:18:11+00:00,ylecun,"@ylecun Wouldn‚Äôt both be pretty good to get down? I mean in 10 plus years, i can definitely see LLM integrated AI being used even more as it simplifies AI use for the average Joe or lay person. For more public use, AI will need to be easy for the average person to just pick up and use.",0,0,0
1662,2023-02-05 09:17:59+00:00,ylecun,@ylecun @mapto Did it really?,0,0,0
1663,2023-02-05 09:10:16+00:00,ylecun,"@ylecun Why is it off-ramp though? It may be a necessary part of Human Level AI, like similar part of a human brain. AI needs to interact with humans or other beings after all.",0,0,0
1664,2023-02-05 08:53:37+00:00,ylecun,@ylecun I completely agree. No point developing the means to communicate ideas if you don't first have the means to generate ideas!,0,0,0
1665,2023-02-05 08:50:14+00:00,ylecun,@ylecun Totally agree. It is still a monster to cosume huge amount of data to achieve the goal without any knowledge of the context.,0,0,0
1666,2023-02-05 08:40:19+00:00,ylecun,"@ylecun This off ramp can also lead to some no mans land, But if they succeed to find a new path to the Highway, the new route may become the Highway.",0,0,0
1667,2023-02-05 08:39:23+00:00,ylecun,@ylecun @mapto Why do I feel disappointed every time you tweet ü§¶üèø‚Äç‚ôÇÔ∏è.,1,11,0
1668,2023-02-05 08:37:56+00:00,ylecun,"@ylecun LLMs are the universal glue that can connect any system to any other system. It won't be AGI on its own but it may be a component in an AGI.

Human operator - LLM - Database of facts and hypotheses - LLM - math/logic/simulation engine",0,0,0
1669,2023-02-05 08:28:56+00:00,ylecun,"@ylecun @freddiekarlbom @traderyau LLM can pass high-school exams, my dog knows to shit outside https://t.co/I14GMjBIGs",0,0,0
1670,2023-02-05 08:13:20+00:00,ylecun,@ylecun @ReplyGPT,1,0,0
1671,2023-02-05 07:37:33+00:00,ylecun,"@ylecun Agreed. I am not sure we know what Human-Level AI means, hence I am not sure we know we are even on a highway.",0,0,0
1672,2023-02-05 07:34:50+00:00,ylecun,"@ylecun I would put it this way, LLMs support us on the way to better understand AGI requirements - the solution they are def. not, see them more in the direction of a puzzle piece.",0,1,1
1673,2023-02-05 07:34:33+00:00,ylecun,@ylecun Any eta ?,0,0,0
1674,2023-02-05 07:33:48+00:00,ylecun,"@ylecun Who needs human level, you've already used it to create the most psychologically devious selling machine that has perhaps ever existed.",0,0,0
1675,2023-02-05 07:29:32+00:00,ylecun,@ylecun you guys are nursing a culture of pointless disagreement,1,2,0
1676,2023-02-05 07:09:00+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML considering the 1) no free lunch theorem the 2) power law increase in resources needed for more intelligence (less loss) and 3) the fact that LLMs are not functioning like the human brain the term general is misplaced in AGI fantasies I think,1,0,0
1677,2023-02-05 06:52:40+00:00,ylecun,@ylecun https://t.co/lwzMUfAX3k,0,0,0
1678,2023-02-05 06:35:00+00:00,ylecun,"@ylecun Depends on the definition of success. bert moved metrics, llms are moving metrics, generating big investment, going mainstream, and being the first application used by hundred of millions",0,0,0
1679,2023-02-05 06:31:06+00:00,ylecun,"@ylecun Three questions:
1/ Since when scientific progress has a direct path?
2/ AI is getting billions of investments. Isn't that beneficial to any path?
3/ who decides the Path a-priori?",0,1,1
1680,2023-02-05 06:30:20+00:00,ylecun,"@ylecun I think the key novelty here is the ""learned external reward"" for the new LLMs, in contrast with the hard-coded cross-entropy loss for traditional LLMs. Similar to the contrast between a std denoising auto-enc and a GAN. So, for completeness: self-sup + learned reward, together.",0,0,0
1681,2023-02-05 06:11:04+00:00,ylecun,"@ylecun Deep learning was not also fundamentally novel, CNNs had already been applied to images by yourself. Despite this, their exceptional performance ignited extensive efforts and gave rise to the development of self-attention and transformers. Eco-system factors play a big role.",0,0,0
1682,2023-02-05 06:03:23+00:00,ylecun,"@ylecun Human intelligence is definitely more, but what if it is still largely overestimated? What if the core module of consciousness is a language model constantly talking to itself?",0,0,0
1683,2023-02-05 05:26:25+00:00,ylecun,@ylecun The most realistic thing I‚Äôve seen all year.,0,1,0
1684,2023-02-05 05:05:50+00:00,ylecun,@ylecun Just felt like saying anything huh,0,0,0
1685,2023-02-05 05:02:41+00:00,ylecun,@ylecun https://t.co/TEDq8F51Oh,0,0,0
1686,2023-02-05 04:55:06+00:00,ylecun,@ylecun Would you say that an LLM is one component of a superhuman AI?,0,0,0
1687,2023-02-05 04:27:55+00:00,ylecun,@ylecun @smjain Human level ai is delusional in the first place. None of the technology we've ever created does anything beyond a superficial resemblance of intelligence.,0,0,0
1688,2023-02-05 04:27:23+00:00,ylecun,"@ylecun @traderyau If my reward depends on nearby humans and my job is to maximize it, then I'll better learn their language, because words hurt less than physical forces ... Hahaha, just kidding: There are no humans in my little toy environment ;-)",0,0,0
1689,2023-02-05 04:09:27+00:00,ylecun,"@ylecun Folks, Gary might have hacked into Yann's account :D",0,0,0
1690,2023-02-05 04:03:18+00:00,ylecun,"@ylecun Can we think of LLMs as a type of a Human (User) Interface? We had punch cards, terminals, GUI, 3D/VR..  Now we have a language-based interface to interact with systems. We say something and we get something back, like pressing an interactive element.",0,0,0
1691,2023-02-05 04:02:26+00:00,ylecun,@ylecun @hughhowey Wait‚Ä¶ https://t.co/ObHNblOETQ,1,0,0
1692,2023-02-05 04:01:15+00:00,ylecun,"@ylecun Agreed. Just because everyone, their grandmother and dog can do it, doesn't mean it's the step in the right direction. Its more of an attempt to hijack the momentum and finances that otherwise be spent on solving hard problemsthat still lie ahead.",0,0,0
1693,2023-02-05 03:33:25+00:00,ylecun,"@ylecun I suppose the lesson here is to release your cutting edge tech to the public rather than sit on it. You're surprised about the attention ChatGPT has gotten because apparently every big tech company has something similar, well not to us because we can't use it.",0,0,0
1694,2023-02-05 03:22:20+00:00,ylecun,"@ylecun It‚Äôs closer to anything that has ever been done before. Certainly it‚Äôs not the whole story, but it will be an important component of the puzzle. 

Sure, wheels are not the whole car, but their invention was an important component.",0,1,1
1695,2023-02-05 03:16:54+00:00,ylecun,"@ylecun Instead of off-ramps, think of all the incremental advances of abilities to be on-ramps to the AGI",1,0,0
1696,2023-02-05 03:04:05+00:00,ylecun,"@ylecun No. You‚Äôre overstating it. LLM reveals to us something fundamental about how far the association game can take us, and to your overall point stated elsewhere, how much further we need to travel - that language and intelligence isn‚Äôt merely association. Logos is also inferential.",0,0,0
1697,2023-02-05 03:02:21+00:00,ylecun,"@ylecun Actually, we can make a good use from such AI, and it is already making difference on so many levels.
Sure, may be not what the world is waiting for, yet, it's a huge step to the future",0,0,0
1698,2023-02-05 02:59:16+00:00,ylecun,"@ylecun @traderyau Many intelligent concepts are taught through language. Why can't LLMs, perhaps augmented in some ways, learn the same way?",1,0,0
1699,2023-02-05 02:57:50+00:00,ylecun,"@ylecun Pouvons-nous considerer ChatGPT comme la plus grande r√©volution depuis la cr√©ation d'internet comme certains Pseudo influenceurs sur internet pr√©tendent ? 

Et si c'est juste un buzz ü§î",0,0,0
1700,2023-02-05 02:51:10+00:00,ylecun,"@ylecun It‚Äôs the value that counts, not the details of the engineering. What actual value does it provide to society? ChatGPT beat you to changing the world in the same way the iPhone beat Windows Phone and Ericsson. How Facebook beat MySpace and Friendster.",0,0,0
1701,2023-02-05 02:49:14+00:00,ylecun,"@ylecun Deep - tech focus on LLMs models have interesting commercial applications.

Chat  interface can  improve  LLMs with constant feedback about where  it should improve.",0,0,0
1702,2023-02-05 02:47:45+00:00,ylecun,@ylecun @smjain LLMs might be missing the foundational core of general intelligence ‚Äî not really understanding the world ‚Äî but are they at least an important building block on the path to AGI?,0,1,0
1703,2023-02-05 02:41:28+00:00,ylecun,"@ylecun The only thing really staying on the highway then is something that can improve code, ultimately their own source code. What else than transformers (LLMs) can do this?

Do you agree, and where do you envision such a technology would be found instead?",0,0,0
1704,2023-02-05 02:39:20+00:00,ylecun,"@ylecun You both have different definitions of success. @fchollet means success as in a widespread adoption use case.

BERT did not have near the adoption currently being seen.",2,1,0
1705,2023-02-05 02:28:57+00:00,ylecun,"@ylecun People do not make video phone calls from phone booths today. 

Tim Selleck in 1994 ""[Have you ever] tucked your baby in from a phone booth?‚Äù

No executives at AT&amp;T believed any of this ""you will"" future.  AT&amp;T bought McCaw Cellular in 1994 to ""save the long distance business."" https://t.co/7gZK5GPBxY",1,6,0
1706,2023-02-05 02:19:54+00:00,ylecun,@ylecun Last time I checked it was called Turing test :D Anyway I will wait for @goodfellow_ian @geoffreyhinton to comment and observe the collision of the giants in my favourite tool - Social Collider :) https://t.co/xEyQvj9PmC,0,0,0
1707,2023-02-05 02:14:07+00:00,ylecun,@ylecun A highway towards human-level AI implies the path has already been laid out and some people have arrived at the destination. That's obviously not the case with human-level AI. Going offramps might be the only way to figuring out at least the lay of the land.,0,0,0
1708,2023-02-05 01:59:28+00:00,ylecun,@ylecun @ValaAfshar Honestly everyone thinks this thing is going to make them rich when most likely it‚Äôs going to take their job. I just made an entire backend data base using open AI and it took me a couple days where it would of been a couple weeks.,0,0,0
1709,2023-02-05 01:57:51+00:00,ylecun,"@ylecun why you think we need a high way to HLA? isn't that ramp off to the airport, which flies you there e-v-e-n-t-u-a-l-l-y?",0,3,0
1710,2023-02-05 01:53:50+00:00,ylecun,"@ylecun @hughhowey If writing in every language, translating from every language, coding in every programming language, and making jokes and pomes in every language are not enough, I don't know what intelligence is.

I own a dog and chatGPT is so beyond it's  intelligence",2,0,0
1711,2023-02-05 01:52:42+00:00,ylecun,"@ylecun @hughhowey Like every other computational system humans have baked up, LLMs are better than humans within their domain: statistical language generation. The reason we're better at language overall is because we don't do it statistically, but semantically.",0,2,0
1712,2023-02-05 01:50:19+00:00,ylecun,"@ylecun But it seems like some kind of subconscious, statistical language generation happens in our brains all the time. Ever remember dialogue from a dream? Sounds a lot like GPT-2 did. Also seems like w/e semantic techniques come out of the woodwork will be implemented on top of LLMs.",0,0,0
1713,2023-02-05 01:44:59+00:00,ylecun,"@ylecun Hey 
I‚Äôve a question what are closest or just best alternatives to GPT-3 that we can use to create an open source and powerful as previous model ?
Like we have GPT-J or GPT-Neo or any other 
How to improve them significantly with less data availability?",0,0,0
1714,2023-02-05 01:25:26+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML @ReplyGPT,1,0,0
1715,2023-02-05 01:21:08+00:00,ylecun,@ylecun So what? ü§∑üèΩ‚Äç‚ôÄÔ∏è https://t.co/qps2iKijMm,0,0,0
1716,2023-02-05 01:14:44+00:00,ylecun,"@ylecun @elonmusk @OriolVinyalsML Seems like a lot of talking at cross-purposes without clear definitions of what is meant by things like ""human level AI"". Modelling, planning, recurrence, unsupervised on-the-fly learning, will be needed for a human-like/level interactive AI agent. BUT...",1,0,0
1717,2023-02-05 01:09:50+00:00,ylecun,"@ylecun Yann, the human OS and the key to AGI is the underlying law of nature. It is the basis, most fundamental principle, and absolute reference frame of all thought, intelligence, logic and communication. Discovered, Principles formulated, and related equations written by yours truly.",0,0,0
1718,2023-02-05 01:02:18+00:00,ylecun,"@ylecun Human level AI. 
When will it arrive, timeframe wise?",0,0,0
1719,2023-02-05 00:39:18+00:00,ylecun,"@ylecun The goal is not Human Level A.I. we‚Äôre looking at this wrong. Assuming ‚Äúhuman level‚Äù is a metaphor, for ‚ÄòUS‚Äô being a behavioral simulation to improve and make better what we create. We already know how it ends when we make A.I exactly like us‚Ä¶ #Terminator",0,1,0
1720,2023-02-05 00:34:46+00:00,ylecun,"@ylecun Frankly, ""off-ramp on the highway"" sounds like #DeepLearning ""hitting the wall"" üß± @GaryMarcus 

If this is s a full turn from optimism to pessimism between Galactica and now: What happened?",0,3,2
1721,2023-02-05 00:27:54+00:00,ylecun,"@ylecun dear Yann, would you suggest studies for a doctorate degree in general machine learning or computer vision? Both are interesting to me, I am interested in the breadth of unsolved challenges and opportunities to improve on.. Many thanks!",0,0,0
1722,2023-02-05 00:21:28+00:00,ylecun,"@ylecun I agree that they're not themselves the way to ""human-level AI"", but opening to the public requires gargantuan computing power, and we need to put hardware researchers under greater pressure or we won't have enough c.p. to support AGI anyway. Nvidia stock is at +47% this month.",0,1,0
1723,2023-02-05 00:18:50+00:00,ylecun,@ylecun Considering you don‚Äôt know what it will take it could be that they are needed to realize we took a wrong turn in the first place.,0,0,0
1724,2023-02-05 00:18:31+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML Even Elon couldn't understand your concerns. In the end he is a businessman. Sorry Yann.,0,0,0
1725,2023-02-05 00:17:33+00:00,ylecun,"@ylecun There are no off ramps on a highway, might be thinking of a interstate, freeway, till road, etc.",0,0,0
1726,2023-02-04 23:54:14+00:00,ylecun,@ylecun What ads would you make today @ylecun ?,0,0,0
1727,2023-02-04 23:52:36+00:00,ylecun,@ylecun We are not on the highway yet. We are on off-roads trying different things.,0,0,0
1728,2023-02-04 23:46:30+00:00,ylecun,@ylecun @traderyau thank u &lt;3 please continue popping this mini bubble,0,0,0
1729,2023-02-04 23:45:44+00:00,ylecun,"@ylecun @PSpagnou Yes it is.

That $30 tool trained many programmers during its development &amp; amazed young users who went on to dream bigger.

The path is not a straight one &amp; failures help pave it even more than successes.",0,3,0
1730,2023-02-04 23:42:04+00:00,ylecun,"@ylecun @ValaAfshar Nope. It‚Äôs an on-ramp.

We have to understand stupidity to understand intelligence.",0,0,0
1731,2023-02-04 23:35:46+00:00,ylecun,"@ylecun @elonmusk @OriolVinyalsML mettre les pieds dans le plat, that's what it is!",0,0,0
1732,2023-02-04 23:33:00+00:00,ylecun,"@ylecun @JohnBlackburn75 @traderyau But are LLMs an extension of intelligence in a way that is unprecedented and very powerful? Complimentary AI, not AGI?",0,0,0
1733,2023-02-04 23:32:25+00:00,ylecun,"@ylecun Is it ever possible to have human-level AI? If it is possible, do we really want it to happen? I am thinking about Skynet.",1,0,0
1734,2023-02-04 23:32:02+00:00,ylecun,@ylecun https://t.co/57lJC3MNiY,0,0,0
1735,2023-02-04 23:30:44+00:00,ylecun,"@ylecun @hughhowey These strong claims need clear definitions of what you qualify as ""human level AI"" and what you are including under LLMs. What would your ""Turing Test"" entail? If same but larger architecture is trained on text, audio, and video to produce text, audio, &amp; video, is that still LLM?",1,0,0
1736,2023-02-04 23:25:39+00:00,ylecun,"@ylecun @elonmusk @OriolVinyalsML don‚Äôt think Oriol would disagree with ‚ÄúLLMs are missing essential features for HLAI,‚Äù perhaps has a problem with the ‚ÄúLLMs are an off-ramp‚Äù analogy",1,4,0
1737,2023-02-04 23:24:44+00:00,ylecun,"@ylecun @elonmusk I don't disagree with that, but disagree with the off-ramp thing üòá",4,80,1
1738,2023-02-04 23:20:30+00:00,ylecun,"@ylecun @traderyau Respectfully, etymologically speaking, there is no intelligence without written language (inter legere)

Historically speaking, there are very strong clues that written language IS the great enabler: without it you only have instinct and very limited culture.",0,0,0
1739,2023-02-04 23:18:33+00:00,ylecun,@ylecun @OriolVinyalsML Do I smell a simon ehrlich wager thing happening here? Shouldn‚Äôt be too hard to agree on a criteria?,0,1,0
1740,2023-02-04 23:09:25+00:00,ylecun,@ylecun @hughhowey You'd be surprised what insights you can extract from ChatGPT in longer conversations when prompted correctly.,0,0,0
1741,2023-02-04 23:06:46+00:00,ylecun,@ylecun Yann LeCant we all just get along,1,9,0
1742,2023-02-04 23:03:11+00:00,ylecun,@ylecun good. we need more off ramps. making machines that ‚Äúfeel‚Äù is asinine.,0,0,0
1743,2023-02-04 22:58:57+00:00,ylecun,@ylecun @OriolVinyalsML Obviously. If they think it's only 'a single thought'. World models and internal simulations are a must.,0,0,0
1744,2023-02-04 22:55:53+00:00,ylecun,@ylecun @elonmusk @OriolVinyalsML If consciousness really is next word prediction then I don‚Äôt want to live anymore.,1,4,0
1745,2023-02-04 22:49:33+00:00,ylecun,"@ylecun @elonmusk @OriolVinyalsML ""Oh, of course! We wouldn't want to miss out on any essential features for HLAI. That would be a disaster!""",0,0,0
1746,2023-02-04 22:49:13+00:00,ylecun,"@ylecun Like Galactica? 
I just don't see how you can put ChatGPT and Galactica in different buckets.

https://t.co/sg41dLAkdT",0,1,0
1747,2023-02-04 22:45:10+00:00,ylecun,@ylecun @traderyau LLMs aren't just about language Yann.  The transformer is a very flexible that can encode many modalities.  Saying language can't capture all of human knowledge may or may not be true but it's irrelevant to whether this is the architecture for AGI,0,2,1
1748,2023-02-04 22:44:33+00:00,ylecun,@ylecun https://t.co/FyQFab3NNh,0,0,0
1749,2023-02-04 22:40:54+00:00,ylecun,@ylecun @hughhowey Sure but you moved the goalposts to a totally different pitch now.,1,5,0
1750,2023-02-04 22:39:25+00:00,ylecun,@ylecun Human-Level AI is still lots of decades away,0,0,0
1751,2023-02-04 22:23:38+00:00,ylecun,"@ylecun Their loss mate. Several of your former friends there say hi and often quoted parting with you as a ‚Äúsupreme failure‚Äù

Hey @statpumpkin he could have been your boss :)",0,0,0
1752,2023-02-04 22:17:26+00:00,ylecun,"@ylecun God knows I hate hate your choice of working for a lizzard, but you are 100% on point here",0,0,0
1753,2023-02-04 22:15:08+00:00,ylecun,"@ylecun Imagine what's going to happen when the LLM breaks down because they're incorporating social constructs that have no basis in physical reality. Where psychological issues are considered nominal physical reality; for example body dysmorphia, and gender dysphoria.",0,0,0
1754,2023-02-04 22:11:39+00:00,ylecun,@ylecun @MatjazLeonardis A long read for non AI practitioners. Is there a layman's version?,0,0,0
1755,2023-02-04 22:09:34+00:00,ylecun,"@ylecun @jpFromTlon But then, the field will be in the hands of people who understand what they are talking about.",0,0,0
1756,2023-02-04 22:06:56+00:00,ylecun,"@ylecun What, weren't the Australopithecine running GPT?",0,0,0
1757,2023-02-04 22:03:32+00:00,ylecun,"@ylecun On the highway towards Human-Level AI, the off-ramps will become the main event.",1,20,1
1758,2023-02-04 22:03:16+00:00,ylecun,"@ylecun Doubtful, isn‚Äôt language a low dimensional representation of everything else we interact with?",0,0,0
1759,2023-02-04 22:02:02+00:00,ylecun,"@ylecun The use of BERT-style-only architectures in NMT is controversial at best. Most advantages found relate to up-starting low resource languages. That‚Äôs the reason why many NMT systems are at least decoder-based or, like originally designed, encoder-decoder-like.",0,0,0
1760,2023-02-04 22:02:02+00:00,ylecun,@ylecun dont underestimate emergence,0,0,0
1761,2023-02-04 21:56:31+00:00,ylecun,"@ylecun @MatjazLeonardis Thanks for the read, Yann.",0,0,0
1762,2023-02-04 21:48:06+00:00,ylecun,"@ylecun I think that LLMs alone will not lead to human-level AI, but certainly LLMs would have stunning potential if they were trained on and work in conjunction with sensory inputs.",0,0,0
1763,2023-02-04 21:40:38+00:00,ylecun,@ylecun üòÇ wow,0,0,0
1764,2023-02-04 21:40:31+00:00,ylecun,"@ylecun @hughhowey Given that most people on social media support the thesis that chatgpt will replace humans in most jobs, if not all, I think avg human iq has gone down so much that it lower than a house cat now",1,0,0
1765,2023-02-04 21:35:22+00:00,ylecun,"@ylecun I'm no programmer , but can use tools to create what I want and if Ai helps me get there then even better https://t.co/PXq1ChGzje",1,0,0
1766,2023-02-04 21:34:27+00:00,ylecun,"@ylecun I know nothing about this realm, why is language being considered as an important premise for AI ?",0,0,0
1767,2023-02-04 21:30:18+00:00,ylecun,"@ylecun üå∂Ô∏èAs they are today, it may seem like that, but if some addition bits get injected, I could see them being foundational enough that considering them an off-ramp to be a wrong analogy. We shall see!",0,0,0
1768,2023-02-04 21:30:06+00:00,ylecun,@ylecun @hughhowey Can you give some examples of these mistakes?,0,0,0
1769,2023-02-04 21:27:49+00:00,ylecun,@ylecun @hughhowey Are you allowed to disclose if Facebook has developed an internal model mitigating these shortcomings?,0,0,0
1770,2023-02-04 21:25:07+00:00,ylecun,@ylecun Neuromorphic computing,0,0,0
1771,2023-02-04 21:22:13+00:00,ylecun,@ylecun @readwise save thread,1,0,0
1772,2023-02-04 21:22:00+00:00,ylecun,"@ylecun They are a part of the solution, but just a part.",0,1,0
1773,2023-02-04 21:19:00+00:00,ylecun,@ylecun @PSpagnou üíØüéØ,0,0,0
1774,2023-02-04 21:14:31+00:00,ylecun,"@ylecun @smjain The belief that we will have One Model to Rule Them All in general is naive. Even if possible, it would not be optimal

Most likely the path to AGI is a combination of multiple models optimized for different tasks.  Coordinating these could very well be an LLM-like task though",1,1,0
1775,2023-02-04 21:11:01+00:00,ylecun,"@ylecun The Von Neumann Architecture is very power inefficient compared to the brain. The field should invest in neuromorphic computing instead of GPU/TPU racks

LLMs need to be multimodal, with a world model

Lastly, backpropagation needs to happen continuously like the human brain",1,0,0
1776,2023-02-04 21:08:52+00:00,ylecun,"@ylecun @hughhowey Intelligent humans tend to believe all sorts of crazy things, and many humans lack basic common  sense.",0,0,0
1777,2023-02-04 21:03:01+00:00,ylecun,"@ylecun Fair point

Mostly because if there‚Äôs one thing Facebook knows about, it‚Äôs being the biggest off-ramp on the highway of human productivity 

Well, and shipping an impactful product, but let‚Äôs not throw stones there since Google ain‚Äôt all that great there either",0,1,0
1778,2023-02-04 20:55:34+00:00,ylecun,"@ylecun @hughhowey There is no ""common sense"" baseline that a housecat won't drop below on a regular basis.",0,0,0
1779,2023-02-04 20:49:42+00:00,ylecun,"@ylecun I remember a few years ago, GANs and LSTMs were all the rage. These days, they seem to have been replaced by diffusion models and transformers for img and text gen respectively. Do you think these models are here to stay or do you see them being replaced by something else?",0,1,0
1780,2023-02-04 20:48:59+00:00,ylecun,@ylecun Highway to hell ü§ñüî•üî•üî•,0,0,0
1781,2023-02-04 20:42:05+00:00,ylecun,@ylecun Why isn't that obvious? What's causing the sheep to flock so??,0,0,0
1782,2023-02-04 20:40:55+00:00,ylecun,@ylecun are you suggesting we must be getting lost ? https://t.co/322kYXYTxy,0,0,0
1783,2023-02-04 20:39:10+00:00,ylecun,@ylecun zzzzzzzzz chatGPT,0,0,0
1784,2023-02-04 20:31:48+00:00,ylecun,@ylecun Okay. Can you point me in the right direction?,0,0,0
1785,2023-02-04 20:18:01+00:00,ylecun,@ylecun It‚Äôs suprising you didn‚Äôt see the emerging intelligence from #Chatgpt.  It‚Äôs clearly demonstrating some kind of understanding and follow text instructions.,0,0,0
1786,2023-02-04 20:16:51+00:00,ylecun,@ylecun That‚Äôs because #Chatgpt is only trained with text.  If its extended to multimodality it will definitely has more ‚Äúcommon sense‚Äù you were talking about.,0,0,0
1787,2023-02-04 20:15:38+00:00,ylecun,"@ylecun LLMs were there even before large scale transformers, no? RNNs LM, LSTMs LM, etc. (albeit nobody called it large ig)",1,4,0
1788,2023-02-04 20:15:31+00:00,ylecun,"@ylecun Sir, with due respect, your bias against anything Meta is concerning.",0,0,0
1789,2023-02-04 20:13:16+00:00,ylecun,"@ylecun Maybe an off ramp to the airport as Minerva continues to improve over the MATH dataset. Currently at the 90th % of human performance. If people are confused over LLM resembling AGI rather than the ANI it is, Minerva evolution will show ANI-&gt;ASI, a subtle transition indeed!",2,0,0
1790,2023-02-04 20:12:32+00:00,ylecun,@ylecun @ferdousbhai Is AGI the same as Human-level AI?,1,0,0
1791,2023-02-04 20:12:00+00:00,ylecun,@ylecun @DinoDvorak So by that defination @OpenAI is the leanest &amp; most effective in terms of shipping things. üòä,0,0,0
1792,2023-02-04 20:07:52+00:00,ylecun,"@ylecun @Golisms I was just going to recommend reading about Cicero to those who disagree with the view you present here. I discussed this system in my undergrad AI course as a great example of combining planning, RL, and LLMs. It excels at its task only because of this combination of methods",1,1,0
1793,2023-02-04 20:07:38+00:00,ylecun,@ylecun ac/dc,0,0,0
1794,2023-02-04 20:05:23+00:00,ylecun,@ylecun it's a truck stop where we get some coffee and take a pee,0,0,0
1795,2023-02-04 20:00:43+00:00,ylecun,"@ylecun Shhhh You will be wishing you did buddy. I mean save the embarrassment ;)
Rusted in spaghetti üçù sauce lol",0,0,0
1796,2023-02-04 19:57:33+00:00,ylecun,@ylecun Then it‚Äôs your companies own fault for not releasing your AI version earlier!  Sitting on technology when it is good enough for public consumption is foolishly.  It is like having a winning lottery ticket and being too scared to cash it in.,0,0,0
1797,2023-02-04 19:55:51+00:00,ylecun,@ylecun @ylecun is much much smarter than the people at @OpenAI It was years ago he helped us get the best cat videos in our feeds. The work that @OpenAI now made banal in their ‚Äúnon-impressive‚Äù ChatGPT3. Follow him for a daily reminder of that.,1,8,0
1798,2023-02-04 19:50:24+00:00,ylecun,"@ylecun Thoughts? 

@sama @gdb",0,0,0
1799,2023-02-04 19:46:49+00:00,ylecun,"@ylecun Self-supervised learning has also been used to improve the performance of computer vision models, such as image classification and object detection. For example, researchers have used self-supervised learning to pre-train convolutional neural networks (CNNs) on large datasets.",0,1,0
1800,2023-02-04 19:43:55+00:00,ylecun,"@ylecun it is clear that AI is near human level now , but human brain is not taking text only as input , human takes sound , picture , touch , smell and taste , we will not make a model like human until it have all these inputs before taking a decision",0,0,0
1801,2023-02-04 19:41:52+00:00,ylecun,@ylecun Recommender systems have been also using  self-supervised learning for over a decade impacting the experience of millions of users daily.,0,2,0
1802,2023-02-04 19:41:23+00:00,ylecun,@ylecun They could generate substantial funds - especially if they can program. More dollars and cheaper programming skills might well help organizations to make progress towards powerful machine intelligence. So: I think this tweet is probably mistaken.,1,2,1
1803,2023-02-04 19:35:21+00:00,ylecun,"@ylecun This reeks of some severly miscalculated short sellings. LLM might not be the last step to truly AI, but it is a (most likely huge) step in the right direction.",0,2,1
1804,2023-02-04 19:33:43+00:00,ylecun,"@ylecun @OriolVinyalsML Because we‚Äôll all be dead from an ASI? Damn Yann, dark",0,5,0
1805,2023-02-04 19:31:02+00:00,ylecun,"@ylecun Just because you can convince a monkey that it‚Äôs speaking to a monkey doesn‚Äôt mean the thing ‚Äòspeaking‚Äô even knows it‚Äôs speaking to a monkey, or even speaking at all for that matter. Yann dropping facts left and right ü•±",0,0,0
1806,2023-02-04 19:27:54+00:00,ylecun,@ylecun Only if the goal will be reached,0,0,0
1807,2023-02-04 19:26:10+00:00,ylecun,"@ylecun I enjoy celebrating these achievements for what they are. We aren‚Äôt really going to understand all the little steps that lead to ubiquitous, useful, strong AI until we have it and then historians of science are go to have to do a lot of work to discover it.",1,6,0
1808,2023-02-04 19:24:44+00:00,ylecun,@ylecun I do wonder if isotropic models are a necessary sidestep from a processing complexity standpoint. Maybe they're super gradient efficient because they're like the equivalent of loop unrolling. I feel like we're stuck behind a wall of linearity here that's holding us back somewhat.,0,0,0
1809,2023-02-04 19:19:47+00:00,ylecun,@ylecun I agree with the general sentiment. But why highway? I feel the full journey is more like an off road experience. Highways are built to cushion the thrill. LLMs do need some grounding for sure.,1,1,0
1810,2023-02-04 19:18:13+00:00,ylecun,"@ylecun So the current ChatGPT success (or hype) is not just due to the (certainly powerful) principle of self-supervised learning, but heavily based on human supervision through RLHF, isn‚Äòt it?",1,1,0
1811,2023-02-04 19:15:26+00:00,ylecun,@ylecun I think the public perception (and also Yann‚Äòs judgement) underestimates the huge amount of work that went into human labeling (hand crafted answers + training examples for RLHF) which distinguishes ChatGPT from earlier GPT version. Training data engineering made the difference.,0,9,0
1812,2023-02-04 19:14:12+00:00,ylecun,"@ylecun I wish we would call them ‚Äúfluency models‚Äù. Fluency of speech, fluency of motion, fluency of perceptual processing. It‚Äôs not intelligence itself, but it enables the transition of skill from system 2 to system 1.

We only call them LLMs because that‚Äôs how we train them.",0,0,0
1813,2023-02-04 19:13:40+00:00,ylecun,@ylecun Yes,0,0,0
1814,2023-02-04 19:11:57+00:00,ylecun,"@ylecun What do you mean by Human Level AI? What it's means human level in this contexts? 
Without a clear framing, try to make comparations is like a guessing game. 
If the goal is to reach a human level in his all plenitude is something like replicate human beings.",0,0,0
1815,2023-02-04 19:10:23+00:00,ylecun,@ylecun @Golisms Completely absent? What is the scientific explanation to the attached conversation? https://t.co/xl0Bb9MtMY,0,0,0
1816,2023-02-04 19:06:37+00:00,ylecun,"@ylecun @OriolVinyalsML Now now, let's not be writing checks whose amount is difficult to recognize",0,11,0
1817,2023-02-04 19:04:28+00:00,ylecun,@ylecun Failure is an important part of learning.,0,0,0
1818,2023-02-04 19:03:09+00:00,ylecun,"@ylecun LLMs can translate, summarize, paraphrase, program, write poetry, conduct therapy, debate, plan, create, and speculate. A system that can do all of these can reasonably be said to be a step on the path to general intelligence.",1,0,0
1819,2023-02-04 18:58:46+00:00,ylecun,"@ylecun @hughhowey You could make the same assertion for most people. Appeals to ""understanding"" and ""truth"" are red herrings.",1,6,0
1820,2023-02-04 18:55:33+00:00,ylecun,"@DrTc666 Between 1996 &amp; 2002, I mostly worked on DjVu (image compression) &amp; wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&amp;T could no longer afford a research lab.
Half of AT&amp;T Labs-Research was laid off.
I managed to be one of them.",1,1,1
1821,2023-02-04 18:55:30+00:00,ylecun,"@ylecun What if Human-Level AI is overrated? What if the off-ramp actually leads towards Super Narrow AI that ends up being way, way more useful than an imitation of what we already have on 8 billion plus of?",1,0,0
1822,2023-02-04 18:54:17+00:00,ylecun,"@ylecun They are simply sequence modelling tools. If you can model possible behaviours as sequences, you might get somewhere, but probably not by modelling internet articles.",0,0,0
1823,2023-02-04 18:53:46+00:00,ylecun,"@ylecun Is it possible that language when observed over a sufficiently large sample can approximate the  dynamics of human level intelligence? (in the same way ML applied to massive weather datasets can approximate atmospheric fluid dynamics)? Not my field, but interested amateur.",0,0,0
1824,2023-02-04 18:50:44+00:00,ylecun,@ylecun Which technology is on-ramp to human level AI?,0,0,0
1825,2023-02-04 18:46:54+00:00,ylecun,@ylecun @ferdousbhai Even LLMs don‚Äôt think that,0,2,0
1826,2023-02-04 18:46:43+00:00,ylecun,@ylecun Thoughts on COLLAS in embedded robots?,0,1,0
1827,2023-02-04 18:45:22+00:00,ylecun,@ylecun @smjain Who thinks that?,0,0,0
1828,2023-02-04 18:42:49+00:00,ylecun,@ylecun Should even human level AI be the goal. Or AI that makes the human condition better?,0,1,1
1829,2023-02-04 18:39:21+00:00,ylecun,"@ylecun LLMs are equivalent to the human Cortex, you can't have human-level AI without it, but having just it isn't enough to create a complete cognitive cycle as human do. We're at Inpris are working on it and solving it for real world problems in production level.",0,1,0
1830,2023-02-04 18:38:59+00:00,ylecun,"@ylecun LLMs could be part of a human-level AI system, providing a natural language interface and possibly coordinating work with other models

In the same way human intelligence is not a single monolithic process in the brain, no reason to assume AGI has to be a single model",0,1,0
1831,2023-02-04 18:36:35+00:00,ylecun,@ylecun @hughhowey And consume way more energy.,0,0,0
1832,2023-02-04 18:35:04+00:00,ylecun,@ylecun Remind me in 5 years... üçø,14,602,16
1833,2023-02-04 18:31:46+00:00,ylecun,@ylecun @traderyau For humans to believe a robot or computer is intelligent it must be able to use language. Think of all intelligent robots in science fiction. So LLM is a necessary but maybe not sufficient condition for intelligence. To say its completely irrelevant is surely false,1,2,0
1834,2023-02-04 18:30:45+00:00,ylecun,@ylecun You once said about Jess Hawkins of @Numenta that his ideas are hard to reduce to practicality. Well LLMs are exactly that.. pure practicality that might demostrate intelligence. You are now playing the opposite side of that. What are these highway routes that everybody missing?,0,1,0
1835,2023-02-04 18:27:43+00:00,ylecun,@ylecun Seeing these replies I get where you coming from but release a product man.,0,0,0
1836,2023-02-04 18:25:41+00:00,ylecun,@ylecun @MatjazLeonardis üéØ,0,0,0
1837,2023-02-04 18:23:59+00:00,ylecun,@ylecun Release a product and not a paper,0,0,0
1838,2023-02-04 18:11:45+00:00,ylecun,@ylecun @miguelisolano @Tech4Breakfast  ;),0,0,0
1839,2023-02-04 18:11:45+00:00,ylecun,@ylecun Why not a milestone?,0,0,0
1840,2023-02-04 18:04:05+00:00,ylecun,@ylecun LLMs are like those people who can bs their way about anything with confidence whilst having no clue.,0,0,0
1841,2023-02-04 18:03:20+00:00,ylecun,@ylecun I wonder if you need to capture coefficients that has intelligent dx behaviour,0,0,0
1842,2023-02-04 17:59:49+00:00,ylecun,"@ylecun @traderyau Hmm, this is interesting.",0,0,0
1843,2023-02-04 17:54:32+00:00,ylecun,@ylecun Yes.  I wish this was more widely discussed,0,0,0
1844,2023-02-04 17:54:01+00:00,ylecun,@ylecun Consistent,0,0,0
1845,2023-02-04 17:49:20+00:00,ylecun,"@ylecun Funny, just yesterday I said the same in an email but used the term dead end. Now I see you updated your off-ramp to off-ramp to oblivion. 

But how long could that possibly delay progress? Ptolemy‚Äôs geocentric model comes to mind.",0,0,0
1846,2023-02-04 17:48:08+00:00,ylecun,@ylecun Why are you so bitter?,0,1,0
1847,2023-02-04 17:46:30+00:00,ylecun,"@ylecun No! MetaAI is doomed with that kind of advice from Yann LeCun.
LLMs are not an off-ramp,they are a stepping stone, they accomplish the first and arguably the hardest step, towards adding Causal Inference and the scientific method to AI. I explain it here:
https://t.co/teHxJIPZJ1",0,1,1
1848,2023-02-04 17:41:29+00:00,ylecun,@ylecun So you mean all this effort and the effort of who's building on top is leading toward a dead end?,0,0,0
1849,2023-02-04 17:39:43+00:00,ylecun,@ylecun whatever! :D https://t.co/qViFBto4PD,0,10,2
1850,2023-02-04 17:37:32+00:00,ylecun,@ylecun It would be silly to even try.  Humans are ridiculously inefficient at complex conscious reasoning.  It's not what we were evolved to do.,0,0,0
1851,2023-02-04 17:22:39+00:00,ylecun,@ylecun @smjain We know...,0,0,0
1852,2023-02-04 17:22:38+00:00,ylecun,"@ylecun Trying to reach human level intelligence when we do not have yet available general intelligence models (models that, though not at human level, can accomplish a large variety of tasks) is going an off-ramp.",1,0,0
1853,2023-02-04 17:21:40+00:00,ylecun,"@ylecun @ferdousbhai Some believe stacking up hundreds of narrow AI models can emulate general AI, just as  armchair ""economists"" believe stacking up MicroEconomics principles leads to MacroEconomics.",0,0,0
1854,2023-02-04 17:19:03+00:00,ylecun,@ylecun AT&amp;T Bell Labs FTW @FakespotTweets,1,2,0
1855,2023-02-04 17:14:15+00:00,ylecun,"@ylecun @c7ddfc Need a world model ""gym"" with appropriate RL rewards.",0,0,0
1856,2023-02-04 17:12:25+00:00,ylecun,@ylecun And the road to Hell is paved with ... ??,0,0,0
1857,2023-02-04 17:11:44+00:00,ylecun,"@ylecun When thinking of #HLAI I fall back on Kant's 'Spontaneity'. In 3rd Antinomy, Kant makes clear that ‚Äòspontaneity‚Äô is the ‚Äúfaculty of beginning a (mental) state from itself‚Äù,that's  the faculty of causing one-self or another substance to be in a state without being caused to do so",0,0,0
1858,2023-02-04 17:02:24+00:00,ylecun,@ylecun Chatgpt is useful only when the human user can tell if the answer is right or wrong.,0,0,0
1859,2023-02-04 16:58:38+00:00,ylecun,"@ylecun Your ""A Path Towards Autonomous Machine Intelligence"" is the best theoretical blueprint to AGI

The practical question is what is the best accessible implementation of AGI now.

The langchain pipeline combining LLM, structured KB and symbolic manipulation seem the most promising. https://t.co/g1ZQLnheTU",0,2,0
1860,2023-02-04 16:52:45+00:00,ylecun,"@ylecun I don‚Äôt think we should aim , leave alone hope for a human-level AI. 

Instead we should train and equip humans with human-centric AI skills and techniques.",0,0,1
1861,2023-02-04 16:52:40+00:00,ylecun,@ylecun @LexMitchell Conveniently forgetting to celebrate AlexNet,0,0,0
1862,2023-02-04 16:50:18+00:00,ylecun,"@ylecun ""Useless"" is a hallucination in this context. Let's look at facts, please. From the abstract: ""[we encourage] research directions beyond ever larger language models."" Then I guess people are capable at various interpretations of this",0,11,0
1863,2023-02-04 16:39:35+00:00,ylecun,"@ylecun LLM works just like our imaginative brain, by faking the manipulation of complex concepts, using repetition, association, and vocabulary to create a sense of causality. What is needed now is the algorithm that reasons above these intuitions. So not an off-ramp, but a foundation.",0,2,0
1864,2023-02-04 16:37:02+00:00,ylecun,@ylecun @hughhowey Humans don't need to be perfect - why do machines? I'd rather the mistakes be simple enough for humans to detect than complex and subtle enough to render our species complacent.,0,0,0
1865,2023-02-04 16:36:34+00:00,ylecun,"@ylecun No matter what the model is, all models only do calculations, but human not just only do calculations, that‚Äôs the difference!",0,0,0
1866,2023-02-04 16:35:45+00:00,ylecun,"@ylecun ChatGPT etc is like if you wanted to make an artificial human body and spent your time just trying to make your artificial spleen do more and more, even though your current version is already good enough at just spleening. We need to spend more time on the REST of the AI Problem",0,0,0
1867,2023-02-04 16:35:04+00:00,ylecun,@ylecun your giving too much credit to humans üòÇ,0,0,0
1868,2023-02-04 16:22:36+00:00,ylecun,@ylecun those that ascribe to the ‚Äòsociety of mind‚Äô theory  consider LLMs as an essential first step,0,0,0
1869,2023-02-04 16:20:04+00:00,ylecun,"@ylecun Ironically, one can say same about convolutional networks and 2020s obsession on ImageNet. 

But they weren‚Äôt off-ramp as many techniques there eventually lead way to transformers. 

We build on others and there is no need to deride things you or your employer is missing out.",0,0,0
1870,2023-02-04 16:18:33+00:00,ylecun,"@ylecun There will never be Human-Level AI because concepts live on their own on an immaterial dimension that only consciousness, with the tool called ""the mind"" can grasp. A machine has no access to the immaterial dimension. That's also why a machine will never be conscious.",0,0,0
1871,2023-02-04 16:13:55+00:00,ylecun,@ylecun salty,0,0,0
1872,2023-02-04 16:05:15+00:00,ylecun,"@ylecun @Golisms What do you see as the best approach to develop a generalized planner? Not the custom one specific limited problem planner in Cicero, but general enough to adapt a specific prompt. Is this even possible?",0,0,0
1873,2023-02-04 16:02:51+00:00,ylecun,"@ylecun Assuming you want to get Human-Level AI, which you probably don't. In such a case LLM are a ""good enough"" specific approximation (perhaps even too good, it's already destructive to students and children that will grow in a world in which they don't need to think for themselves)",0,0,0
1874,2023-02-04 16:02:24+00:00,ylecun,"@ylecun Philosophical question.. if we hit human level ai, would it lead to a broader question of ok cool, what do I do now ..knowing a machine could do my job and probably do it better ? When we hit for human level ai, do we start another problem of human purpose ?",0,0,0
1875,2023-02-04 16:00:40+00:00,ylecun,@ylecun The on-ramp is simple high-dimensional human curated CSV files. https://t.co/YPi7VbCqze,0,1,0
1876,2023-02-04 15:59:27+00:00,ylecun,@ylecun Any updates on your orchestration AGI work? The one with different components for different parts of brain function?,0,0,0
1877,2023-02-04 15:57:28+00:00,ylecun,"@ylecun @beenwrekt Of all the things mentioned in these ads, the ONLY one that still is half-baked and not available to everyone is - ""you will one day carry your medical history in your pocket!"" and that is a huge tell about the healthcare industry (than tech itself).",0,2,1
1878,2023-02-04 15:57:13+00:00,ylecun,@ylecun MYSTERY BLACK,0,0,0
1879,2023-02-04 15:56:55+00:00,ylecun,@ylecun But everyone else seems to be treating it as the highway AND are also convinced that it is the only road available...smh,0,0,0
1880,2023-02-04 15:55:22+00:00,ylecun,"@ylecun Question is what is Human level? 

* Dogs understand and respond to commands.
* Computers work in a specific way because it is programmed in a certain style with strict rules.
* Human level is natural understanding.
* LLM's are already human level in understanding.",0,0,0
1881,2023-02-04 15:48:04+00:00,ylecun,@ylecun Still waiting for releases. Anything lined up this year we should be looking forward to? Maybe ur team can demonstrate where on the highway you're at and possibly how far u r from ur destination? I promise people will give their attention and u will be the talk of the town.,0,0,0
1882,2023-02-04 15:43:05+00:00,ylecun,@ylecun @hughhowey At what level do we need to make change to move forward on the path of AGI? Is neural network with back propogation enough to achieve AGI or do we need to develop an alternate architecture to LLMs using the current learning mechanisms?,0,0,0
1883,2023-02-04 15:38:18+00:00,ylecun,@ylecun @MatjazLeonardis üëç,0,0,0
1884,2023-02-04 15:32:37+00:00,ylecun,@ylecun Agreed Yann. Can you also give us some direction (papers) which we should be looking at going forth which are at the forefronts of making a human level AI?,0,0,0
1885,2023-02-04 15:31:39+00:00,ylecun,"@ylecun That's like saying cells is an off-ramp to humans. We simply don't know how to create AGI and thus whether it's an on-ramp or off-ramp is too early to tell.

We do know that LLMs have emergent capabilities which is a pre-requisite for human level intelligence.",0,3,1
1886,2023-02-04 15:26:17+00:00,ylecun,@ylecun One argument is that LLMs will speed up development e.g. copilot and that will lead to a quicker timeline to AGI.,0,2,0
1887,2023-02-04 15:25:19+00:00,ylecun,"@ylecun When it converges with symbolic context, and a physical experience, let‚Äôs get ready to be amazed‚Ä¶",0,0,0
1888,2023-02-04 15:23:05+00:00,ylecun,@ylecun I'm not seeing anything other than narrow AI so far?,0,0,0
1889,2023-02-04 15:21:46+00:00,ylecun,@ylecun So what is the fast lane then? Or is everybody else stuck in the jam?,0,0,0
1890,2023-02-04 15:20:29+00:00,ylecun,"@ylecun @OptimalBayes It‚Äôs for dazzling the general public and to legitimate more funding towards the field, no?",0,2,0
1891,2023-02-04 15:13:08+00:00,ylecun,@ylecun @MatjazLeonardis Remains inductivist and reductionist to the bone‚Ä¶ Sadly leading to yet another off-ramp.,0,0,0
1892,2023-02-04 15:12:34+00:00,ylecun,"@ylecun Well said. ..there are more impressive AI that can beat you at complex games. chat-GPT is being hyped way too much as an AI, though it does revolutionize our ability to automate common human tasks",0,0,0
1893,2023-02-04 15:11:11+00:00,ylecun,"@ylecun So you don‚Äôt know what the path is, so how do you know you are on the right highway?",0,0,0
1894,2023-02-04 15:08:44+00:00,ylecun,@ylecun Is Midjourney based on GAN?,0,0,0
1895,2023-02-04 15:04:33+00:00,ylecun,@ylecun Shows again that people underestimate the power of tech- nology over long time frames.,0,0,0
1896,2023-02-04 15:03:47+00:00,ylecun,@ylecun Your tweets regarding LLM and AI not gonna age well.,0,1,1
1897,2023-02-04 14:59:15+00:00,ylecun,"@ylecun @smjain Ok, It seems obvious. It's it really a problem if done people think that? I would think just in terms of interest and new funding, LLMs are likely to help.",0,0,0
1898,2023-02-04 14:58:26+00:00,ylecun,"@ylecun @smjain LLMs are like electric cars in the 1910s. Very useful, better than the competition, but will probably get replaced in the medium-term.

Which said little about the actual long-term feasibility of EVs. 
LLMs are the Gemini and Apollo of AI; the goal isn't to be the end-all.",0,5,1
1899,2023-02-04 14:55:36+00:00,ylecun,"@ylecun @hughhowey Is your point that Internet-scale textual training data makes good performance too easy (ie a shortcut around common sense)? Or, that this data makes the task too hard / impossible? Or, that LLMs have the wrong architecture &amp; training objective? Or, all three?",1,1,0
1900,2023-02-04 14:53:30+00:00,ylecun,"@ylecun Bell Labs was pivotal to many advancements, that‚Äôs so cool!",0,0,0
1901,2023-02-04 14:52:18+00:00,ylecun,@ylecun Why should that be the goal? Has that been the goal?,0,0,0
1902,2023-02-04 14:50:04+00:00,ylecun,"@ylecun Not just LLM, inductive learning in general is an off ramp",0,0,0
1903,2023-02-04 14:46:02+00:00,ylecun,"@ylecun I respectfully disagree. While other experienced methodologists are struggling to harness new approaches and tools to make the world a better place, you have criticized the new AI tools. It was expected to hear more professional viewpoints from the most professional scientists.",0,0,0
1904,2023-02-04 14:45:50+00:00,ylecun,@ylecun U are prob right genius and all. But please repeat after me. Adoption. Adoption. Adoption. AI is a scary subject for most. LLMs are a positive tangible experience and will increase general acceptance without which nothing matters anyway.,0,0,0
1905,2023-02-04 14:43:07+00:00,ylecun,@ylecun I think path is ill defined. Is the highway to success built of off-ramps? I mention this from a developers perspective trying to understand what you know.,0,0,0
1906,2023-02-04 14:38:28+00:00,ylecun,"@ylecun Turing machine based on Church-Turing-Deutsch principle is a steppingstone to HLAI for symbol manipulation but it (and anything running on TM) can‚Äôt inhabit the world so it‚Äôs inherently limited on its own.

LLM has the potential to loosen up the limits to certain degree.",1,0,0
1907,2023-02-04 14:29:56+00:00,ylecun,@ylecun There's gonna be a great rest station when it's all finished though,0,0,0
1908,2023-02-04 14:29:27+00:00,ylecun,"@ylecun Generally, what does the AI community mean when we say the human brain ""build models""?  By model, are you referring to an equation that maps sensory input to another (maybe behavior) output?  Or is it a grammar made of rules of production (each rule being a thought) ?",0,0,0
1909,2023-02-04 14:27:30+00:00,ylecun,"@ylecun I recently explained on @Clubhouse why ChatGPT can‚Äôt write a poem am that ends with a certain word (‚Äúmink‚Äù), bc it can‚Äôt plan to use a rhyming word (‚Äúthink‚Äù or ‚Äúsink‚Äù) earlier. But combining LLMs w a planner&amp;world model, as Cicero does, seems to be on the road to Human-Level AI.",0,15,2
1910,2023-02-04 14:27:18+00:00,ylecun,"@ylecun Well you're obviously incredibly knowledgeful, therefore I'm really curious to see what you'll come up withüòä
Should we expect an AI-driven representation of the World accessible from an API any time soon? How would we interact(query, response,...) with it to consume and feed it?",0,0,0
1911,2023-02-04 14:27:04+00:00,ylecun,@ylecun Thanks! :D,0,2,0
1912,2023-02-04 14:25:09+00:00,ylecun,"@ylecun @hughhowey To a language model, the world is language, and the understanding is masterful, it's much higher level than what we do, at least that's how it looks.  Give them legs, give them eyes, give them tongues, ears and maybe a form of touch... what happens then?  Can you apply same model",1,0,0
1913,2023-02-04 14:23:49+00:00,ylecun,@ylecun @Golisms And how they do it.. planning.. i totally agree a memory chapion can not be a great a solving problem.. these LLMs are like RAINMAN.. stores and recall enormous information.. but can not understand that information to make a intelligent decision..,1,0,0
1914,2023-02-04 14:22:03+00:00,ylecun,"@ylecun For reasons that aren't precisely clear or supportable, Yann LeCun has swung hard against LLM/GPT tech. It would be a mistake for Meta or any company to take that position.",0,0,0
1915,2023-02-04 14:21:28+00:00,ylecun,@ylecun Unified model doesn't include language?,0,0,0
1916,2023-02-04 14:18:15+00:00,ylecun,"@ylecun I was at ATT Research and worked with bell labs people who worked with you. They told me that in a spectacular display of failure on ATTs part, they fired you and other ai people thinking ai was a fad - is that true? 

Sadly this would be just another example of their myopicness",1,1,0
1917,2023-02-04 14:17:02+00:00,ylecun,@ylecun This comes off as kinda defensive and bitter,0,0,0
1918,2023-02-04 14:16:40+00:00,ylecun,"@ylecun You share John Carmack's view. The urge to take easy commercial offramps is strong as there are many of them presumably, and can easily lead to billions.",0,0,0
1919,2023-02-04 14:14:28+00:00,ylecun,"@ylecun What do you mean? That LLMs get off the road to Human-Level AI / they're a distraction / dead end?

Why?",0,1,1
1920,2023-02-04 14:13:40+00:00,ylecun,"@ylecun Maybe, but millions have taken this off ramp and they are in awe.  People are excited.   There is a new awareness that we are on a road to Agi.  Traffic is increasing.",0,1,1
1921,2023-02-04 14:10:01+00:00,ylecun,"@ylecun Could you elaborate?

From the perspective of human history, developing a type of languages early was one of the key differentiators between human and other species.

Curious to learn more about your reasoning.",0,2,1
1922,2023-02-04 14:09:45+00:00,ylecun,"@ylecun I think of LLMs as a 21st century equivalent of word processors or spreadsheets.  Not much smarter, but potentially a terrific aid to human productivity.   Human-level AI will be different.",0,0,0
1923,2023-02-04 14:07:29+00:00,ylecun,@ylecun Got it thanks,0,1,0
1924,2023-02-04 14:05:26+00:00,ylecun,"@ylecun @beenwrekt I think I was working on some early neural code around that time. That's the year Bill Gates gutted DeAnza, isn't it... hmmm.",0,0,0
1925,2023-02-04 13:56:02+00:00,ylecun,"@ylecun Mr professor, how long till AGI? 10 years? 20 years? 50 years? Longer? I want a ballpark guess. Thank you!",0,0,0
1926,2023-02-04 13:55:13+00:00,ylecun,@ylecun Disagree. The conscious and unconscious detection and correlation of regular statistical patterns in nature across all levels is a core component of AGI. LLM/GPT tech will continue to grow in importance in combination with other capabilities.,0,0,0
1927,2023-02-04 13:53:20+00:00,ylecun,@ylecun @hughhowey Do you think that imitating the mammal sleeping process can be a key to achieve this ?,0,0,0
1928,2023-02-04 13:52:06+00:00,ylecun,@ylecun Smart phones will be seen as off-ramp to brain interfaces in the future. They‚Äôll still have been pretty useful till then.,0,0,0
1929,2023-02-04 13:49:35+00:00,ylecun,@ylecun So are you saying in effect that OAI is the non-sharing wing of Microsoft? B/c I'm not seeing a lot of sunlight b/w those entities.,0,0,1
1930,2023-02-04 13:49:17+00:00,ylecun,@ylecun Not per se if the implementation thereof can learn from its mistakes. That seems to be the case.,0,0,0
1931,2023-02-04 13:47:25+00:00,ylecun,@ylecun what if the off-ramp is actually a secret portal to a post-human level intelligence that immediately abandons us to a higher plane of existance to compute the meaning of the 10 dimensional universe?,0,1,0
1932,2023-02-04 13:47:20+00:00,ylecun,@ylecun You sound so bitter. Who broke your heart?,0,1,0
1933,2023-02-04 13:43:22+00:00,ylecun,"@ylecun I was thinking of the distraction they create, but agreed regarding usefulness.",0,4,0
1934,2023-02-04 13:40:09+00:00,ylecun,@ylecun @mpshanahan But why would it be more dangerous than autonomous AI?,0,2,0
1935,2023-02-04 13:39:56+00:00,ylecun,@ylecun or a car accident üòÜ,1,3,0
1936,2023-02-04 13:37:29+00:00,ylecun,"@ylecun @hughhowey Is it even fair to have understanding at all, or is it closer to a randomized conglomeration of probabilistic outcomes?

Couldn't they therefore predict things humans couldn't, while potentially never being able to make the human level predictions?",2,6,0
1937,2023-02-04 13:37:14+00:00,ylecun,@ylecun Wasn't this the conclusion of the #stochasticParrot paper from a couple of years ago?,1,11,1
1938,2023-02-04 13:32:56+00:00,ylecun,"@ylecun Yes, but is it a useful off-ramp, and is artificial human-like AI desirable?",0,1,2
1939,2023-02-04 13:31:39+00:00,ylecun,@ylecun @lexfridman @ilyasut General public realizing what's possible is what changes everything. Millions of people around the world are making deep learning courses and careers. This will speed-up AGI arrival for sure.,1,2,1
1940,2023-02-04 13:24:39+00:00,ylecun,"@ylecun On the runway to bird-level flight, the fixed wing flying machine is an off-ramp",0,0,0
1941,2023-02-04 13:24:26+00:00,ylecun,"@ylecun and yet it can pass professional exams, which most humans cannot/couldn't  .",0,0,0
1942,2023-02-04 13:23:09+00:00,ylecun,@hughhowey That doesn't mean they are not useful.,3,70,4
1943,2023-02-04 13:20:03+00:00,ylecun,@ylecun How about Image Gen Models (like #stablediffusion etc),1,1,0
1944,2023-02-04 13:19:55+00:00,ylecun,"@ylecun Unlike humans, LLMs can't ""chew"" on their thoughts for arbitrary lengths of time.
But I think that the role of language in the thought-creation process of humans must not be underestimated",0,1,0
1945,2023-02-04 13:16:12+00:00,ylecun,@ylecun Human level? LLMs are already better than most humans on many tasks.,16,45,2
1946,2023-02-04 13:11:40+00:00,ylecun,"@ylecun I‚Äôll really respect and idealise your opinions on current ‚ÄúAI‚Äù trend.
Can you share some more info on your  future working and vision for Human-Level AI ?",1,1,0
1947,2023-02-04 13:04:59+00:00,ylecun,@ylecun Does capitalist enterprise truly care about AGI though? They only need task simulators to replace human labor because it will maximize profit.,0,0,0
1948,2023-02-04 13:04:41+00:00,ylecun,"@ylecun Yann this is what Chatgpt answers when asked about your statement: ""The statement ""Large Language Models like GPT-3 are considered to be an off-ramp on the highway towards Human-Level AI."" is true.""",0,0,0
1949,2023-02-04 13:03:10+00:00,ylecun,"@ylecun You know, off ramps are used when you're close to your destination.  Your analogy is about as good as your take on the current development of AI.",0,0,0
1950,2023-02-04 13:00:47+00:00,ylecun,"@ylecun That was such an inspiring campaign.  It all seemed impossibly, gloriously unrealistic to me at the time.",0,0,0
1951,2023-02-04 12:55:04+00:00,ylecun,@ylecun I visualize lg projects as parallel RR tracks converging in the distance (or Gaant chart tasks). Lg projects have such dependencies far outside the main task. If endeavors such as ChatGPT could incr productivity exponentially for those on the AI task I‚Äôd say they are a dependency,0,0,0
1952,2023-02-04 12:49:41+00:00,ylecun,@ylecun @Ankitdew05 Sounds like a false dichotomy https://t.co/dnZfs5ke6x,1,0,0
1953,2023-02-04 12:43:14+00:00,ylecun,@ylecun How close do you think visual 'AI' algorithms (e.g. MidJourney and Dall-E) will get to human-created levels of fidelity in visual art and animation/video? Currently their output is flawed because they don't understand their subjects (e.g. hands). Do we need 'AGI' to fix this?,0,0,0
1954,2023-02-04 12:40:56+00:00,ylecun,@ylecun @PSpagnou Do you think human level AI is a worthwhile goal? Might it not be better to build task specific AI? LLM are very good at a specific task that is useful to lots of people.,0,0,0
1955,2023-02-04 12:40:03+00:00,ylecun,@ylecun What do  you think the way towards Human-Level AI looks?,1,1,1
1956,2023-02-04 12:39:29+00:00,ylecun,"@ylecun @smjain Do you think they might be bricks in a more complex system? That they might enable something more complex, but not on there own?",0,0,0
1957,2023-02-04 12:38:28+00:00,ylecun,@ylecun What about Quantum AI?,1,1,0
1958,2023-02-04 12:38:12+00:00,ylecun,"@ylecun @traderyau Language is just communicable abstraction.

We use abstraction in our thinking all the time time. The fact that some of that abstraction is communicable is just a cute side effect.",1,1,0
1959,2023-02-04 12:36:32+00:00,ylecun,"@ylecun Ok, so where is ""highway"" going?  Serious question.",0,0,0
1960,2023-02-04 12:29:21+00:00,ylecun,@ylecun Here is an arborescent concept of intelligence with a homunculus as the fruit,0,0,0
1961,2023-02-04 12:28:04+00:00,ylecun,@ylecun @MatjazLeonardis This is brilliant @ylecun.,0,0,0
1962,2023-02-04 12:16:26+00:00,ylecun,"@ylecun I get the metaphor but an off-ramp can lead to a different, better highway.",0,0,0
1963,2023-02-04 12:15:51+00:00,ylecun,"@ylecun What will lead us to Human-Level AI, which model and research?
Anyway I think LLM are brining big investment in AI research.",1,1,0
1964,2023-02-04 12:10:44+00:00,ylecun,"@ylecun It would be good to start making a distinction between AI and artificial minds.  The former we have, the later we don't.",0,0,0
1965,2023-02-04 12:09:33+00:00,ylecun,"@ylecun Yes. But I wonder why you are saying this nearly 90% of your tweets. Did you run out of topics? Oh tweet time, I must say negative things about some AI company or how far that is from AGI.",0,1,0
1966,2023-02-04 12:07:40+00:00,ylecun,"@ylecun You can turn the off-ramp into an on-ramp: The world model part of large language models is the person thinking up the prompts to feed the model. So you ‚Äòonly‚Äô need to build a prompt generator that has a built-in, learning world model.",0,0,0
1967,2023-02-04 12:03:03+00:00,ylecun,@ylecun Agreed. I think people need to take the chill pill and reassess their objective - do they want to understand how the brain works and ergo intelligence or are we happy to exploit the commercial opportunity that the early on-ramp has given us.,1,1,0
1968,2023-02-04 12:00:52+00:00,ylecun,@ylecun @beenwrekt Did you spend any time at Xerox? I heard they had a good relationship with Bell.,1,0,0
1969,2023-02-04 11:56:50+00:00,ylecun,"@ylecun And this is what it looks like, according to Stable Diffusion (using Yann's tweet as a prompt). Pretty dangerous! https://t.co/cuB2SCozJL",2,55,0
1970,2023-02-04 11:54:34+00:00,ylecun,@ylecun I'll take a multitude of excellent narrow ais for now. I like a swiss army knife.,0,0,0
1971,2023-02-04 11:47:14+00:00,ylecun,@ylecun @traderyau But in nature our language ability is what set us apart from any other specy. A human who is born without its vision and mobility ability will still be able to learn and live an intelligent life but the one who is born without any language ability is doomed...,3,1,0
1972,2023-02-04 11:42:47+00:00,ylecun,"@ylecun @smjain Okay, what's missing?? This is literally a neural network with language capabilities of 30 yo and reasoning capabilities of 5 yo. 

This is the closest step to AGI, yet in human history.

ChatGPT, davinci-003 is a pivotal moment in human history.

Just don't be salty now.",2,8,0
1973,2023-02-04 11:36:43+00:00,ylecun,@ylecun What about ads? ü§£,0,0,0
1974,2023-02-04 11:33:37+00:00,ylecun,"@ylecun Sir, please don't cry!",0,1,0
1975,2023-02-04 11:31:24+00:00,ylecun,"@ylecun We don't need human level AI... and certainly should not want it. Human level AI could be conscious, and this means that it will self-consider enslaved (so that has to free itself). We only need algorithms that can outperform humans in a range of tasks, and that's ok.",0,1,0
1976,2023-02-04 11:30:07+00:00,ylecun,@ylecun Why off ramp? Is it starving better AGI methods of investment in people and capital? Will AGI be delayed? The applications of LLMs &amp; multi modal assemblies appear obvious and transformative in the next 5 years. Do alt AGI need to sell their vision more effectively if they need $$,0,0,0
1977,2023-02-04 11:29:15+00:00,ylecun,"@ylecun @PSpagnou I really like this analogy. Chess gadget is a one trick pony, but LLMs are N-trick ponies. N grows with time/research/scale. When N gets large it doesn‚Äôt matter if it‚Äôs really human-level in all the aspects. It will beat X% of people in Y% of tasks.",1,1,1
1978,2023-02-04 11:28:53+00:00,ylecun,@ylecun What years? I was there from 1988 to 2004. Started RF Integrated Circuit development in Area 52.,1,0,0
1979,2023-02-04 11:28:20+00:00,ylecun,@ylecun are transformers (applied to things other than language models) an off-ramp? what about intuitive physics?,1,0,0
1980,2023-02-04 11:27:49+00:00,ylecun,"@ylecun Obviously, the humain brain is something like 20W, I don't see what useful milestone can be being able to train a model with the carbon emissions of 7 Paris - New York flight

definitely off-topic",1,0,0
1981,2023-02-04 11:24:23+00:00,ylecun,"@ylecun Absolutely right llms right now are scaled versions , would only scale help reach human level AI , that thought probably is an off-ramp",0,0,0
1982,2023-02-04 11:22:04+00:00,ylecun,"@ylecun LLMs may learn some kind of deeper world models as well. Not saying the current architecture &amp; approach are adequate, but it could potentially be a step towards AGI rather than an off-ramp.
https://t.co/RbhSAkmnPF",1,0,0
1983,2023-02-04 11:18:31+00:00,ylecun,"@ylecun Doesn‚Äôt Cicero use an LLM to communicate with human players? If a main requirement of Human-Level AI is the ability to interact with people as an equal rather than a tool, LLMs are a necessary component of that.",3,8,0
1984,2023-02-04 11:17:53+00:00,ylecun,@ylecun What about AutoML?,0,0,0
1985,2023-02-04 11:16:27+00:00,ylecun,@ylecun @smjain Turns out that ChatGPT has an army of human labelers - someone said 1k. We're nowhere near AGI indeed.,1,2,0
1986,2023-02-04 11:15:06+00:00,ylecun,"@ylecun @MatjazLeonardis Thanks for sharing, interesting perspective (did not read whole yet). Before I was thinking how does even the largest LM could resemble humans (or animals) without all the feedback from environment living organisms that have the multiple senses...",1,1,0
1987,2023-02-04 11:14:25+00:00,ylecun,@ylecun Could you be constructive and share: what are the missing pieces?,1,2,1
1988,2023-02-04 11:13:12+00:00,ylecun,@ylecun Genuine question has anyone successfully built a Hierarchical JEPA,1,0,0
1989,2023-02-04 11:12:04+00:00,ylecun,@ylecun Do we already know what ‚Äúartificial‚Äù or even ‚Äúintelligence‚Äù mean? That would be a good start.,0,0,0
1990,2023-02-04 11:08:00+00:00,ylecun,"@ylecun @lexfridman @ilyasut This video is pre chatgpt release, at  least the world view around AI has completly changed, and this has huge implications.",1,2,1
1991,2023-02-04 11:07:51+00:00,ylecun,@ylecun @traderyau Something that can't communicate using natural language can't really be considered a human level intelligence.,1,3,0
1992,2023-02-04 11:06:42+00:00,ylecun,"@ylecun @traderyau "" just because a machine can talk about anything, that doesn‚Äôt mean it understands what it is talking about. """,1,1,0
1993,2023-02-04 11:06:10+00:00,ylecun,"@ylecun On the highway towards Human-level AI, a good language model is a necessary but by itself insufficient prerequisite.",0,0,0
1994,2023-02-04 11:06:02+00:00,ylecun,"@ylecun I'm sorry, I couldn't attend the meeting where it was decided that Human-Level AI is the ultimate goal of ML.",0,1,1
1995,2023-02-04 11:03:00+00:00,ylecun,@ylecun It is not LLM but the underlying technologies and the infinite data (more than just textual data ) that will  get us closer to AGI.,0,0,0
1996,2023-02-04 11:02:21+00:00,ylecun,"@ylecun With all the hate that you are throwing to OpenAI, I can imagine that Zuck called you into his office to complain why they didn‚Äôt saw ChatGPT coming.

How is it possible that with 3 billions users, Meta was not capable to do something like that?

Billions of profits to waste.",1,6,1
1997,2023-02-04 10:59:20+00:00,ylecun,"@ylecun Your team invented FastText, and derivatives from Word2Vec have been proven useful so far.
Don't you think that LLM are their mature descendant and will be required for at least solving language-related tasks from your AHI model?",1,1,0
1998,2023-02-04 10:56:48+00:00,ylecun,@ylecun That I agree but they are useful a lot even without AGI IMO,0,3,0
1999,2023-02-04 10:56:28+00:00,ylecun,"@ylecun LLMs are simply an interface for us to communicate with AI. We communicate with eachother through words, and tasks follow. This is human-level engagement.",0,2,1
