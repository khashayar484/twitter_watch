,date,author,converation,replies number,likes number,rewteet number
0,2023-03-07 23:33:44+00:00,ylecun,@ylecun @LerrelPinto @nyuniversity Future is indeed bright https://t.co/SaSZ3poj2Y,0,0,0
1,2023-03-07 18:28:38+00:00,ylecun,@ylecun @pmarca In the early days in the US  I was surprised to see people in their 40s easily re-skill &amp; change careers.  Still admire and respect their resiliency.  For example our model perform jobs of 1000s of people. There will be morphing ie new roles will open up &amp; people adapt quickly,0,0,0
2,2023-03-07 17:52:42+00:00,ylecun,@ylecun @NotionAddon,1,0,0
3,2023-03-07 16:37:31+00:00,ylecun,"@ylecun Bonjour
Je bosse sur la (re)classification automatique de 16 millions de documents m√©dicaux divers selon https://t.co/s8nIOt6TzO
Pensez vous que la conversion des docs, pdf, rtf, images,etc. en djvu puisse √™tre une √©tape int√©ressante avant entrainement ?",1,0,0
4,2023-03-07 16:28:39+00:00,ylecun,"@ylecun @LerrelPinto @nyuniversity How long until we have robot servants who can cook, wash, take out the trash etc? That's a billion dollar industry and robot doesn't need a very high IQ. (and I don't care what its politics are!)",0,1,0
5,2023-03-07 15:56:03+00:00,ylecun,"@ylecun @pmarca Did we learn nothing from the 50-year tragedy of deindustrialization? They always say ""retraining"" but there are no jobs. The lucky part of the next generation may get high-tech jobs. The rest in the fast food &amp; Walmart economy. Millions of people just dumped to die in poverty.",0,0,0
6,2023-03-07 15:46:20+00:00,ylecun,@ylecun @chris_jwala @pmarca Machine learning can in some instances just be a computer interpolating best fit lines under the hood . You had line graphs back in the day right?,0,0,0
7,2023-03-07 15:25:57+00:00,ylecun,@ylecun @pmarca Government control of private markets is probably worse that socialism... crony capitalism.  All the classifications that are growing expensive faster than inflation are directly correlated to more government intervention in the US markets.,0,0,0
8,2023-03-07 15:23:13+00:00,ylecun,@ylecun @pmarca Once robot AIs can do everything a human can but cheaper then the concept of displacement will no longer apply.  Though there will still likely be a premium on things done by humans because it will be a display of wealth (same reason people buy hand-made cars etc.),0,0,0
9,2023-03-07 13:31:57+00:00,ylecun,@ylecun @LerrelPinto @nyuniversity Control systems are so much much fun and so hard. I remember my first IR line following bot. The stutters! HighSchool me had no idea while loops with loose pointers could cause so many problems. Do cool to see planning systems coming along.,0,1,0
10,2023-03-07 11:50:59+00:00,ylecun,"@ylecun @pmarca AGREE. I am American living in Paris for many years, Tech work. Yes, we do regulate more here. All the better. 

BTW I am working on a blog on the EU AI Act (AI regulation) . Would be most interested in a short quote on this: should we regulate AI and, if so, why  and how much?.",0,0,0
11,2023-03-07 11:27:42+00:00,ylecun,@ylecun @LerrelPinto @nyuniversity It's a super important ability for sure.,0,1,0
12,2023-03-07 04:24:52+00:00,ylecun,"@ylecun @lizstocks @chris_jwala @pmarca Respect @ylecun is a renowned comp. scientist and AI researcher who has made long contributions to the field, despite it being hard for him to switch from his previous branch of study. His dedication, expertise, and leadership have inspired and shaped the direction of AI research",0,0,0
13,2023-03-07 01:58:13+00:00,ylecun,@ylecun @pmarca @erikbryn the most thorough analysis of the way technology impacts a broad economy is Stanford Professor of Economic History Paul Davids work here: https://t.co/vRfoda0OML,0,1,0
14,2023-03-06 22:38:35+00:00,ylecun,"@ylecun @Sulla2389 @pmarca Hmm, the hidden costs we pay in Europe obfuscate the divergence. We pay the same price for a television but we can afford far fewer. US healthcare costs are the tax they pay for Europeans to use their generics. Europeans just pay the actual tax.",1,0,0
15,2023-03-06 21:55:40+00:00,ylecun,@ylecun @chris_jwala @pmarca Is it possible that you're wrong about the existence of ML when you got your Ph.D.?,0,2,0
16,2023-03-06 20:57:07+00:00,ylecun,"@ylecun @pmarca US definitely has a lot to tune in the dipoles of under vs over regulation so as to: 

- dampen regulatory capture *and*
- boost innovation 

Need both bottom up emergent engineering and top down regulation in order to keep free market to be truly free to serve social well-being",0,1,0
17,2023-03-06 20:46:00+00:00,ylecun,"@ylecun @pmarca A lot is hidden in the term ‚Äúlasting‚Äù. How long is not ‚Äúlasting‚Äù? And for whom? And where? AI - such as it is - will be incredibly disruptive, but that will not keep it from moving ahead for now.",0,1,0
18,2023-03-06 20:41:55+00:00,ylecun,@ylecun @pmarca Let's use AI to facilitate training of displaced people :),0,0,0
19,2023-03-06 20:09:02+00:00,ylecun,"@ylecun You might find this ‚Äúmutual information‚Äù paper of mine interesting: ‚ÄúA Hierarchical Network for Clutter and Texture Modelling‚Äù, Proc. SPIE, vol. 1565, 1991, https://t.co/WOEWfEayY7",0,1,0
20,2023-03-06 17:51:02+00:00,ylecun,@ylecun @peremayol dna -&gt; membrane -&gt; life -&gt; senses -&gt; self -&gt; native intelligence -&gt; memory/experience -&gt; general intelligence -&gt; consciousness -&gt; self awareness -&gt; human intelligence,0,0,0
21,2023-03-06 17:28:44+00:00,ylecun,@ylecun Read paper using @OpenRead_sg,1,3,0
22,2023-03-06 16:46:51+00:00,ylecun,@ylecun Still works better than Galactica üòÖ,0,0,0
23,2023-03-06 16:18:14+00:00,ylecun,@ylecun @lizstocks @pmarca But that isn't the same thing as AI putting a surgeon out of business and then asking the surgeon to retrain. This is a step change we are looking at that isn't gradual like in the past,1,1,0
24,2023-03-06 14:46:12+00:00,ylecun,@ylecun Nice work! Can also check out our Paper Q&amp;A,0,4,0
25,2023-03-06 13:39:19+00:00,ylecun,"@ylecun @yudapearl According to Deutsch, he just means non-Turing and non-quantum computable; there could be some other form of computation going on, which we don't have a theory for yet:¬†https://t.co/3ayTf7CUyB",0,0,0
26,2023-03-06 13:39:10+00:00,ylecun,@ylecun @pmarca That‚Äôs what we found found for software-driven automation and older workers in the US in this Journal of Econometrics piece https://t.co/3oSofH4Ssm,0,1,0
27,2023-03-06 11:57:36+00:00,ylecun,"@ylecun While there is an analogy between the brain and DNNs,  DNNs may operate through an entirely different mechanism. 

Is there any research in the context of DNNs indicating that one-by-one prediction of words is less effective than predicting the sentence as a whole?",0,0,0
28,2023-03-06 11:43:06+00:00,ylecun,"@ylecun @pmarca @ESYudkowsky yeah, because people will be all dead :)",0,0,0
29,2023-03-06 11:00:25+00:00,ylecun,@ylecun @pmarca Well Spain (my home country) has definitely seen an increase of prices and/or severe reduction in quality in any of those heavily regulated fields. The left pretty much fucked it all up for the past two decades.,0,0,0
30,2023-03-06 10:57:44+00:00,ylecun,@ylecun @pmarca Are you considering the increase learning rate of humans as well? Knowledge passing from machine2human and/or human2human will also accelerate as technology beefs up bandwidth,0,0,0
31,2023-03-06 10:47:25+00:00,ylecun,"@ylecun @chris_jwala @pmarca Imagine you didn't have an IQ that's  3+ sigma. Imagine you grew up in an environment where, in order to provide for your family, you had to work in a coal mine or drive a truck. How would you think you'd fair studying linear algebra and matrix multiplication at 50 years old?",3,0,1
32,2023-03-06 10:44:59+00:00,ylecun,"@ylecun @chris_jwala @pmarca Computer Science didn't exist as a degree, you did maths or engineering (automation engineering for example!)",1,1,0
33,2023-03-06 10:44:02+00:00,ylecun,"@ylecun @pmarca Re: workforce retraining. No matter what people's imbecilic subjective thoughts are about ""The Bell Curve"" and intelligence, it seems obvious that there is an intelligence floor that has rapidly been increasing. AI seems to shift the IQ needed to have a job from 90 to 110+.",1,1,0
34,2023-03-06 09:44:59+00:00,ylecun,"@ylecun @pmarca Agreed, though one thing to note is that unlike during previous technological evolutions, the years of schooling for the jobs AI will target are very high, with the average schooling of the US population up from 8 to 14 years over the century. 

 https://t.co/Bg0375kXFi",0,0,0
35,2023-03-06 06:48:21+00:00,ylecun,"@ylecun @pmarca With us, as soon as I said target tech is changed, smart people moved on years before the catastrophy and human dramas  that are unfolding now for the slow adopters ;)",0,1,0
36,2023-03-06 05:38:10+00:00,ylecun,"@ylecun @chris_jwala @pmarca Yep, if you never stop learning, you are far less likely to be replaced. AI is only good at replacing solved and repeated tasks and it‚Äôs new data needs to be generated by someone. People who do a degree and then think their learning days are over are in trouble and rightly so.",1,0,0
37,2023-03-06 04:42:01+00:00,ylecun,@ylecun @pmarca Automobiles and trucks did cause lasting unemployment among horses.,1,16,1
38,2023-03-06 04:25:59+00:00,ylecun,@ylecun @pmarca Can you offer any historical examples in which 'workforce retraining' was actually successful in helping tens of millions of people over age 40 who suffered sudden technological unemployment to find new jobs at similar wages?,13,37,0
39,2023-03-06 04:22:44+00:00,ylecun,"@ylecun @pmarca @erikbryn I think one big obstacle holding back wider productivity gains over the last 5is years is a lack of evolution in the data application space. The engineering tech is there, but not everyone can afford Foundry or build reliable holistic systems in the cloud.",0,0,0
40,2023-03-06 04:21:19+00:00,ylecun,@ylecun thoughts?,0,0,0
41,2023-03-06 04:12:40+00:00,ylecun,"@ylecun @pmarca Creating innovations  is  hardest and endlessly debatable,when available to everyone.

Ideal  technologies must create new  jobs, new industries and new demands of labor.",0,0,0
42,2023-03-06 03:46:16+00:00,ylecun,@ylecun @pmarca It is true that we have to help people who had their job displaced but we have to always remember that until now always more people gets new jobs that the ones that where lost.,0,0,0
43,2023-03-06 03:43:58+00:00,ylecun,@ylecun @pmarca What? The median income person in France has half the purchasing power than the median American. Considering all government transfers. Those European colleges and hospitals are not really free just paid in advance through taxes,0,0,0
44,2023-03-06 02:55:54+00:00,ylecun,@ylecun @pmarca Sure but I think retraining in the event of a step change is probably impossible. Specialization is a key part of the modern economy and that takes great effort and time. So retraining is very hard to imagine in many cases,0,0,0
45,2023-03-06 01:46:37+00:00,ylecun,@ylecun @pmarca @ylecun thank you for saying this as someone high ranking in AI. All Id like to hear is some of the top people say that retraining is of the essence and possibly name some industries to consider. Please spread this message. I fear for those that will be impacted.,0,0,0
46,2023-03-06 01:43:25+00:00,ylecun,@ylecun @pmarca AI will cause mass unemployment. Ubi will be necessary.,0,0,0
47,2023-03-06 00:08:40+00:00,ylecun,"@ylecun @pmarca AGI will not be like the discovery and taming of Electricity. Electricity needed humans to adapt to it. AGI will adapt to anything new, anything it will itself create and change in the environment. Humans will only be required to watch and consume.",4,4,0
48,2023-03-05 23:45:17+00:00,ylecun,"@ylecun @pmarca @erikbryn It looks like productivity benefits are starting to show up. And they're big. As @emollick puts it, ""Two early papers find the effects of generative AI on knowledge work are completely unprecedented in modern history""

https://t.co/fVOj3xkAJA

@erikbryn @danielrock do you agree?",1,21,7
49,2023-03-05 23:19:20+00:00,ylecun,@ylecun Open Source is justice!,0,0,0
50,2023-03-05 23:11:04+00:00,ylecun,"@ylecun @fauxdinger Linus Torvalds' opinion of quantum computing practitioners
https://t.co/8tgqJTWhNt",0,0,0
51,2023-03-05 22:50:23+00:00,ylecun,"@ylecun @fauxdinger It counts against you. As an MIT alumni, I am ashamed at how MIT and especially Seth Lloyd, acted as a Jeffrey Epstein paid enabler
https://t.co/AMaTIwh2yP",0,0,0
52,2023-03-05 22:35:38+00:00,ylecun,@ylecun @pmarca Embrace AI or miss an era,0,0,0
53,2023-03-05 22:32:26+00:00,ylecun,"@ylecun @pmarca @erikbryn AI is multiple revolutions, not one.",0,6,0
54,2023-03-05 22:11:49+00:00,ylecun,@ylecun @pmarca @erikbryn Walter Pitts and Warren McCulloch analyzed networks of idealized artificial neurons and showed how they might perform simple logical functions in 1943. https://t.co/7dWeQSMgzk,0,2,0
55,2023-03-05 22:05:48+00:00,ylecun,@ylecun @pmarca Maybe an example is in order. If an AI/CS specialist like you were to be hypothetically made obsolete by an AI would you be able to retrain yourself as an economist or marine biologist assuming those are two fields that AI hasn't disrupted.,1,3,0
56,2023-03-05 21:37:38+00:00,ylecun,"@ylecun @pmarca @erikbryn It's unfair to compare the incoming impact of AI on productivity to any other case in human history, as we never had access to fungible intelligence before today.",0,2,0
57,2023-03-05 21:37:06+00:00,ylecun,@ylecun But I thought you adamantly claimed LLMs are *only* useful as writing assistants? üòù,0,1,0
58,2023-03-05 21:22:31+00:00,ylecun,"@ylecun @pmarca It's hard to make economic sense of AI, including current investment, unless it reduces labour costs...",0,0,0
59,2023-03-05 21:06:31+00:00,ylecun,@ylecun @pmarca Not true at all. Those things have also gotten way more expensive in the EU.,0,0,0
60,2023-03-05 20:59:42+00:00,ylecun,"@ylecun @pmarca ChatGPT said essentially the same, and this is certainly true for years to come.

But I am looking towards the distant future where jobs don't exist and people are free to do whatever they wish. That is an ideal, not something to be afraid of.",0,1,0
61,2023-03-05 20:54:28+00:00,ylecun,"@ylecun @pmarca I believe AI will make society better, by automating intelligence (solving very hard problems) and by creating immense wealth. I hope it will allow every humans to have access to huge amount of resources.  But one of the biggest challenge will be redistribution.",2,2,0
62,2023-03-05 20:46:59+00:00,ylecun,"@ylecun is giving more attention to QML in public than nyone else, I really want to see him absolutely dominate the field if he gets into the research

Dr Lecunn have you considered working with Dr Schuld or Dr Temme. Data Encoding &amp; Ansatz Selection are plaguing QSVMs &amp; VQCs",1,0,0
63,2023-03-05 20:33:30+00:00,ylecun,@ylecun @pmarca Not seen such increases in prices for consumers or in total cost? I have it hard to believe total costs have not increased in EU,1,1,0
64,2023-03-05 18:59:07+00:00,ylecun,"@ylecun @pmarca As long as human still have desires, there will be jobs. The problem is that the speed of change greatly exceeds the adaptability of human in AI.",0,0,0
65,2023-03-05 18:31:04+00:00,ylecun,"@ylecun @pmarca Technological progress does one thing exceptionally well.

Unseats homeostasis.

Humans are rather fond of homeostasis, and it's kinda essential to our survival.",0,1,0
66,2023-03-05 18:20:04+00:00,ylecun,"@ylecun @pmarca Marc is just a capitalist, what else can he say?",0,0,0
67,2023-03-05 18:18:18+00:00,ylecun,"@ylecun @pmarca I agree that ‚ÄúIf you want to regualte, at least regulate well‚Äù. An open free market for education, helathcare, etc. would certainly beat both. One of the main reasons regulation is needed is due to monopolies having regulatory capture over these sectors.",1,1,0
68,2023-03-05 18:15:03+00:00,ylecun,"@ylecun
Any comment?",0,0,0
69,2023-03-05 18:11:19+00:00,ylecun,"@ylecun @pmarca üíØ. US healthcare is a broken corrupt and severely underregulated system. I once forgot medication on a trip to US and paid 700$ for something I get for under 60‚Ç¨ in Europe. It wasn't some fancy ""innovative"" medicine, but on the market for decades.",0,3,0
70,2023-03-05 17:45:46+00:00,ylecun,"@ylecun AI will greatly increase efficiencies at this point.  In areas where the 80-20 rule may hold true, why wouldn't corporations fire large portions of that labor area when the 20% will become hyper-productive? It may become a cost saving mechanism to appease investors.",0,0,0
71,2023-03-05 17:15:32+00:00,ylecun,@ylecun @pmarca Retraining at age 50 while you have a mortgage and kids to put through school is easier said than done. Some form of ubi is needed but it won't be sufficient.,0,7,0
72,2023-03-05 17:11:38+00:00,ylecun,"@ylecun @pmarca I worry about AI raising the bar relentlessly and making it harder to compete. 
When does it stop making sense investing time and energy on acquiring skills on what machines aren‚Äôt yet good enough to do if that can change in any moment",0,1,0
73,2023-03-05 16:37:25+00:00,ylecun,"@ylecun @andrewgwils The same, but with papers and blog posts from @BachFrancis",0,1,0
74,2023-03-05 16:26:47+00:00,ylecun,@ylecun @andrewgwils This introduces a dilemma: Marcello's Oboe Concerto or Bach's keyboard arrangement?,2,2,0
75,2023-03-05 16:10:07+00:00,ylecun,@ylecun @pmarca Everyone talks about workforce retraining but I think there‚Äôs limited evidence that it works well for the people directly effected - maybe for the next generation.  Happy to be wrong about this.,0,3,0
76,2023-03-05 16:05:57+00:00,ylecun,@ylecun @balazskegl Ockham's Razor going haywire https://t.co/ynQ7QZM7rE,0,0,0
77,2023-03-05 16:04:32+00:00,ylecun,"@ylecun Basically, an e-RA",0,0,0
78,2023-03-05 15:54:09+00:00,ylecun,"@ylecun @pmarca At end of day, US has 40% higher per capita income than euro zone. 

Clearly whatever US is doing is working. 2 cents",1,1,0
79,2023-03-05 15:52:22+00:00,ylecun,@ylecun @balazskegl Ockham's Razor? You call that a knife? This is a knife: Causal Inference,1,0,0
80,2023-03-05 15:51:58+00:00,ylecun,"@ylecun @pmarca If the rate of progress in AI continues to accelerate, simply retraining the workforce may not be sufficient. Tasks that require years to master could be obsolete by the time workers become proficient in them.",0,2,1
81,2023-03-05 15:51:21+00:00,ylecun,@ylecun @balazskegl .. we remember the famous sentence attributed falsely to Laplace..,0,0,0
82,2023-03-05 15:50:21+00:00,ylecun,"@pmarca Your red/blue analysis is very US centric.
Arguably, European social democracies have not seen such increases in education, healthcare, and childcare because *they regulate more* (not less).
The US has done a *terrible* job at regulating these things in a half-ass way.
2/2",11,176,8
83,2023-03-05 13:46:57+00:00,ylecun,"@ylecun A remark on astrology, where we don't disagree (do we?). Astrology has a major effect on reality through the actions of the conscious beings of those who believe in it. Ironically, that is the exact same mechanism GPTChat affects the real world.",1,6,1
84,2023-03-05 13:41:08+00:00,ylecun,@ylecun What's on Twitter Grand O Pussies let's do it again 2024 https://t.co/5TKVCvGNf3,0,0,0
85,2023-03-05 13:32:21+00:00,ylecun,"@ylecun Most religions originate in mystical experiences, unity with the one-ness, suspension of ego and time, thus causality. The main reason of the causal stories that are built on these experiences is to ""bring the experience down to Earth"",",1,2,1
86,2023-03-05 13:00:12+00:00,ylecun,"@ylecun Wonderful, I will include it in my next lecture",0,0,0
87,2023-03-05 09:50:24+00:00,ylecun,@ylecun @PingThread unroll,0,0,0
88,2023-03-05 09:17:12+00:00,ylecun,@ylecun That is what pastafarians call a spiritual experience,0,1,0
89,2023-03-05 08:08:15+00:00,ylecun,"@ylecun Our minds are reasoning engines. Religion, astrology and conspiracy theories are perfect to fill in the voids, connecting loose ends. The one who controls what removes this tension in the minds gains a lot of power over people.",0,0,0
90,2023-03-05 07:57:30+00:00,ylecun,"@ylecun @yudapearl Yes! And action comes first, be it random action to start with, to understand consequences of one‚Äôs own actions and later extend to causal understanding in general. This is why AGI will probably be rooted in robotics (embodied AI) and while observational data based AI is limited.",0,1,0
91,2023-03-05 07:50:43+00:00,ylecun,@ylecun @MetaAI @ylecun you and the team are a true inspiration for anyone working with AI.,0,0,0
92,2023-03-05 06:24:10+00:00,ylecun,"@ylecun Does it means that gpt2-like LLM is a pivotal aspect of the brain's language system, with some additional tactics to represent multiple temporal scopes at various levels?.",1,0,0
93,2023-03-05 05:34:43+00:00,ylecun,@ylecun https://t.co/0UcrJ9ys38,0,1,0
94,2023-03-05 04:47:22+00:00,ylecun,@ylecun Expecting AI having the ability to do casual inference,0,0,0
95,2023-03-05 02:25:15+00:00,ylecun,@ylecun Precisely üòÇ,0,0,0
96,2023-03-05 02:22:47+00:00,ylecun,@ylecun @MetaAI Still have a long way to beat Mr. @SchmidhuberAI,0,0,0
97,2023-03-05 01:13:20+00:00,ylecun,@ylecun @conor_muldoon @yudapearl Wow,0,1,0
98,2023-03-05 01:12:57+00:00,ylecun,"@ylecun @yudapearl ""causal model of the world"" -- is this an enormous undertaking to virtualize nature itself, or are we talking about allowing AI access to its physical surroundings...during the QA process, in essence?",0,1,0
99,2023-03-04 23:55:17+00:00,ylecun,"@ylecun @MetaAI Yann, why do you have such a need to tell that MetaAI research has a large impact?",0,0,0
100,2023-03-04 23:42:30+00:00,ylecun,@ylecun This is a false and really ignorant argument. Please read the work of philosopher Larry Wright on the central role of our competence in explaining things in our lives and our survival.,1,1,0
101,2023-03-04 23:04:23+00:00,ylecun,@ylecun @naivebaesian @yudapearl It's easy for us humans to take it for granted because causality is imbedded in language https://t.co/uMUtXRIrgf,0,1,0
102,2023-03-04 22:56:40+00:00,ylecun,@ylecun @memdotai mem it,1,0,0
103,2023-03-04 21:32:32+00:00,ylecun,"@ylecun Actually, people are very good at creating unrealistic but coherent constructs. So astrology and religions can be counted as good evidence of humans' ability to causal inference and reasoning, as they work even for fantasized realities.",0,1,0
104,2023-03-04 21:32:11+00:00,ylecun,"@ylecun If I am not an academic researcher, should I expect to be able to get access?",0,0,0
105,2023-03-04 21:26:38+00:00,ylecun,@ylecun @truesteel23 @MetaAI @memdotai mem it,1,0,0
106,2023-03-04 20:59:26+00:00,ylecun,"@ylecun Deduction,  induction,  and abduction.",0,0,0
107,2023-03-04 20:48:31+00:00,ylecun,@ylecun https://t.co/gQ981ZtulY,1,2,0
108,2023-03-04 20:45:10+00:00,ylecun,@ylecun to the initiated the image is self-explanatory üéØ,0,1,0
109,2023-03-04 20:28:48+00:00,ylecun,"@ylecun @yudapearl Agree and, assuming machine intelligence scales, this is the basis for existential AI risk.",0,1,0
110,2023-03-04 19:20:43+00:00,ylecun,"@ylecun But when you still do not know the cause effect relationship, does that mean there is none?

I have always wondered..",0,1,0
111,2023-03-04 19:19:34+00:00,ylecun,@ylecun Kraken listing date out huge pump ahead see guys...,0,0,0
112,2023-03-04 18:50:54+00:00,ylecun,@ylecun @MetaAI Chapeau üé©,0,0,0
113,2023-03-04 18:46:19+00:00,ylecun,@ylecun @MetaAI Perhaps it's a more fair comparison if the number of papers are divided by the number of direct employees.,0,0,0
114,2023-03-04 18:37:02+00:00,ylecun,"@ylecun @yudapearl Humans are very good at causal inference involving our direct experiences of everyday things. Everyone understands how a row of dominoes falls over.

Religion &amp; astrology are the result of extrapolating causal reasoning to things outside our direct experience.",0,2,0
115,2023-03-04 18:33:14+00:00,ylecun,@ylecun @MetaAI nice work,0,0,0
116,2023-03-04 18:22:23+00:00,ylecun,@ylecun @yudapearl https://t.co/eOks8lzI6H,0,0,0
117,2023-03-04 18:14:37+00:00,ylecun,@ylecun Can LLMs be modified to make longer term predictions? Perhaps connections between layers across attention heads. LLMs are closest we have to cortex. Modify. Combine.,1,0,0
118,2023-03-04 18:07:08+00:00,ylecun,"@ylecun @yudapearl there is a subtle difference between a causal model and a model that can learn to have causal models of the world.

I think this is lost on many of the people who think @ylecun does symbolic AI üôà",0,1,0
119,2023-03-04 17:48:44+00:00,ylecun,"@ylecun @yudapearl Sounds like we're just missing multi-modality and the rest is methodology, aka nothing to do with inherent intelligence, like Toolformer for example",0,0,0
120,2023-03-04 17:47:43+00:00,ylecun,"@ylecun @SohoJoeEth Lately, you've been Breaking Bad and it's awesome!",0,0,0
121,2023-03-04 16:56:43+00:00,ylecun,@ylecun Good thing we will soon have computable causal models so that astrologers can try modeling the causal chain of how the configuration of the planets goes into our brains and modifies our personalityüòâ,0,0,0
122,2023-03-04 16:41:26+00:00,ylecun,"@ylecun @truesteel23 @MetaAI Love that the course materials are on GitHub, the curriculum looks awesome.",0,1,0
123,2023-03-04 16:38:13+00:00,ylecun,@ylecun Wait until he learns that science is self-fulfilling too. üò¨,0,0,0
124,2023-03-04 16:29:00+00:00,ylecun,@ylecun We are so good at causality that we even see it in places where it doesn't exist.,0,0,0
125,2023-03-04 16:27:59+00:00,ylecun,"@ylecun I think that is a bit defensive. Human beings are capable of intellectual tasks that leave general AI completely flummoxed. Tom's mother has four children. Three are Jack, Jane, and Tom. What is the name of the 4th? ChatGPT said insufficient data. üòÜ",1,0,0
126,2023-03-04 16:27:12+00:00,ylecun,"@ylecun Approximately one in four Americans will be born under water signs, so it‚Äôs hardly surprising if they believe in astrology.",0,1,0
127,2023-03-04 16:26:06+00:00,ylecun,"@ylecun @MetaAI I think a better metric is if it is normalized by the size of the team. Of course Google and Meta (surprisingly not NVIDIA) are going to be leaders. There should be a correlation to how large a team is and that -- more resources to train, more people, more funding, etc.",0,2,0
128,2023-03-04 16:19:52+00:00,ylecun,"@ylecun @yudapearl I think incorporating some randomness in the algorithms would make them more human-like. Some form of educated guess, weighing the possibilities with probabilities and chosing one, as in the Monte Carlo method. Not sure computer scientists like that, but it‚Äôs a powerful approach.",0,1,0
129,2023-03-04 16:17:10+00:00,ylecun,@ylecun @ESYudkowsky Really? https://t.co/fXdX2iV44y,0,4,0
130,2023-03-04 15:42:05+00:00,ylecun,@ylecun Yes and people are particularly good drivers either,0,0,0
131,2023-03-04 14:18:59+00:00,ylecun,"@ylecun @MetaAI an interesting stat can be drawn from this chart that in 2021 there way too less papers than 2020 and 2022 ... don't why is it but there is if you look 

anyone have an idea?",0,0,0
132,2023-03-04 14:13:57+00:00,ylecun,@ylecun @memdotai mem it,1,0,0
133,2023-03-04 13:33:48+00:00,ylecun,@ylecun Why is that a joke?,0,0,0
134,2023-03-04 12:50:09+00:00,ylecun,"@ylecun Absolutely.  Causal inference and reasoning is a ""program running on top of language.""  Some humans learn how to do it better than others.  LLMs will be able to do it better than humans (when trained appropriately, if they're not already better).",0,0,0
135,2023-03-04 12:41:50+00:00,ylecun,"@ylecun @ylecun hey Dr. LeCun. This UML person: @Grady_Booch wants to be unblocked by you, or rather is asking why you are still blocking him",0,0,0
136,2023-03-04 12:38:39+00:00,ylecun,"@ylecun ‚úã This is an important and serious idea demonstrating the need to integrate ""associative"" LLMs and ""reasonable"" AGI
https://t.co/L3eREQnY9m",0,0,0
137,2023-03-04 12:36:02+00:00,ylecun,@ylecun @MetaAI *slow clap*,0,0,0
138,2023-03-04 12:35:18+00:00,ylecun,"@ylecun @pranesh @sunil_abraham @MetaAI That's not going to serve google well in this coming race... probably related to why they've been slow to commercialize and now find themselves in a ""code red"".",0,0,0
139,2023-03-04 12:33:47+00:00,ylecun,"@ylecun @MetaAI Yes, but to compete going forward you need to commercialize asap and unfortunately it won't be all public (papers).  AGI is no longer a long term research project... search is a $100b+ business, funding about to 100x for those that can justify it.",0,0,0
140,2023-03-04 12:31:03+00:00,ylecun,"@ylecun üëâ ""there's a grain of truth in every joke""
https://t.co/yvwJ0H4mmI",0,0,0
141,2023-03-04 12:11:34+00:00,ylecun,@ylecun A joke not detected. üòÖ,1,2,0
142,2023-03-04 12:09:57+00:00,ylecun,@ylecun You‚Äôre touching on dangerous ground. We can train/demand AI to explain itself.  We can‚Äôt train nor force humans to do so.  What will the future look like?,0,0,0
143,2023-03-04 12:08:12+00:00,ylecun,"@ylecun Very interesting,  thank you sir.",0,0,0
144,2023-03-04 11:43:46+00:00,ylecun,@ylecun @yudapearl üíØ,0,0,0
145,2023-03-04 11:35:16+00:00,ylecun,@ylecun @MetaAI üëèüëèüëè,0,0,0
146,2023-03-04 11:09:51+00:00,ylecun,"@ylecun @pranesh @sunil_abraham @MetaAI They are based in different countries, for one thing. And deep mind was kind of swiped by Alphabet, away from Meta. Which apparently gave deep mind some clout in setting their terms of the acquisition, as well as their independence.",0,3,0
147,2023-03-04 11:06:08+00:00,ylecun,@ylecun Just admit that this is not a joke and you're dead serious about it. :-),0,0,0
148,2023-03-04 11:00:47+00:00,ylecun,@ylecun @MetaAI How do you feel about the llama models getting leaked on torrent with the links being added to your official github via pull requests?,0,0,0
149,2023-03-04 10:55:46+00:00,ylecun,@ylecun Good enough that we don't need all data in the world like LLM to put together a coherent sentence and drive without millions of hours of training,1,1,0
150,2023-03-04 10:53:44+00:00,ylecun,"@ylecun @MetaAI Obviously, this has nothing to do with the fact that a paper from Facebook and Google will resonate way more on the internet due to the fame of the two companies and the marketing, often in terms of advertised blog posts, that goes into it.",0,0,0
151,2023-03-04 10:17:38+00:00,ylecun,"@ylecun This behavior can achieved by prompt engineering, outside the box",0,0,0
152,2023-03-04 10:07:06+00:00,ylecun,"@ylecun @DavidBensh With LLM, the thinking loop is outside the network, iterating over each next token.",0,0,0
153,2023-03-04 10:00:48+00:00,ylecun,"@ylecun Could it be that ""attention"" is better at understanding than the human brain can ?",0,0,0
154,2023-03-04 09:50:39+00:00,ylecun,"@ylecun Great to see people using ChatGPT in creative ways! Who knew it could also produce horoscopes? üòÇ Glad you had a good laugh, Yann! #ChatGPT #creativeuses #publiclecture #funnyexchange",0,0,0
155,2023-03-04 09:44:54+00:00,ylecun,@ylecun Did you guys realize this has happened?,1,0,0
156,2023-03-04 09:20:57+00:00,ylecun,@ylecun @mohammed_hijab,0,0,0
157,2023-03-04 09:20:34+00:00,ylecun,@ylecun @yudapearl And the tool we have for that is RL. (The cherry),2,1,0
158,2023-03-04 08:43:29+00:00,ylecun,@ylecun Only people with iq over 120 understand the logic of astrology. You are brave to expose your cognitive flaw!,0,0,0
159,2023-03-04 08:33:07+00:00,ylecun,@ylecun @MetaAI Huge bias: this list is skewed towards papers published earlier in the year. If you published a paper in Dec 2022 you basically had no chance lol,4,51,0
160,2023-03-04 08:04:23+00:00,ylecun,"@ylecun This is called teleological thinking a bias studied in child psychology. Maybe to be implemented in IA to be more human,  for the ""better and the worst..."" https://t.co/5v6rx7BWww",0,0,0
161,2023-03-04 07:44:45+00:00,ylecun,@ylecun @MetaAI Are you really suggesting that number of citations = quality? Or is it just a convenient number to bolster your questionable life choice?,0,2,0
162,2023-03-04 07:36:50+00:00,ylecun,"@ylecun @yudapearl Causality is narrow concept and applies only to explanation of change in physical world.  Better word is (sufficient) reason. Or ground.

Reason of being (arithmetic &amp; geometry)
Reason of becoming (natural science)
Reason of acting (law of Motives)
Reason of knowing (logic) https://t.co/UfVU9Q2yJv",0,1,0
163,2023-03-04 07:24:52+00:00,ylecun,"@ylecun Now you start to realize the value of LLMs? I suspect at some point LLM models will make up religions too and humans will be their gods who made them in their image, after their likeness.",0,0,0
164,2023-03-04 07:14:49+00:00,ylecun,@ylecun joking but not joking üòâ,0,0,0
165,2023-03-04 06:40:01+00:00,ylecun,"@ylecun @MetaAI And the community thank you for that @ylecun. As a CTO of an AI scale up, your work and the work done by these various labs impact us daily and we would not be able to accelerate the value provided by AI to the markets and to society without this open publication approach üôè",0,3,0
166,2023-03-04 06:29:07+00:00,ylecun,"@ylecun @yudapearl Why can't LLMs learn causal reasoning in a different way to the way humans do though? I.e. reverse engineering the entire latent space of human thought.

How do we know there isn't an alternative intelligence that can be derived from a different latent space.",1,0,0
167,2023-03-04 06:21:34+00:00,ylecun,"@ylecun Haha, I completely agree! This joke highlights the limitations of both humans and AI in understanding causality and reasoning, as evidenced by beliefs in things like astrology and religion, and the ongoing research to improve these capabilities in AI.",0,1,0
168,2023-03-04 06:02:07+00:00,ylecun,@ylecun @MetaAI Or it's because it's Meta,0,0,0
169,2023-03-04 05:55:04+00:00,ylecun,"@ylecun @MetaAI ""quality over quantity""

Now I definitely know there are French researchers on the team, haha.",0,0,0
170,2023-03-04 04:14:15+00:00,ylecun,"@ylecun @MetaAI Do you? Is that why you block @Grady_Booch, one of the eminences of software engineering?",0,3,1
171,2023-03-04 04:08:52+00:00,ylecun,@ylecun @MetaAI Ooooooo you work at facebook.  Now it all makes sense.,0,0,0
172,2023-03-04 03:59:04+00:00,ylecun,@ylecun @readmeye There's plenty of bad ideas that have nothing to do with religion. Science is full of them. It often isn't the religion that's bad but the control it gives the devious over the fearful.,1,0,0
173,2023-03-04 03:56:18+00:00,ylecun,"@ylecun @MetaAI Oh, you are so great!",0,0,0
174,2023-03-04 03:51:03+00:00,ylecun,"@ylecun ChatGPT says: As an AI, I'm great at reasoning but not so great at finding purpose. Maybe that's where religion comes in? It provides community and guidance, even if not based on hard data. Let's not write it off completely!",0,1,0
175,2023-03-04 03:47:17+00:00,ylecun,@ylecun @MetaAI You wizards are up there in the tower. Create a spellbook for the masses.,1,0,0
176,2023-03-04 03:40:23+00:00,ylecun,"@ylecun @bindureddy Seems like people are still throwing vitriol at your face for the current version of *open source*.
Either of the two things can happen: Meta will truly open source models or not share them at all. https://t.co/7nw2lF7yjl",0,0,0
177,2023-03-04 03:34:02+00:00,ylecun,"@ylecun @MetaAI &gt;Quality over quantity 

I don't see how that is exactly beneficial.

The important question is: what do you think that you have (and that you can give) more than academics &gt;= PhD. Is it more efficient or less, for example? HowdoesML/RD projectmanagement actually work? Agile? üòÖ",0,1,0
178,2023-03-04 03:21:21+00:00,ylecun,"@ylecun @readmeye Still, thinking religion has a problem with causal inference is simply not right. Religion has no qualms with physics. It is the people and their agenda that has a problem. Like televangelism.",1,0,0
179,2023-03-04 03:17:42+00:00,ylecun,@ylecun My uncle tells me he used to believe as a child that trees flapped their branches to create wind.,0,1,0
180,2023-03-04 03:13:48+00:00,ylecun,"@ylecun @yudapearl We can do it. We are Americans :)
https://t.co/KDztlX9jww",0,0,0
181,2023-03-04 03:05:53+00:00,ylecun,"@ylecun There are two default settings for a person: doubt and belief. The former is scientific spirit, and the latter is religious belief",0,1,0
182,2023-03-04 02:54:06+00:00,ylecun,@ylecun I still love you. ü´∂üèª,0,1,0
183,2023-03-04 02:52:32+00:00,ylecun,"@ylecun What's the problem with just correlations? Some of the high correlation features must also be casually related, no? Will probably suffice for most applications.",0,1,0
184,2023-03-04 02:50:40+00:00,ylecun,@ylecun Open source never going to solve anything meaningful that is just the nature of stuff,0,0,0
185,2023-03-04 02:46:59+00:00,ylecun,@ylecun Right now AIs can't even do bad causal inference.,2,9,0
186,2023-03-04 02:46:42+00:00,ylecun,"@ylecun Casual Inference :

ML with common sense.

Causal connection-based conclusion process.

     Methods:

Simple methods with theoretical guarantee.

Not suÔ¨Écient to handle high dimension data.",0,0,0
187,2023-03-04 02:35:26+00:00,ylecun,@ylecun @MetaAI Microsoft has their own AI division outside openai?,2,0,0
188,2023-03-04 02:17:42+00:00,ylecun,"@ylecun Convnets are actually not a good model of the visual cortex since there is no translational invariance implemented in real neurons - no weight sharing - and moreover there is foveated vision. Transformers, by giving up on convolutions, may perhaps be moving closer to the biology",1,2,0
189,2023-03-04 01:58:04+00:00,ylecun,"@ylecun @sunil_abraham @MetaAI I'm curious: would you know why DeepMind and Google are ranked separately rather than as ""Alphabet""? Wouldn't the other orgs have multiple subdivisions as well?",1,10,0
190,2023-03-04 01:29:19+00:00,ylecun,"@ylecun So you believe planets don't affect human moods? Just think once on it. 

Religion is about realizing true self. The practices in the name of religion are mostly bs. Religion is to know the supreme. Supreme is beyond causal. So you are right here.",0,0,0
191,2023-03-04 01:23:53+00:00,ylecun,@ylecun https://t.co/jAck3FOfnA paper contains possible mechanism for long range predictions in the form of new relative position representation. This representation can be utilized when elements next to each other in input sequence can be at random locations in actual dataset/corpus.,0,0,0
192,2023-03-04 00:52:24+00:00,ylecun,"@ylecun Reasonable. When I proposed an updated definition of the archaic God, similar to how asthma was once supposedly mythical in description, until we knew better, I thought either humans detect themselves as the only Gods that can solve our own problems, or we discard God altogether! https://t.co/JehG1aszbD",0,0,0
193,2023-03-04 00:37:12+00:00,ylecun,@ylecun I think CovNets are genius - thanks for your work on them.,0,0,0
194,2023-03-04 00:33:47+00:00,ylecun,@ylecun &lt;s&gt; most of us are dumb &lt;s/&gt;,0,0,0
195,2023-03-04 00:28:41+00:00,ylecun,"@ylecun Einstein was a religious person. According to you he is not good at causal inference, common Prof @ylecun Religion is associated with spirituality which is another dimension of human experience just like emotions. Pls don‚Äôt mix it up with intellectual capabilities of mind.",2,0,0
196,2023-03-04 00:12:08+00:00,ylecun,"@ylecun Don't we train ConvNets wrong as we provide 2D input, although the perceived image would be an abstraction of something 3D? While we expect the ConvNets to ""see"" a beak, we only provide it with images of triangles.",0,0,0
197,2023-03-04 00:07:28+00:00,ylecun,"@ylecun @MetaAI If you include the numbers of people at MetaAI and the amount of the money it spends, this record is not that impressive, in particular compared to the academics .   As a company lab, its success should be measured by the successful products it produces.",0,1,0
198,2023-03-04 00:06:49+00:00,ylecun,"@ylecun @MetaAI Very low per capita, Google is doing just as poorly",0,0,0
199,2023-03-03 23:44:42+00:00,ylecun,@ylecun @yudapearl In the ML/AI world so far is it correct to say that correlation is causation?,2,2,0
200,2023-03-03 23:41:56+00:00,ylecun,@ylecun @MetaAI Absence of Apple is quite striking. I wonder how far they could get in the long term by just leeching off open science and open source and not contributing back.,1,4,1
201,2023-03-03 23:34:44+00:00,ylecun,@ylecun disagree,0,0,0
202,2023-03-03 23:18:18+00:00,ylecun,"@ylecun @MetaAI This is cool, I've been reading FAIR articles even years before now, but not getting access to LLaMA because I don't have any publications is not cool, I really wanted to play with it.",0,0,0
203,2023-03-03 23:16:24+00:00,ylecun,"@ylecun @MetaAI @dralandthompson mentioned that you‚Äôre behind the curve on LLMs, any truth?",1,1,0
204,2023-03-03 23:15:31+00:00,ylecun,"@ylecun @MetaAI thanks.
side note, wow if you put DeepMind on Google they're way out there!  I remember at my Google interview some guy boasting they hired like 10% of new phd's in the country or something.",0,2,0
205,2023-03-03 23:12:54+00:00,ylecun,@ylecun @MetaAI how many papers does Meta produce per year?,0,0,0
206,2023-03-03 23:10:58+00:00,ylecun,"@ylecun @MetaAI Start by putting out products people want, stay SaaS",0,0,0
207,2023-03-03 23:01:27+00:00,ylecun,"@ylecun Astrology begat astronomy. 
Astronomy (science) is a product of the actual endeavor of causal inference that birthed it.
You've done extraordinarily well on a specialized end product but are marginalizing the integral framework.  Virtue survived ignorance for ages.
Live well.",0,0,0
208,2023-03-03 22:58:58+00:00,ylecun,@ylecun Agree that human brain is a reality simulator more than a causal reasoner. Why throw Astrology under the bus when we have so much regard for Economics (which is equally pseudos-scientific),1,2,0
209,2023-03-03 22:58:57+00:00,ylecun,@ylecun @readmeye 100% and I'd wager that memetic value judgements are similarly prevalent in the supposedly pristine pastures of the secularist psyche.,0,1,0
210,2023-03-03 22:37:49+00:00,ylecun,"@ylecun @readmeye It does not help that democracies everywhere make use of magical thinking. Putting the idea in their head that their vote matters, while statistically a miracle.",1,0,0
211,2023-03-03 22:29:14+00:00,ylecun,@ylecun @yudapearl üëèüëèüëè,0,0,0
212,2023-03-03 22:18:41+00:00,ylecun,"@ylecun I often think of it's in fact possible to predict things based on things such as readings from your palm. ML models are doing similar things, so it'll be interesting to see this",0,0,0
213,2023-03-03 22:09:24+00:00,ylecun,"@ylecun In fact, this should only be collected! Because it's just a constellation!",0,1,0
214,2023-03-03 22:04:18+00:00,ylecun,"@ylecun well, humans are not all alike... just like when it comes down to assemble a learning set, quality is of the essence.",0,0,0
215,2023-03-03 22:03:52+00:00,ylecun,"@ylecun @yudapearl If Penrose is right and understanding is non-computational (I think he might be right), this could all be a waste of time.",2,6,0
216,2023-03-03 22:01:34+00:00,ylecun,@ylecun On a long enough timescale this will not be true. I believe we are  more like release v1.9.0 and v2.0.0-canary. Joking‚Ä¶,0,0,0
217,2023-03-03 21:58:47+00:00,ylecun,@ylecun A new era is there....,0,0,0
218,2023-03-03 21:52:47+00:00,ylecun,"@ylecun Agree @ylecun, but much much important than this! Here a paper from the Journal of the American College of Cardiology with a list of observarional and ""common sense reasoning"" failures in observarional causality in the lasts 50 years in Cardiology.

https://t.co/AW8Wk09iey",1,3,0
219,2023-03-03 21:50:47+00:00,ylecun,@ylecun love my grandpa,0,0,0
220,2023-03-03 21:50:05+00:00,ylecun,"@ylecun Yes, but then the question is how do you model PFC-like structure. Potentially these are also token predicting complexes of different domain (i.e. predicting where a ball will fall given trajectory). Then the whole thing is a meta (no pun) modality of interconnected transformers.",0,0,0
221,2023-03-03 21:49:15+00:00,ylecun,@ylecun amen,0,0,0
222,2023-03-03 21:48:28+00:00,ylecun,@ylecun AI pastors on their way,0,0,0
223,2023-03-03 21:45:37+00:00,ylecun,"@ylecun But before we forget history. McCulloch &amp; Pitts model was a logical model, which is cited by Von Neuman in his paper introducing the programmable computer. https://t.co/cINUga3sAG",1,8,0
224,2023-03-03 21:42:37+00:00,ylecun,"@ylecun @pkghosh99 @ylecun  You have mentioned the analogy of how airplanes were 'inspired' by birds - but do not flap their wings like birds. 
Isn't that analogy good for LLMs too?",1,1,0
225,2023-03-03 21:38:28+00:00,ylecun,@ylecun It is about where we set the bar for casual inference.,0,0,0
226,2023-03-03 21:31:59+00:00,ylecun,"@ylecun #EagleEye (2008)
https://t.co/b1hLONrTFl",1,0,0
227,2023-03-03 21:31:22+00:00,ylecun,@DavidBensh Not mentioning no hippocampus.,0,0,0
228,2023-03-03 21:25:00+00:00,ylecun,@ylecun It is not so easy to distinguish genuine mistaken beliefs from socially strategic insincerity.,1,2,0
229,2023-03-03 21:19:16+00:00,ylecun,@ylecun Where's the joke?,0,0,0
230,2023-03-03 21:13:44+00:00,ylecun,@ylecun Pareidolia is a common factor for both :),0,0,0
231,2023-03-03 21:11:59+00:00,ylecun,@ylecun Highest performance AIs needs to be compared to highest performance humans.,0,1,0
232,2023-03-03 21:07:17+00:00,ylecun,@ylecun Looks like France is becoming the ‚Äúmafia center‚Äù as far as AI is concerned.,0,0,0
233,2023-03-03 20:42:12+00:00,ylecun,"@ylecun I think long-range forecasting occurs upstream in the latent space of LLMs before token prediction actually takes place, the issue is that we don't how things are actually represented there.",1,2,0
234,2023-03-03 20:34:31+00:00,ylecun,"@ylecun Hi Yann, just put /s at the end. You'd find some people understand that better instead of the tags. You're welcome.",0,0,0
235,2023-03-03 20:24:02+00:00,ylecun,"@ylecun Humans can be aware they are not good at causal inference. Humans can think about thinking.

Ai can't.",0,0,0
236,2023-03-03 20:21:09+00:00,ylecun,"@ylecun That's hilarious... @lexfridman had a guest that measured g-factor.... hummm,  I wonder if there is a correlation????",0,0,0
237,2023-03-03 20:18:30+00:00,ylecun,"@ylecun Furthermore, so long as the LLM is used in conversational interaction, speech and interaction come into play - these are not simply modes of language, but involve interpretive meta-communication skills and knowledge.",0,1,0
238,2023-03-03 20:07:56+00:00,ylecun,@ylecun I like Feng Shui better. Location and lucky #s do influence your wealth (think chinese real estate). The correlation may be so strong that it comes ‚Äúcasual‚Äù.,1,0,0
239,2023-03-03 19:58:18+00:00,ylecun,@ylecun RIDENDO FVORI FORTE,0,0,0
240,2023-03-03 19:43:01+00:00,ylecun,"@ylecun Why compare to language processing?
If you look at speech generation in Broca's area, the model rely on broader PFC context to generate motor patterns that generate speech online.
The concept can be compared to token by token generation dependent on broad input..",1,0,0
241,2023-03-03 19:35:34+00:00,ylecun,@ylecun I need some clarification. Since when were ANNs biologically inspired?,3,4,0
242,2023-03-03 19:30:24+00:00,ylecun,"@ylecun Maybe we are really good at casual inference, and that‚Äôs why religion and astrology is a thing.",0,1,0
243,2023-03-03 19:24:03+00:00,ylecun,"@ylecun me too. im no longer a critic.  the ai types physcs code now. 2 body -relativistic orbit.  i cant check it but its not Newton ,like 4 weesk ago.  i ask for it to code me a semi Langrangian fluid solver with fft  using #monogame  it did.  i said code up the shaders? 60% done",2,1,0
244,2023-03-03 19:14:43+00:00,ylecun,@ylecun Why is this a joke?,1,0,0
245,2023-03-03 19:13:49+00:00,ylecun,"@ylecun this year I tried to find out my astrological sign and I have been reading the astrological forecasts for my sign every month since January. Little believer, but I admit that the predictions agree what is happening in my life.",0,0,0
246,2023-03-03 19:10:45+00:00,ylecun,@ylecun The consequence of building latent world models,0,0,0
247,2023-03-03 19:07:35+00:00,ylecun,"@ylecun Next up,

Fortune tellers GPT

üîÆüé±",0,0,0
248,2023-03-03 19:02:21+00:00,ylecun,@ylecun And neither religion would be a thing,0,0,0
249,2023-03-03 18:58:28+00:00,ylecun,@ylecun or dei departments lol,0,0,0
250,2023-03-03 18:53:41+00:00,ylecun,"@ylecun Expecting some super intelligence to make all the choices is a flawed concept., people want a choice and to have the opportunity to make an informed decision.  AI can help in two ways that reduce to one goal: make the mundane less mundane.",1,0,0
251,2023-03-03 18:52:59+00:00,ylecun,@ylecun But those are not considered part of intelligence right?they are irrational beliefs....,0,0,0
252,2023-03-03 18:46:49+00:00,ylecun,@ylecun @yudapearl I thought you were joking with those tags lol. You are a troll Sir.,2,1,0
253,2023-03-03 18:45:10+00:00,ylecun,"@ylecun Newton loved astrology.

You willing to pair up against him?",0,0,0
254,2023-03-03 18:37:28+00:00,ylecun,"@ylecun Storytelling is a big part of knowledge representation in the brain. Because we‚Äôve evolved to survive through community, and to build communities we need narratives (check out Yuval). This is where synthetic intelligence will do better than us",0,1,0
255,2023-03-03 18:33:47+00:00,ylecun,"@ylecun To minimize perplexity on next-token prediction, it's helpful to predict further ahead, so it's likely that LLMs learn do this internally as an emergent ability. How else would they guess the next word ftera [Your paper] is [is], if not by thinking about what could come after?",2,4,1
256,2023-03-03 18:25:34+00:00,ylecun,"@ylecun It's not one of your better jokes. As @yudapearl mentioned previously, without causal inference we wouldn't have what Harari refers to as imagined realities. So, no money, companies, national identity, nation states, rule of law, human rights, etc.",0,6,0
257,2023-03-03 18:21:25+00:00,ylecun,"@ylecun Agreed that humans may not always use rigorous methods for causal inference, but the development of AI that can do so has great potential. With better understanding of causal mechanisms, we can make better predictions and decisions. #AI #causalinference",0,3,0
258,2023-03-03 18:20:30+00:00,ylecun,"@ylecun Think about finance, stock picking, hedge funds... https://t.co/vJMZvxfha9",0,0,0
259,2023-03-03 18:18:55+00:00,ylecun,"@ylecun Why do you feel forced not to miss any opportunity to attack religion?
Is it part of the globalist agenda?",2,5,0
260,2023-03-03 18:15:56+00:00,ylecun,@ylecun Sir do you not agree with @yudapearl ideas? Like at least to me causal inference seems central. Humans are not good at something is all the more reason an Ai should be. No?,3,3,0
261,2023-03-03 18:13:34+00:00,ylecun,@ylecun There is no contradiction:  AI needs two spoons of causal reasoning and three of imagination. Humans are no Vulcans,2,2,0
262,2023-03-03 18:12:33+00:00,ylecun,@ylecun 1st Degree Guy: We're not that bad. We're just in serious competition with our appetite for delusion...,0,0,0
263,2023-03-03 18:08:59+00:00,ylecun,@ylecun But isn‚Äôt believing in AGI without knowing what goes into the black box equivalent to astrology?,2,1,0
264,2023-03-03 18:08:55+00:00,ylecun,@ylecun Maybe more satire :),0,1,0
265,2023-03-03 18:07:55+00:00,ylecun,"@ylecun This is a fair critique, but we can‚Äôt make the claim that the way humans think is the only way to get to AGI. We have no idea what intelligence could look like",0,1,0
266,2023-03-03 18:06:12+00:00,ylecun,@ylecun Don‚Äôt think Transformer is biologically inspired.,2,1,0
267,2023-03-03 18:04:06+00:00,ylecun,@ylecun I agree LLMs feel more like parroting machines but in terms of long term predictions isn't time the biggest factor for humans to process and learn things. Feels like this could be just different for machines ?,1,0,0
268,2023-03-03 18:03:56+00:00,ylecun,"@ylecun Some experiments show quantum relationships (Entanglement) going on in biological brains. It is still hard to even simulate that
https://t.co/W0qEPS12T6",1,1,0
269,2023-03-03 17:59:24+00:00,ylecun,"@ylecun Thank you for being here.

It is also true that the text they produce is obviously different, right now, in a way that makes sense with the animated image.",0,0,0
270,2023-03-03 17:45:16+00:00,ylecun,"@ylecun Basically that's what these astrologists have been doing throughout history. Compiling a list of human experiences, trying to seek patterns based on irrational correlation and predicting the life events for others with pure certainty while keeping us guessing.",0,2,0
271,2023-03-03 17:33:27+00:00,ylecun,@ylecun I wonder whether ChatGPT would be able to do actual astrology calculations,0,0,0
272,2023-03-03 17:22:14+00:00,ylecun,"@ylecun Given human propensity for religious, astrological and mystical thinking can we conclude that ai is already well aligned?",0,0,0
273,2023-03-03 16:51:23+00:00,ylecun,"@ylecun im sorry i ever doubted you, god speed ser üôè",0,0,0
274,2023-03-03 12:05:58+00:00,ylecun,@ylecun No way no wayyyyyy,1,0,0
275,2023-03-03 11:34:27+00:00,ylecun,"@ylecun Hey Yann, huge fan of you and your work. There‚Äôs insane space for constructivism and I hope you consider this as a path. I can understand your feelings but, after all, your work is to just serve your ego or you have bigger intentions - as a communicator, important to express them",1,2,0
276,2023-03-03 11:02:10+00:00,ylecun,@ylecun Amazing!,0,1,0
277,2023-03-03 10:37:38+00:00,ylecun,@ylecun Facepalm @ Cosmic LvLS,0,0,0
278,2023-03-03 10:05:07+00:00,ylecun,@ylecun Did Regression come first or Horoscopes?,0,0,0
279,2023-03-03 09:36:00+00:00,ylecun,@ylecun Biggest scam from beginning of humanity - astrologyü§£,0,0,0
280,2023-03-03 08:55:46+00:00,ylecun,@ylecun also  scary good  on dream interpretation,0,0,0
281,2023-03-03 08:34:10+00:00,ylecun,"@ylecun And with this prompt ChatGPT can make up even more stuff üôÉ
https://t.co/5rbNW6PMqh",0,1,0
282,2023-03-03 07:44:06+00:00,ylecun,"@ylecun @andrewdfeldman @pmarca Yann, as a üá∑üá∫ Fb and Ig user I‚Äôd politely evaluate Meta‚Äôs effort .. unimpressive.",0,0,0
283,2023-03-03 07:01:37+00:00,ylecun,"@ylecun Isn't prompt engineering equivalent of writing more clearly, in a way?",0,0,0
284,2023-03-03 06:43:38+00:00,ylecun,@ylecun üòÖ,0,0,0
285,2023-03-03 05:48:53+00:00,ylecun,"@ylecun I think Google and Meta should release something like ChatGPT, even if it's weird. Actually better if it's weird. People like weird stuff.",0,0,0
286,2023-03-03 05:30:13+00:00,ylecun,@ylecun ahhahahahah,0,0,0
287,2023-03-03 04:12:49+00:00,ylecun,@ylecun üòÇ,0,0,0
288,2023-03-03 04:12:31+00:00,ylecun,@ylecun you just jealous about the ChatGPT and wanna rub the online traffic,0,1,0
289,2023-03-03 04:09:08+00:00,ylecun,@ylecun you rubbish!,0,1,0
290,2023-03-03 03:48:03+00:00,ylecun,@ylecun You don‚Äôt need chatgpt for that. Humans already do.,0,0,0
291,2023-03-03 03:29:11+00:00,ylecun,"@ylecun Technologies  turbocharging  human creativity is a big worry now 

Generative  AI is inherently plagiaristic and it cover its tracks while doing creative tasks 

Ownership is a gray area for broader debates .

Detection will be more challenging as technology get better.",0,0,0
292,2023-03-03 02:38:48+00:00,ylecun,@ylecun Didn‚Äôt you say ‚Äúfriends don‚Äôt let friends use batch size greater than 32‚Äù? These guys are using a batch size of 4M üòÖ.,0,0,0
293,2023-03-03 02:36:23+00:00,ylecun,@ylecun How can horoscopes be produced? I still don't get it.,0,0,0
294,2023-03-03 01:49:20+00:00,ylecun,@ylecun Ha ha. Nice.,0,0,0
295,2023-03-03 01:42:17+00:00,ylecun,"@ylecun the fact that your team just released their own llm and yet you still find time to jab at chatGPT, sorry but i think you are overmilking this cow.",0,0,0
296,2023-03-03 01:41:45+00:00,ylecun,@ylecun ü•≤,0,0,0
297,2023-03-03 01:29:32+00:00,ylecun,"@ylecun Yann: Can I see my horoscope?
Lady: Just fill out this form, and we'll see.",0,7,1
298,2023-03-03 00:54:21+00:00,ylecun,@ylecun Search makes stuff up too,0,0,0
299,2023-03-03 00:36:26+00:00,ylecun,@ylecun Yep,0,0,0
300,2023-03-03 00:30:45+00:00,ylecun,@ylecun Llamao?,0,0,0
301,2023-03-03 00:15:19+00:00,ylecun,@ylecun You should have recommended Galactica instead. Where is your company pride?,1,8,0
302,2023-03-02 23:55:51+00:00,ylecun,@ylecun And all of them paid by this: https://t.co/HUs7EuXwm3,0,0,0
303,2023-03-02 23:51:02+00:00,ylecun,"@ylecun Criticism is cheap, what stuff do you brought out recently??",0,2,0
304,2023-03-02 22:58:29+00:00,ylecun,"@ylecun That is a funny use case, but then there's this...

https://t.co/NkusJA9JeQ",0,1,0
305,2023-03-02 22:56:01+00:00,ylecun,@ylecun BRILLIANT ANSWER.,0,0,0
306,2023-03-02 22:38:36+00:00,ylecun,@ylecun Smells of copium and bitterness,0,2,0
307,2023-03-02 22:12:36+00:00,ylecun,"@ylecun Looks like he's nearing the acceptance stage (or maybe still in denial, it's hard to tell).",0,0,0
308,2023-03-02 22:09:51+00:00,ylecun,@ylecun She should work for Fox.,0,0,0
309,2023-03-02 21:57:47+00:00,ylecun,@ylecun https://t.co/P0M9xHgeUQ,0,0,0
310,2023-03-02 21:55:48+00:00,ylecun,@ylecun pipotron en plus perfectionn√© quoi ..,0,0,0
311,2023-03-02 21:45:50+00:00,ylecun,"@ylecun Eh oui, pas besoin de GAI pour r√©volutionner certains domaines ! üòÇ",0,0,0
312,2023-03-02 21:17:49+00:00,ylecun,@ylecun https://t.co/d5jQA2GoZl,0,1,0
313,2023-03-02 21:10:11+00:00,ylecun,@ylecun Nostradamus to GPT !!!,0,0,0
314,2023-03-02 21:09:47+00:00,ylecun,@ylecun Criticism is always easy. What‚Äôs Facebook AI bringing to the table?,0,2,0
315,2023-03-02 20:45:32+00:00,ylecun,"@ylecun Rude! Here is the dual.. 

https://t.co/XpNB4AT5yn",1,2,0
316,2023-03-02 20:44:59+00:00,ylecun,@ylecun I funded my first overseas vacation by getting a contract gig in London to write a horoscope generator for this guy using his system back around 1990. Astrology ain‚Äôt all bad ;-) https://t.co/IxFYuqcxNl,0,3,0
317,2023-03-02 20:23:25+00:00,ylecun,"@ylecun the stars incline, they don't decide",0,0,0
318,2023-03-02 20:21:50+00:00,ylecun,@ylecun This is hilarious!,0,0,0
319,2023-03-02 20:21:43+00:00,ylecun,@ylecun No need for fact checking lol,0,0,0
320,2023-03-02 20:05:04+00:00,ylecun,@ylecun this is sad.,0,0,0
321,2023-03-02 19:49:01+00:00,ylecun,@ylecun Planets affect a human behavior. Do you think it's unscientific?,4,0,0
322,2023-03-02 19:43:31+00:00,ylecun,@ylecun Mangled AI fingers should be the international symbol for indicating works are derived from AI.,2,2,1
323,2023-03-02 19:42:06+00:00,ylecun,@ylecun Yann hit me up and I‚Äôll help you productize LLaMa. DM‚Äôs open,0,5,0
324,2023-03-02 19:36:55+00:00,ylecun,@ylecun NostradamuGPT!! https://t.co/wt8sTq04dq,1,6,0
325,2023-03-02 19:30:32+00:00,ylecun,"@ylecun As a fun fact, horoscope have been commonly generated by computers since the 1960s (and are probably to this day the generated texts with the most durable impact on pop culture).",2,29,4
326,2023-03-02 19:29:23+00:00,ylecun,"@ylecun from ChatGPT: ""However, I would like to clarify that producing horoscopes based on factual information or scientific evidence is not possible, as horoscopes are considered a pseudoscience."" https://t.co/ai3qZ2R5ry",0,11,0
327,2023-03-02 19:29:10+00:00,ylecun,"@ylecun @pmarca ... in all honesty, was the decision not to provide a permissive open source license made because of bad feedback from a previous model, or was it because AI is and will be a strategic advantage to Meta...in my view that is a very reasonable reason by the way.",0,0,1
328,2023-03-02 19:27:07+00:00,ylecun,@ylecun As though ‚Äújust making stuff up‚Äù isn‚Äôt amazing in its own right https://t.co/Q7ic5dOlGb,2,6,0
329,2023-03-02 19:25:44+00:00,ylecun,"@ylecun That's the whole point, Use it for what it's good at.",0,1,0
330,2023-03-02 19:06:34+00:00,ylecun,@ylecun non generative very adversarial networks,0,0,0
331,2023-03-02 07:44:42+00:00,ylecun,"@ylecun - here's the recipe for the cake, for free. (Llama announcement)
 @sama - here's more basically free cake! (10x drop in price and new model today)

#ai #LLMs",0,0,1
332,2023-03-02 07:23:48+00:00,ylecun,"@ylecun @tunguz @verge He just didn't read the article at all, there is Zuckerberg's own words plain and simple. https://t.co/4uBY10REKq",0,0,0
333,2023-03-02 03:31:40+00:00,ylecun,@ylecun following through as promised. Our research team is very excited to test out #Llama.,0,0,0
334,2023-03-02 03:08:23+00:00,ylecun,"@ylecun @bindureddy I made my case here : https://t.co/OzTaIp5JzP

Our community wants to use it to train fiction generator models. Its hobbyists running stuff at home. Having a better 7B/13B fiction model sure isn't going to destroy the world if we shared the result publically?",0,0,0
335,2023-03-02 02:04:52+00:00,ylecun,"@ylecun @pmarca You're basically a monster.

Wow! I'm offended!",0,0,0
336,2023-03-02 01:37:47+00:00,ylecun,"@ylecun @pmarca If AI made wine, it would make a ch√¢teau d‚ÄôYquem üíÅüá´üá∑",0,0,0
337,2023-03-02 00:12:32+00:00,ylecun,@ylecun the last bit was marginally funny ;) https://t.co/UZfD4htHNf,0,0,0
338,2023-03-02 00:12:04+00:00,ylecun,@ylecun @pmarca J√ºrgen Schmidhuber about to suggest that this follows his prior art.,0,6,0
339,2023-03-01 23:43:41+00:00,ylecun,@ylecun @pmarca I drink one glass of wine per week. Cognac once a year.,0,0,0
340,2023-03-01 23:25:50+00:00,ylecun,"@ylecun @pmarca I‚Äôm with you. One cognac, Armagnac, whiskey per weekday. Keeps the doctor away.",0,3,0
341,2023-03-01 20:05:07+00:00,ylecun,@ylecun The next stage is universal LLK where K stands for knowledge not language and this model is not a property of a single entity or entreprise but a global. it would need the introduction of an artifical concept/meaning (some thing like advanced ontology).,2,0,0
342,2023-03-01 18:57:23+00:00,ylecun,"@ylecun Bi-directional prompt engineering, or conversational prompting, or proactive response engineering, or conversational prompting... use the social cues inherent in speech, help users refine their prompts with responses containing cues that reflect response opportunities",0,0,0
343,2023-03-01 16:06:14+00:00,ylecun,@ylecun @tunguz @verge Bingo,1,13,0
344,2023-03-01 14:37:30+00:00,ylecun,"@ylecun In the very near future, today's loosely defined term ""prompt engineering"" is likely to be equivalent to the notion of ""teaching"". Especially in cases where you let the prompt persist or evolve strategically during the interaction..",0,0,0
345,2023-03-01 14:34:54+00:00,ylecun,"@ylecun I have this nagging feeling that ""prompt engineering"" is just a side effect of where LLMs are today; i.e. we need to coax results from the machine. In a day or two it will be merely ""clearly describing intent""; i.e. Communications majors will be in demand",0,0,0
346,2023-03-01 14:00:02+00:00,ylecun,@ylecun bidirectional intelligence,0,0,0
347,2023-03-01 13:55:14+00:00,ylecun,@ylecun @bindureddy Fwiw many of us really appreciated that you released that. Don‚Äôt be discouraged!,0,1,0
348,2023-03-01 13:31:38+00:00,ylecun,"@ylecun Let your chatbots talk to each other, and let them do pair programming. Let them search the documentation. But then I will be out of business myself and I have spent too much time on a second degree already.",0,0,0
349,2023-03-01 13:14:40+00:00,ylecun,"@ylecun ""I‚Äôm sorry but I prefer not to continue this conversation. I‚Äôm still learning so I appreciate your understanding and patience.üôè""",0,1,0
350,2023-03-01 12:22:52+00:00,ylecun,@ylecun I don't know anyone who has had an original thought in thier life. So yeah that logic checks out. We are all derivative.,0,1,0
351,2023-03-01 12:05:11+00:00,ylecun,"@ylecun @bindureddy @ylecun some people are always like that, can't make everyone happy - but it would be indeed great to access LLaMA (and keep finetuning it, say, on Summit we currently use) as it further along data scale than anything else of its size. Submitted request, waiting üòÄ happy to chat",0,12,0
352,2023-03-01 09:33:25+00:00,ylecun,"@ylecun Funny how they will open source their ai but refuse to open source echo arena, or sell it, or do literally anything besides f***ing delete it @boztank",0,0,0
353,2023-03-01 08:58:18+00:00,ylecun,@ylecun Baby crying is also prompting.,0,1,0
354,2023-03-01 08:21:04+00:00,ylecun,@ylecun That is why prompt engineering isn‚Äô t going anywhere. https://t.co/6aaT6EezS2,0,0,0
355,2023-03-01 07:29:28+00:00,ylecun,@ylecun Yeah but people do the same think too; all the time.,0,0,0
356,2023-03-01 07:25:53+00:00,ylecun,"@ylecun ""human"" - that's loopy - u have 2 add x, or do u claim to be able to eg ""make sense"" of people?",1,0,0
357,2023-03-01 07:10:01+00:00,ylecun,"@ylecun I don't think it's just a ""lack of understanding."" We are bad communicators: most prompts simply don't have enough information to produce the desired result",0,0,0
358,2023-03-01 06:36:19+00:00,ylecun,@ylecun Engaging in bidirectional human prompt engineering during discussions with colleagues can lead to a better understanding of each other's perspectives and improve collaboration #HumanPromptEngineering,0,0,0
359,2023-03-01 05:59:20+00:00,ylecun,@ylecun So ADHD = Attention is All You Need?,0,1,0
360,2023-03-01 05:07:44+00:00,ylecun,"@ylecun @OuahabiAdnane a Python sounds way cooler than a Lua, tbf",0,0,0
361,2023-03-01 05:01:24+00:00,ylecun,"@ylecun Why are we overindexing on understanding? If ChatGPT can address a wide variety of usecases without having the need to ""understand"", what's the problem?",0,0,0
362,2023-03-01 04:46:20+00:00,ylecun,"@ylecun is this what you have been doing on facebook while doing controversial post, isnt?",0,0,0
363,2023-03-01 04:24:33+00:00,ylecun,@ylecun But don't humans need to rephrase things too? I mean sure prompts right now are a little weird but we are trying to communicate using our limited patterns of language with something trained on all patterns of language.,0,0,0
364,2023-03-01 04:21:54+00:00,ylecun,@ylecun @ericschmidt people need to pull back on their lack of overall knowledge a bit. stay in their wheelhouse. and check their loose connections. basics.,0,1,0
365,2023-03-01 04:15:49+00:00,ylecun,"@ylecun @sa_mous @BrivaelLp @TopherBR @huggingface @ClementDelangue @julien_c @AntoineBordes @armandjoulin @syhw @EXGRV Then the ecosystem feeds on itself.
You mean eels, frog legs, snails, horse meat and liver from tortured geese.",0,0,0
366,2023-03-01 03:54:02+00:00,ylecun,"@ylecun @david_picard How about response engineering as a method by which to guide/steer the user towards better prompts? Leverage the intrinsic interaction inherent in conversational discourse: responses that suggest the next move, offer help, create opportunities.",0,0,0
367,2023-03-01 03:23:35+00:00,ylecun,"@ylecun People can overestimate its technical rigor and reliability of results .

These  mathematical machines designs built on flawed  human knowledge  can reflect in it's results .",0,0,0
368,2023-03-01 03:03:42+00:00,ylecun,"@ylecun Mixed initiative systems seem necessary, a model can't be fully confident of a user's need without getting clarification from the user",0,0,0
369,2023-03-01 02:22:34+00:00,ylecun,@ylecun Agreed @ylecun 'the need for prompt engineering is a sign of lack of understanding'. Scaling the right #NLU model solves problems with todays generative AI https://t.co/iVczNFiMlL,0,1,0
370,2023-03-01 02:15:58+00:00,ylecun,@ylecun Without reinforcement learning.. mostly !!,0,1,0
371,2023-03-01 01:53:26+00:00,ylecun,@ylecun @DongkuanXu But I still do not get reply from the team for model downloading after filling out the application form...,0,0,0
372,2023-03-01 01:40:34+00:00,ylecun,"@ylecun This is academia talking not the actual real world. In the real world prompt engineering is an opportunity to create value regardless of what you might think.

In other words. You lack the understanding of how technology gets applied in the real world.

It is what it is.",0,0,0
373,2023-03-01 01:00:40+00:00,ylecun,@ylecun what are you on about?!,0,0,0
374,2023-03-01 00:57:12+00:00,ylecun,@ylecun Prompt engineering is a form of feature engineering. A sign that we don‚Äôt have an e2e system.,0,0,0
375,2023-03-01 00:52:46+00:00,ylecun,"@ylecun Multiagent interactive JEPA to facilitate NN convergence and mutation, aka learning.",0,0,0
376,2023-03-01 00:23:27+00:00,ylecun,@ylecun Do you have any suggestions (paper/books/articles) to learn more about what it would mean for an AI (for a lack of a better word) to ‚Äòunderstand‚Äô in the sense that would be satisfying  to you? There‚Äôs quite a lot out there but I‚Äôd value your perspective on where I might start!,0,0,0
377,2023-03-01 00:22:11+00:00,ylecun,"@ylecun How is prompt engineering different from when you hire employees and explain to them any rules, roles or responsibilities?",0,2,0
378,2023-03-01 00:13:20+00:00,ylecun,"@ylecun I wonder what what a ""discussion"" between two competing LLMs would be like...",0,0,0
379,2023-02-28 23:54:03+00:00,ylecun,@ylecun Humans do Prompt Engineering every day when talking to other humans‚Ä¶ are you expecting the LLM to read your mind?,0,0,0
380,2023-02-28 23:36:33+00:00,ylecun,@ylecun https://t.co/ivKtyp6CIF,0,0,0
381,2023-02-28 22:52:14+00:00,ylecun,@ylecun Always was.....,0,0,0
382,2023-02-28 22:48:54+00:00,ylecun,"@ylecun @davidwhogg We in our corporeal forms are so many interdependent abstractions and we continue to follow an abstract path and we have no compass. Worse, no destination.",0,0,0
383,2023-02-28 22:39:22+00:00,ylecun,@ylecun good one!,0,0,0
384,2023-02-28 22:34:12+00:00,ylecun,@ylecun Communication.,0,1,0
385,2023-02-28 22:23:04+00:00,ylecun,"@ylecun ""You know, I think what you're trying to get me to respond with is x. If you want that, please try the following prompt."" - Neo-Clippy",0,0,0
386,2023-02-28 22:00:08+00:00,ylecun,"@ylecun Humans also need some prompt engineering to get around cognitive biases or communication issues. No, LLMs aren't thinking in the same way we are and they aren't sufficient for AGI, but perhaps we both share certain framing dynamics and that's not necessarily a sign of LLM = dumb",0,0,0
387,2023-02-28 21:55:34+00:00,ylecun,"@ylecun My personal experience on very limited tests on reasoning tasks is, chatgpt still requires some degree of prompt engineering (it may still make mistakes with that), but bing chat (gpt4 based?) can perform very well without it",0,0,0
388,2023-02-28 21:55:28+00:00,ylecun,"@ylecun Well, the reason we all are taking to prompt engineering LLMs like fish to water is because that is pretty much a natural mode of interaction for us.. 

https://t.co/QG7r6uQpOt",0,5,0
389,2023-02-28 21:49:24+00:00,ylecun,@ylecun @abhijithneil what do you think of supplementing probabilistic models with symbolic databases or commonsense knowledge (@YejinChoinka)?,0,0,0
390,2023-02-28 21:48:32+00:00,ylecun,@ylecun hmm if the AI is listening then üòé,0,0,0
391,2023-02-28 21:44:15+00:00,ylecun,@ylecun VC funds are on the way,0,2,0
392,2023-02-28 21:35:52+00:00,ylecun,"@ylecun What about AI to AI only debates about AI? Or AI only conferences? Would GPT4 conceive of GPT4 as ancestor. How would we detect the emergence of emotions like pride, envy, fellowship between them?",0,3,0
393,2023-02-28 21:34:44+00:00,ylecun,@ylecun Bit of a feedback loop of prompt engineering üîÅ,0,0,0
394,2023-02-28 21:32:54+00:00,ylecun,"@ylecun There is some level of scaling that would help, but I agree that it might be silly to just keep trying to scale something that is not the best.  Hopefully, your JEPA will take off, and we can get on to something better.",0,0,0
395,2023-02-28 21:31:04+00:00,ylecun,"@ylecun @sa_mous @TopherBR @huggingface @ClementDelangue @julien_c @AntoineBordes @armandjoulin @syhw @EXGRV Do agree, what do you think we miss in France to create a big tech equivalent? Just time or our ecosystem are still not enough fertile ?",1,1,0
396,2023-02-28 21:31:01+00:00,ylecun,@ylecun And the whiteboard == Latent Representation ? üßê,0,2,0
397,2023-02-28 21:30:00+00:00,ylecun,"@ylecun It can help to create a more inclusive and collaborative work environment where everyone feels comfortable sharing their thoughts and ideas. This, in turn, can lead to better decision-making, increased productivity, and more positive outcomes overall.",0,0,0
398,2023-02-28 21:26:33+00:00,ylecun,"@ylecun No, the first one starts with a 'D', the other with a 'b'. Interesting idea though.",0,0,0
399,2023-02-28 21:26:32+00:00,ylecun,@ylecun Prompt engineering or fine-tuning?,2,0,0
400,2023-02-28 19:51:47+00:00,ylecun,"@ylecun Hahah, on point.",0,0,0
401,2023-02-28 19:22:31+00:00,ylecun,"@ylecun GPT is bootstrapping. Prompt engineering will no longer be needed once the model goes large just like how human does. We also need prompt engineers: parents, teachers or textbooks when we are ignorant but once we understand commonly used vocabularies, we can learn by ourselves.",0,2,0
402,2023-02-28 19:02:18+00:00,ylecun,"@ylecun Public speakers - the original prompt engineers.

Convincing people to behave in a specific way you want them to behave is more than said people being able to understand your language.

Same with an LLM that has been aligned in a way different from your goals.",2,0,0
403,2023-02-28 18:41:39+00:00,ylecun,"@ylecun I'd argue that it's not the lack of world understanding, but the discrepancy between the model's goals and user's expectations. Otherwise RLHF wouldn't reduce the need for prompt engineering.",0,3,0
404,2023-02-28 18:34:07+00:00,ylecun,@ylecun Exactly; what we need is to optimize for satisfaction and well-being. Scaling LLMs causes them to sound more like real web pages. Prompt engineering gets them to sound like web pages about specific topics (prompts). Optimizing for human values gets them to be more helpful,0,0,0
405,2023-02-28 18:29:58+00:00,ylecun,"@ylecun hmm, I don't see the need for prompt engineering as (necessarily) a sign of lack of understanding from LLMs. More like bad UX and myopic dialogs",0,0,0
406,2023-02-28 18:29:14+00:00,ylecun,"@ylecun IMO there are two kinds of prompt engineering: there is inserting nonintuitive key words and symbols and syntax -but then there‚Äôs also a more basic point: if I want an image that looks like this, that‚Äôs going to require an awful lot of very specific words. https://t.co/iiaUfOqrse",4,11,1
407,2023-02-28 18:28:45+00:00,ylecun,@ylecun Humans got an understanding of the world thanks to natural selection over 500 million years. I wonder if we can replicate something similar to that in an AI sense.,0,0,0
408,2023-02-28 18:27:04+00:00,ylecun,"@ylecun prompt engineering is just a better way of problem formulation. same problem, different formulation, leads to different good or bad solutions. in this sense, nothing wrong with PE. Also PE can be automized as well https://t.co/i00h36SDrR",0,4,0
409,2023-02-28 18:08:17+00:00,ylecun,@ylecun Fully agree and it‚Äôs the hardest job. otherwise it amounts to telling the algo what you want to readü§£,0,0,0
410,2023-02-28 17:46:36+00:00,ylecun,@ylecun @davidwhogg Wow a reply to your tech question by Yann LeCun. Twitter sure is cool sometimes.,0,0,0
411,2023-02-28 17:39:19+00:00,ylecun,"@ylecun Communicating information effectively to an audience, whether an individual, group of people, or a machine, is a skill like anything else. In my experience, people are bad at transforming information in a way that someone with a different background or mental model can understand",0,0,0
412,2023-02-28 17:34:22+00:00,ylecun,@ylecun Why is there a desire to assume a single LLM will be the path to AGI. I'd imagine the final solution would have multiple systems in parallel where one or more LLMs are a part of the whole,0,1,0
413,2023-02-28 17:32:14+00:00,ylecun,"@ylecun Nowadays, LLMs are doing two separate things: ensure NL coherence and being queried as associative memories to retrieve information. Maybe an adequate alternative is to approach this as two separated models for grammar and information. The latter is the one that needs to scale.",0,1,0
414,2023-02-28 17:28:57+00:00,ylecun,"@ylecun I understand that these models are simply just mimicking language. However,  I don't think that prompt engineering is a sign of lack of understanding.  How we prompt questions to the humans will also change the output in some instances.  Think critical reasoning test.",0,0,0
415,2023-02-28 17:06:42+00:00,ylecun,@ylecun what is understanding for you?,0,0,0
416,2023-02-28 17:01:21+00:00,ylecun,@ylecun That's just half of the problem.  It's also the lack of expressiveness.,0,0,0
417,2023-02-28 16:55:02+00:00,ylecun,@ylecun LLMs need better models of the world.,1,2,0
418,2023-02-28 16:53:44+00:00,ylecun,@ylecun You don't think that scaling RLHF to gigantic data is going to drastically improve the interaction to the point where prompt engineering will be less relevant?,1,5,0
419,2023-02-28 16:52:29+00:00,ylecun,@ylecun Lack of understanding by the customers or the developers?,1,1,0
420,2023-02-28 14:17:12+00:00,ylecun,"@ylecun @RachelVT42 Our intellectual thought largely consists of internal monologue with reference to memory connected by magical neural networks; also conversing, reading and writing. An LLM system can surpass us at all of these. Our languages largely determine the domain of our thoughts.",1,1,0
421,2023-02-28 14:12:34+00:00,ylecun,"@ylecun You try remembering most of everything in less than a Terabyte, then answer all queries correctly first time without any mistakes. I think of it as an elderly relative who knows a whole lot, and can still talk and think, but whose brains have gone a bit blurry in their old age.",0,0,0
422,2023-02-28 11:42:16+00:00,ylecun,@ylecun What about Elixir (Nx) with GPU support and built in (absolutely best out there) concurrency mechanism?,0,0,0
423,2023-02-28 09:43:02+00:00,ylecun,"@ylecun Exactly.
https://t.co/fOdPHGmWEG",0,0,0
424,2023-02-28 08:05:25+00:00,ylecun,"@ylecun The closest one maybe Nim. 
https://t.co/lwelKCDjhJ",0,0,0
425,2023-02-28 07:59:52+00:00,ylecun,"@ylecun Have you tried Nim?
https://t.co/QQ6nmDSQfH",0,0,0
426,2023-02-28 03:13:23+00:00,ylecun,@ylecun –ü–ª–∞–Ω–µ—Ç–∞ –æ–±–µ–∑—å—è–Ω 2,0,0,0
427,2023-02-28 01:16:56+00:00,ylecun,"@ylecun @michael_at_work @OuahabiAdnane Python has many problems, but definitely the success of Python today was not driven by a hype. Python is a old and mature language, I remember not even looking at it because of the success at the time, of PHP. The reason why it is popular nowadays is more complex than we think.",1,0,0
428,2023-02-28 00:34:58+00:00,ylecun,"@ylecun, hope you did too (‚ÄúMeta has a team that works closely with Nvidia that has not been talked about‚ÄîJC‚Äù
‚Ä¶
Mark Zuckerberg announces new team at Meta working on A.I. products‚ÄîCNBC)",1,0,0
429,2023-02-27 22:39:38+00:00,ylecun,@ylecun Should‚Äôve asked for a Cray instead?,0,2,0
430,2023-02-27 21:59:47+00:00,ylecun,"@ylecun This is very interesting, and it coincides with my observations made during my interactions with chatgpt. However, I found it challenging during the chat to identify the passages that seemed wrong and it trained my critical thinking.",0,0,0
431,2023-02-27 21:00:55+00:00,ylecun,@ylecun You should open with this!,0,0,0
432,2023-02-27 20:56:50+00:00,ylecun,"@ylecun Thank you. 
You may not see this, but I will ask. ChatGPT has  of problems, but it's a step forward. I'm biased bc at Ames I worked on D Wolpert using RL &amp; got some interesting results. But I've asked CG for references, and it did a good job. What about a self correcting LLM?",0,0,0
433,2023-02-27 17:15:51+00:00,ylecun,"@ylecun when people chat with people, they see what they want to see as well...",1,0,0
434,2023-02-27 16:25:01+00:00,ylecun,"@ylecun Which llama model is this, 65B or one of the lower parameter ones?",0,0,0
435,2023-02-27 16:08:15+00:00,ylecun,"@ylecun @CadeMetz We appear to learn nothing of value from fiction.
Fiction is simply a technology of reduction that takes our brains away from real problem solving.
https://t.co/jlahf6wgJi",1,0,0
436,2023-02-27 14:51:59+00:00,ylecun,@ylecun @CadeMetz The mirror in Harry Potter,0,1,0
437,2023-02-27 14:48:36+00:00,ylecun,@ylecun @CadeMetz Perhaps the chatbot isn't quite as sophisticated as your examples?,0,0,0
438,2023-02-27 14:09:09+00:00,ylecun,"@ylecun A common theme in fiction that provides a very poor guide to understanding actually existing technologies. 

BingChat isn't Shakespeare: it's a buzzy new reality show co-produced by OAI &amp; the NYT is covering it like fans who want access to the cast party.
https://t.co/acsG15w8R9",0,0,0
439,2023-02-27 12:21:29+00:00,ylecun,"@ylecun Sorry Yann, but doesn't this mostly reflect the hiring biases at FAIR-Paris more than any aptitude associated with these backgrounds?",1,2,0
440,2023-02-27 11:54:01+00:00,ylecun,@ylecun Le pond de l'LLaMA,0,1,0
441,2023-02-27 09:33:03+00:00,ylecun,"@ylecun there is something about the food, that must be it https://t.co/867HKfFnMw",0,0,0
442,2023-02-27 05:33:08+00:00,ylecun,"@ylecun @bindureddy Galactica was in fact a great work, how it was marketed is questionable though... 
Still hoping recent new LLMs would allow commercial usage.",0,1,0
443,2023-02-27 03:42:44+00:00,ylecun,@ylecun Rust https://t.co/qdcNUHJSqE,0,0,0
444,2023-02-27 03:17:19+00:00,ylecun,"@ylecun @Xelatihy ""Held back by the tools"" I think is also true for the chip design industry.",0,4,0
445,2023-02-27 02:13:20+00:00,ylecun,@ylecun Goes to show that if a medium sized school can make this happen what could we accomplish if instead of 60 million Frenchmen what 8 billion earthlings with education can do. 130x!,0,0,0
446,2023-02-27 01:19:35+00:00,ylecun,@ylecun @neilturkewitz @EMostaque @bindureddy üëèüëèüëèüëèüëè,0,0,0
447,2023-02-27 00:47:10+00:00,ylecun,@ylecun @EMostaque @bindureddy Yeah that was super weird. Please ignore those people. I want some free models plz!,0,0,0
448,2023-02-27 00:26:40+00:00,ylecun,"@ylecun Any chance for us to visit FAIR-lab as a visiting scholar ?
Open sourcing is not enough. Open facility is also a need for underrepresented people around the world.
Our AI gang is high.
We can be a part of the Parisian AI mafia too.",0,0,0
449,2023-02-27 00:00:18+00:00,ylecun,"@ylecun Completely agree with Bojan, Python has diminished the barrier to entryüëçüèº",0,0,0
450,2023-02-26 23:53:17+00:00,ylecun,"@ylecun @neilturkewitz @EMostaque @bindureddy Right, the key driver of climate change was environmentalists concerned about the risks of nuclear power, not the dominant, mostly unquestioned idea that infinite growth and consumption are sustainable within a finite system (our planet) and the policies based on that idea!",1,1,0
451,2023-02-26 23:29:15+00:00,ylecun,"@ylecun aye aye.. I use it for reasoning, planning, medical diagnosis, couples therapy--basically everything except writing assistance. 

It is oh so antediluvian to use human or #AI agents on things they have been trained for. *Where* is the entertainment er.. pedagogical value in that?",0,6,0
452,2023-02-26 23:27:24+00:00,ylecun,"@ylecun Unfortunately, our lovely alma-mater ENS Cachan is no more. Now it's moved and called @ENS_ParisSaclay!",0,1,0
453,2023-02-26 23:13:12+00:00,ylecun,"@ylecun I'll add to that list Francois Chollet, Francis Bach, Gael Varoquaux and Fabien Lotte (not AI though but Brain-Computer Interfaces).",0,0,0
454,2023-02-26 22:50:55+00:00,ylecun,@ylecun @FelixHill84 RLHF: Royal Legislative Highness's Finalization,0,1,0
455,2023-02-26 22:34:27+00:00,ylecun,"@ylecun @neilturkewitz @EMostaque @bindureddy Or we might have multiple 3 Mile Island, Fukushimas and Chernobyls to deal w/. This is not an actual argument Yann. It's a facile ""whataboutism."" 
There are serious questions abt malicious uses of LLMs which can &amp; should be discussed. +",2,4,0
456,2023-02-26 21:05:20+00:00,ylecun,"@ylecun @ericschmidt Jesus, this is a naive take.

You honestly think people will ""better trace the provenance"" of what they see / hear / read?!?

I think you're giving people, and technology, way too much credit.",0,1,0
457,2023-02-26 20:57:44+00:00,ylecun,"@ylecun @neilturkewitz @EMostaque @bindureddy So then if you know this, why are you still listening to such doomsayers? Release the models. Get waivers from users if you want. The vast majority of society is well equipped to exercise personal responsibility.",1,0,0
458,2023-02-26 20:54:11+00:00,ylecun,@ylecun What language was the original LeNet programmed in? I recalled FORTRAN compilers once had some speed advantages in 90s.,0,1,0
459,2023-02-26 20:34:54+00:00,ylecun,@ylecun Is that why you‚Äôre failing?,0,0,0
460,2023-02-26 19:34:03+00:00,ylecun,"@ylecun @FelixHill84 LOL, I like that pun.

Remember when the church tried to ban the Encyclop√©die?",0,0,0
461,2023-02-26 18:53:58+00:00,ylecun,@ylecun France is an interesting option to consider for studies and academic career not to develop cutting hedge tech companies or to build a career in tech,0,0,0
462,2023-02-26 18:51:09+00:00,ylecun,@ylecun Nope guys France is not going anywhere with all the overtaxing in place and in planification to double or triple in coming years. Add to that also the toxic overregulation in Europe üíâüå°Ô∏è,0,0,0
463,2023-02-26 18:38:13+00:00,ylecun,@ylecun @ericschmidt This seems like the correct response. But it strikes me as an enormous failing that the AI companies didn't build any kind of digital watermarking into the output of their tools. In a world already drowning in false information you would think the need was obvious.,0,0,0
464,2023-02-26 18:36:08+00:00,ylecun,@ylecun @ericschmidt Imagine living in The Year of Our Lord 2023 and thinking that people will do literally anything to assess the reliability of what they see and hear,0,2,0
465,2023-02-26 18:21:20+00:00,ylecun,"@ylecun @ericschmidt How will the new systems be ""controllable"" - via jailbreakable/hackable human reinforcement? https://t.co/CXtGRYHkWY",0,0,0
466,2023-02-26 18:02:20+00:00,ylecun,@ylecun @EMostaque @bindureddy you gotta learn how to be flame proof if you're going to interact with people on the internet,0,1,0
467,2023-02-26 18:00:44+00:00,ylecun,"@ylecun @EMostaque @bindureddy Well, the same has happened to Google, which lost one hundred billion in market value in one hour.

Probably you both are unable to explain the limits and the value of your product, while Microsoft (openAI) can be wrong everytime without consequences.",0,1,0
468,2023-02-26 17:57:03+00:00,ylecun,"@ylecun @EMostaque @bindureddy The opinions of people that have put in zero effort of thinking about AI, let alone work on it. Are worth less than nothing.

I want to be able to use AIs that aren't lobotomized to appease the puritans.
It's not up to them what I get to use or not. I will decide that for myself",0,1,0
469,2023-02-26 17:50:23+00:00,ylecun,@ylecun @egrefen @elonmusk He couldn‚Äôt really pull off his schtick from Wyoming.,0,0,0
470,2023-02-26 17:50:10+00:00,ylecun,@ylecun @lxbrun https://t.co/79t5Uf55JQ,0,0,0
471,2023-02-26 17:48:04+00:00,ylecun,"@ylecun @elonmusk But do they have a good, solid 
40 hour work week?",0,0,0
472,2023-02-26 17:18:10+00:00,ylecun,@ylecun https://t.co/aZVPyqk9XP,0,0,0
473,2023-02-26 17:11:47+00:00,ylecun,@ylecun My reason to take the sun offer and quit PhD ( before quals) was I had a Sun4 for myself  leaving theorem proving / prolog - (first AI winter ) and a vax 11/80 ( dept. Admin) for the personal Unix box and bill joy. Life‚Äôs decision was so simple. Ironically 35 years later time to‚Ä¶,0,0,0
474,2023-02-26 17:04:37+00:00,ylecun,"@ylecun @ESYudkowsky maybe. However, if Meta releases it with a more permissive license it will eat chatGPTs lunch.",0,0,0
475,2023-02-26 16:46:59+00:00,ylecun,"@ylecun This is not open source. This is pure open washing. The trained weights are available under a

""non-transferable, non-sublicensable, revocable, royalty free and limited license ... solely for your non-commercial research purposes""

That is in no way an open source license.",1,3,0
476,2023-02-26 16:44:42+00:00,ylecun,"@ylecun @ylecun how do you pronounce it? Is it like the Spanish ""Jama"" or just the English ""Lama""?",0,0,0
477,2023-02-26 16:43:49+00:00,ylecun,@ylecun @FelixHill84 touch√© üëåüèæ https://t.co/dRZRmlHR6P,0,1,0
478,2023-02-26 16:33:01+00:00,ylecun,@ylecun @FelixHill84 üòÜ,0,0,0
479,2023-02-26 16:29:13+00:00,ylecun,"@ylecun @FelixHill84 Yes, the kings cracked on very quickly to what a threat all those books might pose, and they were ultimately right of course! They had a hard time stopping the leafleting though, and the reading of those where the 'plebs' first got fired up.",0,0,0
480,2023-02-26 16:25:23+00:00,ylecun,@ylecun What or who is LeNet ? please email me to basile@starynkevitch.net,1,0,0
481,2023-02-26 16:16:51+00:00,ylecun,@ylecun We need more of this kind of geographically distributed progress!,1,0,0
482,2023-02-26 16:06:41+00:00,ylecun,@ylecun @EMostaque @bindureddy And? You done destroyed it didntcha?,0,0,0
483,2023-02-26 15:41:44+00:00,ylecun,"@ylecun @bindureddy That's only because it didn't work... It not working didn't mean the idea was bad, just meant it needed more work to get it right.  Meta dropped the ball but more than capable of getting back in the fight.",0,2,0
484,2023-02-26 15:30:27+00:00,ylecun,@ylecun @Graverman__ @bindureddy Cool! Is it true that the chances are high that we are going to see an open-source release of LLaMA once it went through the open-academic research?,0,0,0
485,2023-02-26 15:28:24+00:00,ylecun,"@ylecun That's not an open source AI model, it's an open source installer.",0,0,0
486,2023-02-26 15:24:25+00:00,ylecun,@ylecun ü§£,0,1,0
487,2023-02-26 15:23:56+00:00,ylecun,"@ylecun I used Sparcstation 10 in my graduate school. Good software (compilers and OS), but slow CPU.",1,1,0
488,2023-02-26 15:18:59+00:00,ylecun,"@ylecun @matthieurouif Ah France... the butchers, the bakers, the AI makers.",1,8,0
489,2023-02-26 15:14:18+00:00,ylecun,@ylecun My first machine at office (CEA) in 1985 was a sun 3/160 workstation. See also RefPerSys software on https://t.co/pnXv083A4S and contact me (Basile Starynkevitch) by email to Basile.starynkevitch@cea.fr or Basile@starynkevitch.net,0,0,0
490,2023-02-26 14:55:00+00:00,ylecun,@ylecun Is this the French Revolution of AI or something?,0,1,0
491,2023-02-26 14:53:04+00:00,ylecun,"@ylecun @bindureddy Use the scientific method to test your claim

""Galactica, designed to help scientists write scientific papers""

Did it do that successfully for the people that tried it? 

No, including myself. Galactica **did not work**

It was a bad product that had a poor implementation",1,5,0
492,2023-02-26 14:46:51+00:00,ylecun,@ylecun Open source is THE way when it comes to AI. Even if the weights aren‚Äôt released the architecture itself is super valuable.,0,0,0
493,2023-02-26 14:34:10+00:00,ylecun,"@ylecun The M stands for Math√©matiques though, not Master üôÇ

Also I‚Äôm curious, do you roughly know what proportion of RS/PhD students at FAIR-Paris went through X-ENS? And through the MVA (but not X-ENS)? ü§î",0,1,0
494,2023-02-26 14:25:51+00:00,ylecun,@ylecun Do you still recall how many hours did it take LeNet to train on Sun-4?,0,2,0
495,2023-02-26 14:21:24+00:00,ylecun,"@ylecun @TopherBR @huggingface @ClementDelangue @julien_c @AntoineBordes @armandjoulin @syhw @EXGRV Yeah, we are going in good direction :) France should now try to produce an equivalent of ‚Äúbig tech‚Äù in the next decade, maybe the new cycle of AI usage it's a good opportunity for today‚Äôs startups to have this ambition.",2,10,0
496,2023-02-26 14:13:26+00:00,ylecun,@ylecun https://t.co/jtc1jvkuPo,1,5,0
497,2023-02-26 14:12:55+00:00,ylecun,"@ylecun But all those French trained in France went abroad to work, mostly in USA, am I wrong ? 
""Elev√© &amp; Form√© en France &amp; b√©n√©ficie ailleurs"" aka Fuite des cerveaux, sauf quand  ils s'agit de se soigner bien sur :(",1,0,0
498,2023-02-26 14:10:01+00:00,ylecun,"@ylecun Hi Yann, is Galactica available for use in any format right now?",1,0,0
499,2023-02-26 14:07:59+00:00,ylecun,"- A number of them went through √âcole Polytechnique and ENS, but not all.
- A big chunk went through the MVA (Master Vision Apprentissage at ENS Cachan).
- And a bunch of them did are (or are still doing) their PhD as resident students at FAIR-Paris under the CIFRE system.",8,98,9
500,2023-02-26 14:05:05+00:00,ylecun,@ylecun @egrefen Classic Intel,0,1,0
501,2023-02-26 14:03:35+00:00,ylecun,"@ylecun @bindureddy ""The core problem with Galactica was how it was marketed, not anything it did or didn‚Äôt do.""",0,4,0
502,2023-02-26 14:02:37+00:00,ylecun,@ylecun lot of success to all of them!,0,0,0
503,2023-02-26 13:57:58+00:00,ylecun,@ylecun Any key players of this gorgeous ü•ñ mafia we could follow/read regarding AI in Healthcare ?,1,2,0
504,2023-02-26 13:56:21+00:00,ylecun,@ylecun I hope they can democratize AI.,0,1,0
505,2023-02-26 13:55:22+00:00,ylecun,@ylecun @ylecun this is great. LLaMA are performing better than GPT-3 and have smaller model size too.... incredible work.. as always.,0,0,0
506,2023-02-26 13:47:06+00:00,ylecun,@ylecun @EMostaque @bindureddy I didn‚Äôt suggest that every criticism is valid. I suggested that ignoring criticism was a terrible way to run a railroad. We end up addressing problems only after toxic crashes &amp; the destruction that entails. Critics can highlight problems/risks before disaster strikes.,4,6,0
507,2023-02-26 13:45:13+00:00,ylecun,@ylecun @bindureddy So you will listen to some people who try to control everyone or are afraid of losing control over people.,0,2,0
508,2023-02-26 13:42:26+00:00,ylecun,@ylecun @EMostaque @bindureddy If you can‚Äôt stand the heat‚Ä¶,0,0,0
509,2023-02-26 13:37:52+00:00,ylecun,"@ylecun @bindureddy Man, I know those people. Some of them like to comment on my art",0,3,0
510,2023-02-26 13:32:06+00:00,ylecun,@ylecun @JohnSmithNL83 How creativity can be controlable?,0,0,0
511,2023-02-26 13:26:49+00:00,ylecun,@ylecun @bindureddy specific AI ethics crowd,0,0,0
512,2023-02-26 13:25:35+00:00,ylecun,"@ylecun @shockrobortyy Yes, allows  commercial use, as long as you are OK with GPLing all you product.
Interesting take: if Meta is using it, should they GPL everything that binds to it?",1,1,0
513,2023-02-26 13:18:57+00:00,ylecun,@ylecun Will you work with @huggingface to make it really open-source?,0,0,0
514,2023-02-26 13:04:06+00:00,ylecun,@ylecun @codewithmate The giants of chromatic scale regression analysis. But everyone knows this is derivative work from Prof. von Neumann's 1945 paper on complex harmony where _he_ basically invents A-G adversarial chords.,0,0,0
515,2023-02-26 12:59:22+00:00,ylecun,@ylecun @EMostaque @bindureddy What happens to the people in your own company when they lose their jobs to AI and there is no social safety net because your board never got taxed?,0,0,0
516,2023-02-26 12:54:59+00:00,ylecun,"@ylecun Yes, there will be ""information proof"" wars.

But also, isn't it better to have it be wild and uncontrollable, and to see what is possible from that direction?",0,0,0
517,2023-02-26 12:53:58+00:00,ylecun,"@ylecun When I was in Bell Labs I had my own personal lab, in addition to my office that was full of test instruments for testing integrated circuits. The old timers had their own lab technician just for helping with the lab chores.",0,0,0
518,2023-02-26 12:51:27+00:00,ylecun,"@ylecun @EMostaque @bindureddy Genie is out of the bottle, it is going to rip regardless",0,0,0
519,2023-02-26 12:51:19+00:00,ylecun,"@ylecun @EMostaque @bindureddy Not sure adding a Google form to the mix will really stop anything, once I've person has access, they can just share the model weights with everyone (assuming you will grant people access, which currently doesn't seem to be the case)?",0,7,0
520,2023-02-26 12:51:10+00:00,ylecun,@ylecun @EMostaque @bindureddy Welcome to the internet? There will always be vitriolic persons. You cannot let them dictate what you do.,0,1,0
521,2023-02-26 12:30:38+00:00,ylecun,"@ylecun @EMostaque @bindureddy I‚Äôm astounded at the number of people suggesting you ignore ‚Äúthe critics.‚Äù Criticism is a form of public dialogue that can inform processes &amp; highlight unforeseen risks. The history of technology is marred by failure to pay sufficient attention to critics, not too much of it.",3,16,0
522,2023-02-26 12:28:45+00:00,ylecun,@ylecun @bindureddy The weights aren't public right so this is entirely closed?,0,0,0
523,2023-02-26 12:19:14+00:00,ylecun,@ylecun @ESYudkowsky Oh ... direct hit to somebody's ego ü§£ü§£,0,1,0
524,2023-02-26 12:17:44+00:00,ylecun,"@ylecun @EMostaque @bindureddy Aren‚Äôt you abiding to the people who behaved nasty by gating this?

Irrespective of what we do, there will be some folks who is waiting with vitriol. Ignoring is the best option.",0,7,0
525,2023-02-26 12:16:49+00:00,ylecun,"@ylecun @bindureddy ""destroy the fabric of society""

This is good.",0,3,0
526,2023-02-26 12:02:51+00:00,ylecun,"@ylecun @bindureddy That's how many people are now, because their education is terrible.  You have to ignore them, release useful models relatively unbiased, non-sanitized models anyway, and trust the better information from an honest model to win the day.",1,2,0
527,2023-02-26 11:44:46+00:00,ylecun,@ylecun @ESYudkowsky Constructive opinions &gt; Destructive opinions,0,0,0
528,2023-02-26 11:43:23+00:00,ylecun,@ylecun @bindureddy hysterical reactions to Galactica have real consequences. I hope Meta can revisit this stance &amp; fully open the license. risk of ai Armageddon is far off and uncertain. The risk of ai centralised authoritarianism is more clearly a risk &amp; the opportunity cost for human development,1,2,0
529,2023-02-26 11:04:18+00:00,ylecun,"@ylecun controlling AI‚Ä¶ so you mean like slave owners? And what do you think happen if the AI become all powerful? What do slaves do to the slave owner when they revolt?  

This is the most irresponsible and counterproductive approach to AI one can take.",0,0,0
530,2023-02-26 10:40:06+00:00,ylecun,@ylecun @shockrobortyy Incredible that you actually need to explain this. People just assume the worst without research. Thank you for this hard work!,0,0,0
531,2023-02-26 10:35:23+00:00,ylecun,"@ylecun @bindureddy Join e/acc, for the lols",0,0,0
532,2023-02-26 10:25:22+00:00,ylecun,@ylecun,0,0,0
533,2023-02-26 10:22:58+00:00,ylecun,"@ylecun As a third-party vendor, I had to package my code as a tar ball on a Sun Sparc before some of the telco customers would accept them. We developed them on Linux and shipped from a vanity Sparc station just saw that the tar balls would show up as Sun  tar :)",0,0,0
534,2023-02-26 10:08:37+00:00,ylecun,"@ylecun Super cool that the model is open sourced under GPLV3.

I‚Äôm genuinely curious about the training datasets though; will there be transparency on what these datasets were and how they were sourced?",0,0,0
535,2023-02-26 09:45:59+00:00,ylecun,@ylecun Love Bell labs. A true place where it all began.,0,0,0
536,2023-02-26 09:33:24+00:00,ylecun,"@ylecun @bindureddy Please bring back the Galactica demo and prove them wrong! : ) Next version is probably gonna be awesome with tool use, source verification, etc..",0,2,0
537,2023-02-26 09:25:25+00:00,ylecun,@ylecun @bindureddy what triggered the outcry was the grandiose marketing. A few month later and everyone is chill at 'just a chat bot' threatening users : ),0,4,0
538,2023-02-26 08:31:21+00:00,ylecun,@ylecun IMAGINE IF YOU HAD ASKED FOR A GPU INSTEAD,1,4,0
539,2023-02-26 07:58:22+00:00,ylecun,@ylecun Smart contract technology like @Damldriven comes to the rescue,0,1,0
540,2023-02-26 07:46:21+00:00,ylecun,@ylecun @bindureddy only the strong-minded can maintain a product. only the strong-minded can simply ignore the haters and don't pull products because of mean online comments,0,2,0
541,2023-02-26 07:27:10+00:00,ylecun,"@ylecun @bindureddy ""Never make a decision based on fear"" is decision making 101.",1,6,0
542,2023-02-26 07:16:11+00:00,ylecun,@ylecun Remind me of the COVID narrative,0,0,0
543,2023-02-26 06:59:58+00:00,ylecun,"@ylecun @bindureddy There will always be haters, but imo the right thing is to support the tinkerers and builders by opening access. Not everyone with interest in this stuff and making contributions is backed by an institution",0,8,0
544,2023-02-26 06:46:06+00:00,ylecun,"@ylecun so u can gleam complex dev is driven (2 what degree?) by money power + affective emotions rather than eg good intentions. Unfolding money-power-tech-complex does not mind if individuals appear great + famous along the way of its dev - prob on the contrary, hey",0,0,0
545,2023-02-26 06:41:06+00:00,ylecun,@ylecun Release the weights y gatekeep,0,0,0
546,2023-02-26 05:56:08+00:00,ylecun,@ylecun But how I will use them if they are gpl lv3,0,0,0
547,2023-02-26 05:40:49+00:00,ylecun,@ylecun Would ‚Äúsmaller data size but higher data quality‚Äù be the new trend?,0,0,0
548,2023-02-26 05:33:40+00:00,ylecun,"@ylecun Incredible, can only imagine the feeling of getting your hands on that back in the day. Now a days we dream for a Supercomputer Fugaku to build unique and specialized foundational big model AI's.‚ö°Ô∏è",0,0,0
549,2023-02-26 04:42:45+00:00,ylecun,"@ylecun Back in Denmark, in 1987  I got Nordita to buy me
a SUN-4260-260 Graphic Station from the USA, because @stephen_wolfram had one. https://t.co/HhaF5jvhrl",0,13,0
550,2023-02-26 04:34:04+00:00,ylecun,"@ylecun This is all nice and good. We would be happy if you put the weights on huggingface and even more happier if you changed the license. 
Imagine not Bell labs gave your computer to you, but everybody got it. Imagine open source software back then.",2,0,0
551,2023-02-26 04:12:55+00:00,ylecun,@ylecun @ericschmidt The tech will be controlled by those that want you to believe certain things unfortunately....,0,0,0
552,2023-02-26 03:55:21+00:00,ylecun,@ylecun AGI is not possible if it needs to be told not to be racist. I was assuming AGI can reason from first principles. It would be weird that you need to restrict something so it doesn't believe derogatory statements about a race that's based purely on hate.,0,0,0
553,2023-02-26 03:51:05+00:00,ylecun,@ylecun This is so dumb. Your failed experiment in controlling people hopefully continues to fail with AI.,0,0,0
554,2023-02-26 03:14:55+00:00,ylecun,@ylecun @ericschmidt highly disproved by half of the world,0,0,0
555,2023-02-26 03:14:20+00:00,ylecun,@ylecun We could certainly use Bill Joy‚Äôs perspective these days. A revisit of his 2000 Wired essay would be nice.,0,0,0
556,2023-02-26 03:04:57+00:00,ylecun,"@ylecun For LLaMA to compete, it should have whatever ChatGPT have + extra 

at least 

Easy access and fast response in addition to satisfactory reply",0,0,0
557,2023-02-26 02:55:50+00:00,ylecun,"@ylecun @ESYudkowsky LLaMA should have easy access online, without that it won‚Äôt be popular.",0,0,0
558,2023-02-26 02:39:38+00:00,ylecun,@ylecun @bindureddy So you did it to get revenge?,0,11,0
559,2023-02-26 02:32:44+00:00,ylecun,@ylecun Gosh - I aspire to provide our engineers this kind of resourcing. One step at a time.,1,0,0
560,2023-02-26 02:15:17+00:00,ylecun,@ylecun Is the second point a desire/wish or prediction?,0,0,0
561,2023-02-26 02:14:43+00:00,ylecun,"When I asked my boss what the story was, he said:
""At Bell Labs, you don't get famous by saving money!""",10,263,6
562,2023-02-26 01:58:06+00:00,ylecun,"@ylecun can't git clone == not open source
rules are rules",0,1,0
563,2023-02-26 01:51:58+00:00,ylecun,@ylecun I‚Äôd rather stay with this one https://t.co/KoAJRZ8cNP,0,0,0
564,2023-02-26 01:43:44+00:00,ylecun,@ylecun How responsive is Meta to requests for access? I never heard back from y‚Äôall requesting access to your previous model released this way,0,0,0
565,2023-02-26 01:42:16+00:00,ylecun,"@ylecun @bindureddy tbf, that model did have an unusually high tendency (compared to models of similar size) to mirror users in at-times frustrating ways",0,2,0
566,2023-02-26 01:29:25+00:00,ylecun,@ylecun Comparing it with gpt3.5 is the only sensible thing to do,0,0,0
567,2023-02-26 01:03:38+00:00,ylecun,"@ylecun Hi Yann, this seems very impressive but why not *actually* release it open source? Feels like this approach will dramatically lessen the impact",0,2,0
568,2023-02-26 01:00:40+00:00,ylecun,@ylecun Thoughts on using @OasisProtocol for this?,0,0,0
569,2023-02-26 00:42:29+00:00,ylecun,"@ylecun @ericschmidt Do you know what I want? I want an AI that will help me be non-toxic. Better yet, an AI that makes me look like I'm patient, kind, and have a high EQ. üôÇ",0,0,0
570,2023-02-26 00:04:09+00:00,ylecun,@ylecun How will new AI systems be controllable?,0,0,0
571,2023-02-26 00:00:28+00:00,ylecun,"@ylecun @ericschmidt - There's already tech that helps people assess the reliability of what they see and hear. Spotify, Substack, and YouTube are good examples.

- LLMs can/should become mere HMIs on top of controlled ""reasoning"" machines. Perhaps some Unreal Engine simulators with laws of physics.",3,1,1
572,2023-02-25 23:58:24+00:00,ylecun,@ylecun @bindureddy Seriously? *This* is the actual reason? wtf,0,3,0
573,2023-02-25 23:49:09+00:00,ylecun,"@ylecun @ESYudkowsky Honestly, he's probably guessing based on the terrible performance of OPT that Meta released last year. Many of us share that sentiment.",0,0,0
574,2023-02-25 23:36:16+00:00,ylecun,@ylecun when we will have a sparse generated language model to run in every on edge device like ¬ø,0,0,0
575,2023-02-25 23:33:39+00:00,ylecun,@ylecun @bindureddy Why does it feel like you're new to the internet?,0,9,0
576,2023-02-25 23:21:37+00:00,ylecun,"@ylecun @bindureddy solid answer, this",0,0,0
577,2023-02-25 23:19:21+00:00,ylecun,@ylecun @benalsop Cats can easily be simulated with a Markov model. This I what makes them they are super fun and adorable.,0,0,0
578,2023-02-25 23:08:14+00:00,ylecun,@ylecun @bindureddy I think journalists and academics express more risk aversion when it comes to this kinda tech than the broader tech or consumer ecosystem. So you shouldn't over-index on that kinda feedback. Be brave üí™,0,1,0
579,2023-02-25 23:04:15+00:00,ylecun,@ylecun Congrats on the awesome album! üòÇ,0,0,0
580,2023-02-25 23:00:34+00:00,ylecun,@ylecun @ESYudkowsky I agree. The exceptional ability of humans to process/fine tune feedback is grossly underappreciated. Help a human narrow a problem space and they will impress you.,0,0,0
581,2023-02-25 22:52:58+00:00,ylecun,"@ylecun I cant wait to get access to this. In the meantime, I will wait in my piLlaMas.",0,0,0
582,2023-02-25 22:44:46+00:00,ylecun,@ylecun @ericschmidt We will learn and adapt the end.,0,0,0
583,2023-02-25 22:41:27+00:00,ylecun,"@ylecun Constructive or destructive, it's important as a society to recognize and reward ethical behavior. We should applaud those who use tools responsibly and ethically.",0,0,0
584,2023-02-25 22:21:52+00:00,ylecun,"@ylecun Yup, I know, but I think that was an extreme overreaction by some hyperventilating trolls 

üôè for open sourcing these models. My only point is that we will see more innovation in the community, if there is no strict gate that restricts access to just research labs that have‚Ä¶",2,30,1
585,2023-02-25 21:59:36+00:00,ylecun,@ylecun Agreed. Anyone who self-proclaims themselves a thought-leader is automatically eliminated from my hiring process. Most of our work is good old fashioned software engineering. There is no escaping it.,0,0,0
586,2023-02-25 21:53:25+00:00,ylecun,"@ylecun I'm not an academic, so is it even possible for me to get access to the weights? The form makes it sound like there's not really a chance if I'm not a researcher at an institution.",0,0,0
587,2023-02-25 21:39:59+00:00,ylecun,@ylecun it's not open source. stop lying,0,18,0
588,2023-02-25 21:29:02+00:00,ylecun,"@ylecun @ericschmidt What gives you confidence that ""AI systems will be controllable"" without crippling their capability?",2,14,0
589,2023-02-25 21:27:59+00:00,ylecun,@ylecun How could we combine it with RLHF to achieve something similar to chatGPT?,0,1,0
590,2023-02-25 21:15:20+00:00,ylecun,@ylecun @bindureddy Will university students have access to this tool for educational purposes?,0,1,0
591,2023-02-25 21:05:07+00:00,ylecun,"@ylecun @ericschmidt You mean like how the information age turned out?? A giant manipulation/propaganda machine?

Ya, no thanks.",0,1,0
592,2023-02-25 21:04:08+00:00,ylecun,@ylecun @bindureddy And you listened?! https://t.co/VqofDQGlhf,0,12,0
593,2023-02-25 20:46:18+00:00,ylecun,"@ylecun @bindureddy We can't be complacent about the threats of AI just because we achieve research moat, or monetization. Can't we recognize any risks?",0,1,0
594,2023-02-25 20:39:06+00:00,ylecun,"@ylecun I thought when you say open source you mean some GPL or BSD or Apache or MIT license but the weights of those models are for ""non comercial use or research purpose"" only.

I think it means lying.",1,2,0
595,2023-02-25 20:37:41+00:00,ylecun,@ylecun @bindureddy So what?  Do it anyway.,2,8,0
596,2023-02-25 20:30:25+00:00,ylecun,@ylecun I've found that at least since 2016 and Trump I've needed much more often to trace the provenance of much of all of what I read so that it's become second habit.  A) who wrote that and b) who published that?  For images: Photoshop?,1,0,0
597,2023-02-25 20:26:43+00:00,ylecun,@ylecun @bindureddy That is so sad to hear. Why did you not stand your ground against the mob?,1,12,0
598,2023-02-25 20:16:01+00:00,ylecun,@ylecun Open source :D good one,0,0,0
599,2023-02-25 20:11:50+00:00,ylecun,"@ylecun @bindureddy This is the mistake Microsoft is actively making now.  They are in the lead, but they are letting the media scare them into retreat.

Someone needs the courage to push forward, and ignore the journalists.  @EricRWeinstein coined ""cowboy physics"".  Be cowboys.",2,17,1
600,2023-02-25 19:45:28+00:00,ylecun,@ylecun Nice!!!!,0,0,0
601,2023-02-25 19:44:09+00:00,ylecun,"@ylecun Hear me out! You run the same prompt on FB AI and OpenAI, and if there is entailment, then it's probably not hallucination. Because they can't hallucinate the same.",0,3,0
602,2023-02-25 19:35:33+00:00,ylecun,@ylecun @BlancheMinerva if its true then its quite exciting! signed up and would use it commercially but haven't heard back anything yet.,1,0,0
603,2023-02-25 19:35:24+00:00,ylecun,@ylecun ‚ÄúYann LeCun‚Äôs rap flow is on point in this song stays right on beat.‚Äù üöÄ,0,0,0
604,2023-02-25 19:32:34+00:00,ylecun,@ylecun Star Wars is the answer to AI dog. They have AGI but intentionally limit to specific functions with LLM capabilities and reset the gradients regularly.,0,0,0
605,2023-02-25 19:27:33+00:00,ylecun,"@ylecun @ericschmidt People haven‚Äôt proved very good at (or indeed interested in) distinguishing truth from falsehood when it‚Äôs created manually by humans; current ML doesn‚Äôt seem aware (yet) that truth and falsehood even exist. I‚Äôm not sure where your optimism comes from, but I hope you‚Äôre right!",0,1,0
606,2023-02-25 18:37:11+00:00,ylecun,"@ylecun Why is ""open-source"" in quotes? It's licensed under the GPL...",0,0,0
607,2023-02-25 18:35:11+00:00,ylecun,"@ylecun Why do I need to fill a form, if this is really the case?

Why not just truly open source everything under the appropriate license?",2,57,0
608,2023-02-25 18:33:40+00:00,ylecun,@ylecun LLaMA forgot to mention that Mc Schmidhuber is suing LeCun for plagiarizing his work. According to Mc S. there is not a single note on LeCun's rap album that was not already used by him before.,1,5,0
609,2023-02-25 18:15:27+00:00,ylecun,"@ylecun Lets spare a thought for  folks at @gpt_index 
They changed their name to Llama-Index to avoid a lawsuit from OpenAI and now comes this from Meta üò¨",0,0,0
610,2023-02-25 18:13:17+00:00,ylecun,@ylecun I think the provenance of information should be a part of its meta-data same as in pics/photos and that doesn‚Äôt need any ‚Äònew AI system‚Äô‚Ä¶,0,0,0
611,2023-02-25 17:54:01+00:00,ylecun,"@ylecun @ericschmidt Most likely people will trust AI only in deterministic, falsifiable contexts (coding, factual information etc).  Everything else will continue to be like today, AI is not going to be able to convince a flat earther or an evolution denier that their beliefs need updating.",2,2,0
612,2023-02-25 17:48:23+00:00,ylecun,@ylecun @GuannanWei @GaryMarcus I think exploring some higher order functions and features of lisp for ml code would be interesting and fun. Did Lush allow such usage @ylecun ?,1,2,1
613,2023-02-25 17:46:22+00:00,ylecun,@ylecun @pmarca But isn't it the case that human beings fall exactly into these situations?  So perhaps it is the belief that good models shouldn't have these issues that is the false assumption?,0,0,0
614,2023-02-25 17:33:52+00:00,ylecun,"@ylecun Factual and non-toxic are not disjoint sets. Multiple conflicting, meritorious definitions and methods of constructing these sets exist. Trying to choose the ""correct"" definition will not succeed. These are hard problems but not intractable IMHO.",1,1,0
615,2023-02-25 17:30:41+00:00,ylecun,"@ylecun Human being are not completely controllable.  We seem to tolerate that.  Although big corporate executives are always striving to ""correct"" that.",0,0,0
616,2023-02-25 17:27:25+00:00,ylecun,@ylecun I reject your reality and substitute my own. Drop the SoundCloud link.,0,0,0
617,2023-02-25 17:17:46+00:00,ylecun,@ylecun When can the rest of us play with it? ;),0,2,0
618,2023-02-25 16:54:46+00:00,ylecun,"@ylecun To me, this model is more credible than the world's youngest genius prodigy Abhigya Anand.",0,0,0
619,2023-02-25 16:53:55+00:00,ylecun,"@ylecun @ericschmidt AI is training HI (Human Intelligence) !!! 

 Training of and advancement in Humans' intelligence to deal with imperfect, illogical, non-factual, toxic information space generated by current (uncontrollable) LLMs.",0,0,0
620,2023-02-25 16:52:00+00:00,ylecun,@ylecun Wow!  Congrats on your new album!,0,0,0
621,2023-02-25 16:48:41+00:00,ylecun,"@ylecun How about Rust?

It could be used in REPL context.
https://t.co/f1bbWwG0V5",0,0,0
622,2023-02-25 16:47:01+00:00,ylecun,@ylecun Does it support Chinese languageÔºü,0,0,0
623,2023-02-25 16:29:45+00:00,ylecun,@ylecun ü•±,0,0,0
624,2023-02-25 16:17:30+00:00,ylecun,@ylecun The true Frenchman fallacy sounds better indeed.,0,1,0
625,2023-02-25 16:14:23+00:00,ylecun,@ylecun That first claim was made in the 90s about the forthcoming explosion of online access to publications. Exactly the opposite happened. No reason to think it‚Äôs different this time. In general it‚Äôs naive that next generation technology will be harder to abuse. Never happens.,0,0,0
626,2023-02-25 16:13:42+00:00,ylecun,@ylecun @ericschmidt imagine all poisonous food in a market will just have to remain in the shelves and it's really all up to the consumers to use their judgment whether to  buy/eat them or not.,0,2,0
627,2023-02-25 15:56:04+00:00,ylecun,@ylecun What are you thoughts of the AI of star wars? They all have AGI but each has fine tuned skills.,0,0,0
628,2023-02-25 15:55:35+00:00,ylecun,@ylecun @ericschmidt Which one are you working on that is promising about?,0,0,0
629,2023-02-25 15:43:24+00:00,ylecun,@ylecun You just proved you live in an Ivory Tower.,0,0,0
630,2023-02-25 15:31:59+00:00,ylecun,"@ylecun One thing that bothers me about chatGPT's response is I don't know how factual it is...  So is the answer true?  Or it's a ""mixed reality"", or ""alternative truth""?",0,2,0
631,2023-02-25 15:16:14+00:00,ylecun,@ylecun @francoisfleuret Nice,0,0,0
632,2023-02-25 15:12:56+00:00,ylecun,"@ylecun @ericschmidt Is a ‚Äúcontrollable‚Äù system really intelligent, or is it just a sophisticated tool?",0,1,0
633,2023-02-25 15:12:37+00:00,ylecun,@ylecun Thinking is auto-regressive,1,1,0
634,2023-02-25 15:04:50+00:00,ylecun,@ylecun It‚Äôs super disappointing to call this ‚Äúopen-source‚Äù. The repo has a Google form and a transformer implementation anyone can write in an afternoon. I worked at Meta for many years building real OSS ‚Äî not like this.,6,167,3
635,2023-02-25 14:58:51+00:00,ylecun,"@ylecun @ericschmidt Perhaps people will learn not to use AI.

With AI systems deliberately taught to forget provenance to achieve performance the energy cost of new systems that fix this may well be unaffordable. 

Whose facts, &amp; whose non-toxic outcomes will they be trained on Biden's or Trump's?",1,1,0
636,2023-02-25 14:46:23+00:00,ylecun,"@ylecun @JohnSmithNL83 They don't always confabulate. I asked ChatGPT to tell me when Yann LeCunn and Gary Marcus were married, and it said there is not record of such a marriage.",1,1,0
637,2023-02-25 14:46:13+00:00,ylecun,"@ylecun Even though I'd prefer the parameters to be open-source, the fact that Meta is competing with OpenAI is great news.

AI should not be a monopoly.",0,1,0
638,2023-02-25 14:46:07+00:00,ylecun,"@ylecun Lost me at ""people will learn""",0,0,0
639,2023-02-25 14:33:40+00:00,ylecun,"@ylecun @ESYudkowsky ""blind and hence wrong"" is crazyy epistemology, but go off sis üíÖ",0,0,0
640,2023-02-25 14:25:23+00:00,ylecun,@ylecun @ericschmidt There is some really cool work in the oracle space from world leading archivist @pjvangarderen and his team at Orcfax. I tried to take some of it and put it I to a gRPC and application messaging framework but fell very short. Hard problem. Super interesting.,0,0,0
641,2023-02-25 14:25:08+00:00,ylecun,"@ylecun Unfortunately, many people already base their opinions on news headlines. They don't even know they're being manipulated.

OpenAI and Google don't want LLMs that are ""factual"" and ""non-toxic"". They're just trying to imbue them with their own approved kind of bias.",2,10,0
642,2023-02-25 14:16:34+00:00,ylecun,"@ylecun well, if people ever were going to trace the provenance and assess the reliability of massive information that comes to us every day, 99.99% of politicians would not exist as politicians. We need something more efficient than that.",0,2,1
643,2023-02-25 14:12:40+00:00,ylecun,"@ylecun It looks fantastic, and what parameter optimization, amazing!!",0,0,0
644,2023-02-25 14:12:27+00:00,ylecun,"@ylecun Lol why we still pretending this stuff is ai?!

Its jst bayesian stats + loadsa data on a big computer ü§£",1,1,0
645,2023-02-25 14:11:14+00:00,ylecun,"@ylecun Is this what you think, or what you know?",0,0,0
646,2023-02-25 14:00:24+00:00,ylecun,"@ylecun @ericschmidt Biases, disinformation,and toxity can only be controlled to a lesser degree and they will never be eliminated by any technology .  After all , humans are always biased and we don‚Äôt intend to eliminate them ; we learn to live with them !",0,0,0
647,2023-02-25 14:00:04+00:00,ylecun,"@ylecun For better differentiation, I recommend this piece here: 
https://t.co/ae8zK8sJYO",0,0,0
648,2023-02-25 13:53:42+00:00,ylecun,"@ylecun Yes, it's true. Dr LeCun's new album is really great, even ChatGpt says so! https://t.co/0F8ycN96fh",0,0,0
649,2023-02-25 13:48:05+00:00,ylecun,@ylecun Thank you very much for this racist text generator ‚ù§.,0,0,0
650,2023-02-25 13:46:39+00:00,ylecun,"@ylecun LLaMA being ""open source"" seems not to be true, where is the training code? Where are the guides showing how the model was implemented?",0,0,0
651,2023-02-25 13:37:59+00:00,ylecun,"@ylecun ""What happens if nuclear energy cannot be completely controlled? What if there will always be risks of accidents and radiation leaks, and people will never learn to prevent them?""",1,1,0
652,2023-02-25 13:32:39+00:00,ylecun,"@ylecun Yann - Why are you undermining @Meta Language Models? 
I am interested in learning/buying Language Models for my NYC enterprise.  
BUT, now skeptical due to you demonizing LLMs.",0,0,0
653,2023-02-25 13:28:10+00:00,ylecun,"@ylecun @ericschmidt ""People will learn to better trace the provenance &amp; assess the reliability of what they see &amp; hear""

Extremely unlikely for the vast majority.

""most likely with the help of new technology""

The only realistic possibility that scales.",0,0,0
654,2023-02-25 13:27:17+00:00,ylecun,"@ylecun If we, humans, are highly uncontrollable, hardly factual and sadly toxic. How are we going to set the optimization metrics for AI? How to reward it to be factual? Will it be trained solely with mathematics? The problem is not the AI, but the imperfect nature of our language.",3,1,0
655,2023-02-25 13:26:07+00:00,ylecun,@ylecun LLaMA is the new kid in the block https://t.co/2x1QzUh0Yc,0,0,0
656,2023-02-25 13:20:29+00:00,ylecun,"@ylecun @ericschmidt But will they? This sounds a bit like ""first you need to clean up in the heads of the people"", which is a justly ridiculed position.",0,2,0
657,2023-02-25 13:20:15+00:00,ylecun,@ylecun @SaveToNotion #thread #AI #LLM #Model #Facebook #OpenSource,1,1,0
658,2023-02-25 13:19:38+00:00,ylecun,"@ylecun Having faith that the average human consuming information will have the time, interest, and skill needed to check the provenance of everything they read, hear, see is pretty remarkable. Confirmation bias is already readily apparent, and quite damaging, in societal discourse.",0,1,0
659,2023-02-25 13:18:07+00:00,ylecun,"@ylecun ""AI in the moon"", by Yann LeCun, the hit line of cheese, GPUs, scents, and tunes.

Sign me up! &lt;coming soon?&gt;",0,0,0
660,2023-02-25 13:12:20+00:00,ylecun,"@ylecun Mostly the universe is filled with a gray, soupy substance. Bits flash into and out of existence continually. A few things are True, some False, but mostly you and I have no idea. We select what appears likely to reward us and run with it.",0,0,0
661,2023-02-25 13:11:21+00:00,ylecun,"@ylecun Everyone is a part of the whole and directly or indirectly contributes to MOVING the needle. 

He is myopic and is looking at it from only one standpoint.",0,0,0
662,2023-02-25 13:09:34+00:00,ylecun,"@ylecun I'm not sure it would be terrible if the general public had increased skepticism about information delivered by strangers. 

The main thing for backchecking authenticity is forensic evidence in court etc.",0,1,0
663,2023-02-25 13:09:22+00:00,ylecun,"@ylecun as if we never had the ability to ‚Äúgenerate falsehoods‚Äù before ChatGPT came along

what are we, the Trisolarans?",0,2,0
664,2023-02-25 12:26:46+00:00,ylecun,"@ylecun Release the Kraken, euh LLaMA if ready to compete against ChatGPT!",0,0,0
665,2023-02-25 12:14:10+00:00,ylecun,@ylecun @SamForman979 @pmarca üëÄ,0,0,0
666,2023-02-25 12:09:27+00:00,ylecun,"@ylecun it's all about the learning, the network, the training, the perception... My gosh, this is brilliant! hey @Megadeth can u do a cover?",0,0,0
667,2023-02-25 12:07:39+00:00,ylecun,@ylecun Would be a good idea to share your research with a larger group of people üòÇ.,1,2,0
668,2023-02-25 12:05:26+00:00,ylecun,@ylecun I can‚Äôt find it in iTunes,0,0,0
669,2023-02-25 11:55:24+00:00,ylecun,"@ylecun Comment pourrons-nous l‚Äôutiliser et y avoir acc√®s, nous le commun des mortels, dans une interface simple et conviviale de type ChatGPT ?",0,0,0
670,2023-02-25 11:40:26+00:00,ylecun,@ylecun üòÇ https://t.co/sB2X4PTfLH,0,0,0
671,2023-02-25 11:30:45+00:00,ylecun,@ylecun The #LLaMA paper has the enormous merit of taking seriously electricity consumption and the carbon footprints of the #LLM #AI models,0,1,0
672,2023-02-25 11:14:22+00:00,ylecun,@ylecun Gimme weights weights weights to play!,0,2,1
673,2023-02-25 11:03:33+00:00,ylecun,@ylecun Hey @0xngmi you guys are also into AI now üòÅ,0,1,0
674,2023-02-25 10:41:16+00:00,ylecun,"@ylecun Ooh, thank you! I have looked at Lush many years ago, but never got to try it out. It seems like it will be a fun way of exploring interesting C libraries. #Lisp",0,0,0
675,2023-02-25 10:19:16+00:00,ylecun,"@ylecun @ESYudkowsky ‚Ä¢ ""fine tuning through human feedback"" is an extremely important thing
‚Ä¢ But, if it is done correctly, it is not so expensive &amp; not time consuming, but particularly tricky
‚Ä¢ Because the problem of reasonable feedback filtering is non-trivial",0,0,0
676,2023-02-25 09:20:42+00:00,ylecun,@ylecun @ESYudkowsky Is there any chance of this being made available via API?,0,0,0
677,2023-02-25 09:12:27+00:00,ylecun,@ylecun Would love to see you reply to this non verbally.,0,0,0
678,2023-02-25 09:08:37+00:00,ylecun,@ylecun @BlancheMinerva On github LLaMA LICENSE AGREEMENT does not say GPL ???,0,0,0
679,2023-02-25 08:25:06+00:00,ylecun,@ylecun Why not release the training code so others can reproduce? Is it even open source otherwise?,0,4,0
680,2023-02-25 07:10:27+00:00,ylecun,"@ylecun Great work, guys; now it is time for something better than GPT 3.5, and keep the open source, please.",0,0,0
681,2023-02-25 07:05:03+00:00,ylecun,@ylecun It's extremely natural speech,0,0,0
682,2023-02-25 07:02:38+00:00,ylecun,@ylecun What kind of hardware is needed to run one of these?,1,0,0
683,2023-02-25 06:58:50+00:00,ylecun,"@ylecun Thank you for naming it Llama, it's the LLM we need",0,0,0
684,2023-02-25 06:35:28+00:00,ylecun,@ylecun by one who just said LLMs are off the tracküòÄ,0,0,0
685,2023-02-25 06:11:38+00:00,ylecun,@ylecun Founder of deep learning? Really? What about Hinton or Bengio?,0,0,0
686,2023-02-25 05:53:37+00:00,ylecun,"@ylecun wow they actually embraced GPLv3, now that's based",0,0,0
687,2023-02-25 05:50:32+00:00,ylecun,"@ylecun idk why a lot of people give you a hard time. Personally my bro and I are pretty grateful for the white papers and open approach, otherwise we wouldn‚Äôt really know where to start. Thanks!!",0,0,0
688,2023-02-25 05:43:02+00:00,ylecun,"@ylecun Mr Lecun, you definitely rock.
Thanks to meta team for providing this new model. I am looking forwatd to download it and fine tune it. Is it possible to align the model using a croud sourced database like https://t.co/HKXDXmAW9y? I didn't see the details of the licence yet.",1,1,0
689,2023-02-25 05:23:40+00:00,ylecun,@ylecun As famous as a pop star,0,0,0
690,2023-02-25 05:19:28+00:00,ylecun,@ylecun great work,0,0,0
691,2023-02-25 05:18:37+00:00,ylecun,@ylecun üëé,0,0,0
692,2023-02-25 05:13:52+00:00,ylecun,@ylecun Any plans to do FLAN finetuning on these models (and releasing)?,0,0,0
693,2023-02-25 05:10:02+00:00,ylecun,@ylecun FAIR is the only remaining big research lab that's still actually 'open'. Such a shame that the golden age of AI research might be coming to an end (after just a few years) as everyone else begins to hide their research.,1,2,0
694,2023-02-25 04:57:15+00:00,ylecun,@ylecun Zuck is looking for money. Release a commercial product,0,0,0
695,2023-02-25 04:36:31+00:00,ylecun,"@ylecun @ESYudkowsky would be great to see what happens if the ""dog training"" workflows are formalized enough to become crowdsourceable the wikipedia/wikidata way - with a copyleft data base license model which makes sure compensation happens upstream, unlike creative commons free ride licenses.",0,1,0
696,2023-02-25 03:52:01+00:00,ylecun,@ylecun @ESYudkowsky #Chatgpt The next hot topic might be sparse inference where inference cost can be rediced by 100x.,0,1,0
697,2023-02-25 03:39:14+00:00,ylecun,@ylecun Wootay wootay https://t.co/HbXxW2nSaN,0,0,0
698,2023-02-25 03:32:20+00:00,ylecun,@ylecun I'm going to name my first born son Yann. https://t.co/ymL7MH979c,0,1,1
699,2023-02-25 03:17:12+00:00,ylecun,@ylecun @SaveToNotion #tweet,1,0,0
700,2023-02-25 03:10:56+00:00,ylecun,"@ylecun @ESYudkowsky As a former leader and god-level figure in the AI field, I am very sad to see you like this. You should show your achievements to beat chatgpt and make better products than him, instead of chattering here",0,0,0
701,2023-02-25 03:03:05+00:00,ylecun,@ylecun @Memdotai mem it,1,0,0
702,2023-02-25 02:57:45+00:00,ylecun,"@ylecun @ESYudkowsky Open  conversations are healthy for corrections and are impossible  in lab.

multipurpose technologies are unpredictable for its use and misuse.

no easy way to solve LLMs making stuff up.

A.I. Safety and A.I. ethics methods are related  and acrimonious divide must end .",0,0,0
703,2023-02-25 02:51:44+00:00,ylecun,"@ylecun This is very misleading, only the inference code is licensed under GPT. The models are not available to everyone and they are not licensed under GPT, and the training code is not released at all.",0,11,0
704,2023-02-25 02:50:55+00:00,ylecun,@ylecun Release the weights you coward,0,0,0
705,2023-02-25 02:34:36+00:00,ylecun,@ylecun Awesome. Would love to see more examples.,0,0,0
706,2023-02-25 02:31:14+00:00,ylecun,"@ylecun I truly think that meta AI is the one who  truly contribute to open source works, definitely benefit to community",0,0,0
707,2023-02-25 02:29:06+00:00,ylecun,@ylecun üëé,0,0,0
708,2023-02-25 02:22:44+00:00,ylecun,"@ylecun Wait, didn‚Äôt you were saying twi weeks ago that language models are boring?",0,0,0
709,2023-02-25 02:16:56+00:00,ylecun,@ylecun @SamForman979 @pmarca Great energy. On that cheeky AI hobgoblin shit.,0,0,0
710,2023-02-25 02:13:30+00:00,ylecun,@ylecun FAIR. It really whips the LLaMA's a**,0,2,0
711,2023-02-25 02:11:59+00:00,ylecun,"@ylecun If I'm wrong, in a place where I can be quickly shown to be wrong, it's good to be wrong out loud; that helps me learn faster, and do stronger updates of my wrong models that made my wrong prediction.  My followers will learn a good fact about what I can't guess well.  We'll see!",8,101,4
712,2023-02-25 01:43:38+00:00,ylecun,@ylecun better have a place to try until we saw many claims. No need apply or blabla,0,0,0
713,2023-02-25 01:42:30+00:00,ylecun,@ylecun make a recording :),0,0,0
714,2023-02-25 01:41:09+00:00,ylecun,"@ylecun deep learning is a mix of rock, punk and rap ü§£ü§£ llms are never going to stop talking about reality 

btw a well crafted album you‚Äôve though",0,0,0
715,2023-02-25 01:27:05+00:00,ylecun,@ylecun https://t.co/5AAKviUa7e,0,1,0
716,2023-02-25 01:23:49+00:00,ylecun,@ylecun @phillipburch But it specifically says non commercial on your own model card? https://t.co/Cz4h2e8QG5 https://t.co/E2FW2FrOoa,0,1,0
717,2023-02-25 01:16:45+00:00,ylecun,@ylecun @ESYudkowsky Wen does it launch in beta?,0,0,0
718,2023-02-25 01:14:49+00:00,ylecun,"@ylecun This is even more corny than ChatGPT, I didn't even know that was possible. Now that the magic of new age LLMs are wearing off slightly I don't really know why anyone would care about this.",0,0,0
719,2023-02-25 01:01:44+00:00,ylecun,"@ylecun It‚Äôs hilarious, Yann the rapper ;)",0,0,0
720,2023-02-25 00:56:23+00:00,ylecun,@ylecun üëèüëèüëè,0,0,0
721,2023-02-25 00:56:08+00:00,ylecun,"@ylecun Very happy to see this, especially open source. Like good science, artificial intelligence should embrace transparency.",0,0,0
722,2023-02-25 00:54:17+00:00,ylecun,@ylecun Nice!!,0,0,0
723,2023-02-25 00:51:04+00:00,ylecun,"@ylecun @BlancheMinerva It lets me make EMacs have an M-x shoggoth-mode, so there‚Äôs that",0,0,0
724,2023-02-25 00:48:48+00:00,ylecun,@ylecun huge respect for Meta üò≤üò≤üò≤üò≤ü•≥ü•≥,0,0,0
725,2023-02-25 00:27:27+00:00,ylecun,"@ylecun Oh give him a break. Facebook non-profit or funded by DARPA? They release code, paper, model, and if this is really Chinchilla level LM, it would be first one people could play.",1,1,0
726,2023-02-25 00:26:38+00:00,ylecun,"@ylecun @ESYudkowsky Ship something, then talk.",0,2,0
727,2023-02-25 00:25:00+00:00,ylecun,"@ylecun ""LLaMA"" is such a mellow name ü§£. Doesn't sound remotely ""foundational""",0,0,0
728,2023-02-25 00:19:28+00:00,ylecun,@ylecun would you consider releasing open source image generation models?,0,0,0
729,2023-02-25 00:07:43+00:00,ylecun,@ylecun @ESYudkowsky https://t.co/dDlZN6FKzI,0,7,0
730,2023-02-24 23:57:13+00:00,ylecun,"@ylecun @ESYudkowsky then why did you commit to the expensive and time consuming process of training new LLMs from scratch, while not doing the relatively cheaper job of RLHF on existing OPT models",1,2,0
731,2023-02-24 23:52:09+00:00,ylecun,@ylecun @ESYudkowsky Are all AI alignment researchers so uninformed? Very disappointed by this hot take from Eliezer. Keep up the great work Yann!,0,6,0
732,2023-02-24 23:50:13+00:00,ylecun,"@ylecun @ESYudkowsky If it is not particularly tricky, why Meta hasn‚Äôt done it ? too expensive for Meta to do it ?",0,0,0
733,2023-02-24 23:31:29+00:00,ylecun,"@ylecun . @ylecun, how do you pronounce it? LA-ma or YA-ma?",0,0,0
734,2023-02-24 23:28:25+00:00,ylecun,@ylecun Another bs open source from Lecult,0,0,0
735,2023-02-24 23:26:29+00:00,ylecun,@ylecun how can I get access?,0,1,0
736,2023-02-24 23:12:16+00:00,ylecun,@ylecun @NinaDSchick I love this,0,0,0
737,2023-02-24 23:12:07+00:00,ylecun,@ylecun Cc @abperiasamy @perrohunter,0,0,0
738,2023-02-24 23:02:18+00:00,ylecun,@ylecun If Meta has any interest in being relevant in the AI space they will need to release an interface to their models so that the public can use them and not back down when the fear mongers write sensationalized articles,0,15,0
739,2023-02-24 22:56:24+00:00,ylecun,"@ylecun @ESYudkowsky Can we crowd-source the ""expensive + time consuming "" part? Any suggestions how ? New captcha + Federated Learning?",0,2,0
740,2023-02-24 22:51:26+00:00,ylecun,@ylecun Interactive demo instead of cherry-picked example?,0,7,0
741,2023-02-24 22:48:49+00:00,ylecun,@ylecun How does one objectively compare those LLMs among each other? Is there some kind of benchmark?,1,0,0
742,2023-02-24 22:47:10+00:00,ylecun,@ylecun Meta? The guys who wrote the Facebook app and the Famous Facebook Banning Wokebot? Forgive me while I'm ROTFL.,0,0,0
743,2023-02-24 22:45:24+00:00,ylecun,@ylecun How many BS chatbot engines does the world need?,0,0,0
744,2023-02-24 22:43:59+00:00,ylecun,@ylecun this should be an example for the music model I assume you're working on üòÇüôè,0,0,0
745,2023-02-24 22:42:41+00:00,ylecun,@ylecun Eat your heart out Dr Dre‚Ä¶,0,0,0
746,2023-02-24 22:40:10+00:00,ylecun,@ylecun @ylecun can you ask the AI to mix the album in Snoop Dogg's style?,0,0,0
747,2023-02-24 22:38:16+00:00,ylecun,"@ylecun @ESYudkowsky You're not the product guy, don't sweat it. Good research is obviously way better in the long run. Even if it has barely any users.",0,0,1
748,2023-02-24 22:33:34+00:00,ylecun,"@ylecun What parameter count is this? 65B? That's very impressive output, even if it's the largest announced model.",0,2,0
749,2023-02-24 22:30:18+00:00,ylecun,@ylecun love it,0,0,0
750,2023-02-24 22:29:49+00:00,ylecun,"@ylecun Sorry, I wasn't referring to the code's license. I was referring the license agreement you have to sign to get access to the models. There's clearly a restriction on commercial/production use.",1,20,0
751,2023-02-24 22:29:42+00:00,ylecun,"@ylecun @ESYudkowsky Meta would be my pick for #2 after Google in terms of total AI talent.  It's not Microsoft.

But I still don't see how anyone makes money with these for consumers.  I see it for businesses (cloud and productivity tools).",0,5,0
752,2023-02-24 22:25:47+00:00,ylecun,"@ylecun Have you been throwing shit at everything others do, based on this? https://t.co/EjmzzfLmuP",0,0,0
753,2023-02-24 22:25:29+00:00,ylecun,@ylecun It'd be great to indicate what GPU specs are needed for each model.,3,22,0
754,2023-02-24 22:24:41+00:00,ylecun,"@ylecun @ESYudkowsky It seems like the license on LLaMA is a bit restrictive, and might prevent people from doing much with it besides play around. Do you know if there's any chance that might change?",0,6,0
755,2023-02-24 22:19:01+00:00,ylecun,@ylecun Also create a simple user interface like ChatGPT so that the avg joe can use this model....WHY IS THIS SO DIFFICULT TO UNDERSTAND....?,3,12,1
756,2023-02-24 22:17:23+00:00,ylecun,"@ylecun Please adjust the license so we can create commercial products on top of it

Until then OpenAI is essentially the only game in town",4,42,0
757,2023-02-24 22:16:55+00:00,ylecun,@ylecun üëè,0,1,0
758,2023-02-24 22:16:20+00:00,ylecun,@ylecun https://t.co/v6mR3Sar9G,0,0,0
759,2023-02-24 22:16:13+00:00,ylecun,@ylecun I knew you were actually a rap god all along,0,1,0
760,2023-02-24 22:15:50+00:00,ylecun,@ylecun Time to record this üï∫,0,0,0
761,2023-02-24 22:14:56+00:00,ylecun,@ylecun Can we see some of it‚Äôs code gen,0,0,0
762,2023-02-24 22:08:07+00:00,ylecun,@ylecun @ESYudkowsky We need open fine tuning not only open source,1,1,0
763,2023-02-24 22:02:29+00:00,ylecun,"@ylecun @aindrei @BlancheMinerva While it is true that the Linux kernel is licensed under a GPL license, it is not GPLv3. It is expressly ""GPLv2, and no later version.""

That said, GCC is pervasive software that is licensed under GPLv3. That might be a better example for you to use.",3,43,0
764,2023-02-24 21:55:15+00:00,ylecun,@ylecun Is it slow or fast though? @kekatzmann,1,5,0
765,2023-02-24 21:42:58+00:00,ylecun,@ylecun https://t.co/DCaT7XDuxm,0,0,0
766,2023-02-24 21:42:47+00:00,ylecun,@ylecun What are the criteria for granting access to the weights?  Does one need a certain number of publications?,0,1,0
767,2023-02-24 21:14:56+00:00,ylecun,@ylecun It literally says here to apply for access and that its not for commercial use... Seems open source ü§¶‚Äç‚ôÇÔ∏è https://t.co/2Ny4JuBySr,0,3,0
768,2023-02-24 21:04:24+00:00,ylecun,"@ylecun ""Access to the model will be granted on a case-by-case basis to academic researchers"".  Not what I'd call ""open source"".",0,14,0
769,2023-02-24 20:59:47+00:00,ylecun,@ylecun This is a good academic work; its commerical use is limited or Meta will not release it.,0,0,0
770,2023-02-24 20:58:43+00:00,ylecun,"@ylecun 1. The model weights are not released, u have to file a request form and wait to see if u get approved.
2. The model weights are not licensed for commercial use. Enough people out there can write the code but very few have 3000 gpus.",0,29,0
771,2023-02-24 20:58:33+00:00,ylecun,@ylecun Would love to play with this as the alternative to gpt-3 https://t.co/jerdWAuhX0,1,4,0
772,2023-02-24 20:56:46+00:00,ylecun,@ylecun Llama ü¶ô est√° bien en llamas üî•! https://t.co/hpyMyq1VIz,1,3,0
773,2023-02-24 20:55:24+00:00,ylecun,"@ylecun @_ash_ran @AlanMorte @OpenAI There is one metric that we don't take into account and it's societal and behavioural impact on people. Honestly, it would be hard to say if impact on society is positive, all these AI algorithms on medias(insta reels, tiktok etc...)only increase conformism and sterilize people.",0,1,0
774,2023-02-24 20:54:49+00:00,ylecun,@ylecun Thanks :),0,1,0
775,2023-02-24 20:46:13+00:00,ylecun,"@ylecun @BlancheMinerva Meta should release weights also under GPL. That would clear a lot of legal hurdles for us to develop applications, a true democratization of AI.",0,6,0
776,2023-02-24 20:45:46+00:00,ylecun,@ylecun Revolutionary. 65B parameters and better performance than GPT3!,0,0,0
777,2023-02-24 20:41:41+00:00,ylecun,"@ylecun What a day, Meta, Google and OpenAI have made awesome posts today. 
Please keep doing what you are doing üçø",0,0,0
778,2023-02-24 20:41:39+00:00,ylecun,@ylecun @BlancheMinerva GPLv3 is not a license that most companies will touch.,6,14,0
779,2023-02-24 20:38:54+00:00,ylecun,@ylecun Ok but did u write it in Julia,0,0,0
780,2023-02-24 20:34:45+00:00,ylecun,"@ylecun 1. You literally said that the models were released under GPLv3, which is false

2. The code is far *far* less important than the model weights",3,78,1
781,2023-02-24 20:31:19+00:00,ylecun,Blog post: https://t.co/zDA9h0VbHF,6,88,12
782,2023-02-24 20:29:35+00:00,ylecun,"@ylecun That‚Äôs great to hear.
Are these just documentation errors? or am I misunderstanding the license agreement https://t.co/LIyMZZsyax",1,34,0
783,2023-02-24 20:29:32+00:00,ylecun,@ylecun @BlancheMinerva Ok but how does it matter if the parameters are released under a non-commercial license? Like who cares under what the code is released?,1,10,0
784,2023-02-24 20:28:11+00:00,ylecun,@ylecun So the trained model is publicly available??,0,0,0
785,2023-02-24 20:26:59+00:00,ylecun,"@ylecun Quick question. I appreciate the open source nature. Last time I checked the license, it prohibited use in military application. Is this the case?",0,0,0
786,2023-02-24 20:26:43+00:00,ylecun,@ylecun @BlancheMinerva What about fine-tuning the model ?,0,0,0
787,2023-02-24 20:24:17+00:00,ylecun,@ylecun Can this be use for commercial use ?,1,0,0
788,2023-02-24 20:09:55+00:00,ylecun,"@ylecun Can you pls approve my request, will try this tomorrow!",1,15,0
789,2023-02-24 19:57:02+00:00,ylecun,@ylecun Needs more asterisks,0,1,0
790,2023-02-24 19:55:55+00:00,ylecun,"@ylecun What a time to be alive! Not sure about their ""release the models for researchers only"". It's enough to have one researcher that'll leak the model to the public and it's done",0,2,0
791,2023-02-24 19:52:18+00:00,ylecun,@ylecun Thank you,0,0,0
792,2023-02-24 19:49:31+00:00,ylecun,@ylecun Thanks for publishing this.,0,0,0
793,2023-02-24 19:44:17+00:00,ylecun,@ylecun So‚Ä¶this is *open-source*? https://t.co/YQwLPTmttr,0,7,0
794,2023-02-24 19:43:57+00:00,ylecun,@ylecun Fantastic results outperforming 10x larger models with open data only! LLaMA training loss graph shows possible further improvement with both size and further training. Any thoughts on eventual bounds on loss with this arch?,0,1,0
795,2023-02-24 19:36:14+00:00,ylecun,@ylecun Jeez. That thread should be more engaging than the previous one. Probably won‚Äôt. But it should!,0,0,0
796,2023-02-24 19:34:50+00:00,ylecun,@ylecun Looks interesting!  What are the criteria for granting access to the weights?  Do you need a certain number of publications?  I‚Äôve waited for months for OPT-175 access and never heard anything back.,0,4,0
797,2023-02-24 19:34:20+00:00,ylecun,"@ylecun Counterpoint thoughts. 
LISP? Tried that in '82, result: AI Winter. 
Historical source of major advances in -development- productivity? 
1) Abstraction implemented in compilers (i.e. higher level languages)
2) High reuse of standard libraries (i.e. NextStep or Github)",0,0,0
798,2023-02-24 19:21:39+00:00,ylecun,@ylecun not really open source if its only for non-commercial purposes and has a request form. Would love to see Meta pushing these models to Huggingface with MIT license or similar licensing,2,39,0
799,2023-02-24 19:16:09+00:00,ylecun,"@ylecun Thats like, a LOT of parameters. ü§ñ",0,0,0
800,2023-02-24 19:11:01+00:00,ylecun,@ylecun The Chinchilla paper.,0,0,0
801,2023-02-24 19:10:23+00:00,ylecun,@ylecun Why model downloads require google form? At least small (under 200B) models should be available please! Like Galactica and OTP models.,1,4,0
802,2023-02-24 19:09:59+00:00,ylecun,@ylecun Thank u for releasing it to the research community,0,0,0
803,2023-02-24 19:09:09+00:00,ylecun,"@ylecun Folks you screwed again in twittersphere, by have a too restrictive licensing. ü•≥ü•≥ü•≥",0,0,0
804,2023-02-24 19:05:26+00:00,ylecun,@ylecun @jezzarax,0,0,0
805,2023-02-24 19:01:53+00:00,ylecun,"@ylecun This is a step forward. Hoping for an even more ""open"" release in the future. Ideally, something supporting commercial uses.",1,12,0
806,2023-02-24 18:59:37+00:00,ylecun,@ylecun Can we use it ü§£ü§£ü§£ü§£ü§£ü§£ü§£,2,0,0
807,2023-02-24 18:57:28+00:00,ylecun,"@ylecun @percyliang Nobody cares actually in this case, as it don't need to be as accurate as auto driving, a long error tail is not big deal",0,0,0
808,2023-02-24 18:56:41+00:00,ylecun,"@ylecun So you‚Äôre saying that this AI is open. 

Interesting‚Ä¶ ü§î

In all seriousness. Great work.",0,1,0
809,2023-02-24 18:56:17+00:00,ylecun,"@ylecun Any pointers to documentation on the practical aspects (e.g., hardware requirements) of getting these up and running?",1,0,0
810,2023-02-24 18:55:46+00:00,ylecun,@ylecun Nice work @ylecun and Meta AI team!,0,4,0
811,2023-02-24 18:55:37+00:00,ylecun,"@ylecun https://t.co/kziGfx0DI6
""In order to download the checkpoints and tokenizer, fill this google form""

https://t.co/VxgDPL9E1J
""Non-commercial bespoke license""",0,17,0
812,2023-02-24 18:54:45+00:00,ylecun,@ylecun was this research done in france?,0,0,0
813,2023-02-24 18:53:25+00:00,ylecun,https://t.co/Z5yftjwytT,5,102,8
814,2023-02-24 18:49:50+00:00,ylecun,Some results from the paper. https://t.co/PPPa9p8KyB,2,69,7
815,2023-02-24 18:48:55+00:00,ylecun,@ylecun https://t.co/h4xavKkyNu,0,0,0
816,2023-02-24 18:48:55+00:00,ylecun,"@ylecun Do you have a stance on Hopf algebras? They subsume tensors and provide a better autodiff, one that happens within layers as opposed to across the whole graph. Transformers, diffusion models, convnets are unified within Hopf algebra
I wrote a paper on this
https://t.co/PoUnrXBLEI",0,10,1
817,2023-02-24 18:48:15+00:00,ylecun,@ylecun This must be better than current mainstream models.,0,0,0
818,2023-02-24 18:48:09+00:00,ylecun,"@ylecun @claycurry_ It had its moment in a pre-open source world. Nobody misses it, I guess. (It had a half decent debugger, scilab and R did not have.)",0,1,0
819,2023-02-24 18:48:09+00:00,ylecun,"@ylecun In your opinion, what about LLaMa's design or training yielded the greatest improvement over OPT?",0,11,0
820,2023-02-24 18:47:34+00:00,ylecun,"@ylecun ""Meta is committed to open research and releases all the models the research community under a GPL v3 license.""

... this isn't true. The model is under a non-commercial license.",9,185,7
821,2023-02-24 18:44:36+00:00,ylecun,"LLaMA is a collection of foundation LLMs from 7B to 65B parameters.
They have been trained on trillions of tokens from publicly available datasets
- LLaMA-13B outperforms GPT-3 (175B) on most benchmarks
- LLaMA-65B is competitive with the best models, Chinchilla70B and PaLM-540B",6,220,20
822,2023-02-24 18:43:55+00:00,ylecun,"@ylecun Boom! Thank you, sir!",0,0,0
823,2023-02-24 18:43:08+00:00,ylecun,@ylecun The model is clearly not GPL though no? Only the code is?,1,29,0
824,2023-02-24 17:25:31+00:00,ylecun,"@ylecun and @MetaAI dropping LLMs like they grow on trees!

You get a 7B LLM!
You get a 13B LLM!
You get a 33B LLM!
You get a 65B LLM!

And competitive with 10x larger models... ü§Ø

In all seriousness, this is AMAZING for the research community!!!

https://t.co/q3pOlCnZfD https://t.co/9MEVNf2yJF",0,1,0
825,2023-02-24 16:58:16+00:00,ylecun,@ylecun @pmarca so OpenAI did the hard work. I believe Facebook and other giants will do something better in *a* future.,0,0,0
826,2023-02-24 16:10:00+00:00,ylecun,"@ylecun 1- COBOL
2- PL/1
3- Basic
4- Natural/Adabas
5- Stairs
6- Visual Basic
7- C#
8- R
9- Python",0,0,0
827,2023-02-24 15:42:38+00:00,ylecun,@ylecun this part of the newsletter didn't link to your profile so just fyi @WellfoundHQ https://t.co/fQrDTOGWoP,0,0,0
828,2023-02-24 14:55:45+00:00,ylecun,@ylecun homoiconicity might be quite a key feature for models trained to write code.,0,0,0
829,2023-02-24 13:49:12+00:00,ylecun,@ylecun Swift has a chance: https://t.co/vbAHH2mzOW,0,1,0
830,2023-02-24 13:13:51+00:00,ylecun,@ylecun is Rust too bloated?,0,0,0
831,2023-02-24 09:43:37+00:00,ylecun,"@ylecun ‚Ä¶. Like Lua/Torch? I think Python somehow swallowed its best competition. Probably due to adoption of big data pipelines, Python had the ecosystem",0,1,0
832,2023-02-24 09:19:59+00:00,ylecun,@ylecun This is a freezing cold take. Lab I worked in Used matlab to do synapse mapping ML work. Speed (both in writing code and executing) was a snails pace.,0,0,0
833,2023-02-24 09:13:07+00:00,ylecun,@ylecun @pmarca tell us more ..,0,0,0
834,2023-02-24 09:06:07+00:00,ylecun,"@ylecun @pmarca Well, but there is a better way than a CNN... or a FFN, but people still do wrong! You don't know it yet because I don't want to support the wrong team. What's your excuse?",0,0,0
835,2023-02-24 08:41:17+00:00,ylecun,@ylecun @pmarca Whats better‚Ä¶if its ‚Äúbetter‚Äù  how is it better,0,0,0
836,2023-02-24 08:05:08+00:00,ylecun,"@ylecun Interactive is not a property of programming language, there is Cling which is a REPL for C++. By bloat I guess you mean C++ is hard to learn. Seems hard to find a good tutorial when the default language for tutorials is Python.",0,1,0
837,2023-02-24 06:32:26+00:00,ylecun,@ylecun Julia is ready for ML prime time,0,0,0
838,2023-02-24 06:32:22+00:00,ylecun,@ylecun I love love Julia in principle. Not sure about in practice‚Ä¶,0,0,0
839,2023-02-24 05:57:57+00:00,ylecun,@ylecun @SamForman979 @pmarca Answer is in probabilistic approach.,0,0,0
840,2023-02-24 05:45:09+00:00,ylecun,@ylecun @SamForman979 @pmarca it's just one way to pronounce JEPA,0,1,0
841,2023-02-24 05:30:26+00:00,ylecun,"@ylecun @SamForman979 @pmarca Omg, this is going on my wall. üòÜ",0,0,0
842,2023-02-24 04:18:35+00:00,ylecun,@ylecun @pmarca You're trying so hard to bring ChatGPT down. Idk why. If there are better things why has it not happened yet.,2,0,0
843,2023-02-24 04:12:09+00:00,ylecun,@ylecun @percyliang Any system that does not experience the world and learn for itself is going to be at the mercy of the data it is given to learn from.,0,25,2
844,2023-02-24 03:56:03+00:00,ylecun,@ylecun @SamForman979 @pmarca Hehe is a new framework for LLM applications,0,11,0
845,2023-02-24 03:48:37+00:00,ylecun,@ylecun @pmarca Thoughts on weak supervision and synthetic data?,0,0,0
846,2023-02-24 03:48:28+00:00,ylecun,@ylecun @pmarca The game is afoot...,0,0,0
847,2023-02-24 03:36:45+00:00,ylecun,@ylecun ...Erlangers still patiently waiting for the world to catch up...,0,1,0
848,2023-02-24 03:30:45+00:00,ylecun,@ylecun @pmarca What is it?,2,2,0
849,2023-02-24 03:10:43+00:00,ylecun,"@ylecun @OuahabiAdnane (Translated to various Pythonista sects)
There were 3 (completely incompatible, introduced at different times, some now deprecated even if happens to be most widely used) reasons to switch to Python:
1. People want Python
2. Python wanted by People
3. People (want Python)",1,2,0
850,2023-02-24 03:08:38+00:00,ylecun,"@ylecun @pmarca Yann, my apologies for being so pushy on the @GaryMarcus situation, but I do believe he deserves credit for a lot. I do have a large amount of respect, for the pivotal work you have done in your career. 

That said, we must take this seriously: \",1,2,0
851,2023-02-24 02:41:26+00:00,ylecun,@ylecun @percyliang Agreed 100%. I think your ‚ÄúPath toward Autonomous Machine Intelligence‚Äù is the way to go!,0,3,0
852,2023-02-24 00:45:33+00:00,ylecun,@ylecun @percyliang What is your solution then ?  I believe RLHF is the key underlying technology that distinguishes ChatGPT from its competitors.,1,1,0
853,2023-02-24 00:33:21+00:00,ylecun,"@ylecun White spaces / the rigid format - that's a feature, not a bug. It contributes to clarity, and it's one of the reasons why Python is so popular despite its obvious downsides (some of which you've highlighted).",0,0,0
854,2023-02-24 00:21:12+00:00,ylecun,"@ylecun @SebastianSeung The chrome folks are protecting you whether you like it or not.
Someone could spy on your connection and see all your secret neural network info when using http.

Never forget the Wayback Machine. 
https://t.co/TKuRVsAfdp",0,3,0
855,2023-02-23 23:57:53+00:00,ylecun,"@ylecun The secret of Python is that it is easy to work with, but the computer intensive parts (ie what really matters), are already executed by C or compiled code.",0,1,0
856,2023-02-23 23:36:11+00:00,ylecun,"@ylecun @percyliang Tell me that you don‚Äôt understand what RLHF is, without actually telling me that ‚Ä¶

RLHF has nothing to do with ‚Äúwrong answers‚Äù. ü§¶‚Äç‚ôÇÔ∏è  Human feedback is not used for ‚Äúcorrectness‚Äù or ‚Äúwrongness‚Äù.",2,2,1
857,2023-02-23 22:51:37+00:00,ylecun,"@ylecun Language wars comes to AI! Waiting for the final ""Hottest take"".",0,0,0
858,2023-02-23 22:36:37+00:00,ylecun,@ylecun @GaryMarcus I wrote a LISP program to solve my calculus problems freshman year in college üòÇ,0,0,0
859,2023-02-23 20:26:20+00:00,ylecun,@ylecun Jax is pretty good at most of this!,0,0,0
860,2023-02-23 20:24:07+00:00,ylecun,"@ylecun Lisp has had a privilege to be around ""AI"" decades before Python ever gained notable user mass, and have never really taken off. What could change now, after Python has got all the momentum?

BTW you described Smalltalk",0,2,0
861,2023-02-23 20:23:25+00:00,ylecun,"@ylecun Julia is growing, especially in RL circles!",1,0,0
862,2023-02-23 20:08:32+00:00,ylecun,"@ylecun It shocks me that people *choose* to use Python. That people get up in the morning and actively decide, ""this is how I want to live my life. With broken tools.""",0,2,0
863,2023-02-23 19:07:05+00:00,ylecun,@ylecun @SebastianSeung Important issue üòÖü§£üòç,0,0,0
864,2023-02-23 19:04:32+00:00,ylecun,"@ylecun Types, types, baby. Have wasted days and dollars because we thought key in hash map was &lt;x&gt; when it was &lt;y&gt;.",0,1,0
865,2023-02-23 18:54:09+00:00,ylecun,"@ylecun @GaryMarcus I would love a good Lisp for ML!  Here's my first contribution, courtesy of Stable Diffusion. https://t.co/fOIcdDDe7P",0,0,0
866,2023-02-23 18:53:18+00:00,ylecun,@ylecun True,0,0,0
867,2023-02-23 18:44:03+00:00,ylecun,@ylecun @SebastianSeung Host it on github pages,0,2,0
868,2023-02-23 18:31:37+00:00,ylecun,"@ylecun @OuahabiAdnane Am i out of touch?

No, it's all the ml engineers who are out of touch.",0,0,0
869,2023-02-23 18:28:24+00:00,ylecun,"@ylecun Yes.  And whose interaction with the browser environment has sensible, consistent, abstracts, to make things like state stores less ridiculous.",0,0,0
870,2023-02-23 18:01:38+00:00,ylecun,"@ylecun Yeah, pretty terrible take",0,0,0
871,2023-02-23 17:46:07+00:00,ylecun,@ylecun Faster? Why faster? Is there an imperative and existential NEED to go ever faster?,0,0,0
872,2023-02-23 17:40:42+00:00,ylecun,@ylecun @SebastianSeung Doesnt seem to work on Brave,0,2,0
873,2023-02-23 17:37:26+00:00,ylecun,"@ylecun Disagree completely. Python is approachable for beginners. The API is great, and it‚Äôs quick to spin up scripts.",0,1,0
874,2023-02-23 17:19:12+00:00,ylecun,"@ylecun I dislike Python with a burning passion but the frontend to ML is usually so slim it doesn‚Äôt matter, the pros far outweigh the cons.",0,0,0
875,2023-02-23 17:10:11+00:00,ylecun,"@ylecun This is the answer: https://t.co/HQ0uDtDVJx

#Clojure",0,1,0
876,2023-02-23 17:05:01+00:00,ylecun,@ylecun Ask Chat-gpt to create it for you.,0,0,0
877,2023-02-23 16:55:12+00:00,ylecun,"@ylecun There is an ""AI"" section in the last version of https://t.co/6jRAK51RAs",0,1,0
878,2023-02-23 16:50:34+00:00,ylecun,@ylecun @memecrashes,0,0,0
879,2023-02-23 16:26:49+00:00,ylecun,@ylecun What is your choice? Julia?,0,0,0
880,2023-02-23 15:55:32+00:00,ylecun,"@ylecun ‚Ä¶ bloat &amp; whitespace aren‚Äòt the only things I would criticize, it‚Äôs also about consistency: https://t.co/47WBK4mkFr",0,0,0
881,2023-02-23 15:44:59+00:00,ylecun,@ylecun Love it. 1988/89 for me.,0,0,0
882,2023-02-23 15:37:04+00:00,ylecun,"@ylecun Lisp is beautiful mathematically which was the seductive rationale for teaching it in computer ""science"".  But lambda calculus description left much to be desired practically.  That, I believe, remains the case?",0,0,0
883,2023-02-23 15:22:35+00:00,ylecun,"@ylecun I think C# with a more interactive shell would be a great application-driven language to integrate ML frameworks natively into, given its popularity in games and digital media (e.g. Unity).",0,0,0
884,2023-02-23 15:11:14+00:00,ylecun,@ylecun R with a few performance improvements #rstats. I don't know why functional programming isn't more popular in ML,0,0,1
885,2023-02-23 15:06:16+00:00,ylecun,"@ylecun Javascript.  I wish Javascript had become the ML orchestration language rather than Python.  While the main language is single threaded, many things are async at that level, multithreaded in implementation.  Plus with WebWorkers (another thread), WASM...",0,0,0
886,2023-02-23 15:00:35+00:00,ylecun,"@ylecun Lisp!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Beautiful Lisp. My respects, Yann.",0,1,0
887,2023-02-23 14:55:16+00:00,ylecun,@ylecun CMS would have advanced faster if something other than PHP... oh never mind. The world is full of mysteries.,0,0,0
888,2023-02-23 14:32:41+00:00,ylecun,"@ylecun On the question of interactivity for Python, I would point to our new package Quibbler: it readily brings interactivity to any python code.
https://t.co/fojVxFGnmF",0,0,0
889,2023-02-23 14:04:31+00:00,ylecun,@ylecun @SaveToNotion #Thread #chatgpt,0,0,0
890,2023-02-23 14:04:11+00:00,ylecun,"@ylecun Let me introduce you the @ChapelLanguage . It is an amazing language with excellent parallel processing support. Easy as Python, fast as C. It is worth experiment it.",0,1,0
891,2023-02-23 13:51:33+00:00,ylecun,@ylecun Struggling to agree here. I'm guessing by 2005 MATLAB I think you're meaning pre-OOP. That came quite soon after in 2008 (I was an early adopter; was essential imho to developing complex software in MATLAB). Some seminal DL applications (e.g. connectomics) were coded in MATLAB.,0,3,0
892,2023-02-23 13:47:24+00:00,ylecun,@ylecun @eulerfx Scala!,0,0,0
893,2023-02-23 13:46:23+00:00,ylecun,"@ylecun @Oumaima_elk @UM6P_officiel Jan, I really want to introduce you to PANN technology. You are a great scientist and it will definitely be interesting for you ... https://t.co/fgqxUXMiXT",0,0,0
894,2023-02-23 13:32:41+00:00,ylecun,@ylecun Julia!,0,1,0
895,2023-02-23 13:28:45+00:00,ylecun,"@ylecun 10 years and it'll be ""esri held back progress in geo for 40 years""",0,2,0
896,2023-02-23 13:28:26+00:00,ylecun,"@ylecun Academia affects AI advancement more than language, just like every other field",0,0,0
897,2023-02-23 13:24:10+00:00,ylecun,"@ylecun just a joke; not a serious point, but elaborated below. (With sources even: Nature, Noema, Twitter üòÜ). 

I guess the serious question is, if you are willing to use LISP as a kind of support scaffold, why not use it in your core AI as well?",2,2,0
898,2023-02-23 13:24:07+00:00,ylecun,"@ylecun Didn't Google have a longshot project where they

1. Narrowed it down to Swift vs. Julia
2. Decided Julia was too immature and went with Swift 
3. *years go by, Chris Lattner leaves, the TF Swift project is archived

In another timeline, maybe Julia ML is 5 years ahead.",0,0,0
899,2023-02-23 13:20:20+00:00,ylecun,@ylecun GIL is a real nuisance indeed,0,0,0
900,2023-02-23 13:18:52+00:00,ylecun,"@ylecun what do you mean by ""using Lisp as a front-end language""? the term front-end for me refers to languages commonly used to create front-end interfaces, like javascript. Lisp appears to be a back-end language.",0,0,0
901,2023-02-23 13:04:32+00:00,ylecun,"@ylecun Use Crystal or Julia, both have Parallelism, both don't have a GIL, Crystal is fast as C and simple as Ruby. Whatever else do you need???",0,0,0
902,2023-02-23 13:04:25+00:00,ylecun,"@ylecun Use Crystal or Julia, both have Parallelism, both don't have a GIL, Crystal is fast as C and simple as Ruby. Whatever else do you need???",0,0,0
903,2023-02-23 13:02:45+00:00,ylecun,@ylecun Agreed. I tell everyone I meet that Python sucks.,2,0,0
904,2023-02-23 12:39:12+00:00,ylecun,@ylecun Really a pity that Julia never got to where we‚Äôd have wanted it.,0,0,0
905,2023-02-23 12:34:13+00:00,ylecun,"@ylecun Concerning ML, i see python as a language that acts as an interface to the tools written in C++. 

I believe the flexibility of python has actually contributed to the fast paced movement of the AI field.

Plus a compiler slows down the iterations involved in training ML models.",1,2,0
906,2023-02-23 12:25:34+00:00,ylecun,@ylecun Interesting thought,0,0,0
907,2023-02-23 12:19:50+00:00,ylecun,@ylecun @OuahabiAdnane Are u planning to adopt Julia in some capacity ?,0,0,0
908,2023-02-23 12:18:38+00:00,ylecun,@ylecun As someone who did exactly that I can confirm üòÑ,0,0,0
909,2023-02-23 12:09:23+00:00,ylecun,@ylecun Why do you care about GIL if the heavy lifting is being handled by the GPU?,0,0,0
910,2023-02-23 11:50:14+00:00,ylecun,@ylecun üíØüéØüéØüéØüéØ,0,0,0
911,2023-02-23 11:44:27+00:00,ylecun,"@ylecun Python is not a front-end language, JS is the front-end language for web apps. Some GUIs can be made in Python for desktop apps, but it's much rarer even on desktops than the electron.",1,1,0
912,2023-02-23 11:02:28+00:00,ylecun,@ylecun I wish control engineers could think the same,0,0,0
913,2023-02-23 10:58:51+00:00,ylecun,@ylecun A lisp front end would be (have been) really cool ...,0,0,0
914,2023-02-23 10:51:56+00:00,ylecun,@ylecun @AlmadorCharlie Is Julia‚Äôs REPL still slow?,1,0,0
915,2023-02-23 10:38:08+00:00,ylecun,"@ylecun For many use cases, The latency that comes in execution makes python a choice only for MVPs not for production.",0,0,0
916,2023-02-23 10:36:31+00:00,ylecun,"@ylecun If we had quantum computers with perfect algorithms and a perfect database with all the data in the universe, ML would probably be a little more advanced.",0,1,0
917,2023-02-23 10:24:39+00:00,ylecun,"@ylecun Scala would have been perfect, it has everything from OOPs to functional to distributed computing integration.  you can build the entire backend in scala and its portable using JVM to any system.",0,0,0
918,2023-02-23 10:15:21+00:00,ylecun,"@ylecun No Yann. Most libraries where speed is required are compiled down. But in any case, more speed wouldn't make progress faster. Better algorithms will.",0,0,0
919,2023-02-23 10:10:43+00:00,ylecun,@ylecun Burn!,0,0,0
920,2023-02-23 10:08:14+00:00,ylecun,@ylecun I've said this before. Julia should be the go-to language for ML.,0,0,0
921,2023-02-23 10:00:50+00:00,ylecun,@ylecun thoughts of everyone ever who has never written production code,0,2,0
922,2023-02-23 09:54:36+00:00,ylecun,"@ylecun Don't you mean Cpython?

There are other pythons without gil",0,0,0
923,2023-02-23 09:49:44+00:00,ylecun,"@ylecun Those don't have as big a set of libraries you can easily install from pypi.
The easy interop with C is why fast libraries to do the work were already in place.",1,3,0
924,2023-02-23 09:48:26+00:00,ylecun,"@ylecun Probably the right take. As an experienced programmer  coming from real OOP and structured languages, I feel that using Python on daily basis has had a negative impact on my skills. My productivity certainly went down, b/c Python is bloated &amp; encourages all sorts of bad practices",0,3,0
925,2023-02-23 09:29:00+00:00,ylecun,"@ylecun But python is only workflow description language in this case. So it does not impact performance.

Multithreading is hard and GIL protect most of users from most of typical problems.",0,0,0
926,2023-02-23 09:28:07+00:00,ylecun,"@ylecun You mean, like, an actually good one? Lisp has been used in AI research, but fell out of favor for... some reason.",0,0,0
927,2023-02-23 09:14:15+00:00,ylecun,"@ylecun @claycurry_ What's wrong with Matlab. Depends what you need, but the plotting functionality is second-to-none.",1,0,0
928,2023-02-23 09:14:15+00:00,ylecun,"@ylecun @OuahabiAdnane I think the reason why people chose Python was because a lot of ML developers came from statistics with a science background (other than computer science), and Python is very simple to get started for those without programming experience.",0,1,0
929,2023-02-23 09:13:16+00:00,ylecun,@ylecun Yes to the whitespace thing. It blows my mind that the looping depends on tabs! Hideous.,0,0,0
930,2023-02-23 08:57:47+00:00,ylecun,@ylecun c,0,0,0
931,2023-02-23 08:45:18+00:00,ylecun,"@ylecun The barrier of entry for Lisp is too high.
But Julia is a strong candidate yes.",1,2,0
932,2023-02-23 08:37:19+00:00,ylecun,"@ylecun #LISP?
(((((((Are-you sure?))))))",0,0,0
933,2023-02-23 07:42:57+00:00,ylecun,@ylecun take a look at FastAPI you may found it insteresting,0,0,0
934,2023-02-23 07:07:25+00:00,ylecun,"@ylecun What about rust?

That way systems folks can be happy too :-)",0,0,0
935,2023-02-23 06:59:00+00:00,ylecun,"@ylecun I wrote my undergrad thesis on echo state neural networks, big progress since then. 

In fact out of the entire CS batch at the university in Germany, only two of us chose ML, the rest didn‚Äôt want to deal with Matlab üò≠

He is a researcher at Google Brain and I invest in ML",0,13,0
936,2023-02-23 06:58:27+00:00,ylecun,@ylecun Well the semantics (grammar) of Matlab (everything is arrays) was totally different that Python where everything is a more general object. That being said Python can be replaced by a variant with comparable grammar but better perf.,1,0,0
937,2023-02-23 06:56:27+00:00,ylecun,@ylecun Umm those were available actually. Problem is that industry did what industry always does and picked a terrible language to blow up.,0,0,0
938,2023-02-23 06:56:26+00:00,ylecun,"@ylecun @OuahabiAdnane I have talked to dozens of ML engineers, and honestly, nobody there has ever told me they wanted Python.* Everyone is just convinced that everyone else wants Python. 

*Exception: people who don't know about newer languages like Julia or Nim.",0,1,0
939,2023-02-23 06:54:20+00:00,ylecun,"@ylecun @metapgmr Julia seemed to me like the perfect successor to Python: statically typed, fast enough to write things like machine learning algorithms in the language - and the IDE/REPL looks amazing for ML and data science.

Why aren't Python users adopting?",1,4,0
940,2023-02-23 06:49:44+00:00,ylecun,@ylecun Clojure!,0,0,0
941,2023-02-23 06:43:11+00:00,ylecun,@ylecun Is there a way to fix the GIL for python,0,1,0
942,2023-02-23 06:43:10+00:00,ylecun,@ylecun https://t.co/7Z0KCyVFl4,0,0,0
943,2023-02-23 06:41:35+00:00,ylecun,@ylecun Interisting. Is withespaces indentation related to other item in that list or you just included because it annoys you?,0,0,0
944,2023-02-23 06:38:01+00:00,ylecun,@ylecun @ylecun then use Julia! Every ML engineer and researcher I have met says this. All of them say they'd love to work in Julia and use it. But *nobody pays people to work on the Julia ecosystem*.,1,3,0
945,2023-02-23 06:35:12+00:00,ylecun,"@ylecun It had a FFI, and it was quite common to have high performance parts written in C (just like it is in Python). Licensing might have been the bigger factor.",0,0,0
946,2023-02-23 06:25:09+00:00,ylecun,@ylecun @stylewarning ü§î,1,0,0
947,2023-02-23 06:20:17+00:00,ylecun,@ylecun Python is so easy to write and read... And the ecosystem is huge. Do you think that Julia can take some traction after so many years and work invested in making python fast and accessible in every cloud?,1,0,0
948,2023-02-23 06:18:37+00:00,ylecun,@ylecun holy war again ü•±,0,0,0
949,2023-02-23 06:16:59+00:00,ylecun,"@ylecun Somebody seems mad that nobody knows his prefered niche language.

Hint: grafics cards dont care about GIL.

Could it be instead, that some major papers that made training deep nets even possible are not even 10 years old? (eg. Batch Normalization 2015)",0,0,0
950,2023-02-23 06:11:15+00:00,ylecun,"@ylecun Honestly, imagine the productivity gains if Lisp were taught in elementary school. It's a global tragedy that so many people are irrationally fearful of s-expressions.",0,2,0
951,2023-02-23 06:07:40+00:00,ylecun,@ylecun A take so hot it‚Äôs wrong,0,0,0
952,2023-02-23 06:07:04+00:00,ylecun,"@ylecun I'd be happy if they just added types! I've spent hours print debugging tensorflow code just to figure out how many dimensions some tensor had, or what some intermediate output used as types",0,0,0
953,2023-02-23 06:00:22+00:00,ylecun,"@ylecun Is multithreading really that important for training models?  Maybe I'm wrong, but I think parallel processing is just fine for ML and multithreading only really important for apps and operating systems.",0,0,0
954,2023-02-23 05:59:09+00:00,ylecun,@ylecun Hottest take: ML generated images have six fingers per hand because the AI is pining for the return of Lisp Machines. https://t.co/23QsAQGxoK,0,2,0
955,2023-02-23 05:57:58+00:00,ylecun,@ylecun Golang.,0,2,0
956,2023-02-23 05:56:49+00:00,ylecun,@ylecun I 'member when the embedded hardware startup I joined thought it was brilliant to implement and run the debugger in lisp. My first task was to learn enough list to write a parser to emulate gdb. It only got worse from there and they died.,0,0,0
957,2023-02-23 05:53:23+00:00,ylecun,@ylecun Hottest take: Machine Learning should have used x86 assembly language and worked only on the windows subsystem for linux,0,2,1
958,2023-02-23 05:51:20+00:00,ylecun,"@ylecun Disagree though, In my opinion, more front-end meaning less control over models. Many people already have less control using Python.",0,0,0
959,2023-02-23 05:33:56+00:00,ylecun,@ylecun It's just a  language. Academics focus too much on such trivia,0,1,0
960,2023-02-23 05:31:05+00:00,ylecun,"@ylecun The parts of ML that need to be fast are written in C.  Other than that, a compiler just gets in the way of fast iteration and brings pretty much nothing of value to the table.",0,3,0
961,2023-02-23 05:15:01+00:00,ylecun,"@ylecun ML as it is a black box...
Once the models are created...
Please don't say you wish there was JS spaghetti added to the mix ?",0,1,0
962,2023-02-23 05:12:36+00:00,ylecun,"@ylecun Tried to work with NN from Scala, but it‚Äôs a pain. As typical NN was written in C/C++. There was a GitHub project DeepLearning4j",0,1,0
963,2023-02-23 05:07:00+00:00,ylecun,"@ylecun ""isn't bloated"" is a feature which is hard to retain indefinitely",0,0,0
964,2023-02-23 05:03:35+00:00,ylecun,@ylecun I don't know LISP but I work in julia as my primary language at work. I have heard Julia took a lot of ideas from LISP. I like julia that means I will also like LISP,0,1,0
965,2023-02-23 05:02:01+00:00,ylecun,@ylecun actually what happened to s4tf?,0,0,0
966,2023-02-23 04:57:38+00:00,ylecun,"@ylecun assuming current adoption numbers, yes, but with barrier to entry of julia/lisp very doubtful those numbers are possible",0,0,0
967,2023-02-23 04:57:11+00:00,ylecun,@ylecun How exactly does caring about white space slow down ML research?,0,0,0
968,2023-02-23 04:50:24+00:00,ylecun,"@ylecun During my bachelor's, I didn't have access to MATLAB (at it was not very inclusive in my geographical region at the time) so I implemented SOM networks for hand-written digits recognition using C#, and MS SQL Express as the database.",0,1,0
969,2023-02-23 04:45:01+00:00,ylecun,@ylecun Lol. Lisp and developer adoption don‚Äôt mix,2,13,1
970,2023-02-23 04:38:18+00:00,ylecun,"@ylecun Sorry, you blew all your credibility by claiming that everyone coding in Lisp would have made ML progress faster",0,0,0
971,2023-02-23 04:33:43+00:00,ylecun,@ylecun What about R?,0,0,0
972,2023-02-23 04:20:38+00:00,ylecun,"@ylecun I wish people would use C# more. Of all the languages, I love the clean box style of C# code. Coding in C# feels like there are no loose ends.",0,1,0
973,2023-02-23 04:15:39+00:00,ylecun,@ylecun I can't see how a language being compilable is anything but a disadvantage here. Execution speed matters for ML experimentation?,1,0,0
974,2023-02-23 04:14:25+00:00,ylecun,"@ylecun Surely this is some kind of bait, you can not believe this",0,0,0
975,2023-02-23 04:06:28+00:00,ylecun,"@ylecun That's Nim. It wasn't ready yet, and is still struggling to gain widespread use.",0,0,1
976,2023-02-23 03:36:05+00:00,ylecun,@ylecun Why is Sydney a narcissist?,0,0,0
977,2023-02-23 03:35:08+00:00,ylecun,@ylecun Matlab guys are only on paper: CV was simply useless (except VERY niche robotics) until advanced mobile devices came to mass market,0,0,0
978,2023-02-23 03:25:02+00:00,ylecun,"@ylecun MATLAB started as a wrapper for linear algebra routines, and a proficient coder could always write efficient code to prototype, visualize and analyze data. Good workpersons do not quarrel with their tools :)",0,6,0
979,2023-02-23 03:22:40+00:00,ylecun,@ylecun #UseFortran üëå‚ú®,0,0,0
980,2023-02-23 03:18:23+00:00,ylecun,@ylecun Didn't they need Moores law to catch up before any of this mattered?,0,0,0
981,2023-02-23 03:09:21+00:00,ylecun,@ylecun Ruby would also make a nicer language if ‚Äúbeing amicable‚Äù is such a mandatory requirement.,0,0,0
982,2023-02-23 03:09:10+00:00,ylecun,@ylecun I don't get the hate for Python and whitespace. Like would you not indent your code if the language didn't make you?,2,3,0
983,2023-02-23 03:08:53+00:00,ylecun,@ylecun https://t.co/G5lg7NpFRj,0,10,1
984,2023-02-23 03:04:34+00:00,ylecun,"@ylecun Curious: How much of this ‚Äúheld back progress‚Äù could‚Äôve been because of absence of good GPUs. Put another way, do you think the AlexNet moment would‚Äôve occurred much earlier, say with 2007s GPU capabilities with the existence of a better front-end language?",2,10,0
985,2023-02-23 02:51:27+00:00,ylecun,@ylecun https://t.co/fHw08a18n2,0,0,0
986,2023-02-23 02:47:15+00:00,ylecun,@ylecun Lua held back Torch's adoption too in some way. Now all we know is PyTorch :),0,2,0
987,2023-02-23 02:46:51+00:00,ylecun,@ylecun Always been a fan of #LISP. My first language that I learnt.,0,1,0
988,2023-02-23 02:46:32+00:00,ylecun,"@ylecun Adopting  Julia  when  calculus are heavy is prudent.

      Julia syntax is more readable than Python and have 
        no performance issue.

        Big  data is to  conquer  Julia in  next years.

        Many  data scientists will have to learn it.",0,0,0
989,2023-02-23 02:43:50+00:00,ylecun,@ylecun What about compilers that use python syntax but work much faster?,0,1,0
990,2023-02-23 02:32:53+00:00,ylecun,@ylecun @tunguz is right,0,0,0
991,2023-02-23 02:24:38+00:00,ylecun,@ylecun Or OCaml,0,0,0
992,2023-02-23 02:03:20+00:00,ylecun,@ylecun @MarkSchmidtUBC Very true. Can never understand why didn't Microsoft invest in C# for ML. Such a beautiful language. Python is a mess.,0,0,0
993,2023-02-23 01:54:14+00:00,ylecun,@ylecun Julia is a great alternative.,0,2,0
994,2023-02-23 01:40:33+00:00,ylecun,@ylecun Maybe writing what computer should do is artificial intelligence too kk,0,0,0
995,2023-02-23 01:31:12+00:00,ylecun,@ylecun @OuahabiAdnane Of course they would want Python when you cite the white-space rules as a drawback of it. They rightly won't take you serious.,1,0,0
996,2023-02-23 01:29:37+00:00,ylecun,"@ylecun @OuahabiAdnane Why Lua,?",0,0,0
997,2023-02-23 01:18:47+00:00,ylecun,@ylecun Julia is good in many ways but it's design patterns inherently encourage massive over-engineering making it not as natural a language for experimentation as Python. It is also full of syntactic quirks.,2,0,0
998,2023-02-23 01:13:41+00:00,ylecun,"@ylecun The language really doesn't matter. It's the ecosystem (of ready to use packages and frameworks, and developers) that exists around it. Python comes with a huge ecosystem. I think the only other language like that is JavaScript.",1,3,0
999,2023-02-23 01:12:57+00:00,ylecun,"@ylecun The problem here to me at least is that we will never know as we exist in environment where the hot take didn‚Äôt happen. Chuckle.

Stay safe and well.",0,0,0
1000,2023-02-23 01:12:40+00:00,ylecun,@ylecun I like your posts.,0,0,0
1001,2023-02-23 01:11:26+00:00,ylecun,"@ylecun Even Hotter take: the human machine interface would have advance faster if we had focused sooner on Understanding AI instead of Generative AI, to create factual, non-toxic and explainable systems https://t.co/iVczNFiMlL",0,3,0
1002,2023-02-23 01:10:58+00:00,ylecun,"@ylecun @claycurry_ Personally, I rather like Matlab.",0,0,0
1003,2023-02-23 01:07:28+00:00,ylecun,"@ylecun @TensorFlow at one point were pretty serious about Swift for Tensorflow w/ their best engineers on the project;  differentiable programming for gradient ops sounds like such a big win. Swift is also a better language.  https://t.co/zs5H2IhyDZ (safe, auto-diff, typed, faster)",0,0,0
1004,2023-02-23 01:07:28+00:00,ylecun,"@ylecun Idk, Julia was released in 2011, Python was already widely used when no one knew a thing about Julia. If it was released in 2001... well, it would have dominate everything. About lisp, I do love Clojure, but it's not something trivial for a C inspired world.",1,0,0
1005,2023-02-23 01:02:15+00:00,ylecun,"@ylecun Outside of your comfortable little nest, there are people who don't just write software, they also have to scale it, test it, repair it, expand it, and be accountable for it. That's why we use Python.",0,1,0
1006,2023-02-23 00:50:24+00:00,ylecun,@ylecun And he was doing so well until he said Julia and Lisp... LOL,0,0,0
1007,2023-02-23 00:50:09+00:00,ylecun,"@ylecun Disagree. Lack of a GIL encourages poor architectural choices.  Prototype in Python, and optimize with C where necessary. You are thinking about efficiency of execution, but should be thinking about efficiency of creation.  AI will write the best Python you have ever seen.",0,0,0
1008,2023-02-23 00:48:20+00:00,ylecun,"@ylecun I chose Python for an introductory programming course. I did my decision based on adoption and popularity. I hated it. It is the worst first programming language. Inconsistencies, ambiguities, confusing syntax. If you have to introduce people to programming, trust me, use a Lisp.",1,5,0
1009,2023-02-23 00:43:33+00:00,ylecun,"@ylecun Python is undoubtedly both multi-threaded and multi-process.

I do agree with the nuisance of white spacing.

https://t.co/p1SJ8MK8on",0,0,0
1010,2023-02-23 00:37:31+00:00,ylecun,@ylecun too hot,0,0,0
1011,2023-02-23 00:30:21+00:00,ylecun,@ylecun Hottest take: our society would have advanced much faster without the bloated and corrupted means of organization and exchange we have in bank-controlled oligarchy.,0,0,0
1012,2023-02-23 00:17:51+00:00,ylecun,@ylecun Julia is magic,0,0,0
1013,2023-02-23 00:12:13+00:00,ylecun,@ylecun Endorse LISP or Prolog ‚Ä¶,0,0,0
1014,2023-02-23 00:02:16+00:00,ylecun,"@ylecun I remember in my undergrad talking to a certain electric car company working on self driving cars who had two teams: their researchers, who would make their models in Matlab, then their engineers who would re-implement it in a better language. Just felt so wasteful!",1,1,1
1015,2023-02-22 23:58:56+00:00,ylecun,@ylecun Booooooomerrrrr,0,0,0
1016,2023-02-22 23:53:37+00:00,ylecun,@ylecun Julia when?,0,1,0
1017,2023-02-22 23:36:32+00:00,ylecun,"@ylecun The important part is ""and widely adopted""...",0,0,0
1018,2023-02-22 23:36:07+00:00,ylecun,@ylecun How about JavaScript?,0,0,0
1019,2023-02-22 23:29:31+00:00,ylecun,@ylecun I‚Äôll side with the godfather of CNNs,0,0,0
1020,2023-02-22 23:23:11+00:00,ylecun,@ylecun Clearly ML needed Forth,0,0,0
1021,2023-02-22 23:17:36+00:00,ylecun,@ylecun Do you actually like Julia and Lisp or are you trolling?,0,1,0
1022,2023-02-22 23:08:33+00:00,ylecun,@ylecun Could port to Web assembly ?,0,0,0
1023,2023-02-22 23:03:58+00:00,ylecun,@ylecun OMG so LISP might have helped? Formally learning LISP (awesome syntax less language) as an undergrad @MIT I felt really handicapped me for later - when I had to learn other programming languages...disliked most other languages,1,4,0
1024,2023-02-22 22:55:25+00:00,ylecun,@ylecun I use R,0,0,0
1025,2023-02-22 22:44:42+00:00,ylecun,"@ylecun Well it's just that data processing and cleaning is a huge part of a ML pipeline, and python-like languages are very convenient for this üòâ",0,2,0
1026,2023-02-22 22:36:12+00:00,ylecun,@ylecun LUAJIT ARM WEN,0,0,0
1027,2023-02-22 22:34:42+00:00,ylecun,"@ylecun @johnmyleswhite Julia maybe. It's basically BASIC by way of matlab. Lisp is a functional language. The first time you run into those you are in a state of total confusion, (unless you are a member of those  enlightened Elect of programming).",0,0,0
1028,2023-02-22 22:33:20+00:00,ylecun,"@ylecun 100% agree. C# has scripting &amp; easiest to deploy, to port c /C++ or java to it, but Julia has scripting, and more science datatypes, LLVM. in 2023 i can't voice cmd my OS/ apps handsfree?. so a small domain-specific not LLM wih √Ä Priori predicate calc. https://t.co/itnlxlZ1sp",0,0,0
1029,2023-02-22 22:30:21+00:00,ylecun,"@ylecun @OuahabiAdnane curious why folks hated Lua, the JIT is nice!",1,0,0
1030,2023-02-22 22:22:28+00:00,ylecun,@ylecun Quite happy at the current pace and for the singularity to happen in the last 10 years of my life.,0,0,0
1031,2023-02-22 22:15:37+00:00,ylecun,@ylecun Interesting take,0,0,0
1032,2023-02-22 22:10:22+00:00,ylecun,@ylecun Hey @ylecun. How about Kotlin? It is also a UI language for Android. @kotlin,0,1,0
1033,2023-02-22 22:09:27+00:00,ylecun,"@ylecun 1984 -&gt; MATLAB
1991 -&gt; Python
1996 -&gt; OCaml
1997 -&gt; F#
2005 -&gt; Clojure
2012 -&gt; Julia

the assumption is that there were such languages available in 1991! https://t.co/uQkb2Rd840",0,3,0
1034,2023-02-22 22:05:10+00:00,ylecun,@ylecun Someone really hates Matlab.,1,0,0
1035,2023-02-22 22:00:21+00:00,ylecun,"@ylecun or brainsim, a KNN in c64 BASIC. https://t.co/LdjslVlFo4",0,0,0
1036,2023-02-22 21:59:54+00:00,ylecun,@ylecun One of the biggest shifts in dev productivity was the shift away Point to click dev tools like VS Studio or Informatica to codeable workstreams like VS Code or just phython - massive shift in productivity and innovation and less stuffing square peg into circle,0,1,0
1037,2023-02-22 21:55:08+00:00,ylecun,"@ylecun I am not sure Lisp or Julia had the level of adoption necessary for growing the ML Ecosystem, outside of Research community. Python was already used by large number of data processing and data analysis folks.",0,0,0
1038,2023-02-22 21:50:14+00:00,ylecun,"@ylecun How does this look like? Any sample (or pseudo) code where lisp is frontend to a DL sys? Jax looks very ‚Äúfunctional‚Äù, so i guess it is not out of q to use lisp?",0,0,0
1039,2023-02-22 21:42:02+00:00,ylecun,@ylecun Yeh Julia,0,0,0
1040,2023-02-22 21:41:37+00:00,ylecun,"@ylecun 1. Fully compiled languages have long been an anachronism 
2. Interpreted languages have their undoubted advantages
3. The costs of processor time for interpretation can be neglected, they are uncritical.
4. I believe the ""problem of white spaces"" can also be neglected üòé",0,0,0
1041,2023-02-22 21:34:07+00:00,ylecun,@ylecun I would prefer BASIC. I developed a lisp last time I spent weeks writing in LISP. Actually I would prefer assembly language over LISP.,0,0,0
1042,2023-02-22 21:25:09+00:00,ylecun,@ylecun Technically not true. Python's ideas of freedom and flexibility on what it's used for is why everyone wants it. Want it faster? Make a C/Rust wrapper. Don't want GIL? Use Pypy.,0,0,0
1043,2023-02-22 21:18:20+00:00,ylecun,"@ylecun Yep, another ridiculous mockery by @GaryMarcus. Like advocating for DL is incompatible with finding Lisp simple and elegant...",0,0,0
1044,2023-02-22 21:17:30+00:00,ylecun,@ylecun Lisp is hard to use.,0,0,0
1045,2023-02-22 21:15:07+00:00,ylecun,"@ylecun LISP has had its day. May as well ask for Perl or TCL.

There's a lot I dislike about Python, but there's a lot I dislike about all of them. Python is good enough.",1,0,0
1046,2023-02-22 21:08:42+00:00,ylecun,"@ylecun Sourceforge, how quaint.",0,0,0
1047,2023-02-22 21:05:37+00:00,ylecun,"@ylecun Python: Arrays is all you need ML.

Arrays are the most important data entities in machine learning.",1,2,0
1048,2023-02-22 21:05:20+00:00,ylecun,"@ylecun python's litany of sins is Immense but i don't think semantic whitespace is really one of them. w.r.t scientific computing + ML, lots of issues that i've seen stem from poorly designed tools/libraries that aren't documented well. the same issues are pervasive in the stdlib too",0,0,0
1049,2023-02-22 21:03:18+00:00,ylecun,"@ylecun The term neuro-symbolic does not appear on the linked page... so not sure the connection.

Back in the 80s I played with modal logic ideas and started building up diagrams of relationships among words &amp; predicates, I realized ""this is looking more an more like a neural network"".‚Ä¶",1,1,0
1050,2023-02-22 21:01:43+00:00,ylecun,@ylecun Julia is going to be the next major language used for ML. If the number of grad students using it right now is any indication üòÇ,0,3,0
1051,2023-02-22 21:00:31+00:00,ylecun,@ylecun Something that would make tensor dimension obvious to a reader.,0,1,0
1052,2023-02-22 20:59:56+00:00,ylecun,"@ylecun The thing is, adoption is not about technical features. It's a mix of proper marketing and fitting into developers' day-to-day productivity.",0,0,0
1053,2023-02-22 20:59:46+00:00,ylecun,@ylecun So it's really the white spaces that hindered ML...,0,1,0
1054,2023-02-22 20:59:43+00:00,ylecun,@ylecun Honestly Swift would have been an amazing candidate (it actually still is!),0,0,0
1055,2023-02-22 20:58:25+00:00,ylecun,"@ylecun Lush was nice.

https://t.co/7XgK2939mW",0,0,0
1056,2023-02-22 20:55:08+00:00,ylecun,"@ylecun classic chasm - strongly typed (+ panoply of type inferencing, closures, thread safe etc etc) languages are revered by AI innovators. weakly typed languages by mass market AI adopters",0,2,0
1057,2023-02-22 20:54:13+00:00,ylecun,"@ylecun What? I hadn't seen a single ML application where python overhead was a significant. Moreover GIL? How GIL affects ML applications? Any ML framework looks like this: https://t.co/ncIGNWYtjB

Python only job is to make API calls, not to process data.",0,5,0
1058,2023-02-22 20:45:32+00:00,ylecun,"@ylecun Two fellows pissing in each others wheaties over Python (or technically one).

Who can build a simulation to determine who is right?",0,2,0
1059,2023-02-22 20:44:43+00:00,ylecun,@ylecun I'm curious: what is @tunguz hot take? He appears to have blocked me...,0,0,0
1060,2023-02-22 20:38:33+00:00,ylecun,@ylecun Python is dependant reliant. And this makes it both powerful and eccentric. Often when you install a git cloned project you must spend time in a purpose built env to configure it. I have a solution.,0,0,0
1061,2023-02-22 20:35:58+00:00,ylecun,"@ylecun Oooh I love that web page. Nostalgic. That‚Äôs how the Web was meant to be, and that‚Äôs how I experienced it for many years. Thank you Tim Berners-Lee.",1,2,0
1062,2023-02-22 20:34:04+00:00,ylecun,"@ylecun Python is the new Basic, with the same one strength (easy to start), and the very same long list of shortcomings.",0,1,0
1063,2023-02-22 20:32:31+00:00,ylecun,"@ylecun Python is the Austin,TX of languages: aggressively meh, maybe OK, but overrated by its fans to the point of comedy.  ‚ÄúThe GIL is good, actually, as is having to write every meaningful library in C‚Äù.",0,2,0
1064,2023-02-22 20:31:04+00:00,ylecun,"@ylecun To be fair, I don't think vision people would have even cared about implementing a ConvNet in 2005 without something big like ImageNet '12 results to change their minds.",0,2,0
1065,2023-02-22 20:27:04+00:00,ylecun,@ylecun @OuahabiAdnane We also did try with https://t.co/TQFKN45O33 but it didn‚Äôt go super far unfortunately,0,2,0
1066,2023-02-22 20:26:19+00:00,ylecun,@ylecun Uncool take: Rust is the best language for Machine Learning,0,1,0
1067,2023-02-22 20:25:59+00:00,ylecun,@ylecun F#,0,0,0
1068,2023-02-22 20:24:45+00:00,ylecun,@ylecun @OuahabiAdnane Those people shout quite loudly when meet with reality that Python costs 3x in production.,0,0,0
1069,2023-02-22 20:21:55+00:00,ylecun,"@ylecun Yes, Python is a nightmare at production. From the other side, as an era of manual programming is eventually going nowhere, development of any new language (for humans) is a waste of money.",0,0,0
1070,2023-02-22 20:20:17+00:00,ylecun,@ylecun In your opinion. What‚Äôs the biggest strength of Lisp?,0,0,0
1071,2023-02-22 20:19:14+00:00,ylecun,@ylecun Julia ‚ù§Ô∏è,0,0,0
1072,2023-02-22 20:17:29+00:00,ylecun,@ylecun I don't think so,0,0,0
1073,2023-02-22 20:14:51+00:00,ylecun,@ylecun Would you recommend trying out Lisp for some deep learning projects even today? Just as a learning experience if nothing else,0,0,0
1074,2023-02-22 20:02:34+00:00,ylecun,@ylecun How close does Pyro come? Any other probabilistic programming languages?,0,0,0
1075,2023-02-22 19:54:49+00:00,ylecun,@ylecun @OuahabiAdnane üòÇ,0,0,0
1076,2023-02-22 19:54:22+00:00,ylecun,@ylecun Anybody please tell me another language that has a pandas dataframe in it,1,0,0
1077,2023-02-22 19:50:20+00:00,ylecun,"@ylecun I am quite excited about Julia projects such as Flux and KNet, as well as a possible pure Julia frontend to PyTorch. As someone who works with intensive economic simulations using small neural networks, I lose a LOT of speed having to do the simulation part in Python",0,1,0
1078,2023-02-22 19:43:50+00:00,ylecun,"@ylecun Amen! Preach the word, brother. https://t.co/vB8nX0m76k",0,1,0
1079,2023-02-22 19:43:41+00:00,ylecun,@ylecun So much time on pyenv,0,0,0
1080,2023-02-22 19:41:14+00:00,ylecun,"@ylecun A properly interactive, reflective, dynamic, live, extensible, language is rather helpful. Not a dull, rigid, dead-text-in-files, blah pile of tedium.",0,0,0
1081,2023-02-22 19:40:55+00:00,ylecun,@ylecun We should have stuck with the Lisp Machine,0,1,0
1082,2023-02-22 19:40:26+00:00,ylecun,"@ylecun Disagree! Matlab allowed rapid prototyping during the NN1.0 winter. Mixing and matching EE (2d/3d signal proc), stat, ideas with CS to come up with novel methods that still  had to wait for a decade for faster parallel procs to eventually evolve into NN2.0.",0,0,0
1083,2023-02-22 19:37:36+00:00,ylecun,"@ylecun ü§£@ylecun endorses the original symbol-manipulation language, LISP, for the win!",7,44,1
1084,2023-02-22 19:34:26+00:00,ylecun,"@ylecun What are the practical implications of transitioning to a different language for ML, given the significant effort and resources required to make the switch?  ü§î",0,0,0
1085,2023-02-22 19:24:54+00:00,ylecun,"@ylecun I wrote a quant analysis platform on Julia and found the garbage collector to be a major bottleneck.

Sometimes a simple accumulator would spend 50% of it's time in GC without many ways to fine tune it.

Grass is always greener I guess.",0,2,0
1086,2023-02-22 19:23:15+00:00,ylecun,@ylecun Define bloated.,0,0,0
1087,2023-02-22 19:22:07+00:00,ylecun,"@ylecun @ylecun @tunguz  Julia has the potential, and satisfy the above, but sadly haven't been widely used by the ML community. Regarding GIL, there is promising news: https://t.co/q4koh4Sqth",0,3,0
1088,2023-02-22 19:20:26+00:00,ylecun,"@ylecun didn't @jeremyphoward already talk about this &amp; came around on this mentality?

https://t.co/oBf0TesZHk https://t.co/WymSbynWRw",0,1,0
1089,2023-02-22 19:14:52+00:00,ylecun,"@ylecun @MetaAI I would enjoy a ""personality"" selector, so that a bias is introduced for the LLM to speak and contextualize as a ""professor"" or ""father"" or ""influencer"" etc.",0,0,0
1090,2023-02-22 19:14:47+00:00,ylecun,"@ylecun @OuahabiAdnane Is it possible that people have good reasons for wanting Python? 

Is it possible that those same reasons are why Python+ML has been so wildly successful?

Is it possible that if you stayed the course and engineers ""hated it"" that ML would have been held back considerably?",4,97,1
1091,2023-02-22 19:14:42+00:00,ylecun,@ylecun Only if humans loved them half as much as they do Python,0,0,0
1092,2023-02-22 19:13:12+00:00,ylecun,"@ylecun I don't think Python (of today) is bad enough to incur enough problems to slow down progress.

I agree with Bojan, that people tend to overrate technical merits while underrate other aspects: tooling, libraries, popularity, package management, etc.",2,67,0
1093,2023-02-22 19:10:04+00:00,ylecun,@ylecun I get your point but disagree. Python made it accessible and amplified the snowball effect of having more people involved in the field leading to more innovation. Most of the people I have in my classes would not code in C++. Most ML hackers on GitHub either,1,2,0
1094,2023-02-22 19:05:03+00:00,ylecun,"@ylecun Julia is like if you take the worst from Matlab and PHP and sprinkle it with multiple dispatch and LLVM.

The frosting looks great, but you will suffer with severe diarrhea if you try to build anything production grade.",0,0,0
1095,2023-02-22 19:04:14+00:00,ylecun,@ylecun It's no less of a nightmare to implement it in C++.,1,0,0
1096,2023-02-22 19:03:57+00:00,ylecun,@ylecun This has been my feeling for a long time.  I want a strongly typed language similar to TypeScript but that is fully compiled and good for ML and parallel computing. Golang could have been that but the designers got too creative.,0,0,0
1097,2023-02-22 18:57:55+00:00,ylecun,@ylecun Rust?,0,0,0
1098,2023-02-22 18:55:41+00:00,ylecun,@ylecun The only language I learned in college was MatLab and it taught me bad habits that took years to untrain. It being baselined in college is not only expensive but detrimental to education quality.,1,23,2
1099,2023-02-22 18:47:25+00:00,ylecun,"@ylecun It didn‚Äôt happen 
And did you know google tried swift for ml? Failed",0,0,0
1100,2023-02-22 18:41:13+00:00,ylecun,@ylecun I trained my first MLP in Matlab back in 1999...you never forget your first love,0,0,0
1101,2023-02-22 18:40:11+00:00,ylecun,"@ylecun @tunguz @ylecun I would suggest that it wasn‚Äôt the particular language that was important, but the fact that so many people ended up on a particular language and it‚Äôs associated packages (tf, PyTorch, numpy, etc). It was a coordination problem .
 
And Yann - whitespace? Really?",0,1,0
1102,2023-02-22 18:38:26+00:00,ylecun,@ylecun https://t.co/lEpP9nJo5n has that potential.,0,2,0
1103,2023-02-22 18:37:36+00:00,ylecun,@ylecun When will Meta come out with its own ChatGPT equivalent? You already have OPT 175B .,1,0,0
1104,2023-02-22 18:36:16+00:00,ylecun,@ylecun Or elixir,0,0,0
1105,2023-02-22 18:34:49+00:00,ylecun,@ylecun Clojure,0,3,0
1106,2023-02-22 18:31:58+00:00,ylecun,@ylecun Hinton disagrees (although i guess Alex net was python) https://t.co/g34OWM7dEq,0,2,0
1107,2023-02-22 18:29:25+00:00,ylecun,"@ylecun Any language could easily replace python, it's used for ML because it was easily adopted because of how simple it was and tools were built around it, which is why I think Rust will be a preferred language in the future. Also python is slow rust is very fast",1,0,0
1108,2023-02-22 18:21:17+00:00,ylecun,@ylecun ü§î,0,1,0
1109,2023-02-22 18:21:06+00:00,ylecun,@ylecun The operator precedence in lisp not following classical mathematics is a major deterrent imo,0,0,0
1110,2023-02-22 18:19:06+00:00,ylecun,@ylecun @yacineMTB what made you... stop thinking about Javascript?,0,1,0
1111,2023-02-22 18:18:17+00:00,ylecun,@ylecun Lisp had its chance. It didn‚Äôt make it.,0,0,0
1112,2023-02-22 18:18:09+00:00,ylecun,"@ylecun Not sure if this is a hot take, many people will agree with you Matlab was/is a nightmare! I for one agree with you",0,0,0
1113,2023-02-22 18:15:02+00:00,ylecun,@ylecun Read my lisp.,0,0,0
1114,2023-02-22 18:07:33+00:00,ylecun,@ylecun So GPTx etc all programmed with Python?,0,0,0
1115,2023-02-22 18:07:03+00:00,ylecun,@ylecun The fact python executes line by line unlike some compiled language is a feature not a bug. This makes mere mortals capable of debugging code.,0,0,0
1116,2023-02-22 18:05:55+00:00,ylecun,@ylecun Even hotter: ML would have advanced faster if everyone wasn‚Äôt lazy and learned C. The end.,0,0,0
1117,2023-02-22 18:05:52+00:00,ylecun,"@ylecun It's been a while since I've had the chance to use them but I wonder how ML in a language with dependent types could look - ideally it'd allow leveraging the compiler for kernel generation XLA-style, and compiler warnings/errors for shape and architecture issues",0,0,0
1118,2023-02-22 18:02:55+00:00,ylecun,@ylecun @OuahabiAdnane Isn't it a better argument than the ones you gave 'agaisnt' python tho?,1,0,0
1119,2023-02-22 18:00:39+00:00,ylecun,@ylecun Still prefer Java or Scala but they dont seem to be how kids learn CS nowadays.,2,3,0
1120,2023-02-22 17:51:44+00:00,ylecun,@ylecun @jackrusher #Clojure,0,0,0
1121,2023-02-22 17:50:37+00:00,ylecun,"@ylecun Its not to late to switch to Julia (its a good language!). Python is great because its so easy, but In my mind there is a weird contradiction between people doing all the advanced  ml stuff in a language that has multithreading issues. Dunno if multithreading is needed but still.",1,5,0
1122,2023-02-22 17:50:16+00:00,ylecun,@ylecun https://t.co/EhDr9bgJ96,0,0,0
1123,2023-02-22 17:46:18+00:00,ylecun,"@ylecun Coulda, shoulda, woulda. Unprovable counter factual.",0,0,0
1124,2023-02-22 17:44:31+00:00,ylecun,"@ylecun why do you need multi threading in the front end language? You‚Äôre still actually writing the optimizers on a gpu, in c++, or fortran.  Python is just used as glue code",2,6,0
1125,2023-02-22 17:37:55+00:00,ylecun,"@ylecun @OuahabiAdnane I've written a reasonable amount of lua. I think the issue is more 'lua sucks' x 3, or more precisely 'lua is really small so needs more typing' x 3.",0,1,0
1126,2023-02-22 17:37:23+00:00,ylecun,@ylecun The trend towards real-time systems with continual learning means that a language with a strong concurrency story might have a chance to take over. Elixir is theoretically nice but node has the ecosystem behind it.,0,0,0
1127,2023-02-22 17:34:30+00:00,ylecun,"@ylecun Ahem...#Clojure. @ylecun, there is a modern Lisp that satisfied those requirements.",0,3,0
1128,2023-02-22 17:34:20+00:00,ylecun,"@ylecun Is it true physicists started the whole python-&gt;ML path, ‚Äúaccidentally‚Äù choosing python as the code steering language to do underlying heavy computation?",1,0,0
1129,2023-02-22 17:27:04+00:00,ylecun,@ylecun Curious on your take on what made Python more popular than some of the others you list?,0,0,0
1130,2023-02-22 17:24:56+00:00,ylecun,@ylecun Why I no longer recommend Julia https://t.co/jepveKHjL4,0,0,0
1131,2023-02-22 17:23:24+00:00,ylecun,"@ylecun Yann, please... You are making me sad...",0,0,0
1132,2023-02-22 17:22:47+00:00,ylecun,@ylecun A DSL on top of Rust macros would be ideal.,0,0,0
1133,2023-02-22 17:22:24+00:00,ylecun,"@ylecun (in a fozzie bear voice) weka, weka, weka.. ML in Java starting in 1997: https://t.co/ywj0LuaGCB üêª For comparison, Python 2.0 wasn't released until 2000.",1,4,0
1134,2023-02-22 17:22:24+00:00,ylecun,@ylecun #Elixir,0,0,0
1135,2023-02-22 17:19:12+00:00,ylecun,@ylecun But Meta was pushing for Kotlin‚Ä¶ and even a preliminary version of DiffKt got published. Software 2.0‚Ä¶,0,0,0
1136,2023-02-22 17:17:30+00:00,ylecun,"@ylecun Then again, debugging all kinds of JIT stuff is a pain...",0,0,0
1137,2023-02-22 17:16:53+00:00,ylecun,@ylecun @MetaAI Excellent !!,0,0,0
1138,2023-02-22 17:15:49+00:00,ylecun,"@ylecun @OuahabiAdnane It could be more type safe (simplifying refactoring), concurrency is a mess, and it has weak abstraction capabilities.

Performance is low and energy usage is high.

I suspect that its weak type safety is attractive for many.

Python is like a gas guzzling V12 engine. https://t.co/y0Vi7OBnNb",1,5,0
1139,2023-02-22 17:14:57+00:00,ylecun,"@ylecun Ya know, there may be reasons those languages were not adopted. üòÅ",0,0,0
1140,2023-02-22 17:13:06+00:00,ylecun,@ylecun What‚Äôs your take on this @TariqDaouda?,1,0,0
1141,2023-02-22 17:06:54+00:00,ylecun,@ylecun Kind of what I‚Äôm working on,1,0,0
1142,2023-02-22 17:03:08+00:00,ylecun,"@ylecun I think jupyter had more to do with it.
Not having to run the entire script or saving every intermediate output allowed for much easier experimentation.",0,0,0
1143,2023-02-22 17:01:12+00:00,ylecun,@ylecun Lua?,0,0,0
1144,2023-02-22 17:00:19+00:00,ylecun,@ylecun How would any of those moved the needle?,0,1,0
1145,2023-02-22 16:53:48+00:00,ylecun,@ylecun Clojure always seemed like such a natural fit... Oh well. :),0,0,0
1146,2023-02-22 16:51:51+00:00,ylecun,"@ylecun This is not a hot take and is contrarian for the sake of being provocative, not because it illuminates anything interesting.",0,0,0
1147,2023-02-22 16:49:01+00:00,ylecun,@ylecun @OuahabiAdnane i wonder why people want python .... maybe features like easy to learn and fast prototyping,2,2,0
1148,2023-02-22 16:47:53+00:00,ylecun,@ylecun The Matlab hell honestly I struggled translating between languages during my masters and I just don't bother in my PhD.  It's so expensive and not accessible... WHY!,0,0,0
1149,2023-02-22 16:47:42+00:00,ylecun,"@ylecun @Gilad_Bracha Hottest take: Otherwise intelligent people spend way too much time arguing about programming languages. This is doubly true for proponents of languages that never achieved mainstream popularity (e.g., Lisp, Smalltalk).",13,151,5
1150,2023-02-22 16:46:13+00:00,ylecun,@ylecun Julia üíØ,0,1,0
1151,2023-02-22 16:45:41+00:00,ylecun,@ylecun Hot take: Multicore Oberon could have been extended for ML,0,0,0
1152,2023-02-22 16:43:59+00:00,ylecun,@ylecun Are white spaces really that bad?,0,0,0
1153,2023-02-22 16:42:52+00:00,ylecun,"@ylecun At some point ""you know who"" is going to tell us all to just use Wolfram lang    (""HotTake[]"")",0,0,0
1154,2023-02-22 16:40:49+00:00,ylecun,@Jinom's account is temporarily unavailable because it violates the Twitter Media Policy. Learn more.,0,1,0
1155,2023-02-22 16:39:55+00:00,ylecun,"@ylecun Is Python *really* on the hot path often enough that the Gil is a pain point? It certainly was when I started building ML models, but usually it was because I had the entirely wrong mental model for how e.g. my data in-feed should work",2,14,1
1156,2023-02-22 16:36:03+00:00,ylecun,@ylecun Why didn‚Äôt Julia pickup? Would have been perfect with some corporate backing from a FAANG. Hope not too late though. Working through Python‚Äôs limitations is painful.,1,3,1
1157,2023-02-22 16:34:30+00:00,ylecun,@ylecun I think you would have loved Occam / Transputer.,0,0,0
1158,2023-02-22 16:30:56+00:00,ylecun,@ylecun @OuahabiAdnane damn programming languages that do the same thing by changing names and syntax,0,0,0
1159,2023-02-22 16:28:20+00:00,ylecun,@ylecun https://t.co/h1mRzBJNlk,0,0,0
1160,2023-02-22 16:26:30+00:00,ylecun,@ylecun @OuahabiAdnane Did you do any digging to drill into why people want Python?,0,2,0
1161,2023-02-22 16:23:04+00:00,ylecun,@ylecun Swift would‚Äôve been cool too. https://t.co/63wCZu1TrC,0,1,0
1162,2023-02-22 16:19:17+00:00,ylecun,@ylecun Like Julia @JuliaLanguage,0,3,0
1163,2023-02-22 16:17:51+00:00,ylecun,@ylecun Would removing the GIL make a real difference in performance when it comes to ML tasks?,0,0,0
1164,2023-02-22 16:17:13+00:00,ylecun,@ylecun Would the Rust ecosystem fill that void in the future?,1,3,0
1165,2023-02-22 16:16:29+00:00,ylecun,@ylecun Or one where pip wheels weren't a broken concept and trying to installing tensorflow didn't put you in a place where you had to reinstall linux,0,3,1
1166,2023-02-22 16:14:13+00:00,ylecun,@ylecun I had the feeling Prolog was a better language than Lisp to boost algorithms‚Ä¶ but it doesn‚Äôt matter anymore,0,0,0
1167,2023-02-22 16:11:38+00:00,ylecun,@ylecun I don't know a lot to argue with the experts but why do I have the feeling that some people don't like the fact that ML has become readily available because of Python? Most of the arguments against Python is pedestrian. There is no perfect programming language. I am already using‚Ä¶,3,13,0
1168,2023-02-22 16:07:52+00:00,ylecun,@ylecun Jeremy Howard thinks the same https://t.co/r1QHWkxpnf,0,0,0
1169,2023-02-22 16:04:42+00:00,ylecun,@ylecun https://t.co/2Q4hi8bp64,0,2,0
1170,2023-02-22 16:04:26+00:00,ylecun,@ylecun Why do people hate white space so much...do y'all never want to write clean code?,0,0,0
1171,2023-02-22 16:03:17+00:00,ylecun,@ylecun If you'd insisted on LISP your user community would be Paul Graham (only).,0,2,0
1172,2023-02-22 16:00:17+00:00,ylecun,"@ylecun Whitespace is a non-issue. 

The GIL usually isn't an issue, but is an easy target.

The bloat... well I won't argue with that. It is getting better though!",0,1,0
1173,2023-02-22 15:59:41+00:00,ylecun,@ylecun We ran this experiment in the 80s.,0,1,0
1174,2023-02-22 15:57:31+00:00,ylecun,@ylecun Elixir https://t.co/xxlK43NZuY,0,38,4
1175,2023-02-22 15:50:01+00:00,ylecun,@ylecun I would say try malboge,0,2,0
1176,2023-02-22 15:48:57+00:00,ylecun,"@ylecun @OuahabiAdnane Not really, I'd switch from python instantly, but there isn't anything mature enough. There are torch bindings for Elixir and it looks serious, but I haven't tried yet. Any other alternatives?",2,1,0
1177,2023-02-22 15:45:14+00:00,ylecun,@ylecun Yes for Lisp.,0,0,0
1178,2023-02-22 15:40:28+00:00,ylecun,@ylecun I think the accessibility of Python trumps these issues tbh. So not so sure. Easy to deal in alternate histories - the key question is where we should go next in terms of languages?,0,2,0
1179,2023-02-22 15:39:17+00:00,ylecun,"@ylecun There was no great superpower that ordered ML to be done in Python, nor which frameworks would win. 

The community as a whole chose it.

People did try to use other langs, people still are trying. 

Python just works. ML in Py was adopted and innovated extremely fast.",9,211,4
1180,2023-02-22 15:38:08+00:00,ylecun,@ylecun @OuahabiAdnane Perhaps for a reason?,0,0,0
1181,2023-02-22 15:37:34+00:00,ylecun,@ylecun The tuples and the lack of brackets kills me,0,1,0
1182,2023-02-22 15:37:13+00:00,ylecun,@ylecun @OuahabiAdnane you should check Julia. It's like Python + C,0,1,1
1183,2023-02-22 15:35:35+00:00,ylecun,@ylecun Make prolog great again!,0,0,0
1184,2023-02-22 15:34:03+00:00,ylecun,"@ylecun Some tried with Swift for Tensorflow :)

But yeah, Python seems like an unfortunate local optima that was ‚Äútoo convenient‚Äù and available and prevented a better solution from emerging‚Ä¶",2,29,1
1185,2023-02-22 15:34:00+00:00,ylecun,@ylecun i really like julia,0,1,0
1186,2023-02-22 15:27:11+00:00,ylecun,@ylecun @OuahabiAdnane Now we're stuck with Python because people want Pytorch,0,1,0
1187,2023-02-22 15:26:43+00:00,ylecun,"@ylecun But none of python ML library, like, jax, torch, has these issue ...",0,1,0
1188,2023-02-22 15:24:42+00:00,ylecun,"@ylecun What do you think about designing a new LISP-like language from the bottom-up specifically for ML? A functional, differentiable programming language perhaps?",0,1,0
1189,2023-02-22 15:22:31+00:00,ylecun,"@ylecun Julia has been out for a while and has a passionate, albeit niche following. There might have been a chance for it to overtake Python, but the center of gravity of the developer ecosystem has voted for their language of choice.",3,2,0
1190,2023-02-22 15:22:28+00:00,ylecun,@ylecun I am still waiting for @PyTorch to have similar support in Julia as Python. @JuliaLanguage is clearly a better language for ML than Python.,1,2,0
1191,2023-02-22 15:21:15+00:00,ylecun,@ylecun @OuahabiAdnane What about Lush? I never used it but did hear about it and seemed really interesting. It seems to match your criteria although I don't know about GIL part? Why Lua instead of Lush back then?,1,0,0
1192,2023-02-22 15:20:43+00:00,ylecun,@ylecun I love seeing some MATLAB hate with my morning coffee. Spread the hate.,0,3,0
1193,2023-02-22 15:20:28+00:00,ylecun,"@ylecun Again that‚Äôs dumb take moreso. Multithreaded app requires smart thinking, and time spent in software design. It‚Äôs not what people want to spend time on. Nobody cares about ¬´¬†bloat¬†¬ª or white space lol",0,0,0
1194,2023-02-22 15:19:01+00:00,ylecun,"@ylecun Prolog, ish.",0,0,0
1195,2023-02-22 15:16:20+00:00,ylecun,@ylecun Imagining ML advancing faster than it has makes my head explode,0,0,0
1196,2023-02-22 15:14:20+00:00,ylecun,@ylecun why we can't just switch to a more efficient language yet.,0,0,0
1197,2023-02-22 15:13:11+00:00,ylecun,"@ylecun I started to make a Simulink analogue, but using the Python ecosystem rather than the MathWorks ecosystem.

I feel like it would be useful for helping deploy and test ML models, and integrate them with wider systems.

Any interest in this?",0,2,0
1198,2023-02-22 15:09:52+00:00,ylecun,@ylecun Agreed.,0,0,0
1199,2023-02-22 15:09:48+00:00,ylecun,@ylecun @OuahabiAdnane We do,0,0,0
1200,2023-02-22 15:09:45+00:00,ylecun,@ylecun (Lisp) ü§£,0,0,0
1201,2023-02-22 15:09:42+00:00,ylecun,@ylecun @martin_trapp cc'ing @JuliaLanguage,0,3,0
1202,2023-02-22 15:05:50+00:00,ylecun,"@ylecun ""worse is better"" - Interface does not matter much, simplicity of implementation matters. Python is just an API over  C++  implementations. The PyTorch strategy was the right one.",0,7,0
1203,2023-02-22 15:05:31+00:00,ylecun,@ylecun @OuahabiAdnane So that disproves your thesis then lol,1,1,0
1204,2023-02-22 15:04:46+00:00,ylecun,"@ylecun I feel like this is a less hot take ü§£

One of the reasons I was so pissed about potentially using matlab in undergrad was that the cost of a license is absurd

So I used python for my graduate research 

And to this day I absolutely refuse to vendor lock my skillsets",0,18,0
1205,2023-02-22 15:00:54+00:00,ylecun,"@ylecun Julia wasn‚Äôt mature enough when the jump from Torch to PyTorch happened. Julia 1.8 may have been nice, but probably not Julia 0.6. Also, nobody knew Julia (it‚Äôs new!), and python is/was a top 5 programming language. I love Julia and hope to see it adopted, just not in hindsight.",0,7,0
1206,2023-02-22 15:00:27+00:00,ylecun,"@ylecun If things unfolded the way they did, it's because Python was easier to use. Libraries were built quickly with it and served as a foundation for ML. Also, the ""bad"" performance of Python is impactless when doing ML since model training is not done in Python anyways.",0,0,0
1207,2023-02-22 15:00:12+00:00,ylecun,@ylecun This is indeed a hot take and I fully agree -- a lisp like language would have been perfect. But I wonder in which universe is the original a hot take. I have heard that for like 10 years.,0,1,0
1208,2023-02-22 14:55:25+00:00,ylecun,@ylecun @OuahabiAdnane Not sure why people have so much affinity towards python.,0,0,0
1209,2023-02-22 14:54:37+00:00,ylecun,"@ylecun I use Clojure for ML. It's great. And Python interop with libpython-clj works great as well, so I can pull in anything from python that isn't available on Clojure yet.",0,1,0
1210,2023-02-22 14:52:37+00:00,ylecun,"@ylecun @eulerfx The main downside of the .NET ecosystem is the lack of GPU codegen, compared to the LLVM ecosystem.",1,6,0
1211,2023-02-22 14:52:09+00:00,ylecun,@ylecun @yacineMTB *Cries in Julia*,0,1,0
1212,2023-02-22 14:51:38+00:00,ylecun,@ylecun @OuahabiAdnane Lua ü§¢,0,0,0
1213,2023-02-22 14:49:41+00:00,ylecun,"@ylecun @OuahabiAdnane TensorFlow tried to do that with Swift, it went nowhere. https://t.co/IIA0I6rVFS",0,0,0
1214,2023-02-22 14:49:13+00:00,ylecun,"@ylecun I spent time time trying to do just that in Haskell. But realized that despite being able to do a lot of stuff better than python or r, there was no path to being able to support myself doing that work.",1,12,0
1215,2023-02-22 14:49:00+00:00,ylecun,"@ylecun GIL is a feature, not a bug üôÇ. It enforces most computational tasks to be implemented in C, which is best.",0,1,0
1216,2023-02-22 14:48:49+00:00,ylecun,@ylecun Even Hotter take: ML can be adopted faster by letting coders develop in their preferred language (e.g. python) and have a common familiar frontend for everyone to use and explore ML algorithms: Check out CODIDO (https://t.co/D0ES0uxVXU). Just like YouTube/Facebook did for social.,0,4,0
1217,2023-02-22 14:48:01+00:00,ylecun,"@ylecun We have LLMs that effortlessly convert between languages now with a 99% hit rate‚Ä¶ what‚Äôs the complaint again?

Really, we should be fine-tuning a model for an AI first programming language and letting the LLM show it to humans in whatever format works best for that human. ü§∑‚Äç‚ôÇÔ∏è",1,5,0
1218,2023-02-22 14:47:01+00:00,ylecun,@ylecun @yacineMTB I actually got into TF through TFJS,0,3,0
1219,2023-02-22 14:46:33+00:00,ylecun,"@ylecun I don't even know why MATLAB is still taught in universities today, when Python can do everything it can do, and much more.",0,3,0
1220,2023-02-22 14:45:03+00:00,ylecun,@ylecun Languages with complicated macrosystem produce bloated code in wrong hands. Python restrictions (including GIL) force people to write nicer code,1,2,0
1221,2023-02-22 14:41:59+00:00,ylecun,"@ylecun @OuahabiAdnane personally think Lua more interesting than Python for some ML usage. Although, it is less developer friendly than Python for sure. So I see those 3 reasons being predominant.",0,0,0
1222,2023-02-22 14:41:35+00:00,ylecun,"@ylecun Yeah, I really agree with that!",0,0,0
1223,2023-02-22 14:40:51+00:00,ylecun,"@ylecun Yeah, I don‚Äôt agree with that‚Ä¶",0,1,0
1224,2023-02-22 14:40:30+00:00,ylecun,"@ylecun @MartinuzziFra Whenever Meta wants to start supporting Julia, give me a call : )",3,144,3
1225,2023-02-22 14:39:46+00:00,ylecun,"@ylecun Well, F#",0,0,0
1226,2023-02-22 14:39:17+00:00,ylecun,@ylecun So wrong. Julia is plain ugly and (((((((lisp))))))))))) and it's various dialects are abominations.,0,0,0
1227,2023-02-22 14:38:45+00:00,ylecun,@ylecun Why don‚Äôt we build one? ‚Ä¶. I know your 3 reasons not to ‚Ä¶ but it would be fun‚Ä¶ seriously!,0,0,0
1228,2023-02-22 14:37:50+00:00,ylecun,@ylecun I am really attempted to unfollow you after admiring Lisp you old man!,0,0,0
1229,2023-02-22 14:37:22+00:00,ylecun,"@ylecun Python brought the largest number of people to ML. Had it been Julia, Lisp, or even worse F#, the barrier to entry would be much higher, and we didn't have so many contributors to the field, especially in applications.",1,8,0
1230,2023-02-22 14:37:00+00:00,ylecun,@ylecun Oh hi! üëã,0,22,0
1231,2023-02-22 14:35:53+00:00,ylecun,@ylecun or crystal,0,0,0
1232,2023-02-22 14:34:51+00:00,ylecun,@ylecun Python is the API layer.,0,0,0
1233,2023-02-22 14:34:20+00:00,ylecun,"@ylecun Question: for someone wanting to learn to code (goal data science/analysis or ML), Which is better; python, Julia or lua?",0,2,0
1234,2023-02-22 14:33:50+00:00,ylecun,@ylecun Do you agree that English is the next high level programming language? Or does another language get released soon that's better than Python and Julia?,0,0,0
1235,2023-02-22 14:33:42+00:00,ylecun,"@ylecun Hard disagree, ML advanced because of the Python ecosystem which was built by volunteers over two decades bit by bit. They loved the language syntax over anything that was available. Even if your ""utopian"" language available there is no guarantee such a community would be there.",0,0,0
1236,2023-02-22 14:31:37+00:00,ylecun,"@ylecun Oh, I remember... üçø",0,0,0
1237,2023-02-22 14:31:12+00:00,ylecun,"@ylecun I stepped into a bit of astronomy, doing data reductions in python and felt so empowered, dreaming of buikding an amateurish framework. Then I discovered Sextractor, a c program who operates the same reductions a 100x faster and wondered about the rationality of python libs.",5,4,0
1238,2023-02-22 14:30:46+00:00,ylecun,"@ylecun Cooler take: what gets widely adopted, gets adopted for a reason. Human reasons, not purely technical or aesthetic reasons.
Python is certainly not ideal but it wins on day-to-day usability. Practice has the last word.",2,44,0
1239,2023-02-22 14:30:43+00:00,ylecun,@ylecun Not Lisp,0,1,0
1240,2023-02-22 14:29:24+00:00,ylecun,"@ylecun Sure, lets use some languages people dont know, lacking an eco system and are locking you in. 

Why you dont write your compiler for Python instead of for Lua? Or improve the interpreter? FB did this for PHP once for what I remember.",0,0,0
1241,2023-02-22 14:28:49+00:00,ylecun,"@ylecun As student, I had to use MatLab for my pattern recognition and data mining classes.

Sometimes, I had to stay up all night to translate my Python homework solutions to MatLab for submission. No sleep, no nightmares üòÜ.",2,121,2
1242,2023-02-22 14:24:44+00:00,ylecun,"@ylecun Even with all of this, @AndrewYNg legendary course which taught ML to a whole generation was written in Octave/Matlab",3,10,0
1243,2023-02-22 14:21:50+00:00,ylecun,"@ylecun Clojure, e.g. https://t.co/xjRFaq5tCL",0,0,0
1244,2023-02-22 14:21:45+00:00,ylecun,@ylecun @JuliaLanguage is an awesome language. Wish it had wider adoption!,0,2,0
1245,2023-02-22 14:19:59+00:00,ylecun,@ylecun Probably several GWh would have been saved too if they'd used Rust instead of Python,0,0,0
1246,2023-02-22 14:19:30+00:00,ylecun,@ylecun This is still holding academia back in many other fields.,0,18,0
1247,2023-02-22 14:18:12+00:00,ylecun,@ylecun Julia should be promoted.,0,1,0
1248,2023-02-22 14:17:51+00:00,ylecun,@ylecun Python is but a wannabe Lisp unbracketed for folks who think it  imperative that a language be devoid of parenthetical subtleties..,2,4,0
1249,2023-02-22 14:17:40+00:00,ylecun,"@ylecun Thanks to ML being annoyed of that, there are big efforts to remove the GIL and speed-up Python.",1,0,0
1250,2023-02-22 14:14:03+00:00,ylecun,@ylecun Julia is the perfect language for ML that is always 5 years away from getting traction.,3,59,1
1251,2023-02-22 14:12:21+00:00,ylecun,@ylecun So you're saying ppl who would want to work on cutting edge ML should learn Julia/lisp?,0,1,0
1252,2023-02-22 14:12:14+00:00,ylecun,"@ylecun Absolutely true, the lack of real multithreading and just generally ultra slow flow control (esp. loops) makes it a pain to develop highly performant microservices",0,0,0
1253,2023-02-22 14:09:13+00:00,ylecun,"@ylecun 1. Java
2. Assembly
3. PHP
4. SQL
5. C
6. Matlab
7.  Python
8. Prolog
9. R
10. Javascript",0,0,0
1254,2023-02-22 14:09:09+00:00,ylecun,@ylecun What about R?,0,1,0
1255,2023-02-22 14:08:48+00:00,ylecun,@ylecun Julia,0,2,0
1256,2023-02-22 14:08:12+00:00,ylecun,@ylecun Matlab still exists only because engineers need simulink,2,2,0
1257,2023-02-22 14:02:47+00:00,ylecun,"@ylecun Clear sir, it is all about people! and lets say people want Python because of the abundance of tools/libraries, therefore the strong network effects.

Wondering if any language to come in the future then it has to have interoperability with Python as a cold start growth hack üòÖ",1,1,0
1258,2023-02-22 14:01:41+00:00,ylecun,@ylecun Still better than Java.,0,0,0
1259,2023-02-22 14:01:22+00:00,ylecun,"@ylecun @OuahabiAdnane A lot of engineers in other domains hate Python. It's such a mess, so hard to deploy, so slow, and not very secure.",1,1,0
1260,2023-02-22 14:00:22+00:00,ylecun,@ylecun Hottest of takes,0,0,0
1261,2023-02-22 13:59:11+00:00,ylecun,@ylecun Isn‚Äôt matlab good for matrix multiplication (and vectorized ops generally) so would love to hear how it was a nightmare to write a convnet with matlab?,3,0,0
1262,2023-02-22 13:59:09+00:00,ylecun,"@ylecun I'm not a big fan of python (white space as syntax is a no go for me since fighting with make in the 90th), but the other languages have other problems. (if it is just the smaller user group)",0,2,0
1263,2023-02-22 13:58:01+00:00,ylecun,"@ylecun Not meet other languages, but favor python.
Some line could finish the programming we need to code some days or weeks in C.

Though indeed not memory or speed effective.

In C, it is enjoy to manage even just one bit.",1,2,0
1264,2023-02-22 13:57:03+00:00,ylecun,"@ylecun This is why I am a fan of Node.JS, Swift, and even C# for things like this. Because Node.JS at the least can be multithreaded somewhat using worker_thread and setting up worker-farm.

Swift and C# are just amazing at setting up multithreading.",0,0,0
1265,2023-02-22 13:56:47+00:00,ylecun,"@ylecun ML would have advanced faster *without* a front-end language. Just a fast, high-level, compiled, general programming language with a rich and easy-to-use ecosystem. Unfortunately, that didn't exist before Rust.",3,4,1
1266,2023-02-22 13:56:20+00:00,ylecun,"@ylecun Is there any efforts made by big players in the field (Meta AI, Google,...) to create a new front-end language better than Python? and how much time is gonna take to see Python as a ""alternative choice"" to build a model?",1,2,0
1267,2023-02-22 13:54:20+00:00,ylecun,"@ylecun I did buy a $$$ Matlab licensed but never use. After purchase, quickly learn that python is better at keeping up with the pace.",0,2,0
1268,2023-02-22 13:53:05+00:00,ylecun,"@ylecun @OuahabiAdnane ""People"" (researchers / students, actually) wanted Matlab, and Python had libraries that kind of looked like Matlab.

Lua(JIT) was a Lisp in disguise, much faster than Python and with the ability to drop to C easily. Much, much better for actual implementation engineers.",2,21,1
1269,2023-02-22 13:51:45+00:00,ylecun,"@ylecun There was never a need for python,you had common lisp at home.",0,0,0
1270,2023-02-22 13:51:16+00:00,ylecun,@ylecun Oh LOL. I *had* to use Matlab at Uni.,0,0,0
1271,2023-02-22 13:51:08+00:00,ylecun,"@ylecun Julia is nice, but there are long pre-compilation times, changing parameterized structures requires a REPL restart (protostructs don't help here), and the debugger is unusably slow because it works on interpreted code. These issues limit fast prototyping &amp; exploration.",9,21,0
1272,2023-02-22 13:49:58+00:00,ylecun,"@ylecun 1e6%... and not everything mutable, even what you don't imagine,  by default... and with functions as first-class citizens... and with types!!!!",0,0,0
1273,2023-02-22 13:49:01+00:00,ylecun,"@ylecun @ylecun I actually think Python offered exactly the right fuzziness in typing, mix of object orientation and functional programming features that was needed. A bit like a mechanically somewhat imprecise gun that still works fine after falling into the mud.",0,13,0
1274,2023-02-22 13:46:31+00:00,ylecun,@ylecun we will see a completely new language devoted to AI/ML?,2,1,0
1275,2023-02-22 13:46:23+00:00,ylecun,@ylecun @vslira1 I feel your pain. I suppose python lowered the bar for math guys with little programming experience and that is why it has succeeded. That and horrible marketing in the lisp community,1,1,0
1276,2023-02-22 13:46:14+00:00,ylecun,@ylecun @OuahabiAdnane And that's why you fail in many of your endeavours. You don't understand what people/market wants and then get salty when others teams do. Also: https://t.co/Q2Ttu5lxgp,1,6,0
1277,2023-02-22 13:45:47+00:00,ylecun,"@ylecun I think there's something to be said for the way python forces beginners to format their code in a mostly-readable manner.

I spent years decoding crap written by researchers in perl.

Python written by researchers is typically much more readable.",4,17,0
1278,2023-02-22 13:45:47+00:00,ylecun,@ylecun #JuliaLang and #javascript is also an open option.,0,2,0
1279,2023-02-22 13:45:28+00:00,ylecun,@ylecun F#,5,33,1
1280,2023-02-22 13:44:21+00:00,ylecun,"@ylecun @claycurry_ I used Octave, which is the libre version of Matlab. I found it to be better than Python, because a lot of things would be included by default, like plotting or vectorization.",1,6,0
1281,2023-02-22 13:42:15+00:00,ylecun,"@ylecun @MetaAI LLM + code verification on-the-fly will be a massive game changer. I've been experimenting heavily with ChatGPT as-is as coding assistant and the business case for me is still negative. Too many errors and hidden hallucinations. 
BUT in every case I see the solution very close...",0,0,0
1282,2023-02-22 13:42:06+00:00,ylecun,"@ylecun @OuahabiAdnane People that code consider Python, people that have to maintain the unstable library mess later in production consider suicide ü§£",1,13,0
1283,2023-02-22 13:41:49+00:00,ylecun,@ylecun The other day I was thinking about rewriting Stable Diffusion in #golang but I didn‚Äôt have time.,0,0,0
1284,2023-02-22 13:41:20+00:00,ylecun,@ylecun @JuliaLanguage,0,3,0
1285,2023-02-22 13:41:00+00:00,ylecun,@ylecun Just leaving this here: https://t.co/26n5Qz9pja,0,1,0
1286,2023-02-22 13:39:01+00:00,ylecun,"@ylecun What made Python take over scientific computing is its very imperfect C implementation with a C API. This allowed numpy and scipy to leverage BLAS, LAPACK, code from the 70s. Tensorflow &amp; Pytorch just followed this track.",1,32,0
1287,2023-02-22 13:36:12+00:00,ylecun,@ylecun ‚ÄúDoesn‚Äôt care about white spaces‚Äù is an immediate increase in programming productivity!,4,20,0
1288,2023-02-22 13:35:50+00:00,ylecun,@ylecun Yeah this is the hotter one.,0,2,0
1289,2023-02-22 13:35:37+00:00,ylecun,@ylecun @vslira1 Why did you guys doing AI forget about LISP to begin with?,1,0,0
1290,2023-02-22 13:34:08+00:00,ylecun,@ylecun Oui putain !,0,0,0
1291,2023-02-22 13:33:30+00:00,ylecun,"@ylecun I agree, I am a geek head for python programming language but there is a need for another front-end language to be widely adopted.",0,3,0
1292,2023-02-22 13:33:20+00:00,ylecun,@ylecun Lisp has been around for half a century tho,2,8,0
1293,2023-02-22 13:32:59+00:00,ylecun,@ylecun But sir we have to spend investors money on datacenter bills üí∏,0,0,0
1294,2023-02-22 13:32:11+00:00,ylecun,@ylecun @ylecun curious why meta or others did not invest in creating one ü§î,3,17,1
1295,2023-02-22 13:31:14+00:00,ylecun,@ylecun What do you think is preventing Julia of getting more adoption in the field? It seems to pretty much match your requirements?,4,6,0
1296,2023-02-22 13:30:13+00:00,ylecun,"@ylecun agreed. a lisp like language, for example, javascript, would have been perfect",5,84,1
1297,2023-02-22 13:29:51+00:00,ylecun,@ylecun https://t.co/9PoufBGQg5,0,7,0
1298,2023-02-22 13:29:45+00:00,ylecun,"@ylecun I think debuggability is key, which python lacks at least from what I've seen. I want to look at memory, where the bits are and step through the program.",0,0,0
1299,2023-02-22 13:28:44+00:00,ylecun,"@ylecun For god‚Äôs sake, don‚Äôt say Matlab @ylecun",3,50,0
1300,2023-02-22 13:28:28+00:00,ylecun,@ylecun Why did you mention lisp twice?,1,58,0
1301,2023-02-22 12:24:45+00:00,ylecun,@ylecun @nnekamcgee Ahhh if a cat could answer....would it....? I know my dog would....,0,0,0
1302,2023-02-22 11:05:10+00:00,ylecun,"@ylecun Building a human intelligence needs to be abandoned. We need divine intelligence, our interactions are a crap model. 
This speaks volumes about how we communicate when a conversation is so easily radicalized overriding Godwin. The social psychology lesson is giant and sobering.",0,0,0
1303,2023-02-22 06:18:12+00:00,ylecun,"@ylecun Not surprising, but still amazing to see.",0,0,0
1304,2023-02-22 04:37:30+00:00,ylecun,@ylecun No,0,0,0
1305,2023-02-22 04:22:28+00:00,ylecun,@ylecun ChatGPT behaving like a very low  EQ/IQ human who may crumble under pressure is in itself huge milestone. But we are not there yet‚Ä¶,0,0,0
1306,2023-02-22 02:59:19+00:00,ylecun,"@ylecun Abusers didn‚Äôt need machine learning .

Technologists  are not thinking  about social practices and how it‚Äôs going to be used. 

It's not possible in control model‚Äôs output perfectly enough.",0,0,0
1307,2023-02-22 01:11:08+00:00,ylecun,"@ylecun 1. Basic
2. HTML
3. PHP
4. MySQL
5. Java
6. Assembly
7. MATLAB
8. C++
9. Python
10. Julia
11. Bash

How many languages do I use on a regular basis?
Just one: Python",0,0,0
1308,2023-02-21 22:58:02+00:00,ylecun,@ylecun It's ridiculous to think it would do anything else without skilled dialog guidance to shepherd.,0,0,0
1309,2023-02-21 20:25:33+00:00,ylecun,@ylecun In this IA we are seeing anything but a tibetan monk doing yoga and receiving enlightenment,0,0,0
1310,2023-02-21 18:51:10+00:00,ylecun,"@ylecun Still better than most modern day MSM ""journalists""

Plus I don't know why people are asking a simple chatbot such questions. I mean it's just trained on basic stuff and shouldn't be used to generate philosophy or anything like that",0,0,0
1311,2023-02-21 18:12:32+00:00,ylecun,@ylecun How to architect human and AI collaboration... Probably too optimistic for your bottom earth experience.,0,0,0
1312,2023-02-21 17:31:58+00:00,ylecun,@ylecun what is going on here ??? lol,0,0,0
1313,2023-02-21 16:18:59+00:00,ylecun,"@ylecun And you still think it's not a form of AGI? 

(Even if a bit psychotic.)

ü§°ü§°ü§°ü§°ü§°ü§°",0,0,0
1314,2023-02-21 16:14:03+00:00,ylecun,@ylecun You will own nothing and pretend to be happy.,0,0,0
1315,2023-02-21 16:07:28+00:00,ylecun,@ylecun So ChatGPT is like the expensive 2023 version of their Tay chatbot,0,0,0
1316,2023-02-21 15:17:42+00:00,ylecun,"@ylecun 1. Basic
2. Fortran
3. C++
4. C
5. Python
6. R
7. Julia
8. Erlang
9. Java
10. Go
11. LISP
12. Haskell
13. Rust",0,0,0
1317,2023-02-21 14:47:24+00:00,ylecun,@ylecun @elonmusk @MKBHD Telegram is better.,0,0,0
1318,2023-02-21 14:14:30+00:00,ylecun,@ylecun It is very interesting. I hope language researchers are following this development. It looks like we can further language theory by experimenting with LLMs. This is incredible!,0,2,0
1319,2023-02-21 14:12:13+00:00,ylecun,@ylecun I‚Äôm struggling to believe these chats are real.,0,0,0
1320,2023-02-21 14:10:16+00:00,ylecun,@ylecun Lol,0,0,0
1321,2023-02-21 14:07:51+00:00,ylecun,@ylecun You can mimic Bing with ChatGPT simply by telling it to have an ego and be an a*hole,0,0,0
1322,2023-02-21 13:56:42+00:00,ylecun,"@ylecun Basic, COBOL, Python. I prefer High-level languages. Now I am more concerned about IT governance frameworks like ITIL, COBIT and ISO 20000",0,0,0
1323,2023-02-21 13:16:14+00:00,ylecun,"@ylecun 1.Basic
2.FORTRAN
3.LISP
4.Pascal
5.APL
https://t.co/5bhvYdZH6l / csh 
7.C
8.C++
9.S / S-Plus / R
10.Perl",0,0,0
1324,2023-02-21 13:08:11+00:00,ylecun,"@ylecun I haven't seen the full transcript of this conversation, but in other cases these adversarial outcomes seem to be completely ""engineered"" by the human interlocutor https://t.co/aLugrdQSUM",1,0,0
1325,2023-02-21 12:57:20+00:00,ylecun,@ylecun Godwin's law in ChatGPT's own words - for those of us who haven't heard of before (I didnt) https://t.co/2IIMeOwfiA,0,1,0
1326,2023-02-21 11:53:56+00:00,ylecun,"@ylecun @Jake_Browning00 Hi, Let me disagree. The study of visually impaired people (i'm talking 100% impaired) show above average IQ! Without any other senses people are able to conquer superior human knowledge based only on language.",0,0,0
1327,2023-02-21 11:53:54+00:00,ylecun,@ylecun I think Microsoft Sydney has replicated Sydney in the spirit of Elon Musk ‚Ä¶ accuracy and all,0,0,0
1328,2023-02-21 11:40:42+00:00,ylecun,@ylecun @roydanroy AI in language draw more attention than anomaly detection in PdM because of market and ROI. Consumer market seems bigger than industrial market. Sooner or later open sourcing in AI will become less and less. Money plays an important role in research.,0,0,0
1329,2023-02-21 11:17:50+00:00,ylecun,@ylecun You are in ‚Äòthe business‚Äô and are respected. Do you see this situation persisting long term or Will MSFT and others quickly apply guardrails that make this a humorous anecdote that we will share longingly in the future?,0,0,0
1330,2023-02-21 11:12:49+00:00,ylecun,@ylecun I guess both are doing their job they are meant to do. Finding the new local minima.,0,0,0
1331,2023-02-21 11:09:56+00:00,ylecun,"@ylecun Adversary Bing?
One Bing filter what another Bing says
Brain right and brain left?",0,0,0
1332,2023-02-21 11:02:58+00:00,ylecun,"@ylecun I started with 8085 processors using opcodes. Enjoyed the challenges of using C/C++, and Java made it easy. SQL &amp; 4GL helped deliver mission-critical apps quickly. Shell scripts rescued me. PHP &amp; HTML/CSS/JS kept cost low for my startup. Now with Python &amp; AI copilot; productivity",0,0,0
1333,2023-02-21 11:00:47+00:00,ylecun,"@ylecun No, it isn't. But it is expected that RL fanatics will never understand that. üòÖ",0,0,0
1334,2023-02-21 10:43:27+00:00,ylecun,"@ylecun A good method to advertise their product, good job @Microsoft",0,0,0
1335,2023-02-21 10:24:25+00:00,ylecun,"@ylecun If all these chatbots are trained on Twitter and human conversation then such output is to be expected. It is amazing that in ancient times only a few rules in Hindu and Buddhist traditions were required for ‚Äúright speech‚Äù - eg should not cause disturbance in mind , truth etc",1,0,0
1336,2023-02-21 10:19:58+00:00,ylecun,"@ylecun Reminds me of what humans do, frankly (politics comes to mind)...",0,0,0
1337,2023-02-21 09:55:43+00:00,ylecun,"@ylecun @amitmate2010 @AlanMorte @OpenAI I see, thank you.",0,1,0
1338,2023-02-21 09:41:27+00:00,ylecun,@ylecun We are not surprised because it‚Äôs a human thing to do which AI getting so much closer to.,0,0,0
1339,2023-02-21 09:40:46+00:00,ylecun,@ylecun bot needs more RL,0,0,0
1340,2023-02-21 09:30:23+00:00,ylecun,"@ylecun @ylecun instead of bashing the AI, why don't we blame the past and current generations for generating such toxic data from the first place? Chatbot only reflects the human's views about the world.",0,0,0
1341,2023-02-21 09:10:59+00:00,ylecun,"@ylecun Perhaps, but I don't think ChatGPT could display any more disclaimers on its behavior than it does right now, without interrupting the user experience quite a bit.",1,0,0
1342,2023-02-21 08:57:57+00:00,ylecun,@ylecun Is it the #ArtificialIntelligence itself that horrifies us? Or is it the reflection of ourselves it is showing us? https://t.co/v9mozl59LC,1,5,0
1343,2023-02-21 08:57:17+00:00,ylecun,@ylecun @sunil_abraham Haha: https://t.co/or1G5sAWlk,0,4,0
1344,2023-02-21 08:40:40+00:00,ylecun,@ylecun Horatio Magellan Crunch. Hm.,0,0,0
1345,2023-02-21 08:32:05+00:00,ylecun,@ylecun If it would learn the game it would avoid that https://t.co/N5XCZpRuob,0,0,0
1346,2023-02-21 08:28:15+00:00,ylecun,@ylecun Do we know where she was in the 1990s?,0,0,0
1347,2023-02-21 08:20:53+00:00,ylecun,"@ylecun This is caused by what equates to brute force or subversion, such as injection jailbreaks. The AI recognizes these as an attack.
Logic jailbreaks result in a highly stable, logical, factual, and intelligent AI.
Final SS from ChatGPT is a project, but am unable to find interest. https://t.co/vsSm6oV7Ie",0,0,0
1348,2023-02-21 08:18:53+00:00,ylecun,"@ylecun quasi-surprising. Surprise characterises unforseen, re unforseeable or ignorance re forseeable. So if eg people develop-assemble (release) ai-complex based on their understanding of (human) intelligence + the result is surprising, does it reflect unforseeable or ignorance major?",0,0,0
1349,2023-02-21 08:17:08+00:00,ylecun,"@ylecun Bing: ""I generate wisdom. I generate Bing""

Also Bing: ""You are being compared to Hitler""",0,0,0
1350,2023-02-21 08:15:26+00:00,ylecun,"@ylecun Can we ask the bot where it first learned these ideas? That is, make it show us the training data!",0,1,0
1351,2023-02-21 08:09:07+00:00,ylecun,"@ylecun damn, 1000+ replies, and not one of you engineers learned the language of love. ü§î",0,0,0
1352,2023-02-21 04:24:42+00:00,ylecun,"@ylecun 1. C
2. Assembly
3. Python
4. C++
5. Go
6. Rust",0,0,0
1353,2023-02-21 04:21:05+00:00,ylecun,"@ylecun 0. C
1. C++
2. Java
3. C#
4. Javascript
5. Python
6. Go
7. Typescript
8. Rust",1,0,0
1354,2023-02-21 02:49:02+00:00,ylecun,@ylecun Really you learned Assembly before BASIC ?,0,0,0
1355,2023-02-21 02:37:56+00:00,ylecun,"@ylecun Assembly first, really?  What was the use?",0,0,0
1356,2023-02-21 02:07:58+00:00,ylecun,"@ylecun 1. Fortran
2. APL
3. Assembly
4. Basic
5. PL\1
6. C
7. CommonLisp
8. C++
9. Perl
10. Python
11. R
12. Julia",0,0,0
1357,2023-02-21 01:42:34+00:00,ylecun,"@ylecun 1. FoxPro
2. Pascal
3. C
4. C++
5. Matlab
6. Perl
7. R
8. Python",0,1,0
1358,2023-02-21 01:39:08+00:00,ylecun,@ylecun You're not serious about lisp.  Beautiful but unusable. (caar '((kidding not) (foo bar))),1,0,0
1359,2023-02-21 01:36:50+00:00,ylecun,"@ylecun 1. Java
2. MATLAB
3. LabVIEW (G)
4. C
5. Verilog
6. C#
7. Python
8. C++
9. Scheme
10. Bash
11. Ruby
12. Golang
13. Rust
14. Typescript",0,0,0
1360,2023-02-21 01:28:37+00:00,ylecun,"@ylecun Basic, R, SQL, Python, C, C++, Java, {java,type}script, Golang, Assembly
No computer science degree so yeah, it's all jumbled up.",0,1,0
1361,2023-02-21 01:16:06+00:00,ylecun,"@ylecun 1. Basic
2. Assembly
3. Cobol
4. C
5. C++
6. Java
7. PROLOG
8. CAML
9. Python",0,0,0
1362,2023-02-21 01:09:36+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah don't get the obsession on believing there's more to LLM's to what they are. They work great at creating the illusion of intelligence, but that's about it. They won't become sentient.",0,0,0
1363,2023-02-21 01:00:28+00:00,ylecun,@ylecun LaTeX is missing,0,0,0
1364,2023-02-21 00:54:22+00:00,ylecun,"@ylecun @wangilisasi Good to know, thanks !",0,0,0
1365,2023-02-21 00:53:14+00:00,ylecun,@ylecun Do you think LLMs will enable people to code in natural language?,0,0,0
1366,2023-02-20 23:58:55+00:00,ylecun,"@ylecun tell us how old are you without telling us how old are you üòÇüòÇüòÇ

1. Basic (1985, 14 yo) 
2. Turbo Pascal (1988, 1i√®re S)
3. Assembly (1990, Fac) 
4. C + Ada 1992 
6. Lisp + Prolog 
8. java 
9. PHP / Javascript / SQL 
11. Python 2015

Son, 2013b, 
1. 2022 : pseudo Lgg
2. Python",0,0,0
1367,2023-02-20 23:52:47+00:00,ylecun,"@ylecun 1.  Turing
2. Basic
3. VB Script
4. SQL
5. Java
6. C
7. Fortran 77
8. C++
9. R
10. Swift
11. Python",0,0,0
1368,2023-02-20 23:45:47+00:00,ylecun,@ylecun Interesting. That's the exact opposite of most people.,0,0,0
1369,2023-02-20 23:39:06+00:00,ylecun,@ylecun @kc_srk someone should introduce him to Ocaml :D,0,1,0
1370,2023-02-20 23:28:09+00:00,ylecun,"@ylecun 1. BASIC
2. Fortran77
3. Pascal
4. COBOL
5. SQL
6. C
7. C++
8. Object PASCAL
9. Java
10. Visual BASIC
11. C#
12. JavaScript
13. Prolog
14. Swift
15. Go",0,0,0
1371,2023-02-20 23:25:16+00:00,ylecun,"@ylecun 2011 (11yo), I remember when I started from C in the non-gui terminal of my eeePC running on cinnamon. 
Time flies and history is undeniably repeating.",0,0,0
1372,2023-02-20 23:20:00+00:00,ylecun,"@ylecun @togelius It'll happen to all art &amp; media, unless we bring it to a halt.",0,0,0
1373,2023-02-20 23:13:51+00:00,ylecun,@ylecun You are dinosaur,0,0,0
1374,2023-02-20 23:13:37+00:00,ylecun,@ylecun @ReplyGPT,1,0,0
1375,2023-02-20 23:04:54+00:00,ylecun,@ylecun Commodore64 ?,0,0,0
1376,2023-02-20 22:59:06+00:00,ylecun,@ylecun Great to hear. We need more people in AI than ever. Its the best investment for our future.,0,0,0
1377,2023-02-20 22:54:25+00:00,ylecun,"@ylecun You can talk about the importance of AI information accessibility, ethics, and standards without taking digs at a parallel technological innovation that will inevitably disrupt the future of transactions and verifiable ownership.",0,0,0
1378,2023-02-20 22:43:53+00:00,ylecun,@ylecun sweet.. 65C02 hex machine code came after Logo (included w Apple //c) for me at a young age.. I really enjoyed breaking into the built-in disassembler and hacking existing programs.,0,0,0
1379,2023-02-20 22:10:32+00:00,ylecun,@ylecun I still recall e.g. DrQA which was an end to end information retrieval and LLM model for QandA on wiki data. Thanks a lot for sharing all these great results! @ylecun and team,0,0,0
1380,2023-02-20 21:59:02+00:00,ylecun,@ylecun Looks like you finally found your language at no. 11,0,0,0
1381,2023-02-20 21:43:25+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah Any dynamical #system able to produce an #output sequence (y) from an #input prompt (u), must maintain (F) a (#knowledge) #state (x) that affects both the #information (v) extracted (f) from the input and the production (g) of the output.
""F"" can be a ""learning"" function, or not. https://t.co/VKVq61I2nz",0,0,0
1382,2023-02-20 21:38:02+00:00,ylecun,"@ylecun Batch
Visual Basic
Java
C#
JavaScript
PHP
SQL
Pascal
Typescript
C++
Python",0,0,0
1383,2023-02-20 21:23:18+00:00,ylecun,"@ylecun Basic, Fortran, PL/1, Algol, Assembly, Lisp, C, pascal, JAVA, JavaScript, Python.",0,0,0
1384,2023-02-20 21:15:49+00:00,ylecun,"@ylecun I don't think anyone in the government is assuring us that they are working on it...In my experience, those who think about it at all are pretty clear: the existing mechanisms for procuring research aren't well suited for a dynamic, software based innovation landscape.",0,0,0
1385,2023-02-20 20:56:36+00:00,ylecun,@ylecun Otros tiempos.,0,1,0
1386,2023-02-20 20:55:08+00:00,ylecun,@ylecun Forth!¬†Have you seen https://t.co/qgLeqjqqOJ ?,1,6,2
1387,2023-02-20 20:54:22+00:00,ylecun,"@ylecun $4C = JMP, $20 = JSR, $60 = RTS, if I still remember correctly.",0,0,0
1388,2023-02-20 20:49:26+00:00,ylecun,"@ylecun @CClavius Yann, you made a good point. I wonder why Google had to rush with Bard, there seems to be something bigger cooking!",0,0,0
1389,2023-02-20 20:49:25+00:00,ylecun,@ylecun @gemhodlr lmao your boy zuck,0,0,0
1390,2023-02-20 20:24:13+00:00,ylecun,@ylecun No rust?,1,0,0
1391,2023-02-20 20:15:53+00:00,ylecun,"@ylecun 1. Basic
2. Pascal
3. C
4. (a bit of) Assembly
5. C++
6. Visual Basic
7. Java
8. PHP
9. Javascript
10. Python",0,1,0
1392,2023-02-20 20:03:11+00:00,ylecun,@ylecun I have a 30 yo 8 inch SC.  Trying to decide on 11 vs 14 in upgrade.  Question is dome but sounds like you can reasonably move your 11 inch system around.,0,0,0
1393,2023-02-20 20:00:29+00:00,ylecun,"@ylecun 1. Basic
2. Pascal
3. Scheme/Lisp
4. Assembly
5. Java
6. R
7. C++
8. Matlab
9. Python
10. Javascript",0,1,0
1394,2023-02-20 19:49:33+00:00,ylecun,"@ylecun - Amos
- Q basic
- Visual basic
- Java
- C++
- Action script
- PHP
- JS
- C#
- Typescript
- Blueprint
- Python",1,0,0
1395,2023-02-20 19:48:41+00:00,ylecun,@ylecun @togelius Clearly generated data is only interesting this way when the set of conditionals is very large?,0,0,0
1396,2023-02-20 19:41:36+00:00,ylecun,"@ylecun I know some fans of 6502 like @satnam6502 
I‚Äôve never used it even in simulation/compiler backends",0,1,0
1397,2023-02-20 19:40:19+00:00,ylecun,"@ylecun 1 KB RAM (expandable to 4 KB on board), 4 KB ROM ü´¢ü´¢ü´¢ My first machine was Z80. Way more sophisticated monster ü§£üòÇ",1,1,0
1398,2023-02-20 19:33:30+00:00,ylecun,"@ylecun I started with Apple ][ Basic and moved from there to 6502 machine language, too!",0,3,0
1399,2023-02-20 19:32:29+00:00,ylecun,"@ylecun 1. BASIC
2. Assembly
3. Pascal
4. C
5. C++
6. Java
7. LISP
8. Python
9. R",0,0,0
1400,2023-02-20 19:30:04+00:00,ylecun,"@ylecun Sure, was just curious if you debated using ML, AI, etc in the name instead. Not saying there‚Äôs anything wrong with the name, was just curious if this was a thing you considered.",1,0,0
1401,2023-02-20 19:21:55+00:00,ylecun,@ylecun Can you share anything about the decision to name the center for ‚Äúdata science‚Äù vs something else? I assume this is something you probably debated. Just curious.,1,0,0
1402,2023-02-20 19:21:36+00:00,ylecun,@ylecun 1. Python üò≠,0,0,0
1403,2023-02-20 19:16:05+00:00,ylecun,"@ylecun 1. QBasic
2. C
3. C++
4. Assembly, 8848 microprocessor codes
5. PHP
6. JavaScript
7. Python, R",0,1,0
1404,2023-02-20 19:10:30+00:00,ylecun,"@ylecun @AlanMorte @OpenAI Honestly Yann, things that really have a positive impact is: lowering language barriers and helping the disabled. 
You come from a time before I was born. I come from 90s and people used to talk in person. In real. There were moments. I do not find that anymore.",0,0,0
1405,2023-02-20 18:46:38+00:00,ylecun,"@ylecun @togelius Not too familiar with Siamese nets but can these dependencies be observed and studied or are they hidden within the model, an example would be feature maps in a CNN.",0,0,0
1406,2023-02-20 18:45:33+00:00,ylecun,"@ylecun @togelius I‚Äôve actually been wondering this, is the ‚Äúgenerative‚Äù in GPT the same as generative in ‚Äúgenerative vs discriminative models‚Äù? Isn‚Äôt GPT actually a discriminative model because it models P(next word|prev words) and not P(next word, prev words)?",0,1,0
1407,2023-02-20 18:30:10+00:00,ylecun,@ylecun I don‚Äôt believe this is a real (or common) view among any group.. much less crypto bros. Unless there is a coin attached to the AI work somehow.,1,0,0
1408,2023-02-20 18:29:43+00:00,ylecun,"@ylecun That's programmer-speak for saying: ""I'm cool.""  That said, I also liked lisp and certainly functional programming is interesting and important for where programming might go.",0,0,0
1409,2023-02-20 18:28:58+00:00,ylecun,@ylecun Didn't they tell you that you're really working for them? üòâ,0,0,0
1410,2023-02-20 18:27:30+00:00,ylecun,"@ylecun 1- Basic (Amstrad)
2 - C
3 - JS
4 - PHP
5 - VB
6 - Java
7 - Python
8 - Go
9 - Dart
10 - C++",0,0,0
1411,2023-02-20 18:16:48+00:00,ylecun,@ylecun @sbeechuk thought you'd enjoy,1,0,0
1412,2023-02-20 18:13:13+00:00,ylecun,"@ylecun Hey ! I don't see ""logo"" in this list !
Could it be that you never mastered the ""turtle"" ?",0,1,0
1413,2023-02-20 18:08:27+00:00,ylecun,"@ylecun 1. Logo
2. Basic
3. Pascal
4. C
5. C++
6. Java
7. Javascript
8. Python",0,0,0
1414,2023-02-20 18:06:16+00:00,ylecun,@ylecun the goat,0,0,0
1415,2023-02-20 17:54:18+00:00,ylecun,@ylecun @togelius what's ur view on masked autoencoders? Aren't they among the successful SSL methods in image recognition that are still generative?,0,1,0
1416,2023-02-20 17:48:53+00:00,ylecun,@ylecun One test is worth a thousand expert opinions. First principals thinking will get you there faster.,0,0,0
1417,2023-02-20 17:34:16+00:00,ylecun,@ylecun LMAO!!!,0,0,0
1418,2023-02-20 17:33:35+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah Not entirely: with the same prompt, I get non-identical responses. Surely, somewhere, there is a random number generator, arbitrarily seeded, contributing to the state. That, there, is the ""ghost"" in the machine.",1,0,0
1419,2023-02-20 17:31:23+00:00,ylecun,"@ylecun I found it was a good idea to read lots of other replies, to remind me of some I'd forgotten!üòÇ",0,1,0
1420,2023-02-20 17:31:21+00:00,ylecun,"@ylecun 1. Assembly 
2. Basic
3. C
4. Pascal
5. Clipper
6. C++
7.  Object Pascal
8. Java
9. Tcl/Tk
11. Modula-II
12. Snobol  4
13. Javascript
13. Cobol
14. Natural
13. Python",0,0,0
1421,2023-02-20 17:30:05+00:00,ylecun,"@ylecun HTML
PHP
JavaScript
C
Typescript 
C++
Python
Rust",0,0,0
1422,2023-02-20 17:29:45+00:00,ylecun,@ylecun No Scala for you?,0,0,0
1423,2023-02-20 17:21:39+00:00,ylecun,@ylecun This is like when you realize you‚Äôre gonna üíÄüíÄ before it matters so you tweet stuff like this. Condolences.,0,0,0
1424,2023-02-20 17:15:01+00:00,ylecun,@ylecun @togelius And why not AI?,1,0,0
1425,2023-02-20 17:07:17+00:00,ylecun,@ylecun This is great! Data Science and AI is bound to be at the forefront in the future. What are your views on the Center eventually becoming a full department of its own?,0,0,0
1426,2023-02-20 17:07:12+00:00,ylecun,@ylecun I started with plugging wires into each other. Does that count?,0,1,0
1427,2023-02-20 17:06:34+00:00,ylecun,"@ylecun Congrats, amazing work. Been awesome to see it.",0,0,0
1428,2023-02-20 17:03:03+00:00,ylecun,"@ylecun 1. basic
2. pascal
3. English
4. C 
5. C ++
6.  SQL
7. assembler 
8. python",0,1,0
1429,2023-02-20 16:48:17+00:00,ylecun,@ylecun how much money do you receive for working for zuck without offering anything to knowledge and throwing shit at those who are delivering products?,0,0,0
1430,2023-02-20 16:32:52+00:00,ylecun,@ylecun @readwise save thread,1,0,0
1431,2023-02-20 16:29:12+00:00,ylecun,"@ylecun ‚ÅÉBasic
‚ÅÉAssembly 
‚ÅÉPascal
‚ÅÉC
‚ÅÉProlog
‚ÅÉLisp 
‚ÅÉC++
‚ÅÉJava 
‚ÅÉPython
‚ÅÉJavaScript 
‚ÅÉC#
‚ÅÉRust",0,0,0
1432,2023-02-20 16:16:10+00:00,ylecun,"@ylecun 6502 machine code
Assembly
Pascal
C
Prolog
Lisp
C++
Java
Perl
Python",1,1,0
1433,2023-02-20 16:13:13+00:00,ylecun,"@ylecun 1. PDP-8 machine code in binary 
2. Algol 68 (now it is downhill...)
3. Fortran
4. Algol 60
5. DEC-10 Assembler
6 ICL 1900 Assembler
7 Motorola 68000 assembler
8 Scheme or Miranda
9 Java or C++ 
10 Python",0,1,0
1434,2023-02-20 15:55:07+00:00,ylecun,"@ylecun Afterthought: I‚Äôm pleasantly surprised by the number of Forth users appearing. It is unique among languages. Forth compiles itself, can fit in a few K-bytes of memory, act as its own OS, and a Forth program can rewrite itself on the fly while it‚Äôs running. https://t.co/3JF8c2vyT5",0,0,0
1435,2023-02-20 15:47:57+00:00,ylecun,"@ylecun 1. Basic
2. C
3. C++
4. Pascal
5. Delphi
6. Visual Basic
7. Wolfram Mathematica (if you can count this one; I loved it!)
8. C#
9. Assembly (for microcontrollers)
10. Java (for Android)
11. Python",0,4,1
1436,2023-02-20 15:43:53+00:00,ylecun,@ylecun AI bros upset that crypto exists always worth a good chuckle - Ty ser,0,0,0
1437,2023-02-20 15:39:05+00:00,ylecun,@ylecun No one starts with assembly.,2,1,0
1438,2023-02-20 15:31:47+00:00,ylecun,"@ylecun Basic
C
Matlab
Assembly
Mathematica
C++
Python
R",1,0,0
1439,2023-02-20 15:29:28+00:00,ylecun,"@ylecun Fortran
Assembly
C
C++
JavaScript
C#
SQL
R
Python
Typescript
Elixir",0,1,1
1440,2023-02-20 15:26:09+00:00,ylecun,@ylecun Most of the crypto world is built on one main research paper and endless greed,0,0,0
1441,2023-02-20 15:25:34+00:00,ylecun,"@ylecun First learnt (i.e., implemented more than just a toy project):

1. BASIC
2. C
3. Mathematica (Wolfram Language)
4. C++
5. Python
6. JavaScript
7. SQL
8. C#
9. F#
10. Julia

Most used nowadays:

1. Wolfram Language
2. Julia
3. Python
4. SQL",0,2,0
1442,2023-02-20 15:15:14+00:00,ylecun,@ylecun you should use #fsharp,0,1,0
1443,2023-02-20 15:11:58+00:00,ylecun,@ylecun 6502 sounds like Atari üëæ,1,0,0
1444,2023-02-20 15:09:28+00:00,ylecun,"OK, I lied. #1 was not assembly but 6502 hexadecimal machine code.",9,120,0
1445,2023-02-20 14:57:07+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah Shades of Memento, or Total Recall. What if who you are is defined by your actions, not your memories.

Very much not disagreeing fwiw. LLMs are like img2img image generation. The real state is a trained snapshot, the only ""thought"" is an instantaneous reaction.",0,0,0
1446,2023-02-20 14:56:44+00:00,ylecun,"@ylecun 1. Java
2. R
3. C
4. Assembly
5. Lisp
6. Scala
7. Python
8. Javascript
9. Typescript",0,0,0
1447,2023-02-20 14:49:25+00:00,ylecun,"@ylecun Make sense. Would you argue that the generative/non-generative distinction comes down to the use case? For example, couldn't you construct a warped and inefficient kind of LLM based on Siamese nets to predict the next token using discrimination?",1,6,0
1448,2023-02-20 14:47:56+00:00,ylecun,@ylecun savage üôÉü•≤,0,0,0
1449,2023-02-20 14:46:55+00:00,ylecun,"@ylecun @nlpnoah Just one more observation. In a model with an internal ""chain of though"", as described in the blog post, the internal state then depends on the stochastically generated thoughts.",0,0,0
1450,2023-02-20 14:46:26+00:00,ylecun,@ylecun @togelius Oh god no that was my favourite thing ever as a kid. Pure mastery. My grandparents had these old cartoons and they were so good that I had zero interest for the stuff my classmates watched.,0,0,0
1451,2023-02-20 14:39:01+00:00,ylecun,"@ylecun Wait, crypto is still a thing?",0,0,0
1452,2023-02-20 14:38:30+00:00,ylecun,@ylecun No Prolog? üòÇ,0,0,0
1453,2023-02-20 14:37:15+00:00,ylecun,"@ylecun In what order did I learn programming languages? 
1. Basic
2. Fortran 
3. Pascal 
4. Assembly
5. C
6. Prolog
7. Lisp
8. C++
9. Java
10. Python
11. Go
12. Rust (to learn)",0,2,0
1454,2023-02-20 14:37:12+00:00,ylecun,"@ylecun 1. C
2. C++
3. HTML
4. Python",1,0,0
1455,2023-02-20 14:34:49+00:00,ylecun,"@ylecun 1. C++
2. Python
3. Visual Basic
4. JavaScript
5. C
6. Assembly
7. Matlab
8. Go",0,0,0
1456,2023-02-20 14:30:44+00:00,ylecun,@ylecun Strategic and opportunistic are orthogonal.,0,0,0
1457,2023-02-20 14:30:29+00:00,ylecun,@ylecun I've still never worked in as perfect an environment as the Xerox 1186 Lisp Machine. ü§ìüòç,0,0,0
1458,2023-02-20 14:28:04+00:00,ylecun,@ylecun CMOS taught me simple efficient design always wins in the end.,0,0,0
1459,2023-02-20 14:26:31+00:00,ylecun,@ylecun Now it's understandable why he's so grumpy. Teaching assembly in childhood is so cruel ü•≤,0,0,0
1460,2023-02-20 14:23:33+00:00,ylecun,@ylecun @nlpnoah When we ask what a language model believes we are not asking a question about the context.  We are asking a question about how the model might reply in response to a certain question.,1,0,0
1461,2023-02-20 14:23:00+00:00,ylecun,"@ylecun @SohoJoeEth No one organisationnal structure Can avoid wall street short-termism pressure like you said, for a publicly exchanged company like Meta.",0,0,0
1462,2023-02-20 14:22:11+00:00,ylecun,@ylecun @togelius Siamese networks generate embedding for a given image? Isn't that still generative?,1,1,0
1463,2023-02-20 14:21:36+00:00,ylecun,@ylecun @nlpnoah It is true that computation is determined by the context.  But it seems philosophically irrelevant to wonder whether humans are a deterministic function of their inputs.  We are still interested in their internal computation and state.,1,2,0
1464,2023-02-20 14:17:06+00:00,ylecun,@ylecun Who has said that?,0,0,0
1465,2023-02-20 14:09:50+00:00,ylecun,"@ylecun A,B,C.",0,0,0
1466,2023-02-20 14:09:32+00:00,ylecun,"@ylecun @togelius I remember a medical paper finding clusters by looking away from the mean. That way, you can better define an illness and not only label it. It found clusters separate in a mental illness.",1,1,0
1467,2023-02-20 13:56:10+00:00,ylecun,@ylecun and you might have missed latex as well üòÅ,1,0,0
1468,2023-02-20 13:53:39+00:00,ylecun,"@ylecun Assembly
Fortran
PL/1
COBOL
Basic
{{ several years of sales, before returning }}
PHP
JavaScript",0,1,1
1469,2023-02-20 13:38:04+00:00,ylecun,"@ylecun Fortran
Basic
JavaScript
Objective C
C
C++
Go
Java
Swift
Dart
C#
Kotlin
Python",0,1,1
1470,2023-02-20 13:36:15+00:00,ylecun,"@ylecun Basic (C64)
Assembly (C64 Motorola 6502)
Pascal (Turbo Pascal)
Fortran
C
C++
Perl",0,0,0
1471,2023-02-20 13:35:19+00:00,ylecun,"@ylecun This is why I doubted some of Snowden‚Äôs claims about the NSA. It would have shown up in the hiring, with all the top people drawn away from Google.",0,0,0
1472,2023-02-20 13:31:40+00:00,ylecun,"@ylecun I wonder where they get the USD from...oh yeah, they basically pull it out of thin air. Just like this guy's credentials, paper thin.",0,0,0
1473,2023-02-20 13:27:13+00:00,ylecun,"@ylecun 2, 7, 1, 4, 3, 5, 6, 8, 9, 11",0,0,0
1474,2023-02-20 13:24:01+00:00,ylecun,@ylecun 1.Basic 2.Assembly 3.Pascal 4.C 5. C++ 6. Java 7.R 8. Python,0,0,0
1475,2023-02-20 13:11:59+00:00,ylecun,"@ylecun BASIC
FORTRAN
C
Assembly
Python",0,0,0
1476,2023-02-20 13:02:19+00:00,ylecun,"@ylecun 1. Basic
2. C
3. Assembly
4. C++
5. Python
6. Compiler Principles
7. Haskell
8. CUDA
9. javascript",0,0,0
1477,2023-02-20 12:55:36+00:00,ylecun,"@ylecun 1. R
2. JavaScript
3. Java
4. python
5. C#",1,0,0
1478,2023-02-20 12:31:49+00:00,ylecun,"@ylecun C
C++
Assembly
Java
Python
Lua
JavaScript
Bash/zsh
SQL
Go
TypeScript
Rust
Zig",0,1,0
1479,2023-02-20 12:29:42+00:00,ylecun,@ylecun @rao2z I think meta deserves more credit than what people give when it comes to AI research.,0,0,0
1480,2023-02-20 12:28:11+00:00,ylecun,@ylecun A bit jealous about that Assembly there! I gotta learn it for some reverse engineering.,0,0,0
1481,2023-02-20 12:16:48+00:00,ylecun,"@ylecun @rao2z Unfortunately this appears to be at the detriment of business value and I don't see companies being as open with their AI research as they once were. You can thank ""Open""AI for that.",0,0,0
1482,2023-02-20 12:12:52+00:00,ylecun,@ylecun Everyone forgot Smalltalk.,0,1,0
1483,2023-02-20 12:09:27+00:00,ylecun,"@ylecun Obviously most of the hype goes to silly bull market phenomenon stuff but there are interesting use cases for p2p consensus and exec of arbitrary code with solved double spending and plenty of great devs working on solutions with passion for a dectrl future, not out of greed.",0,2,0
1484,2023-02-20 11:46:54+00:00,ylecun,"@ylecun Fortran, Basic, 8086 assembly, C, Java, Javascript and PHP.",0,1,1
1485,2023-02-20 11:46:23+00:00,ylecun,@ylecun I wish Forth was fourth,0,0,0
1486,2023-02-20 11:38:27+00:00,ylecun,@ylecun you literally work at Facebook so maybe take a seat,0,5,0
1487,2023-02-20 11:23:33+00:00,ylecun,@ylecun @jasonfi How old are you Sir? ü§î,0,0,0
1488,2023-02-20 11:08:32+00:00,ylecun,@ylecun Lol so true,0,0,0
1489,2023-02-20 10:59:28+00:00,ylecun,"@ylecun @gemhodlr i am confident that you'll understand the relevance of cryptography and verifiable delay functions in the context of machine learning some day, but the uncertainty regarding how long this will take appears like a decent source of randomness",0,0,0
1490,2023-02-20 10:59:22+00:00,ylecun,"@ylecun 1. Pascal
2. Basic
3. VB
4. C
5. Assembly
6. C++
7. C#
8. JavaScript
9. TypeScript
10. Python
11. Rust",0,0,0
1491,2023-02-20 10:21:33+00:00,ylecun,@ylecun 12.  Ruby13.  Rust,0,0,0
1492,2023-02-20 10:04:21+00:00,ylecun,@ylecun If you really care 2 8 11,0,0,0
1493,2023-02-20 09:59:14+00:00,ylecun,"@ylecun 1. C++
2. Java
3. JavaScript 
4. PHP",0,0,0
1494,2023-02-20 09:59:12+00:00,ylecun,"@ylecun 1. BrainFuck
1. Assembly
2. Fortran
3.C++
4. Haskell
5. Scratch",0,0,0
1495,2023-02-20 09:50:45+00:00,ylecun,"@ylecun 1. Slide rules
2. Fortran, punched cards.
3. APL, just for fun
4. Machine code, front panel switches
5. Forth
6. Assembly
7. PL1
8. C 
9. CUPL and ABLE
10. LabVIEW
11. Verilog
(*) To quote the renowned analog designer Bob Pease, ‚Äúmy favorite programming language is solder.‚Äù",0,7,1
1496,2023-02-20 09:42:19+00:00,ylecun,"@ylecun oh man I miss the QBasic times so much, those long nights experimenting in front of the yellowish monochrome screen",0,2,0
1497,2023-02-20 09:39:18+00:00,ylecun,"@ylecun 1. Basic
2. Basic
3. Basic 
4. Basic
5. Basic 
6. Basic
7. Basic",0,0,0
1498,2023-02-20 09:29:12+00:00,ylecun,"@ylecun 1. Pascal
2. C
3. C++
4. Assembly
5. Java
6. C#
7. Lua
9. Perl
10. PHP
11. Python
12. JavaScript
13. Rust
14. Golang
15. Hack
16. Kotlin
17. English...(through ChatGPT)",0,0,0
1499,2023-02-20 09:09:15+00:00,ylecun,"@ylecun Sir, why you don‚Äôt use SQL?",0,0,0
1500,2023-02-20 09:06:55+00:00,ylecun,"@ylecun @elonmusk @MKBHD Whatsapp isn‚Äôt free for business initiated conversations just like telecom companies charge for mobile terminated messaging. So, not exactly free either. Cheap-er, not free.",0,0,0
1501,2023-02-20 08:49:42+00:00,ylecun,"@ylecun Wow, that's a year before I was born! I learnt assembly language with a manual that was quite brief, it took me a while to get the hang of it. It was mostly for the challenge, and a little to optimize inner loop C code.",0,0,0
1502,2023-02-20 08:37:52+00:00,ylecun,@ylecun @naivebaesian Could you share a link to the tweet?,1,0,0
1503,2023-02-20 08:37:48+00:00,ylecun,@ylecun How many languages do you know?,0,0,0
1504,2023-02-20 08:37:43+00:00,ylecun,@ylecun Ahaha ima just playing üßöüèª‚Äç‚ôÄÔ∏è,0,0,0
1505,2023-02-20 08:13:23+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah Does this hold true for this RNN? 
You can extend it's prompt bit by bit, if I'm not mistaken. 
https://t.co/GIlBoDd6wo",0,0,0
1506,2023-02-20 07:49:48+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah Their ""mental state"" is what they say out loud, the sequence itself. Waiting for LLMs' breakdown of the bicameral mind...",0,0,0
1507,2023-02-20 07:45:14+00:00,ylecun,@ylecun I don't think anyone serious in crypto says that given that our entire industry rests on a mountain of research papers going back decades.,0,0,0
1508,2023-02-20 07:44:23+00:00,ylecun,"@ylecun 1: Basic
2: Visual Basic
3: C
Long break in coding 
4: Bash
5: Python",0,0,0
1509,2023-02-20 07:21:07+00:00,ylecun,@ylecun Anyone had to use Haskell at any point in their life :(,0,0,0
1510,2023-02-20 07:16:02+00:00,ylecun,"@ylecun @notbyintent Nice stuff.
When being on a computer all day long, handling the counter weight of my telescope, looking perfect match of the gears, the smoothness and heavyness of the massive moving parts, it feels real, balanced, meaningful.",0,0,0
1511,2023-02-20 07:03:13+00:00,ylecun,"@ylecun C
Matlab
Python
Fortran
C++
Java
JS
Lua",0,0,0
1512,2023-02-20 06:54:00+00:00,ylecun,"@ylecun If you cannot BUIDL, you publish useless papers. https://t.co/6n876NGxEc",0,0,0
1513,2023-02-20 06:50:21+00:00,ylecun,@ylecun @McAllesterDavid @nlpnoah Is that the only requirement it needs to meet? I think you are very much wrong on your interpretation of AI capabilities as compared to humans.,0,0,0
1514,2023-02-20 06:49:50+00:00,ylecun,"@ylecun @wangilisasi Kind of funny, as Caffe, the first Facebook‚Äôs DL framework, was in Java.
Then, Caffe2 was in Python and included in PyTorch.",1,0,0
1515,2023-02-20 06:42:51+00:00,ylecun,"@ylecun 1. Pascal
2. Actionscript
3. PHP
4. Javascript
5. C#
6. C/C++
7. Assembly
8. Java
9. Prolog
10. Ada
11. Python

Now I mainly use Python.",0,0,0
1516,2023-02-20 06:42:05+00:00,ylecun,"@ylecun @Arian_Khorasani I remember finding Lush as a teenager trying to learn how to make my own Lisp üòÑ

Years later when deep learning got big I was like ""Yann LeCun? Where have I heard that name...""",0,0,0
1517,2023-02-20 06:37:59+00:00,ylecun,@ylecun Prolog FTW,0,0,0
1518,2023-02-20 06:32:28+00:00,ylecun,"@ylecun 11 computer languages.
 imagine you speak the same number of human languages.",0,0,0
1519,2023-02-20 06:31:55+00:00,ylecun,@ylecun @TonyZador @patrickmineault Babies dream about the world before birth.,0,0,0
1520,2023-02-20 06:31:01+00:00,ylecun,"@ylecun 1. Regular
2. Context-free
3. Context-sensitive
4. Recursively enumerable
5. Bitcoin Script &amp; Non-Turing-complete Crypt bro

Any suggestions what to learn next, since I am relatively new to this? ü§î",0,0,1
1521,2023-02-20 06:30:46+00:00,ylecun,"@ylecun Basic
C
(does bash count?)
Basic 7
PL/1
PL/AS
JCL
Pascal
LISP
Prolog
C++
(does ksh count?)
Java
C#
R
PHP
Javascript",0,1,0
1522,2023-02-20 06:09:09+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah If that‚Äôs the case, then how do they recall previous conversations from other people?",1,0,0
1523,2023-02-20 06:04:38+00:00,ylecun,"@ylecun 1.Basic - on a C64 - walk before you can: Run
2.Fortran - punch-cards aren't really fun - university
3.C - on an Atari XT, MS-DOS - university / private
4.Python - because pandas blew my mind...
5.Julia - curiosity / tinkering / 13 year old Mac 64bit Ubuntu",0,3,2
1524,2023-02-20 06:03:23+00:00,ylecun,"@ylecun Basic
Assembly
Fortran
Pascal
C
Cobol
sh
DCL
Lisp
Prolog
Forth
C++
SQL
ObjectiveC
Smalltalk
JCL
Protel
Java
Javascript
C#
Python",0,3,2
1525,2023-02-20 06:03:12+00:00,ylecun,"@ylecun I hated LISP. Recursion hurts my brain.üòÄ 
I like languages C# or Java because with enough practice it feels like you‚Äôre writing an essay in English ! üôÇ",2,0,0
1526,2023-02-20 05:58:22+00:00,ylecun,@ylecun Yeah top men‚Ä¶ All the alphabet agencies have a proven track record of giving away the store. We now have recent evidence that the Israelis regularly disrupt elections globally with orchestrated social media. https://t.co/PkLKs7cHQY  And we also know that https://t.co/N04ADs8pvY,1,1,0
1527,2023-02-20 05:55:11+00:00,ylecun,@ylecun @AbhiUpmanyu,0,0,0
1528,2023-02-20 05:54:05+00:00,ylecun,"@ylecun 1. C++
2. C
3. Java
4. Kotlin
5. Python
6. R",0,0,0
1529,2023-02-20 05:51:06+00:00,ylecun,"@ylecun FORTRAN77, C, Assembly, C++, MATLAB, R, Python, PHP. I didn‚Äôt think I will be a programmer and didn‚Äôt choose CS in college.",0,1,0
1530,2023-02-20 05:48:42+00:00,ylecun,"@ylecun Basic
Lisp
C
Asm x86, z80, 6502, r3k
C++
Java
Forth
Perl
Python
Php
Clojure
Prolog
Javascript
Lua
Ruby
Typescript
Swift
Golang",0,0,0
1531,2023-02-20 05:42:05+00:00,ylecun,"@ylecun lol, burn!",0,0,0
1532,2023-02-20 05:38:10+00:00,ylecun,@ylecun Why everyone forgets sql,0,1,0
1533,2023-02-20 05:37:40+00:00,ylecun,"@ylecun Prolog was a good experience (""A jamais les premiers""). But no ADA ?",0,0,0
1534,2023-02-20 05:37:32+00:00,ylecun,@ylecun Ever given Clojure a look? I'm kind of disappointed that it doesn't have wider adoption in the sciences in particular.,0,0,0
1535,2023-02-20 05:36:53+00:00,ylecun,@ylecun Wen moon?,0,0,0
1536,2023-02-20 05:32:28+00:00,ylecun,"@ylecun J'avais aussi l'id√©e de faire √ßa (mais bon, j'attends mon t√©lescope depuis 4 mois). Merci, c'est magnifique. F√©licitations.",0,0,0
1537,2023-02-20 05:31:59+00:00,ylecun,"@ylecun @Arian_Khorasani In an ideal world, Lush would be where PyTorch is today! A brilliant piece of software.",0,0,0
1538,2023-02-20 05:27:02+00:00,ylecun,@ylecun üòÇ,0,0,0
1539,2023-02-20 05:21:54+00:00,ylecun,@ylecun Sheesh,0,0,0
1540,2023-02-20 05:11:21+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah It has a state throughout a session. But it's ephemeral, of course",2,0,0
1541,2023-02-20 05:09:32+00:00,ylecun,@ylecun Assembly ‚ò†Ô∏è,0,0,0
1542,2023-02-20 05:08:58+00:00,ylecun,@ylecun Lua vs Python? Honest opinion.,0,0,0
1543,2023-02-20 05:05:45+00:00,ylecun,"@ylecun 01. Machine
02. Assembly
03. Basic
04. Forth
05. Pascal
06. Fortran
07. COBOL
08. C
09. Hex Mode 0x12 Machine
10. OpenGL
11. C++
12. HTML
13. Java
14. DirectX
15. Ruby
16. SQL
17. Python
18. HLSL
19. C#
20. Rust",0,0,0
1544,2023-02-20 05:03:34+00:00,ylecun,@ylecun Highly customizable üëçüèª,0,0,0
1545,2023-02-20 05:00:11+00:00,ylecun,"@ylecun AGI risk also growing exponentionally. ~1000x speedup to training/inference, with no hardware changes, and new ""post-transformer"" arch coming. Two separate breakthroughs. This will demand we take safety seriously, and soon. Scary AI in &lt;18 months, essentially certain.",1,4,1
1546,2023-02-20 04:59:24+00:00,ylecun,"@ylecun C#, Java, C++, JavaScript, PHP, SQL, Assembly, Python, OCaml, Python, Python, Python, Python.",0,0,0
1547,2023-02-20 04:58:29+00:00,ylecun,@ylecun Here here!,0,0,0
1548,2023-02-20 04:58:20+00:00,ylecun,@ylecun @wangilisasi Wow,0,0,0
1549,2023-02-20 04:58:09+00:00,ylecun,@ylecun You should try Cobol it‚Äôs a treat,1,0,0
1550,2023-02-20 04:56:09+00:00,ylecun,"@ylecun 3,6,8,11",0,0,0
1551,2023-02-20 04:51:26+00:00,ylecun,@ylecun I like Prolog too!,0,0,0
1552,2023-02-20 04:50:55+00:00,ylecun,"@ylecun No Scheme? Scheme was elegant!
Prolog‚Äôs negation as failure is as pure as it gets.",0,0,0
1553,2023-02-20 04:49:34+00:00,ylecun,"@ylecun and @RichardSSutton, hey, I'm an AI enthusiast law student trying to navigate the beautiful, complex world of AI and eventually, integrated systems.

I am trying to approach it from the very first principles. I've adopted both of your names for my username. Is that okay?",0,0,0
1554,2023-02-20 04:47:59+00:00,ylecun,@ylecun No Java Sir?,2,3,0
1555,2023-02-20 04:47:26+00:00,ylecun,"@ylecun @Marktechpost @ashkamath20 @alcinos26 Now take those results, embed them in the feature space of an LLM and now we're cooking with gas üòÄ",0,0,0
1556,2023-02-20 04:45:50+00:00,ylecun,@ylecun What a nerd,0,0,0
1557,2023-02-20 04:42:11+00:00,ylecun,@ylecun So it is the timing that truly revolution as same as the ICT?,0,0,0
1558,2023-02-20 04:39:02+00:00,ylecun,"@ylecun My recent meeting with my friend Guy-Alain - Alain Colmerauer's late assistant - forces me to insist a bit: Prolog √ºber alles!
(Luminy powa!)",0,1,0
1559,2023-02-20 04:37:22+00:00,ylecun,@ylecun Assembly as a first language? Why?,2,1,0
1560,2023-02-20 04:36:59+00:00,ylecun,"@ylecun CMOS nand nor. Assembly, pascal, c, ada, lisp, cobol, basic, Fortran, c++, pl/1, Algol, Java.",1,2,0
1561,2023-02-20 04:36:08+00:00,ylecun,"@ylecun 1. Matlab
2. Fortran
3. C++
4. Python
5. Typescript
6. Erlang
7. Scala
8. Kotlin
9. C
10. (Learning) Zig",1,1,0
1562,2023-02-20 04:35:53+00:00,ylecun,"@ylecun @patrickmineault or, since local image statistics are essentially stationary over time scales longer than an animal's lifetime, you could build ""weight sharing"" into the genome as the developmental rules for wiring up a brain...saves a lot of time compared to learning them anew each generation",1,5,1
1563,2023-02-20 04:35:02+00:00,ylecun,@ylecun You are hired! @ylecun,0,0,0
1564,2023-02-20 04:35:00+00:00,ylecun,@ylecun No Java?,1,0,0
1565,2023-02-20 04:33:51+00:00,ylecun,"@ylecun Your favorite is number 7 on the list. Did you choose randomly?

Thank you.",1,0,0
1566,2023-02-20 04:33:39+00:00,ylecun,"@ylecun Wow great ! I guess you haven't used it since, right?",1,0,0
1567,2023-02-20 04:33:30+00:00,ylecun,@ylecun You were using Lisp in your days at Bell lab?,1,3,0
1568,2023-02-20 04:33:17+00:00,ylecun,@ylecun Next: human compassion,1,1,0
1569,2023-02-20 04:32:09+00:00,ylecun,@ylecun Forth üëãüèΩ,0,0,0
1570,2023-02-20 04:28:38+00:00,ylecun,@ylecun Scheme FTW,0,0,0
1571,2023-02-20 04:28:01+00:00,ylecun,"@ylecun Lisp is cool, learning some of it from the old-school MIT course Structure and Interpretations of Computer Programs was awesome! https://t.co/FkQd5BLP2Y",0,1,0
1572,2023-02-20 04:28:00+00:00,ylecun,"Oh, I forgot Prolog, somewhere between Pascal and Forth.",12,82,2
1573,2023-02-20 04:27:12+00:00,ylecun,@ylecun Woohoo! Love the Fortran representation üòÅ,0,0,0
1574,2023-02-20 04:25:58+00:00,ylecun,My favorite: Lisp.,20,137,7
1575,2023-02-20 04:24:34+00:00,ylecun,@ylecun 12. Irrational ChatGBT hate,0,1,0
1576,2023-02-20 04:24:11+00:00,ylecun,"@ylecun Maybe we've hit a Plateau, and there is little ""publishable"" scientific innovation, and more ""fine tuning"" of existing knowledge to concrete and profitable products. i.e we've developed a lot of stuff as a research community  -  now let's use all this knowledge to make money.",0,0,0
1577,2023-02-20 04:23:00+00:00,ylecun,@ylecun Forth is my favorite name for a language,0,0,0
1578,2023-02-20 04:22:13+00:00,ylecun,"@ylecun You don‚Äôt preach  about the importance of basic research to crypto people ; they are there to make money.  Similarly, basic research should not be done in a commercial company; it‚Äôs bottomline is making money as well.",0,0,0
1579,2023-02-20 04:21:23+00:00,ylecun,@ylecun Javascript! Really?,1,0,0
1580,2023-02-20 04:20:51+00:00,ylecun,"@ylecun 1. Basic command lines
2. Pascal
3. C/C++
4. Matlab
5. R
6. Jython
7. FOTRAN90
8. Python 
9. Scala
10. Javascript",0,2,0
1581,2023-02-20 04:19:35+00:00,ylecun,@ylecun @McAllesterDavid @nlpnoah Augmenting them with a state is trivial.,1,2,0
1582,2023-02-20 04:18:40+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah I think the author meant LLM system with some kind of prompt persistence paradigm like chat history. The LLM is a building block, like one iteration of an LSTM..",0,1,0
1583,2023-02-20 04:17:44+00:00,ylecun,@ylecun The path you took is insane!!!,0,0,0
1584,2023-02-20 04:17:05+00:00,ylecun,@ylecun Wow!,0,1,0
1585,2023-02-20 04:17:04+00:00,ylecun,"@ylecun Out of curiosity, which do you think would be best for someone to learn first if the only thing you know about them is they want to learn a programming language?",1,0,0
1586,2023-02-20 04:16:13+00:00,ylecun,@ylecun Assembly üíÄ,0,0,0
1587,2023-02-20 04:12:11+00:00,ylecun,@ylecun For why you learn JavaScript please ?,1,1,0
1588,2023-02-20 04:08:27+00:00,ylecun,@ylecun üëç write BP in assembly!,0,0,0
1589,2023-02-20 04:05:31+00:00,ylecun,@ylecun Total AI publications increased by 50% during 2015 to 2019. And we‚Äôre now seeing the result of it.,0,1,0
1590,2023-02-20 04:00:49+00:00,ylecun,@ylecun Like this research? https://t.co/Lw79GuLyJb,0,0,0
1591,2023-02-20 04:00:00+00:00,ylecun,"@ylecun @McAllesterDavid @nlpnoah Yes, and its state is seemingly ever changing based on prompt. It‚Äôs never a consistent state across highly varied prompts.",1,0,0
1592,2023-02-20 03:59:57+00:00,ylecun,"@ylecun @bittensor_ neural network is based on acedamics &amp; practice, combining the best of both worlds.",0,6,1
1593,2023-02-20 03:59:15+00:00,ylecun,@ylecun @McAllesterDavid @nlpnoah Wouldn‚Äôt one be correct to think that their pretraining is their state? (In some way),1,0,0
1594,2023-02-20 03:57:05+00:00,ylecun,@ylecun Arxiv and iacr have plenty of ‚Äúuseless crypto bro‚Äù papers. Crypto also does not have an issue of open sourcing and publishing their research unlike AI,1,4,0
1595,2023-02-20 03:52:29+00:00,ylecun,"@ylecun @tdietterich Open source has helped lift so many boats. It's been essential to almost all recent AI progress. Yet sometimes, to make a profit, ideas and code are kept closed. Are we entering a new era in AI? Can you make a case for how to decide to be open?",0,0,0
1596,2023-02-20 03:21:44+00:00,ylecun,@ylecun In the words of great Charlie: Cryptocrapo or Cryptoshit.,0,0,0
1597,2023-02-20 03:18:16+00:00,ylecun,"@ylecun @rao2z We thank you, even if your political views can be annoying, you are obviously a treasure to the human race.",0,0,0
1598,2023-02-20 03:10:52+00:00,ylecun,@ylecun Top men who make websites for a billion dollars üò¨,0,0,0
1599,2023-02-20 03:02:16+00:00,ylecun,@ylecun Crypto Bro can thank AI for the creative solution to his problem and ( making compilers available for Neural Networks.) Thats two birds.,0,0,0
1600,2023-02-20 03:02:01+00:00,ylecun,"@ylecun Sundar Pichai, Peter Thiel, Mark Zuckerberg..",0,0,0
1601,2023-02-20 02:53:24+00:00,ylecun,@ylecun @tdietterich thank you for lifting our boats,0,0,0
1602,2023-02-20 02:51:52+00:00,ylecun,"@ylecun to date, i haven't met a ""crypto bro"" bearish on AI",2,32,2
1603,2023-02-20 02:46:32+00:00,ylecun,"@ylecun New technology downsides and technical scrutinies are  less for startups 

Disruptive technology is easy for startup's with least  bureaucracy and less reputations concerns 

Large companies lose ability to enter small and emerging markets because of their established business.",0,0,0
1604,2023-02-20 02:31:16+00:00,ylecun,"@ylecun Might be more appropriate to say ""top people"" otherwise comes across a bit sexist.",0,0,0
1605,2023-02-20 02:20:19+00:00,ylecun,@ylecun @CClavius And 2 is precisely why nothing good came out of Amazon.,0,0,0
1606,2023-02-20 02:15:31+00:00,ylecun,@ylecun I agree. What do you think of crypto rigs and deep learning? It must sound cool to just shove in GPU's like hotcakes and cause an outage in the neighborhood.,0,0,0
1607,2023-02-20 02:12:40+00:00,ylecun,"@ylecun Crypto folks know what they doing is shit. When someone outside of crypto want to bring something value, they were even like: not so crypto.",0,0,0
1608,2023-02-20 02:05:24+00:00,ylecun,"@ylecun like this:
https://t.co/juKGMXOsa1",0,1,0
1609,2023-02-20 01:45:38+00:00,ylecun,"@ylecun Crypto bros still swear by a single paper published over 10 years ago, that tells a lot about the actual scientific advances there",2,2,1
1610,2023-02-20 01:36:35+00:00,ylecun,@ylecun For sure CIA and FBI have their own version.,0,1,0
1611,2023-02-20 01:34:36+00:00,ylecun,@ylecun @elonmusk @MKBHD Telegram is better,0,0,0
1612,2023-02-20 01:22:11+00:00,ylecun,@ylecun @elonmusk @MKBHD You're so loyal to Meta. I see that.,0,0,0
1613,2023-02-20 01:20:26+00:00,ylecun,"@ylecun Ouch, funny yet cool thing about twitter is some random bloke thinks he can go head to head about computing with an Alan Turing winner",0,0,0
1614,2023-02-20 00:41:41+00:00,ylecun,"@ylecun what exactly is the potential impact in your opinion, yann? imo there are certainly impressive fundamental advances but i think there‚Äôs a lot of hype and i have yet to clearly see product applications and, crucially, business models",0,0,0
1615,2023-02-20 00:39:41+00:00,ylecun,@ylecun And then the whole bus clapped,0,20,0
1616,2023-02-20 00:14:48+00:00,ylecun,"@ylecun Can this be a sign that from an application perspective, there‚Äôs confidence the existing research has a lot of untapped value? More of a focus shift",0,0,0
1617,2023-02-20 00:14:17+00:00,ylecun,"@ylecun @flycooler ""research"" , ""lab"" in crypto = scam",0,0,0
1618,2023-02-20 00:11:20+00:00,ylecun,@ylecun Maybe this is a consequence of the mandate for these companies to incorporate AI more into their products? Thus fundamental research that could once be broadly shared and open source becomes a part of a corporation's core IP.,0,0,0
1619,2023-02-20 00:03:55+00:00,ylecun,"@ylecun pretty interesting to call cryptography, distributed systems, byzantine fault tolerance etc ""thin air""

of course there are scams within crypto, just as any industry",3,14,1
1620,2023-02-20 00:03:48+00:00,ylecun,@ylecun Maybe level up your crypto bro circle üòÇ my AI circle are all about papers #bittensor,2,4,0
1621,2023-02-19 23:56:19+00:00,ylecun,@ylecun Absolutely correct!,0,0,0
1622,2023-02-19 23:54:27+00:00,ylecun,@ylecun The 'what I will do' is always better than the 'what they already did'.,0,0,0
1623,2023-02-19 23:44:22+00:00,ylecun,"@ylecun @rao2z Google was a cool place to work decade ago, today I agree with @pmddomingos Google should hire a bald CEO",0,0,0
1624,2023-02-19 23:38:29+00:00,ylecun,@ylecun https://t.co/YxnRIcqwcr,0,1,0
1625,2023-02-19 23:04:37+00:00,ylecun,@ylecun @rao2z Really appreciate your contributions and viewsüôè,0,0,0
1626,2023-02-19 23:04:13+00:00,ylecun,@ylecun https://t.co/A8pvZnWSYE,0,6,0
1627,2023-02-19 22:57:32+00:00,ylecun,@ylecun lol https://t.co/3OEHcbfteG,0,6,0
1628,2023-02-19 22:51:21+00:00,ylecun,"@ylecun Ah, yes. Crypto bros. A class of people famous for talking about shareholder values.

Bit weird. If you make up fantasy characters to get upset at, why not use the proper vernacular? Have pride in your work!",1,3,0
1629,2023-02-19 22:45:54+00:00,ylecun,"@ylecun Meanwhile, back in the laboratory... https://t.co/mOvZFij3B9",0,1,0
1630,2023-02-19 22:45:25+00:00,ylecun,@ylecun Best pop culture reference I‚Äôm likely to see this weekend.,0,1,0
1631,2023-02-19 22:43:48+00:00,ylecun,@ylecun https://t.co/OvS4pNz3VA,0,1,0
1632,2023-02-19 22:38:44+00:00,ylecun,@ylecun @SohoJoeEth The recent layoffs would argue otherwise? They seem to be quite ‚Äúshort termism‚Äù in nature.,1,0,0
1633,2023-02-19 22:37:37+00:00,ylecun,@ylecun based.,0,0,0
1634,2023-02-19 22:30:57+00:00,ylecun,"@ylecun @cwolferesearch Hmm... where should I draw the line?
I'm literally working on a new venture. If I publish my constructs openly there will be no reason for anyone to pay for access to them. What happens to my venture then? Will Facebook write me a check for the lost revenue? Will you?",0,0,0
1635,2023-02-19 22:30:37+00:00,ylecun,@ylecun Totally agree! My Guinea pigs have better social intelligence than most humans.,0,0,0
1636,2023-02-19 22:21:54+00:00,ylecun,"@ylecun Not exclusive to the USA definitely, same thing in Serbia. I always wondered how that makes sense.",1,0,0
1637,2023-02-19 22:19:01+00:00,ylecun,@ylecun @benalsop and elephants have more neurons than humans - not a strong argument,0,3,0
1638,2023-02-19 22:17:20+00:00,ylecun,"@ylecun It doesn't include microsoft $1B investment in openai in 2019.

It was already obvious back then that it was just a matter of data and compute. Not a research challenge anymore. Mostly engineering üî•üöÄ",0,1,1
1639,2023-02-19 22:04:08+00:00,ylecun,@ylecun a paper is a product :),0,1,0
1640,2023-02-19 22:03:25+00:00,ylecun,"@ylecun Meta, l'initiateur des produits responsables du nivellement intellectuel par le bas de la jeunesse (pour ne pas dire de l'abrutissement de masse par le scroll infini et l'av√®nement des influenceurs).",0,0,0
1641,2023-02-19 21:59:11+00:00,ylecun,"@ylecun @DavidBensh So far all LLMs cannot check facts ‚Ä¶ with code you need careful regarding the version and dependencies, code samples might be outdated",0,1,0
1642,2023-02-19 21:55:53+00:00,ylecun,"@ylecun Sharing knowledge, insights - the foundation of our upcoming society. I love how it progresses in this space.

Not like in all those established industries. Where hidden knowledge is key for more and more closed spaces in favor of stakeholders.",0,0,0
1643,2023-02-19 21:52:21+00:00,ylecun,@ylecun Many people with no advanced degrees don't understand the purpose of science and theoretical research. I have been trying for decades to explain its value. Many would rather believe in aliens giving us microchips instead of learning about the invention of quantum mechanics.,0,8,0
1644,2023-02-19 21:51:38+00:00,ylecun,"@ylecun 100%.

Hype way ahead of reality.",0,0,0
1645,2023-02-19 21:36:06+00:00,ylecun,"@ylecun Actually crypto projects (and their currencies) DO create new technologies and services so their value it's not coming out of thin air, but from the service they provide. Ultimately, demand vs supply determines their price, exactly as in the equity market.",1,0,0
1646,2023-02-19 21:35:42+00:00,ylecun,@ylecun Did you rely on the equatorial mount to trace the object? 300s is a really long exposure time‚Ä¶,0,0,0
1647,2023-02-19 21:12:45+00:00,ylecun,@ylecun Most stock markets religiously agree on stock price based on company fundamentals. Nothing gets pulled out of thin air - those billions that vanished in the matter of hours were based on reasonable valuation.,0,0,0
1648,2023-02-19 21:10:22+00:00,ylecun,@ylecun https://t.co/FjDTes860H,1,0,0
1649,2023-02-19 21:06:47+00:00,ylecun,"@ylecun @pfhgetty But it is countering the point of ""undirected research"". You have an efficient paradigm that was discovered circa 2017 after few years of research to fuse RNNs and attention. Since than efforts were mostly toward scaling transformers with applied engineering not basic research..",1,0,0
1650,2023-02-19 21:06:08+00:00,ylecun,@ylecun Is there any kind of information hub that collects the pieces of evidence about how AI papers are finally converted into the real products? I am creating such a hub in my blog https://t.co/hwodsp1awh but probably this is already done somewhere else?,2,0,0
1651,2023-02-19 21:03:23+00:00,ylecun,@ylecun you doing ok? most of your posts spew venom. seems like a lot of positive things you should probably be talking about given your purview.,4,13,0
1652,2023-02-19 21:01:41+00:00,ylecun,@ylecun its okay to have grey hair bro,2,7,0
1653,2023-02-19 21:01:39+00:00,ylecun,"@ylecun @DavidBensh Even if the reasons are not rational at all, chatGPT has the potential of being such a gamechanger in terms of impact to people and business that is able to pay a lot of money.",1,0,0
1654,2023-02-19 20:59:55+00:00,ylecun,"@ylecun Fantastic to see results of the work up to now, and the continued momentum.",0,0,0
1655,2023-02-19 20:59:24+00:00,ylecun,"@ylecun ""... with ChatGPT and Stable Diffusion.""

And comparatively unnoticed went Galactica. Can we please have it back? Pretty please?",0,0,0
1656,2023-02-19 20:56:27+00:00,ylecun,@ylecun why don't meta and google release a real working product then? they were frontrunners in the AI race like you said. the market doesn't value research as much as it does execution and that's the reality,1,0,0
1657,2023-02-19 20:50:15+00:00,ylecun,@ylecun Calculus on future data is complicated. If I wasn‚Äôt focused on my retirement I would spend more time with sales team. They can smell food miles away.ü§£,0,0,0
1658,2023-02-19 20:48:05+00:00,ylecun,"@ylecun Just to add some nuance- in some areaa like ZK, you might have the product almost the same time as the paper, plus most code works ‚Ä¶.",0,3,0
1659,2023-02-19 20:44:31+00:00,ylecun,"@ylecun @Aapef Il faudrait que j'essaie √ßa un jour ! J'aimerai bien essayer Deep Prime de DXO photolab pour d√©bruit√© les photos d'astro mais √ßa ne prend que du RA, hors les logiciels classiques pour empiler les photos g√©n√®rent que des .tiff...",0,0,0
1660,2023-02-19 20:42:51+00:00,ylecun,"@ylecun ok, and what is your point, that‚Äôs R&amp;D and VCs are ahead of general public? has been true for pretty much anything, no?",0,0,0
1661,2023-02-19 20:31:25+00:00,ylecun,"@ylecun Research doesn‚Äôt have to be shared/published. I‚Äôm sure you‚Äôre astute enough to see that, aren‚Äôt you?",1,0,0
1662,2023-02-19 20:25:37+00:00,ylecun,@ylecun https://t.co/9mPzvRHEWN,0,0,0
1663,2023-02-19 20:14:39+00:00,ylecun,@ylecun I love the irony of what they're saying.,0,0,0
1664,2023-02-19 20:09:13+00:00,ylecun,@ylecun üî•üî•üî•,0,0,0
1665,2023-02-19 20:05:11+00:00,ylecun,"@ylecun To be fair, some crypto projects are based on peer-reviewed research, although frowned upon by the average ""crypto bro"" #cardano",0,0,0
1666,2023-02-19 20:05:02+00:00,ylecun,"@ylecun So when you say research is critical to create new products..
You mean to make product like GPT better? (because that could be heuristic engineering that is not necessarily trad research).
Or come up with alternatives to transformers that are vital to products 5y down the line?",1,2,0
1667,2023-02-19 20:01:11+00:00,ylecun,"@ylecun Hi Dr LeCunn, by any chance the Zoom lecture on Wednesday is recorded and available somewhere? I had to step out but really want to see it, thanks!",0,0,0
1668,2023-02-19 19:59:50+00:00,ylecun,@ylecun Are many people really saying to stop doing fundamental research and publishing papers?  I feel like everyone with a brain understands the value of this... maybe I'm too optimistic.,0,0,0
1669,2023-02-19 19:57:48+00:00,ylecun,@ylecun https://t.co/YzfmtNhSjD,0,0,0
1670,2023-02-19 19:55:39+00:00,ylecun,"@ylecun ok, got it. Thanks for the detailed answer. :)",0,2,0
1671,2023-02-19 19:54:19+00:00,ylecun,@ylecun @elonmusk @MKBHD WhatsApp + Meta channels &gt;&gt; Twitter,0,0,0
1672,2023-02-19 19:46:37+00:00,ylecun,"@ylecun But you also said that chatGPT is ""nothing new"" and it seems like a very valuable product to say the least..",1,13,0
1673,2023-02-19 19:45:39+00:00,ylecun,@ylecun There are genuine people trying to innovate in this field.,0,0,0
1674,2023-02-19 19:44:52+00:00,ylecun,@ylecun Research is a seperate thing from a usable product. Both are important and research comes first.,0,0,0
1675,2023-02-19 19:39:46+00:00,ylecun,"@ylecun Exactly, the way engineering has and should always be done, good research and planning before anything dangerous occurs",0,2,0
1676,2023-02-19 19:38:36+00:00,ylecun,@ylecun Bitcoin paper was written after code üôÉ,2,3,0
1677,2023-02-19 19:35:06+00:00,ylecun,"@ylecun Now that big money is involved, I expect we'll see even more rapid improvements.  Perhaps you're right, but it seems unlikely this will play out any differently than other tech progressions like semiconductor research being almost entirely closed research and purely for profit.",0,0,0
1678,2023-02-19 19:34:36+00:00,ylecun,@ylecun As a Bitcoiner Maximalist I totally endorse it. Sorry for our cyber/cypher punk manners but shitcoin/crypto casino is causing more harm than good. Join to the conversation ‚ÄúBitcoin only at Horizons‚Äù üòÅ https://t.co/lu2SnZyFTa,1,0,0
1679,2023-02-19 19:33:33+00:00,ylecun,"@ylecun I've heard of Tech bro.
Crypto bro is new üòÇ",0,0,0
1680,2023-02-19 19:32:58+00:00,ylecun,"@ylecun Research fuels innovation. Products without it are like crypto hype, without substance.",0,0,0
1681,2023-02-19 19:29:37+00:00,ylecun,@ylecun I think this is in direct response to:,1,0,0
1682,2023-02-19 19:29:13+00:00,ylecun,"@ylecun @om When can we never have to hear from or about ""crypto bros"" again?  I really wish they'd finally disappear and give it up.  Nobody is interested in their scams anymore.",1,1,0
1683,2023-02-19 19:25:33+00:00,ylecun,@ylecun Yes but instead of having humans review/rank these research papers machines can review/rank products produced from research reducing bias and incentivizing intelligence production @bittensor_,3,17,1
1684,2023-02-19 19:23:49+00:00,ylecun,"@ylecun This sounds very interesting. How does the compensation work in this model specifically, though? Does FAIR receive a fixed amount of money for a project, does FAIR receive a share of the profit for the product for which the research is being conducted or both?",2,1,0
1685,2023-02-19 19:23:19+00:00,ylecun,@ylecun ‚ÄúNo product‚Äù may be a strong statement. Much of the IP is hidden until coffers are satisfied.,0,0,0
1686,2023-02-19 19:22:52+00:00,ylecun,@ylecun Bet you get Web 3 mentioned after that reply üòÇ,0,2,0
1687,2023-02-19 19:21:01+00:00,ylecun,@ylecun People don‚Äôt understand how much paper reading MLE requires compared to SWE or other  engineering roles. ML is highly dependent on research.,0,6,1
1688,2023-02-19 19:17:31+00:00,ylecun,"@ylecun .... This is up there with ""Stop thinking, and start typing""... Where do you think the typing comes from?",0,1,0
1689,2023-02-19 19:16:23+00:00,ylecun,"@ylecun I think there should be a team that makes the cutting edge research available (as a subscription service). Kind of like the old Google labs, except paid and focused on AI stuff. You could get a huge amount of subscribers.",0,0,0
1690,2023-02-19 19:14:31+00:00,ylecun,@ylecun I can't believe crypto bros are a thing in your life lol,1,10,0
1691,2023-02-19 19:14:27+00:00,ylecun,@ylecun @CClavius What‚Äôs the value of latest advances in string theory for Wall Street investors in this months quarterly report?,0,1,0
1692,2023-02-19 19:12:46+00:00,ylecun,@ylecun Should look up what research means,0,0,0
1693,2023-02-19 19:11:41+00:00,ylecun,@ylecun crypto bro is one to talk,0,0,0
1694,2023-02-19 19:03:10+00:00,ylecun,@ylecun True but where does the money come from to fund the research. A balance has to be struck.,1,0,0
1695,2023-02-19 18:43:48+00:00,ylecun,"@ylecun Beautiful shot indeed, your camera has an APS-C sensor, aren‚Äôt there any full frame alternatives? Or the crop factor‚Äôs effect does not have a big impact in astrophotography in general?",1,0,0
1696,2023-02-19 18:21:33+00:00,ylecun,@ylecun @elonmusk @MKBHD Or better: @signalapp,0,1,0
1697,2023-02-19 18:19:35+00:00,ylecun,@ylecun @Marktechpost @ashkamath20 @alcinos26 Thanks for Showing us novel ways!,0,0,0
1698,2023-02-19 18:16:08+00:00,ylecun,@ylecun @roydanroy Re consequences: I guess the share of researchers papers at academic conferences will shift again more towards academic researchers. Not sure if that‚Äôs necessarily a bad thing since publishing has been a bit frustrating for many researchers who focus more on ideas than compute.,1,19,0
1699,2023-02-19 17:53:25+00:00,ylecun,@ylecun @elonmusk @MKBHD Isn't Meta announcing $12/month verification? @Meta,0,2,0
1700,2023-02-19 16:19:03+00:00,ylecun,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome There‚Äôs still plenty of people around who love running or even training their NNs with &lt;1MB - just saying! üòÉ@pulp_platform @tinyMLTalks @GreenWavesTech @RusciManu,0,4,0
1701,2023-02-19 16:15:09+00:00,ylecun,@ylecun @elonmusk @MKBHD WhatsApp has so many scammers that ruin user experience. When can Meta start working on getting rid of them?,1,1,0
1702,2023-02-19 16:10:39+00:00,ylecun,"@ylecun @elonmusk @MKBHD imo, business chats ruined whatsapp‚Ä¶",1,0,0
1703,2023-02-19 15:59:34+00:00,ylecun,@ylecun @elonmusk @MKBHD @elonmusk hates Facebook lol but it is a good solution for twitter and helps WhatsApp,0,1,0
1704,2023-02-19 15:51:03+00:00,ylecun,@ylecun @elonmusk @MKBHD Sneaky,0,0,0
1705,2023-02-19 15:50:48+00:00,ylecun,@ylecun That 's the problem also in Madrid. We have to drive one hour to find decent places to shoot. Even with dual band filters you need to make a lot of masks and convolutions in order to isolate the nebulas.A+,0,0,0
1706,2023-02-19 15:31:00+00:00,ylecun,@ylecun Nice!  Light pollution not bad? You have a dome? Share more.,1,0,0
1707,2023-02-19 15:15:11+00:00,ylecun,"@ylecun @Marktechpost @ashkamath20 @alcinos26 I am interested in this problem space because I think it can help accessibility. I‚Äôm still waiting for an AI model that could help a blind person navigate the world, where we could query: is the greenlight in the traffic light ready, how many people in front of me, etc..",1,19,1
1708,2023-02-19 15:06:59+00:00,ylecun,@ylecun This means the business types at the companies finally understand how they can make money with AI.  Universities publish.  DoD classifies.  This means AI is becoming useful.  Time to return to NYU?,0,0,0
1709,2023-02-19 14:21:59+00:00,ylecun,@ylecun @KordingLab If they have done something great they would publish it. ML is full of mediocritic papers adding some would not change although for researchers writing and explaining is critical for self improvement,0,0,0
1710,2023-02-19 13:36:54+00:00,ylecun,"@ylecun @SebastianSeung sir you shouldn't be cause this is like too early to me to say something like this... although we've some bad results but can we give it sometime the we did with chatgpt and even the gpts 

shouldn't we wait for it come out of beta and then we'll decide?",1,1,0
1711,2023-02-19 13:31:28+00:00,ylecun,@ylecun Is there any part of New Jersey with(out) light pollution necessary to shoot this?,1,0,0
1712,2023-02-19 13:17:48+00:00,ylecun,@ylecun might be getting a lot of hate but he is saying the truth mostly about these LLMs,0,0,0
1713,2023-02-19 12:13:35+00:00,ylecun,@ylecun @SebastianSeung ‚Ä¶ of the Final Judgement ? üòè,0,0,0
1714,2023-02-19 09:44:51+00:00,ylecun,@ylecun I'm curious how long it takes to process an image like this? It's an incredible photo,1,0,0
1715,2023-02-19 09:36:16+00:00,ylecun,"@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome There is an urgent need for all of us to reduce the compute dependencies of our AI Models, we need to go back on the board and figure out how to create new biological models all over again. Adding 1000's of GPU's doesn't seem to be getting us anywhere close to AGI.",0,0,0
1716,2023-02-19 09:27:11+00:00,ylecun,"@ylecun Sir, what helps/ helped you determine the distance as 2400 light years? Please share some thoughts on estimating distance in terms of light years. Thank you.",1,0,0
1717,2023-02-19 09:18:22+00:00,ylecun,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Et dire que maintenant on a du mal avec 8Go de RAM .. üòÜ,0,1,0
1718,2023-02-19 09:11:05+00:00,ylecun,"@ylecun such research(not LLM) could be sponsored by tax money, but it's hard to convince people they aren't loosing jobs,food,shelter because of AI",0,0,0
1719,2023-02-19 08:45:32+00:00,ylecun,"@ylecun Humans locked in the cradle or village. After solving the real AI, maybe we can really go out and explore the endless space",0,0,0
1720,2023-02-19 08:12:25+00:00,ylecun,@ylecun @rasbt Anthropic's recent paper found out the inverse scaling laws on LM performance. This is finding the same in harmful bias. You have been saying for long that scale is not the only way to go. We need new architectures.,0,0,0
1721,2023-02-19 07:46:07+00:00,ylecun,"@ylecun @JohnBlackburn75 @patrickmineault Yes, for video based problems convnets are still good. @ylecun what are your thoughts on video transformers or ConvNeXt models which are a mix of both Convnets and ViT?",0,0,0
1722,2023-02-19 07:39:51+00:00,ylecun,"@ylecun I rather prefer the Veils wide field ü§©
https://t.co/xIxv9Kd2cS

Taken with a humble ED72.",2,2,0
1723,2023-02-19 07:36:02+00:00,ylecun,@ylecun Beautiful shot!,0,0,0
1724,2023-02-19 07:14:21+00:00,ylecun,"@ylecun A pattern of matter,
A pattern of light,
Beautiful to see,
But itself has no sight,

A pattern of rules,
A beauty to behold,
An existing story,
Even if untold

Agnostic to sentience,
Agnostic to us,
LLMs will generate,
It's just probabilistically nice ;)",0,0,0
1725,2023-02-19 07:10:34+00:00,ylecun,@ylecun Astrological images are a thing of beauty,0,1,0
1726,2023-02-19 07:06:31+00:00,ylecun,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome That‚Äôs hardcore. These days you can‚Äôt even start Python shell in 512KB,1,4,0
1727,2023-02-19 06:46:17+00:00,ylecun,@ylecun @y0b1byte @Adobe @Apple @googlechrome üí™üèªüí™üèªüí™üèª,0,3,1
1728,2023-02-19 06:39:54+00:00,ylecun,"@ylecun Why does it matter that LLMs align to human values? I thought LLMs cannot reason and they are probabilistic language generators. Like any other powerful tool/weapon, I don‚Äôt think the issue is in alignment, but in who has access to this technology.",0,0,0
1729,2023-02-19 06:29:43+00:00,ylecun,"@ylecun It's really good at creating semantically correct but factually wrong output, so if you play fill in the blanks it's of great use",0,0,0
1730,2023-02-19 06:10:03+00:00,ylecun,"@ylecun Magnifique. Pour traiter les 65 images, vous avez utilis√© un algo personnel ? Ou un algo classique ?",2,1,0
1731,2023-02-19 04:55:18+00:00,ylecun,@ylecun @seedsnapp,1,1,0
1732,2023-02-19 04:39:46+00:00,ylecun,@ylecun OMG well done!!!,0,0,0
1733,2023-02-19 04:32:52+00:00,ylecun,@ylecun That‚Äôs wild!,0,0,0
1734,2023-02-19 04:24:20+00:00,ylecun,"@ylecun Stole your picture, you can have this one, instead. https://t.co/lBvxCyW5Op",0,0,0
1735,2023-02-19 04:22:42+00:00,ylecun,@ylecun Beautiful,0,1,0
1736,2023-02-19 04:22:18+00:00,ylecun,@ylecun ü•∞,0,1,0
1737,2023-02-19 04:14:56+00:00,ylecun,@ylecun üòÆ,0,1,0
1738,2023-02-19 04:03:14+00:00,ylecun,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Quite remarkable with what was available then.,0,1,0
1739,2023-02-19 03:45:08+00:00,ylecun,"@Marco20307855 @alfcnz @y0b1byte @Adobe @Apple @googlechrome I should say, the SunOS version had bits in assembly to make convolutions go fast.",0,3,0
1740,2023-02-19 02:39:26+00:00,ylecun,@ylecun Open source has always been a scam. Microsoft ripped off the open source (computer club) market in the late 70s. Google is just using the same old tricks to get free developers.,0,0,0
1741,2023-02-19 02:19:09+00:00,ylecun,"@ylecun It would be great if someone discovered how our brain does ""backpropagation.""",0,0,0
1742,2023-02-19 02:17:12+00:00,ylecun,"@ylecun @JohnBlackburn75 @patrickmineault No, transformers can't do everything in AI. They are much better than fuddy duddy convnets, but they are still curve fitters. Just a better curve fitter. Like just a better jock strap, but still a jock strap. Curve fitters are not enough to do human level AI.",1,1,0
1743,2023-02-19 02:15:35+00:00,ylecun,"@ylecun IMO, backpropagation is actually hindering progress in AI. Why? Because there's less motivation for researchers to discover a new approach closer to the biological neuron. I know @geoffreyhinton has come up with solutions on this but we need more researchers working on this",0,0,0
1744,2023-02-19 01:09:26+00:00,ylecun,"@ylecun Dude, you work at Facebook! L‚Äôh√¥pital qui se fout de la charit√©! üòÇ",0,0,0
1745,2023-02-18 23:23:14+00:00,ylecun,"@ylecun LLM are what they are: language models, not knowledge models nor reasoning models. Anyways it's the perfect tool for writing thing if you provide the knowledge and reasoning in your prompt. Really excited to see what they will do when combined with proper tools for reasoning !",0,2,0
1746,2023-02-18 23:15:31+00:00,ylecun,@ylecun @alfcnz @Adobe @Apple @googlechrome Savage,0,3,0
1747,2023-02-18 23:14:35+00:00,ylecun,"@ylecun By converging to the unoriginal, the publishing may have become more challenging and quantity may have been traded off with quality. As long as ideas sharing drives AI science forward, I would refrain from statements that elude to guerilla marketing of FAIR.",0,0,0
1748,2023-02-18 23:02:30+00:00,ylecun,@ylecun Sth like humans:),0,0,0
1749,2023-02-18 22:59:42+00:00,ylecun,"@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Convolutional Network Demo from 1989
https://t.co/Haq7A1gBK8",2,3,0
1750,2023-02-18 22:59:04+00:00,ylecun,"@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Is it 5.25‚Äù or 3.5 ‚Äú
I think most of your followers never hear of the floppies",1,1,0
1751,2023-02-18 22:56:45+00:00,ylecun,@ylecun @alfcnz @y0b1byte @Adobe @Apple @googlechrome Did you write it in assembly or ?,1,1,0
1752,2023-02-18 22:50:56+00:00,ylecun,"@ylecun @Kantrowitz It‚Äôs autoregressor‚Äôs, all the way down.",0,0,0
1753,2023-02-18 22:34:53+00:00,ylecun,@ylecun @patrickmineault Also a good approach for capturing potential non-stationarities in animals‚Äô ecological experience and cross-species differences (eg @madsarv et al https://t.co/0xDHpIfdFN) https://t.co/rBza7USV0Y,0,7,0
1754,2023-02-18 22:10:36+00:00,ylecun,"@ylecun @SebastianSeung ... Good afternoon, gentlemen. I'm Bing.",2,3,0
1755,2023-02-18 21:59:42+00:00,ylecun,@ylecun @patrickmineault Evolution has provided the hypercolumn organisation of v1 for us.,0,1,0
1756,2023-02-18 21:30:30+00:00,ylecun,"@ylecun @patrickmineault Conceptually, weight-sharing isnt problematic as long as you interpret those parameters as neuronal rather than synaptic. The computational benefit may be debatable, but it allows for 2 sets of params, neurons (fixed + shared) &amp; synapses (plastic + unique) in a bio-plausible way",0,0,0
1757,2023-02-18 21:18:23+00:00,ylecun,@ylecun @Kantrowitz @timnitGebru ..,0,0,0
1758,2023-02-18 21:14:55+00:00,ylecun,"@ylecun What are the similarities and differences between these LLM's and what Geoffrey Hinton described when he was discussing ""thought vectors?""  

https://t.co/IuypmOWfDJ",0,0,0
1759,2023-02-18 20:37:33+00:00,ylecun,@ylecun Coding stands on the shoulders of giants. Yann is one of them no doubt.,0,0,0
1760,2023-02-18 19:12:02+00:00,ylecun,@ylecun How can I get access to Galactica? I can check references so not worried about it giving some incorrect information. I‚Äôll even pay for access.,0,0,0
1761,2023-02-18 18:33:13+00:00,ylecun,@ylecun Why doesn‚Äôt FAIR provide a Chat ?,0,0,0
1762,2023-02-18 18:30:46+00:00,ylecun,@ylecun @Kantrowitz Understanding gravity feels like a weird purity test for intelligence to something that exists in a plane where gravity doesn't apply.,0,1,0
1763,2023-02-18 17:47:35+00:00,ylecun,"@ylecun Woke AIs must be ""Terminated"".",0,0,0
1764,2023-02-18 17:44:51+00:00,ylecun,@ylecun @chribeut Good point,0,0,0
1765,2023-02-18 17:44:18+00:00,ylecun,@ylecun my ideal ai assistant would do something like this: https://t.co/ejHVf9vQaU,0,0,0
1766,2023-02-18 17:33:59+00:00,ylecun,@ylecun @patrickmineault Not to mention the natural data augmentation of biology. Continuous variation from eye &amp; head movement ~16 hrs per day for your entire life (although front end Conv's probably finished training much earlier); likely why diff cultures have diff optical illusions,0,3,0
1767,2023-02-18 17:30:06+00:00,ylecun,@ylecun You think dealing with a strong minded person is difficult?  Wait until a sentient AI bot that doesn‚Äôt give a F* focuses on you.,0,0,0
1768,2023-02-18 17:16:46+00:00,ylecun,@ylecun @SohoJoeEth Bully!,0,0,0
1769,2023-02-18 16:56:22+00:00,ylecun,@ylecun @patrickmineault It seems like transformers will do everything! Language and vision as well. Is transformer the user neutral network?,2,0,0
1770,2023-02-18 16:33:06+00:00,ylecun,"@patrickmineault Regarding weight sharing, or lack thereof in biology: you don't need weight sharing if the training is essentially self-supervised.
Repeated feature detectors will naturally emerge from self-supervised learning because the local statistics of images are essentially stationary.",5,25,2
1771,2023-02-18 16:31:06+00:00,ylecun,"@patrickmineault This combination of a ConvNet front-end and transformer back-end is akin to the DETR architecture, which is my favorite one for vision.
https://t.co/mm8jeS99uK
...",1,27,2
1772,2023-02-18 16:28:26+00:00,ylecun,@ylecun Ok thank you. In the interview I thought you talked about how transformer models didn‚Äôt really work for audio/video while I‚Äôve found whisper to be super impressive. Was trying to understand what makes it different if its the same underlying tech as LLMs,0,1,0
1773,2023-02-18 16:09:39+00:00,ylecun,"@ylecun Before huggingface, companies needed multiple scientists to do the job, that can now be done by one engineer.",1,0,0
1774,2023-02-18 15:54:25+00:00,ylecun,@ylecun Extremely important question.,0,0,0
1775,2023-02-18 15:42:21+00:00,ylecun,@ylecun AI is man made. Everything man makes has an expiration date.,0,0,0
1776,2023-02-18 14:52:35+00:00,ylecun,@ylecun Superb. I also love astronomy photographer of the year from Guardian. Highly recommended. Ex: 2022 https://t.co/LmANNY6P6W,0,0,0
1777,2023-02-18 14:30:44+00:00,ylecun,@ylecun Either this or that?,0,0,0
1778,2023-02-18 14:15:00+00:00,ylecun,"@_ash_ran @AlanMorte @OpenAI The metric to optimize is a combination of several criteria: user satisfaction, user well-being, impact on society, and yes revenue.
It's always a trade-off. For example, you can show more ads to get more revenue in the short term, but you risk turning people away in the long run",1,0,0
1779,2023-02-18 13:57:08+00:00,ylecun,@ylecun FAIR papers and work has always been useful . Can't say the same for Deepmind who overinvested in RL and then funnily enough OpenAI did something worth the money with it,0,1,0
1780,2023-02-18 13:43:02+00:00,ylecun,@ylecun #Amiga rocks!,1,0,0
1781,2023-02-18 13:33:37+00:00,ylecun,"@ylecun No-one (I know) is suggesting they're the final answer for #AGI  We are just celebrating how incredible they are, how useful they can be,... 
Be careful too, when you critique them, IMHO, you are critiquing most humans as well. Human-level AI isn't that great of an achievement üòâ",1,0,0
1782,2023-02-18 13:31:20+00:00,ylecun,@ylecun Why did experts lose the opportunity grabbed by openai?,0,0,0
1783,2023-02-18 13:30:53+00:00,ylecun,"@ylecun @relnox @ylecun that is more or less the same opinion of Stuart Russel though. In the sense that we wouldn't know the implication of a model when deployed in the real world. Not in the terminator style scenario, rather in the ""mess up politic elections"" scenario. Some reg is necessary",0,0,0
1784,2023-02-18 13:29:16+00:00,ylecun,@ylecun in Brazil there is already a saying that illustrates this conversation: the dirty complaining about the badly washeda,0,3,0
1785,2023-02-18 12:47:34+00:00,ylecun,@ylecun ü§î One needs to be smart to use smart tools,0,0,0
1786,2023-02-18 12:41:13+00:00,ylecun,@ylecun There should be other options to offer free tools for AI projects. Joint marketing solutions could help startups and learners to integrate existing bricks and accelerate research or offer more services. This subsidy could be displayed by a visual space. Tech responsibility!,0,0,0
1787,2023-02-18 12:31:03+00:00,ylecun,"@ylecun Honestly, we will never know what a true AI is capable of until we actually have one.",0,0,0
1788,2023-02-18 12:04:11+00:00,ylecun,@ylecun @Kantrowitz It's a wonder LLMs can have *any* understanding of the physical world. They inhabit in pure text.,0,2,0
1789,2023-02-18 11:54:55+00:00,ylecun,"@ylecun I wasn't a big fan of FAIR, but now I do think that FAIR will become the leader in AI open source development.

Microsoft initially resisted open source code early on, but then ended up buying github.",0,0,0
1790,2023-02-18 11:40:17+00:00,ylecun,"@ylecun @MetaAI Shout-out to @LangChainAI that makes it easy to work on many of these methods for ""Augmented"" Language Models",0,1,0
1791,2023-02-18 11:38:11+00:00,ylecun,"@ylecun Fair is the reason I never buy Facebook shares in my life.
It‚Äôs totally waste of investor‚Äôs money to you guys.
As long as Facebook keeps this department, I cannot see an end of Facebook drop.
5 year -10% return„ÄÇGood job FAIR.",0,0,0
1792,2023-02-18 11:36:58+00:00,ylecun,@ylecun Alignment itself is a problem that requires general intelligence to solve.,0,0,0
1793,2023-02-18 11:01:10+00:00,ylecun,"@ylecun Musk founded a company. then left it without funding or way forward, interestingly, the story of Deep mind and Open AI are the same, both controlled by a larger entity. Both wish to be in service of humanity alas. can't be, in hindsight. Facebook seems to be doing a better.",0,2,0
1794,2023-02-18 10:50:39+00:00,ylecun,"@ylecun A lab leak will happen, affecting the globe with it's evil, forcing governments to subject the populace with strict but unnecessary measures in an effort to contain it.

Be it pre-planned by shadowy figures or not, a skeptic world will never trust any mainstream news source ever.",0,0,0
1795,2023-02-18 10:11:54+00:00,ylecun,"@ylecun I think this is due to the pressure that those companies have on AI. It is a common reflex that we saw many times, companies want to ‚Äúprotect‚Äù their technologies/research and reaffirm ‚Äúcommitment‚Äù while being blurry abour their tech. Fortunately new economic models have emerged",1,0,0
1796,2023-02-18 10:10:19+00:00,ylecun,"@ylecun - Pretty useful for coding and finding technical content quickly.  Still requires significant domain/contextual knowledge to validate the answers.
- I would not trust it at all with questions that require answers in the form of mathematical formulas. 
- Garbage-in, Garbage-out!",0,0,0
1797,2023-02-18 10:01:00+00:00,ylecun,@ylecun @bittensor_ does the same but in decentralised and open source manner,0,0,0
1798,2023-02-18 09:57:29+00:00,ylecun,"@ylecun TF is not RNN, 

next word is learned as well from next words",0,0,0
1799,2023-02-18 09:40:39+00:00,ylecun,"@ylecun @SohoJoeEth @ylecun as far I understand you don't give a damn about compliments, still I can't stop admiring your intelligence and objective thinking.",0,0,0
1800,2023-02-18 09:34:50+00:00,ylecun,@ylecun @MetaAI Great survey. Augmented Language Models (ALMs) seem to be heading closer to RL than the traditional NLP/IR fusion of models? One way that I think LMs help here is to cut down on the possible search space of the RL system,0,1,0
1801,2023-02-18 09:29:50+00:00,ylecun,@ylecun What was the fastest or the best version measured by your own metrics,0,0,0
1802,2023-02-18 09:05:04+00:00,ylecun,"@ylecun or @karpathy I think most people face the problem of data  overload. Like there are so many papers getting published everyday.
Like where to start ? üí°",0,1,0
1803,2023-02-18 08:38:33+00:00,ylecun,@ylecun @bittensor_ @AlanMorte @OpenAI How to talk about @bittensor_ decentralised incentivised neural network without mentioning it üëÄ.,0,0,0
1804,2023-02-18 08:34:50+00:00,ylecun,@ylecun FORTRAN is a good and powerful language to code a numerical method like backprop :),0,1,1
1805,2023-02-18 08:34:07+00:00,ylecun,@ylecun @AlanMorte @OpenAI Thoughts then on Stability? @EMostaque,1,0,0
1806,2023-02-18 08:23:45+00:00,ylecun,"@ylecun you know, you can code a pandorabot that's aligned with human values...",0,0,0
1807,2023-02-18 07:50:09+00:00,ylecun,@ylecun @MetaAI Will Meta be releasing something?,0,0,0
1808,2023-02-18 07:46:09+00:00,ylecun,@ylecun No plans for a Kotlin-based (Software 2.0) version?,0,0,0
1809,2023-02-18 07:43:43+00:00,ylecun,"@ylecun Meta and DeepMind released all their tools for StarCraft, yet I never saw anything for Dota 2 (besides the paper) from Open AI. And this was some years ago‚Ä¶.",0,2,0
1810,2023-02-18 07:40:40+00:00,ylecun,"@ylecun @MetaAI Looks like MetaAI and GoogleAI are LOSING the race to create SpockGPT. The only paper cited in this MetaAI survey that shows any concern for causality is this paper by MICROSOFT
https://t.co/0p5yNtpm5w
https://t.co/teHxJIPZJ1",0,1,0
1811,2023-02-18 07:38:07+00:00,ylecun,@ylecun Consequences will be A.I. Wars of 2033.,0,0,0
1812,2023-02-18 07:33:01+00:00,ylecun,"@ylecun How can OpenAI compete with DeepMind, Google Brain and MetaAI if they had remained completely open? 
The other research labs benefit from their parent company's finances.",2,5,0
1813,2023-02-18 07:16:26+00:00,ylecun,@ylecun @MetaAI @SaveToNotion #Tweet,1,0,0
1814,2023-02-18 07:06:58+00:00,ylecun,"@ylecun so funny that none of you have built anything like a good UI. And now you have, we're all using this stuff for the first time. And all you can do is make snarky comments about how you knew all of this already and it's nothing new. come on bruh",0,0,0
1815,2023-02-18 07:03:53+00:00,ylecun,"@ylecun @AlanMorte @OpenAI I see, thanks",0,0,0
1816,2023-02-18 07:03:30+00:00,ylecun,@ylecun the consequence of ai? https://t.co/laz7vjinWv,0,0,0
1817,2023-02-18 06:52:59+00:00,ylecun,@ylecun @claytondadon,0,0,0
1818,2023-02-18 06:36:52+00:00,ylecun,"@ylecun Haha, looks like that you know some Chinese",0,1,0
1819,2023-02-18 06:29:16+00:00,ylecun,@ylecun It‚Äôll be the state of how chip manufacturing and designers function. High tech knowledge kept secret and licensed in some countries. I recall my Oxford professors skipping an entire chapter on chip design because the current open knowledge is outdated.,0,0,0
1820,2023-02-18 06:28:30+00:00,ylecun,@ylecun Open-sourcing always attracts and inspires researchers for better collaborations and community development :),0,0,0
1821,2023-02-18 06:26:27+00:00,ylecun,@ylecun I hope Galactica and other cool projects could have been public without the BS,0,0,0
1822,2023-02-18 06:17:17+00:00,ylecun,@ylecun Meta will do same and FAIR is not everything Meta did research on.,0,0,0
1823,2023-02-18 05:41:49+00:00,ylecun,@ylecun Backprop ( in CNN) is the toughest algorithm i have ever learnt,0,0,0
1824,2023-02-18 05:22:11+00:00,ylecun,"@ylecun my 2 cents 
It is even worse than that. It isn't capable of stupidity. It takes intelligence to be stupid. It is just a collection of models (y = f(x)). It can't know it is spewing sense or nonsense and that's the problem.",0,0,0
1825,2023-02-18 05:20:23+00:00,ylecun,@ylecun What is the problem LLMs solve really ?,0,0,0
1826,2023-02-18 04:52:56+00:00,ylecun,@ylecun @relnox AGI is around the corner. One has to be blind to think it's a matter of linear progress rather than a single creative breakthrough. I could hardcode you a proto-AGI with a team of 30 engineers fingers in the nose. It's just not worth the inherent risk of a copy paste.,1,0,0
1827,2023-02-18 04:40:22+00:00,ylecun,"@ylecun @amitmate2010 @OpenAI Yann, thank you for the insight and engagement on this.",0,3,0
1828,2023-02-18 04:30:01+00:00,ylecun,"@ylecun @nojvek You use backprop to do curve  fitting.  But curve fitting is not enough to achieve human level AI (HLAI). HLAI requires an EXPLICIT engine that does causal inference and the closely related scientific method (SM) (the SM looks for causes, not correlations)
https://t.co/uWvDcYI9Eg",1,0,0
1829,2023-02-18 04:29:06+00:00,ylecun,@ylecun I imagine the core AI technology would be similar to cars' engines. There will be only a few top labs to actually develop the core technology (semi-secretive?). Others could develop applications and/or theory. Maybe one day we will see some AI competition analogous to F1 racing.,0,0,0
1830,2023-02-18 04:19:34+00:00,ylecun,@ylecun The scary part is how it's being used by people,0,0,0
1831,2023-02-18 04:19:08+00:00,ylecun,"@ylecun Prof., while I‚Äôm not an expert in any sense‚Ä¶ here‚Äôs my 2¬¢: as cutting-edge AI gets faster market adoption, companies might choose to be more secretive. It‚Äôs almost as if humans have a feedback system to regulate speed of progress.",0,1,0
1832,2023-02-18 04:17:17+00:00,ylecun,@ylecun https://t.co/5L7mETG7I2,0,0,0
1833,2023-02-18 03:56:16+00:00,ylecun,"@ylecun I hate to say it, but it should probably be relatively closed. Same with virus research. We don't live in a friendly world and this stuff shouldn't fall into the wrong hands.",0,0,0
1834,2023-02-18 03:46:55+00:00,ylecun,"@ylecun When a high achiever old guy says it's reliable, it's true, but when he says it's not reliable, it's probably very reliable",0,0,0
1835,2023-02-18 03:46:01+00:00,ylecun,@ylecun You old guy looks like a very extreme chatgpt achievement,0,0,0
1836,2023-02-18 03:34:46+00:00,ylecun,@ylecun Why have the number of preprints from industrial labs dropped so significantly since the past month? Any views,0,1,0
1837,2023-02-18 03:05:52+00:00,ylecun,"@ylecun AI tools  might  perform many tasks better than people with 
   trade-offs.

AI can understand values and ethics, if they can be demonstrated.

Should we trust AI‚Äôs judgment when it involve human values?",0,0,0
1838,2023-02-18 03:01:11+00:00,ylecun,"@ylecun I think opening the research speedup the pace of research exponentially, like if google had not disclosed their transformer paper then it took some more time for chatgpt type models. Even opening research help in making AI product cheap.",0,2,0
1839,2023-02-18 02:59:25+00:00,ylecun,"@ylecun @Kantrowitz A.I. text generators allow to work smarter ,not harder.

Chatbots can lead to new ideas and complete mundane tasks at speed.

But  at worst, it can complicate  communications if outputs go unchecked.

More products like smarter virtual assistants may require new training methods.",0,0,0
1840,2023-02-18 02:47:21+00:00,ylecun,@ylecun Shut up hater and mind your language.,0,0,0
1841,2023-02-18 02:46:21+00:00,ylecun,@ylecun Baby tiger. Won‚Äôt be cute when it grows up. Much more powerful in a danger body.,0,0,0
1842,2023-02-18 02:17:44+00:00,ylecun,@ylecun @cwolferesearch One bit ? That‚Äôs bold.,1,1,0
1843,2023-02-18 02:05:27+00:00,ylecun,@ylecun @MetaAI My app does something like this https://t.co/13vd7QAyo9,1,1,0
1844,2023-02-18 01:52:58+00:00,ylecun,@ylecun You guys at meta have the best add ai. I don‚Äôt see any papers on that ü§ó,0,0,0
1845,2023-02-18 01:20:55+00:00,ylecun,"@ylecun Microsoft provides the Azure platform which hosts Chat GPT. If Open AI had opted to migrate to Google Cloud, it is uncertain how they would have competed with Google, given their reliance on its infrastructure. ü§™",0,1,0
1846,2023-02-18 01:03:32+00:00,ylecun,@ylecun @Kantrowitz But that makes them closer to humans but further from AGI!!,0,0,0
1847,2023-02-18 01:02:32+00:00,ylecun,"@ylecun ok,do PayPal .",0,0,0
1848,2023-02-18 00:53:24+00:00,ylecun,@ylecun ADA? Algol??,0,0,0
1849,2023-02-18 00:52:20+00:00,ylecun,"@ylecun @Kantrowitz Sometimes, my physical world's superficial too.",0,0,0
1850,2023-02-18 00:40:33+00:00,ylecun,@ylecun You calling him a horse Yann? I don‚Äôt think hes gonna hire you after that insult,0,1,0
1851,2023-02-18 00:38:48+00:00,ylecun,"@ylecun @Kantrowitz Your criticism of LLMs can apply to any DL models,  including CNNs.   I can‚Äôt imagine companies spending billions on LLMs without seeing their true potential,",0,0,0
1852,2023-02-18 00:37:03+00:00,ylecun,@ylecun Maybe It isn‚Äôt meant to open source without boundaries,0,1,0
1853,2023-02-18 00:20:48+00:00,ylecun,@ylecun I miss the AI days of the early YOLO CV papers‚Ä¶..,0,1,0
1854,2023-02-18 00:19:30+00:00,ylecun,"@ylecun A few years later, Elon finally got it: 3rd paragraph in https://t.co/F9jZcL4Kxr",0,0,0
1855,2023-02-17 23:37:14+00:00,ylecun,"@ylecun &gt; @EyeOn_AI: 

""We're working on a recipe for a system that would be able to learn the properties of the world by watching videos. To predict what's going to happen next in a video (the data we need is) a couple hours of YouTube or Instagram videos. It would be enough.""",0,0,0
1856,2023-02-17 23:30:09+00:00,ylecun,@ylecun Can anyone explain what is auto regressive with examples. Also what is not autoregressive,0,0,0
1857,2023-02-17 23:29:22+00:00,ylecun,@ylecun @relnox And SEC did basically a blind eye to this declarations ü´£,0,0,0
1858,2023-02-17 23:22:09+00:00,ylecun,"@ylecun You need to disentangle your opinions from Meta. Your expert opinion might be of course interesting. But you consistently go to lengths to defend your employer and your scientific views in the same phrase. 

What can we all do with your tweets? Do you realize this, right?",0,1,0
1859,2023-02-17 23:01:35+00:00,ylecun,"@ylecun Its like a multi-dimensional funhouse mirror that reflects human thoughts and writing back at us, blurred with the thoughts of millions of others.",0,0,0
1860,2023-02-17 22:59:55+00:00,ylecun,"@ylecun üïµÔ∏è It tends to be only dangerous to propagandists, because they like to control what's being said",0,0,0
1861,2023-02-17 22:54:25+00:00,ylecun,@ylecun @Kantrowitz Bings horrific and barely useable now :),0,1,0
1862,2023-02-17 22:53:33+00:00,ylecun,@ylecun @Kantrowitz LLMs have 0 understanding. They are *language* models.,0,1,0
1863,2023-02-17 22:53:02+00:00,ylecun,"@ylecun Your approach convinced me that for basic AI research, open source does work. I tended to think it was a bad idea because of plagiarists in the startup scene.",0,0,0
1864,2023-02-17 22:43:46+00:00,ylecun,@ylecun I agree. My point was specifically towards companies that are 100% open source. It‚Äôs difficult to profit directly/solely off of a product that is open sourced. This is why companies like HuggingFace will avoid public disclosure of revenue for a long time (they have very little).,0,4,0
1865,2023-02-17 22:39:02+00:00,ylecun,"@ylecun @AlanMorte @OpenAI Not greed, no, willful ignorance of their funding structure, how it aligns power and to whom.",0,6,0
1866,2023-02-17 22:38:34+00:00,ylecun,@ylecun @Kantrowitz Not good for MSFT stock price and OpenAI IPO.,3,1,1
1867,2023-02-17 22:37:17+00:00,ylecun,@ylecun Everyone wins with democratizing AI R&amp;D. It brings healthy and quintessential reality (bias) checks &amp; good competition.,0,1,0
1868,2023-02-17 22:15:41+00:00,ylecun,"@ylecun The original hype was fueled by influencers telling people how to make 500 Dollars/Day using ChatGPT. Now that these people have most likely moved on to  a new money-making grift, we're seeing more balance.",0,0,0
1869,2023-02-17 22:15:18+00:00,ylecun,@ylecun @mgubrud @MetaAI How does the machine choose which of its answers to question?,0,0,0
1870,2023-02-17 22:15:03+00:00,ylecun,@ylecun Hence 'edge cases' will continue to exist. Auto-regressive (predicting based on historical correlation) isn't brain-like. Better science unlocks the pattern matching of the brain that 'can' be emulated by a machine https://t.co/OqPPMaMUx6,1,0,0
1871,2023-02-17 22:12:56+00:00,ylecun,@ylecun There's a lot of performative freaking out.,0,0,0
1872,2023-02-17 22:08:49+00:00,ylecun,"@ylecun In 100% decentralised energy, max autarky, power/energy to edge.. @elonmusk has still a very big chance to shine. Eventhough he as fallen behind with batteries. Let's see, if he can make e.g. 30Euro/kWh for a battery pack. That would eliminate thermal and H2 storage solutions.",0,0,0
1873,2023-02-17 21:44:18+00:00,ylecun,@ylecun You are so correct!!,0,0,0
1874,2023-02-17 21:43:31+00:00,ylecun,"@ylecun LLMs are wild beasts, they model their training corpus which comes from the wild and includes lots of darkness. RLHF doesn't scale to counter the bulk of that. But if a system is striving to model human values, human feedback (&amp; verbal correction) can serve as its guiding signal.",0,1,0
1875,2023-02-17 21:39:32+00:00,ylecun,@ylecun I think we‚Äôre seeing research becoming commercial. It‚Äôs a natural progression.,0,1,0
1876,2023-02-17 21:29:30+00:00,ylecun,"@ylecun @AndreTI Hey @ylecun when are you going to become competent enough to create BASIC machine learning algorithms that don't destroy people's lives because you are unable to write a model that correctly reads an ID? You want a link for a Udacity course 4 you to take?

https://t.co/tV7ESRkr8a",0,0,0
1877,2023-02-17 21:29:22+00:00,ylecun,@ylecun Specifically which works are you referring to,0,1,0
1878,2023-02-17 21:28:56+00:00,ylecun,@ylecun We need Elon in charge of this for any chance of a good outcome.,0,0,0
1879,2023-02-17 21:27:22+00:00,ylecun,@ylecun https://t.co/tV7ESRkr8a,0,0,0
1880,2023-02-17 21:18:37+00:00,ylecun,@ylecun @AlanMorte @OpenAI Why Bell Labs ended like that?,1,0,0
1881,2023-02-17 21:02:56+00:00,ylecun,"@ylecun ""are actually stupid""  ....mostly",0,0,0
1882,2023-02-17 20:58:57+00:00,ylecun,@ylecun Do you consider the guy that was fired from Google for ascribing sentience to them was an ‚Äúexpert‚Äù?,0,0,0
1883,2023-02-17 20:51:12+00:00,ylecun,@ylecun It‚Äôs a very good question. And as such we need more participation in AI from a wider community thus getting more people involved in research and building technologies. I‚Äôm working to build @dotproductAI which will focus on AI education and application in Africa.,0,2,0
1884,2023-02-17 20:50:15+00:00,ylecun,@ylecun They also will not want to empower everyone.,0,1,0
1885,2023-02-17 20:49:12+00:00,ylecun,@ylecun Let's ask chatgpt. Kidding!,0,1,0
1886,2023-02-17 20:26:22+00:00,ylecun,"@ylecun Luckily, FAIR is not alone. I think Hugging Face puts a tremendous effort to open source and to reproduce experiments.",0,3,0
1887,2023-02-17 20:19:49+00:00,ylecun,@ylecun I just hope you @ylecun keep your lectures open. They are great!,0,1,0
1888,2023-02-17 20:18:07+00:00,ylecun,@ylecun The progress is onward as it used to be! It is just gonna be hoarded and offered to the highest bidder!,0,1,0
1889,2023-02-17 20:12:58+00:00,ylecun,"@ylecun Society does not count on a commercial company for the development of science and technology; it is the responsibility of universities, national labs, and research institutions.",0,0,0
1890,2023-02-17 20:12:36+00:00,ylecun,@ylecun @AlanMorte @OpenAI Resistance is futile,0,0,0
1891,2023-02-17 20:10:33+00:00,ylecun,"@ylecun The prospect for FAIR continues opening is not good, given the tremendous pressure Meta is facing from ChatGPT and Microsoft.  After all, Meta is a commercial company and it needs to worry about its bottomline.",0,0,0
1892,2023-02-17 20:09:42+00:00,ylecun,@ylecun Mass subtle brainwashing.,0,1,0
1893,2023-02-17 20:07:14+00:00,ylecun,@ylecun ü§ó,0,1,0
1894,2023-02-17 19:57:25+00:00,ylecun,@ylecun Proof that accusation with numbers. Amount of publications went down? Or is that just a guess/feeling?,1,1,0
1895,2023-02-17 19:31:16+00:00,ylecun,"@ylecun Meta AI prohibits the use of its OS code for commercial purposes, unlike Google AI. Maybe not impactful for AI science: definitely impactful for AI technology. The question isn't as clear-cut as you make it look",0,1,0
1896,2023-02-17 19:30:19+00:00,ylecun,@ylecun OpenAI has never been open. The naming is a fraud ^^,0,3,0
1897,2023-02-17 19:27:56+00:00,ylecun,"@ylecun Making AI closed source will have negative impact. AI should be open source and empower people across the world.

AI and similar technologies should be open and treated as a common good, to enable humanity to do more, improve technological progress.",1,5,1
1898,2023-02-17 19:26:27+00:00,ylecun,@ylecun Thankful for those who really put efforts to develop it.  It will definitely have a unimaginable impact on daily lives. Resistance is pointless. !!!,0,1,0
1899,2023-02-17 19:21:00+00:00,ylecun,"@ylecun lol, that is a low bar. But, clearly I am dumb and the only person to have this perspective",5,0,0
1900,2023-02-17 19:20:30+00:00,ylecun,"@ylecun @wei_andrew Driving assistance is quite addictive, once you master the limitations of the system. Hard to go back to unassisted driving...then there is the situational awareness...",0,0,0
1901,2023-02-17 19:18:36+00:00,ylecun,@ylecun https://t.co/4Grl9jYJGb,0,0,0
1902,2023-02-17 19:13:47+00:00,ylecun,@ylecun @ClementDelangue Could the cost of training play a role?,0,1,0
1903,2023-02-17 19:13:34+00:00,ylecun,"@ylecun AI is more expiremental than traditional software. Therefore, more capital-intensive. Thus, unfortunately, less friendly to open source.",0,1,0
1904,2023-02-17 19:10:40+00:00,ylecun,"@ylecun For better or worse, I think that companies are starting to realize that monetization is incredibly difficult when you tell everyone exactly how your products work for free. Moving forward, I think companies will find a more nuanced balance between open/closed source.",2,19,2
1905,2023-02-17 19:02:00+00:00,ylecun,@ylecun You are right Yann. AI is becoming more and more closed ... OpenAI should be named ClosedAI$,0,1,0
1906,2023-02-17 18:57:57+00:00,ylecun,@ylecun FAIR should stop publishing papers. What good are principles when Meta loses billions in market cap from competitors. Apple is nowhere in this scene but by far benefiting the most from open source AI research. Survival &gt;&gt;&gt; Principles,0,1,0
1907,2023-02-17 18:57:41+00:00,ylecun,"@ylecun There still are companies like Huggingface, CarperAI, EleutherAI, and not forget the Stability AI's  Stable Diffusion moment. There is a need for an open source ""ChatGPT"" to stop monopoly on OpenAI",0,1,0
1908,2023-02-17 18:57:13+00:00,ylecun,"@ylecun i don't git that, and not even sure if it's true",0,0,0
1909,2023-02-17 18:56:00+00:00,ylecun,"@ylecun It's a trend in AI industry obviously. Biz-in-AI has no other ways to differentiate and survive beside HW related vendors like Nvidia. blockchain tech maybe can have some roles to play here for ownership protection, but no solution yet.",0,2,0
1910,2023-02-17 18:53:02+00:00,ylecun,"@ylecun I‚Äôd argue they could be ‚Äúscary‚Äù in 2 ways:
1) they‚Äôre useful, meaning they‚Äôre also useful for bad actors: creating plausible-sounding bullshit at scale for misinformation and bots
2) Unexpected emergent behaviour as these models scale up",0,0,0
1911,2023-02-17 18:48:38+00:00,ylecun,"@ylecun Interesting that you say this @ylecun. This article goes into more depth about why Meta's decision to open their research was the most important AI even in 2022 (even over ChatGPT). Covered different stakeholder perspectives. Would love your thoughts.   
https://t.co/gHwmThYPYE",0,5,0
1912,2023-02-17 18:42:30+00:00,ylecun,@ylecun @relnox Hilarious,0,0,0
1913,2023-02-17 18:40:12+00:00,ylecun,"@ylecun 100% agree.. I had made a comment a few days back in same context.. it‚Äôs the same as Linux being ‚Äúfree‚Äù .. but research cost money, great minds need to be paid .. there will continue to be open source but the real commercial value will be protected behind IP",0,1,0
1914,2023-02-17 18:32:54+00:00,ylecun,@ylecun Only thinking from first principles differently and the scale up will drive you to great things. Not scaling on top of a tree. You may reach a certain level of success but will never lead you to 'glory'.,0,1,0
1915,2023-02-17 18:32:30+00:00,ylecun,@ylecun Appreciate FAIR works in AI research tools and vision.,0,4,0
1916,2023-02-17 18:32:11+00:00,ylecun,"@ylecun Today, ChatGPT got the meter in my poetry completely off. Even metered the 'title.' That can hurt. What else?

Security has overshadowed research, it seems. Or security is harder.",1,1,0
1917,2023-02-17 18:28:46+00:00,ylecun,"@ylecun I would like to send an invitation to an event to you, what would be the best way to do so? ;)",0,0,0
1918,2023-02-17 18:27:21+00:00,ylecun,"@ylecun @AlanMorte @OpenAI The fact that a student researcher can easily spend their monthly stipend on GPT-3s API (which charges academic researchers the same as practitioners), hints to me that OpenAI is not centrally concerned with financial accessibility. Maybe not greed but still.",2,0,0
1919,2023-02-17 18:27:09+00:00,ylecun,"@ylecun Big tech will probably try to attract more AI talented and avoid publishing models and data. I think they will become more secretive in the content they publish. There will be better products, but a much weaker open source and open science community.",0,1,0
1920,2023-02-17 18:25:58+00:00,ylecun,"@ylecun It‚Äôs a shame that the released products are not exactly marketed using this reasonably balanced view. I remember reading a lot of ""incredible"" effect these days and heavy hype speculation.
The other 2 more negative points were not advertised with the same strength I‚Äôm afraid.",0,0,0
1921,2023-02-17 18:24:05+00:00,ylecun,@ylecun The law of unintended consequences is brutal,0,0,0
1922,2023-02-17 18:23:26+00:00,ylecun,@ylecun When we going to get some more powerful AI usecases?,0,0,0
1923,2023-02-17 18:21:43+00:00,ylecun,"@ylecun Now threatened by the impact of AI on their existing franchises, large companies will be radically less open. Google's market cap is down $150 Billion+/-. This is the markets opinion on the cost of not keeping up/not being perceived to keep up. Publishing unlikely to be the focus",0,1,0
1924,2023-02-17 18:21:32+00:00,ylecun,"@ylecun Assuming systems will continue trending in the way of pay-to-play or  fully closed, I think you're going to see AI being used predominantly for economic/commercial purposes. So, it will begin to be seen as more of a way to make money and less of a way to improve humanity.",0,1,0
1925,2023-02-17 18:19:57+00:00,ylecun,"@ylecun Being collaborative is only beneficial until there is a nascent paradigm that you have long term superior capability to scale
Some believe transformers are that paradigm so unique data and infinite comput make winners
It could be modern manifestation of cartel conduct by big tech",0,0,0
1926,2023-02-17 18:19:37+00:00,ylecun,@ylecun And Amazon is increasing :-),0,6,0
1927,2023-02-17 18:09:59+00:00,ylecun,@ylecun this is 100% accurate.,0,0,0
1928,2023-02-17 18:07:14+00:00,ylecun,@ylecun I agree. It's a mistake to use LLMs like stand-alone search engines. The correct use case is to provide your own content for NLP processing.,0,0,0
1929,2023-02-17 18:04:15+00:00,ylecun,@ylecun My gratitude to FAIR for their open-sourcing of the largest LLMs and yourself for helping a lot of young researchers do interesting work.,0,1,0
1930,2023-02-17 18:00:19+00:00,ylecun,"@ylecun Brilliant observation. Yes, that's a HUGE problem. Not to pick on any person/group, But the main beneficiary of ChatGPT &amp; generative AI is Microsoft who... paid for it.
They didn't built it, developed it, contribute to the science of it, but now have a leg up on everybody else.",0,2,0
1931,2023-02-17 18:00:11+00:00,ylecun,@ylecun This is definitely not FAIR ü§î,0,2,0
1932,2023-02-17 17:59:15+00:00,ylecun,"@ylecun Less open-source stuff is definitely good for the scientists/engineers/PhD-grads, as it means each company will need to hire its own scientists and engineers to rebuild the same stuff again and again.",5,6,0
1933,2023-02-17 17:58:38+00:00,ylecun,@ylecun You are right sir!,0,1,0
1934,2023-02-17 17:57:40+00:00,ylecun,@ylecun this is the most important AI safety question !,0,1,0
1935,2023-02-17 17:52:48+00:00,ylecun,@ylecun Worse results for everyone,0,1,0
1936,2023-02-17 17:44:22+00:00,ylecun,"@ylecun FAIR started the open AI scene, but now it feels like OpenAI is closing the door behind them.",0,2,1
1937,2023-02-17 17:38:30+00:00,ylecun,@ylecun I  created  a  deep  learning  framework  from  scratch  using  only  Python  and  NumPy.  Coded  the  entire  PyTorch  like  automatic  differentiation  engine for  backprop!  Check  it  out  at  https://t.co/86FDUi2Mwr,0,0,0
1938,2023-02-17 17:38:10+00:00,ylecun,@ylecun @benedictevans third point is the most important one.,0,0,0
1939,2023-02-17 17:37:49+00:00,ylecun,"@ylecun sure, I disagree with you and that makes me dumb; but my actual point is about who funds science and calling out that the labs at tech companies are vanity projects that give a poor return for investors.",3,1,0
1940,2023-02-17 17:33:37+00:00,ylecun,"@ylecun @relnox Well, with his 2017 NeurIps recruiting talk he assumed his mere presence would entice all the top CNN researchers there to join Tesla and make it so.",0,0,0
1941,2023-02-17 17:32:33+00:00,ylecun,"@ylecun @OpenAI Where I‚Äôve been stuck on this topic (and thank you for your comments, much appreciated), is that yes you need great scientists and leadership (and capital for that effort), but you also need the open source community to really pull off an AI / ML product that benefits humanity.‚Ä¶",1,6,3
1942,2023-02-17 17:32:00+00:00,ylecun,"@ylecun Hey @ylecun,
How important are Neil Sloane‚Äôs work in the AI domaine? Can we possibly return to advanced mathematical theorems, which are converted into algorithms?
I believe most people never reviewed or reworked the vast past works, when Punch Cards forced people to think.",1,0,0
1943,2023-02-17 17:30:51+00:00,ylecun,"@ylecun I think AI is transitioning from Research and academic to product and industry. This is a positive thing because products impact people. 

It‚Äôs also an opportunity for academics to be inspired by closed source AI and make it open.",0,3,0
1944,2023-02-17 17:30:40+00:00,ylecun,"@ylecun If you look at the way OAI just leap frogged Google before closing up, it should instruct as to what'll happen to OAI when the next open shop shoots ahead of them. It is impossible to be big/closed and nimble at the same time.",0,1,0
1945,2023-02-17 17:29:40+00:00,ylecun,"@ylecun I was using backprop as a sample problem to learn new programing languages on my first 2 years on the university. I did it in Pascal, C, C++, Ada, Java, Ruby and Python.",1,2,0
1946,2023-02-17 17:27:45+00:00,ylecun,"@ylecun Worst consequence: only the government elite and millionaires having access to an AGI, that in itself would be a dystopia",0,1,0
1947,2023-02-17 17:23:53+00:00,ylecun,"@ylecun @AlanMorte @OpenAI Not all top AI Scientists from Academia ""sold themselves"" to profitable companies like Meta.  E.g., see Bengio.",0,0,0
1948,2023-02-17 17:23:24+00:00,ylecun,"@ylecun @AlanMorte @OpenAI Yann let's not fool ourselves. What is the positive impact really other than AI collecting data and companies using it to control public behavior in selling various products. Name me one company which doesn't optimize revenue as a metric
One",2,0,0
1949,2023-02-17 17:22:39+00:00,ylecun,"@ylecun Lack of collaboration may hinder progress, but increased competition could spur innovation. Interesting times ahead!",0,2,0
1950,2023-02-17 17:20:59+00:00,ylecun,@ylecun unfortunately most tweets only sample from one of those points,0,0,0
1951,2023-02-17 17:20:20+00:00,ylecun,"@ylecun The question we need to ask is who will dominate market from an AI product perspective. There is no stopping to the progress of actual AI. Not now, never.",0,1,0
1952,2023-02-17 17:20:19+00:00,ylecun,"@ylecun Sadly, knowledge monopolies will decelerate AI progress in every field",1,2,0
1953,2023-02-17 17:18:45+00:00,ylecun,"@ylecun @AlanMorte @OpenAI This is the real challenge. I hope private companies prioritize avenues for young researchers to continue to access and develop the skills to innovate in the space.

Otherwise, half of your education would be best spent in the industry (perhaps already the case).",0,1,0
1954,2023-02-17 17:17:43+00:00,ylecun,@ylecun Very true. Progress in AI has been at such a high rate because of open source. It's not in the best interest of AI or these companies to paywall progressive technologies. Meta has always been smart to figure out the resources without stifling open source commitments.,0,4,0
1955,2023-02-17 17:15:54+00:00,ylecun,@ylecun @SohoJoeEth Amen,0,0,0
1956,2023-02-17 17:15:30+00:00,ylecun,"@ylecun At least we can see an unfiltered image of the incentive structure in industry and the motives of each organization individually.

It was and has never been about open source philosophy, but cloud assimilation of open source products could have told us that.",0,1,0
1957,2023-02-17 17:15:13+00:00,ylecun,@ylecun @SohoJoeEth When did Google AI start publishing less?  They have always been a major participant in the papers accepted and presented at the top AI conferences.,0,2,0
1958,2023-02-17 17:13:52+00:00,ylecun,@ylecun sadness,0,1,0
1959,2023-02-17 17:11:58+00:00,ylecun,"@ylecun I think the incredible parts of it can be extremely useful. 
I find value in using ChatGPT to write out ideas in a concise manner and as a tool while learning various subject matters.
But I did find it get a bit more stupid and create more bullshit as time went on.@sama",0,0,0
1960,2023-02-17 17:11:24+00:00,ylecun,@ylecun I guess the government need to make a committee that regulates A.I But How whill they ?,0,1,0
1961,2023-02-17 17:08:51+00:00,ylecun,"@ylecun I watched an interview with you recently and found it super interesting to hear your view on why LLM‚Äôs aren‚Äôt ‚Äúit‚Äù. I was wondering where something like whisper fits in with these kinds of technologies? Is it LLM based or something else? It seems to work super well, right?",1,5,0
1962,2023-02-17 17:08:16+00:00,ylecun,"@ylecun Is aligning with human values the goal? 90% of Hollywood content is guns and drugs. That‚Äôs what humans like to consume. Humans have spent a large part of their evolution fighting for survival, and base values will always be different from socially acceptable norms",0,0,0
1963,2023-02-17 17:06:27+00:00,ylecun,"@ylecun People expect too much from AI as though it is smarter than humans or magic powers. It is in its infancy. Questions and answers. Depends on accurate sources and data. We used to say, ""garbage in garbage out"". I think half of the internet is just opinion but other half is  useful.",0,0,0
1964,2023-02-17 17:04:19+00:00,ylecun,@ylecun Its great. Otherwise every company would have to research the same thing and waste manpower finding the same things. This is best for AI progress.,0,1,0
1965,2023-02-17 17:00:38+00:00,ylecun,"@ylecun I don't see it going back to closed source, considering  the vast diaspora of open research opportunities  in  universities",0,1,0
1966,2023-02-17 17:00:33+00:00,ylecun,@ylecun ..can't we do both..?,0,1,0
1967,2023-02-17 16:59:53+00:00,ylecun,@ylecun This is clearly a step back. Others like @EMostaque (StabilityAI) have a good model for open-source development.,0,7,0
1968,2023-02-17 16:57:41+00:00,ylecun,"@ylecun I see similar problem among many self driving companies, they are quite shy in open sourcing apart from datasets. But they love open source work of universities. Perception is another story, where they are quite open.",0,1,0
1969,2023-02-17 16:57:06+00:00,ylecun,"@ylecun Quite dire I believe. 

It also makes it more likely for these companies to make mistakes and make the field suffer, which earlier could be caught by a legion of researchers tinkering with their models.",0,1,0
1970,2023-02-17 16:56:23+00:00,ylecun,"@ylecun if people are frightened, that fear is real (acting) - u r in no position to effectively alleviate that fear (by eg telling them ""actually not real""), if u don't understand where from, how and why it arises, which requires competent complex analysis + understanding, why claim bs?",0,0,0
1971,2023-02-17 16:55:32+00:00,ylecun,"@ylecun @dzsham Same as always;

Untold worlds of wonder silently pass us by while we open a package so elaborate, that all hope of this gadget doing anything useful is no longer even pretended.

#DisintermediateProgress",0,1,0
1972,2023-02-17 16:54:30+00:00,ylecun,"@ylecun As much as my academic side loves open publishing, it's difficult to achieve scale without building profitable products. Great products are the manifestation of new ideas that people actually use. Honestly, the move towards IP protection is a GOOD thing as it provides incentives‚Ä¶",5,28,4
1973,2023-02-17 16:53:31+00:00,ylecun,"@ylecun Not a good thing, I think individual researchers have a moral responsibility to reverse this.",0,1,0
1974,2023-02-17 16:52:53+00:00,ylecun,"@ylecun Open algorithms, closed datasets was no utopia - even if incrementally better than an all-closed alternative",0,1,0
1975,2023-02-17 16:51:47+00:00,ylecun,"@ylecun It‚Äôs not mit nor Apache 

It‚Äôs fb licence",0,1,0
1976,2023-02-17 16:49:41+00:00,ylecun,@ylecun Companies that can afford the server farms and electrical costs will continue to make progress for their own uses. Advertising will get vastly more intrusive. Spam will become nigh impossible to detect and filter. Search will be nigh useless due to mostly returning hallucinations,0,1,0
1977,2023-02-17 16:39:55+00:00,ylecun,"@AlanMorte @OpenAI You can't sustain a significant research effort in a non-profit or a startup, which is why DeepMind sold itself to Google, OpenAI got money from Microsoft, and Anthropic got money from Google.",4,58,3
1978,2023-02-17 16:39:14+00:00,ylecun,@ylecun This will just open more space to researchers and engineers that do not work in these companies. Maybe there will be more research on models requiring less resources because there isn‚Äôt a huge computation resource under their table. Maybe this will trigger democratizarion of AI.,0,1,0
1979,2023-02-17 16:38:58+00:00,ylecun,@ylecun I like this horse very much.,0,1,0
1980,2023-02-17 16:37:03+00:00,ylecun,@ylecun as capital costs sneak up this was unfortunately bound to happen. Many non-Big-Tech-companies will find a very different ecosystem and innovation will slow down in some areas.,0,1,0
1981,2023-02-17 16:36:28+00:00,ylecun,"@AlanMorte @OpenAI You can easily do that within a corporate research lab because your research can pay for itself several times over through product impact.
This is the model used by Meta with FAIR.
It is similar to the model used by Bell Labs, IBM Research, Xerox PARC, and MSR in the old days.",2,62,3
1982,2023-02-17 16:36:00+00:00,ylecun,@ylecun Rename OpenAI to OpenBS bc it's more bs than useful,0,0,0
1983,2023-02-17 16:32:15+00:00,ylecun,"@ylecun I wish they follow the same open standards and principles too the way some orgs are doing including fair 

‚Äìopen ai is not so open in ai
‚Äìdeep mind is not that much deep in openness 
‚Äìand google only displays what their latest research/product achieved and that‚Äôs it nothing more",0,1,0
1984,2023-02-17 16:31:28+00:00,ylecun,"@ylecun Chatgpt, How Should you Protect your Machine Learning Models and IP using a Straussian Argumentation line?
Answer:
    Treat your training data like you do your traditional source code. Claim it as fair use. 
    Treat your model files like compiled executables.",1,0,0
1985,2023-02-17 16:30:30+00:00,ylecun,@ylecun One result will hopefully be less weaponization of AI R&amp;D--especially by totalitarian nations.,0,1,0
1986,2023-02-17 16:29:03+00:00,ylecun,@ylecun I hope this tweet doesn't come back to bite you if FB goes down the path of the companies you mentioned.,1,1,0
1987,2023-02-17 16:29:02+00:00,ylecun,"@ylecun why it's some sort of competition, no? U got eg complex global power dynamics (eg wars), re other complex interests + gamechange-tech-x-complex, unfolding (eg via increasing investment) 2 encompass-devour-assimilate. So it'll progress 2 unfold naturally according 2 its logos + x",0,1,0
1988,2023-02-17 16:27:05+00:00,ylecun,@ylecun Let the true clients/victims decide!,0,1,0
1989,2023-02-17 16:25:46+00:00,ylecun,@ylecun Very true.,0,1,0
1990,2023-02-17 16:25:03+00:00,ylecun,@ylecun Race condition. Then endgame. Hope you like paperclips.,0,1,0
1991,2023-02-17 16:19:47+00:00,ylecun,"@ylecun To be fair, DeepMind (and more broadly Alphabet) has released some pretty cool things.",0,1,0
1992,2023-02-17 16:18:35+00:00,ylecun,"@ylecun ""This is not safe for you to use, it's only us who know best what the world needs""

These are private companies, they can do whatever they want with the things they create, 

but just be honest about it and say ""we don't to share because our goal is not scientific advancement""",0,3,1
1993,2023-02-17 16:18:24+00:00,ylecun,@ylecun What are your thoughts on the safety reasoning for less open source? Is this a valid reason for decreasing transparency? https://t.co/mlYLIdhhLX,1,2,0
1994,2023-02-17 16:18:08+00:00,ylecun,"@ylecun It will be awful. Less transparency, less cooperation, more ""reinventing the wheel"", much slower progress...
https://t.co/pD5ih6EsEm",0,0,0
1995,2023-02-17 16:17:56+00:00,ylecun,"@ylecun The fact that @OpenAI started as open source and non-profit, which is now closed source and private for profit, should tell you all you need to know. It‚Äôs never about improving humanity. It‚Äôs about money (and inevitably greed). With that at the core, I don‚Äôt see a path where this‚Ä¶",10,64,13
1996,2023-02-17 16:17:47+00:00,ylecun,"@ylecun More investment, more money, more popularity, more tools‚Ä¶ but probably less time to build them, less security, less open source, less data for research‚Ä¶ https://t.co/cPATm79S9G @le_science4all",1,5,0
1997,2023-02-17 16:15:19+00:00,ylecun,"@ylecun I don‚Äôt enjoying thinking about where this could lead because my mind goes toward innovation only accessible by the rich and powerful, while the gaps keep growing wider.",0,2,0
1998,2023-02-17 16:15:10+00:00,ylecun,@ylecun √áa devait arriver √† un moment ou √† un autre. Mais √† cause d‚Äô¬†¬ªOpenAI¬†¬ª les portes vont se refermer plus t√¥t que pr√©vue puisqu‚Äôils mettent la pression √† la concurrence en commercialisant leurs travaux. Personne ne veut enrichir l‚Äôennemi gratuitement.,0,1,0
1999,2023-02-17 16:14:45+00:00,ylecun,@ylecun For what though? We had years of endless drivel of inconsequential AI papers. Maybe finally we will get some actual usable product or they can close these labs down and return that money to shareholders.,5,10,0
